---
title: "In-Class Exercise 4"
subtitle: "#todo"
# draft: true
date: "Sep 16, 2024"
date-modified: "last-modified"
author: Teng Kok Wai (Walter)
execute:
  echo: true # Include the source code in output
  eval: true
  freeze: auto
  message: false
  warning: false # if false, don't include warnings in the output
format:
  html:
    toc: true
number-sections: true
number-offset: 1
editor: visual
---

## Exercise Reference

[ISSS626 Geospatial Analytics and Applications - In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods](https://isss626-ay2024-25aug.netlify.app/in-class_ex/in-class_ex04/in-class_ex04)

## Overview

In this session, we will learn about Geographically-Weighted Models.

> Geographically weighted regression (GWR) is a spatial analysis technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these predictors and an outcome of interest.
>
> GWR is an outgrowth of ordinary least squares regression (OLS)
> see more: [Geographically Weighted Regression | Columbia University Mailman School of Public Health](https://www.publichealth.columbia.edu/research/population-health-methods/geographically-weighted-regression#:~:text=Courses-,Overview,and%20an%20outcome%20of%20interest.)

::: callout-note
GWModel is under active development. It supports many features such as GW discriminant analysis, GW PCA, regression models and so on.

GWM is distance-based and does not support adjacency matrices.
:::

## Learning Outcome

- Review techniques to merge geospatial and aspatial datasets using **dplyr** functions like `left_join()`, covered in Hands-on Exercise.
- Convert spatial data from **sf** to **sp** format for compatibility with the **GWmodel** package.
- Compute geographically weighted summary statistics with adaptive and fixed bandwidth using **GWmodel**.
- Visualize geographically weighted summary statistics using **tmap**.

## Import the R Packages

The following R packages will be used in this exercise:

| **Package**       | **Purpose**                                                                                          | **Use Case in Exercise**                                                                                        |
|-------------------|------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------|
| **sf**            | Handles spatial data; imports, manages, and processes vector-based geospatial data.                   | Importing and managing geospatial data, such as Hunan's county boundary shapefile.                              |
| **GWmodel**       | Provides functions for geographically weighted regression and summary statistics.                     | Computing geographically weighted summary statistics using adaptive and fixed bandwidth methods.                 |
| **tidyverse**     | A collection of R packages for data science tasks like data manipulation, visualization, and modeling. | Wrangling aspatial data and joining with spatial datasets.                                                      |
| **tmap**          | Creates static and interactive thematic maps using cartographic quality elements.                      | Visualizing geographically weighted summary statistics and creating thematic maps.                              |
| **ggstatsplot**   | Enhances plots with statistical details and facilitates data visualization.                            | Statistical graphics for analysis, comparison, and visualization of summary statistics.                         |
| **knitr**         | Enables dynamic report generation and integration of R code with documents.                           | Formatting output and generating reports for the exercise.                                                      |

To install and load these packages, use the following code:

```{r}
pacman::p_load(sf, ggstatsplot, spdep, tmap, tidyverse, knitr, GWmodel)
```


## The Data

The following datasets will be used in this exercise:

| **Data Set**                  | **Description**                                                                                       | **Format**         |
|-------------------------------|-------------------------------------------------------------------------------------------------------|--------------------|
| **Hunan County Boundary Layer** | A geospatial dataset containing Hunan's county boundaries.                                            | ESRI Shapefile     |
| **Hunan_2012.csv**             | A CSV file containing selected local development indicators for Hunan in 2012.                        | CSV                |

```{r}
hunan_sf <- st_read(dsn = "data/geospatial", 
                 layer = "Hunan")
```
::: callout-tip
For admin boundaries, we will typically encounter **polygon or multipolygon** data objects.

A polygon represents a single contiguous area, while a multipolygon consists of multiple disjoint areas grouped together (e.g., islands that belong to the same admin region).
:::

```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
glimpse(hunan2012)
```

::: callout-note
Recall that to do left join, we need a common identifier between the 2 data objects. The content must be the same eg. same format and same case. In Hands-on Exercise 1B, we  need to (PA, SZ) in the dataset to uppercase before we can join the data.
:::

```{r}
hunan_sf <- left_join(hunan_sf, hunan2012) %>%
  select(1:3, 7, 15, 16, 31, 32)
hunan_sf
```

## Mapping GDPPC

To plot a chrolopleth map of geographic distribution of GDP per Capita (GDPPC) in Hunan:

```{r}
basemap <- tm_shape(hunan_sf) +
  tm_polygons() +
  tm_text("NAME_3", size=0.5)

gdppc <- qtm(hunan_sf, "GDPPC")
tmap_arrange(basemap, gdppc, asp=1, ncol=2)
```

## Converting to SpatialPolygonDataFrame

::: callout-note

GWmodel presently is built around the older sp and not sf formats for handling spatial data in R.

:::

```{r}
hunan_sp <- hunan_sf %>%
  as_Spatial()
```

## Geographically Weighted Summary Statistics with Adaptive Bandwidths

In this section, we aim to determine the optimal adaptive bandwidth for performing Geographically Weighted Regression (GWR). Specifically, we are interested in finding the best bandwidth to use for summarizing the spatial variation in GDP per capita (GDPPC) across the Hunan region.

### Determine Adaptive Bandwidth

An adaptive bandwidth allows the number of neighbors considered in the model to vary depending on the density of data points. This is particularly useful when data points are unevenly distributed across the study area.

We will use two different criteriaâ€”cross-validation (CV) and [Akaike information criterion](https://en.wikipedia.org/wiki/Akaike_information_criterion) to determine the optimal bandwidth. 

**The bandwidth that minimizes these metrics will be selected.**

#### Cross Validation

```{r}
bw_CV<- bw.gwr(GDPPC ~ 1,
               data = hunan_sp,
               approach= "CV",
               adaptive = TRUE,
               kernel = "bisquare",
               longlat = T)  # great circle distance
```

```{r}
bw_CV
```


#### Akaike Information Criterion (AIC)

Next, we use the AIC approach to determine the optimal bandwidth. AIC is a model selection criterion that balances model fit and complexity, with a lower AIC value indicating a better model. 

We use the same GWR model setup, but the bandwidth is now optimized based on the AIC value instead of cross-validation.


```{r}
bw_AIC<- bw.gwr(GDPPC ~ 1,
               data = hunan_sp,
               approach= "AIC",
               adaptive = TRUE,
               kernel = "bisquare",
               longlat = T)
```

```{r}
bw_AIC
```

::: callout-note

**Intepretation**

The output from these 2 methods indicate the number of nearest neighbour we should choose. In this case, both methods produce the same result: 22 nearest neighbours.

Sometimes the result may differ, and either methods is acceptable for further analysis.

:::

## Geographically Weighted Summary Statistics with adaptive bandwidth

To compute Geographically Weighted Summary Statistics:

```{r}
gwstat <- gwss (data = hunan_sp,
                vars = "GDPPC",
                bw = bw_AIC,
                kernel = "bisquare",
                adaptive = TRUE,
                longlat = T)
```

::: callout-note

We use `bw_AIC` as the bandwidth parameter, which was determined previously based on AIC optimization. 

Additionally, we apply the same `bisquare` kernel for consistency with the CV and AIC computation above.

The output of the `gwss()` function is a `gwss object`, which is a **list containing localized summary statistics for GDPPC across Hunan**.

Note that the abbreviation in the output refers to:

- LM : local mean

- LSD: local standard deviation

- LVar: local variance

- LSKe: standard estimations

- LCV: local correlation variance

:::

### Preparing the output data

Let's observe the `gwstat` object before converting to a suitable format for analysis.

```{r}
class(gwstat)
gwstat
```

```{r}
gwstat$SDF
```
In particular, we are interested to extract the `SDF` data table from `gwstat`. We can convert it into a data frame and append it onto `hunan_sf`.

```{r}
gwstat_df <- as.data.frame(gwstat$SDF)
hunan_gstat <- cbind(hunan_sf, gwstat_df)
```

### Visualising geographically weighted summary statistics

```{r fig.width=16, fig.height=10}
tm_shape(hunan_gstat) +
  tm_fill("GDPPC_LM",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Distribution of geographically weighted mean",
            main.title.position = "center",
            main.title.size = 2.0,
            legend.text.size = 1.2,
            legend.height = 1.50, 
            legend.width = 1.50,
            frame = TRUE)
```
## Geographically Weighted Summary Statistics with Fixed Bandwidth

Similarly, we can use the same process to generate summary stats with fixed bandwidth.

### Determine Fixed Bandwidth

1. Cross-Validation


```{r}
bw_CV_fixed <- bw.gwr(GDPPC ~ 1, 
             data = hunan_sp,
             approach = "CV",
             adaptive = FALSE, 
             kernel = "bisquare", 
             longlat = T)
```

```{r}
bw_CV_fixed
```

2. AIC

```{r}
bw_AIC_fixed <- bw.gwr(GDPPC ~ 1, 
             data = hunan_sp,
             approach ="AIC",
             adaptive = FALSE, 
             kernel = "bisquare", 
             longlat = T)
```

```{r}
bw_AIC_fixed
```

::: callout-note

Note the results differs this time. 

We will just use `bw_AIC_fixed` for this example.

:::

```{r}
gwstat_fixed <- gwss(data = hunan_sp,
               vars = "GDPPC",
               bw = bw_AIC_fixed,
               kernel = "bisquare",
               adaptive = FALSE,
               longlat = T)
```

### Preparing the output data

```{r}
gwstat_df_fixed <- as.data.frame(gwstat_fixed$SDF)
hunan_gstat_fixed <- cbind(hunan_sf, gwstat_df_fixed)
```

### Visualising geographically weighted summary statistics

```{r fig.width=16, fig.height=10}
tm_shape(hunan_gstat_fixed) +
  tm_fill("GDPPC_LM",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Distribution of geographically weighted mean",
            main.title.position = "center",
            main.title.size = 1.8,
            legend.text.size = 1.2,
            legend.height = 1.50,
            legend.width = 1.50,
            frame = TRUE)
```

## Visualizing Correlation

**Business question: Is there any relationship between GDP per capita and Gross Industry Output?**

```{r}
ggscatterstats(
  data = hunan2012, 
  x = Agri, 
  y = GDPPC,
  xlab = "Gross Agriculture Output",
  ylab = "GDP per capita", 
  label.var = County, 
  label.expression = Agri > 10000 & GDPPC > 50000, 
  point.label.args = list(alpha = 0.7, size = 4, color = "grey50"),
  xfill = "#CC79A7", 
  yfill = "#009E73", 
  title = "Relationship between GDP PC and Gross Agriculture Output")
```

::: callout-note

Note that above shows a **conventional statistical solution** to the business question. We can also approach the same question with a geospatial approach.

:::

## Geographically Weighted Correlation with Adaptive Bandwidth

To come up with the geospatial analytics solution, we can repeat what we have learnt above.

```{r}
# determine bandwidth
bw <- bw.gwr(GDPPC ~ GIO, 
             data = hunan_sp, 
             approach = "AICc", 
             adaptive = TRUE)

```

```{r}
# compute gwCorrelation
gwstats <- gwss(hunan_sp, 
                vars = c("GDPPC", "GIO"), 
                bw = bw,
                kernel = "bisquare",
                adaptive = TRUE, 
                longlat = T)

gwstats$SDF
```

```{r}
# convert result to df
gwstat_df <- as.data.frame(gwstats$SDF) %>%
  # select(c(12,13)) %>%
  select(c("Corr_GDPPC.GIO","Spearman_rho_GDPPC.GIO")) %>%
  rename(gwCorr = Corr_GDPPC.GIO,
         gwSpearman = Spearman_rho_GDPPC.GIO)

hunan_Corr <- cbind(hunan_sf, gwstat_df)
hunan_Corr
```

### Visualizing Local Correlation

1. Local Correlation Coefficient

```{r fig.width=12, fig.height=8}
tm_shape(hunan_Corr) +
  tm_fill("gwCorr",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Local Correlation Coefficient",
            main.title.position = "center",
            main.title.size = 2.0,
            legend.text.size = 1.2,
            legend.height = 1.50, 
            legend.width = 1.50,
            frame = TRUE)
```
::: callout-note
**Interpretation**

- The strongest correlations are found in the eastern and northern parts of the province, indicated by the darker shades.
- The weaker correlations are located in the central and western areas, where the lighter colors predominate.

:::

2. Local Spearman Coefficient

Note that we will observe similar trend using Local Spearman Coefficient. See notes below.

```{r fig.width=12, fig.height=8}

tm_shape(hunan_Corr) +
  tm_fill("gwSpearman",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Local Spearman Rho",
            main.title.position = "center",
            main.title.size = 2.0,
            legend.text.size = 1.2,
            legend.height = 1.50, 
            legend.width = 1.50,
            frame = TRUE)
```

::: callout-tip
**Notes on local correlation coefficient and the local Spearman coefficient**:

1. Local Correlation Coefficient (Pearson)

- **Type**: Parametric
  - The local correlation coefficient, often represented by Pearson's correlation coefficient, assumes that the data follows a normal distribution.
- **Nature**: Continuous
  - It measures the linear relationship between two continuous variables.
- **Type of Measure**: Not Ranked
  - The Pearson correlation is sensitive to the actual values of the data points, not their ranks. It considers both the magnitude and direction of the linear relationship.

2. Local Spearman Coefficient

- **Type**: Non-Parametric
  - The local Spearman coefficient is a rank-based measure and does not assume any specific distribution for the data. It is robust to non-normality.
- **Nature**: Continuous (based on ranks)
  - Although it works with ranks, the coefficient itself can take any continuous value between -1 and 1, like Pearson's.
- **Type of Measure**: Ranked
  - The Spearman correlation is based on the ranks of the data rather than their actual values. It measures the strength and direction of a monotonic relationship between two variables.

:::
