---
title: "7A: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method"
subtitle: "In this exercise, we will learn to build hedonic pricing models for private high-rise property using Geographically Weighted Regression (GWR) methods to account for non-stationary variables."
# draft: true
date: "Sep 27, 2024"
date-modified: "last-modified"
author: Teng Kok Wai (Walter)
execute:
  echo: true
  eval: true
  freeze: true
  message: false
  warning: false
format:
  html:
    code-link: true
    toc: true
number-sections: true
number-offset: 1
editor: visual
---

## Exercise 7A Reference

[R for Geospatial Data Science and Analytics - 13Â  Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method](https://r4gdsa.netlify.app/chap13.html)

## Overview

In this exercise, we will learn to build [hedonic pricing](https://www.investopedia.com/terms/h/hedonicpricing.asp) models for private high-rise property using Geographically Weighted Regression (GWR) methods to account for non-stationary variables.

**Geographically weighted regression (GWR)** is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable).

> In this exercise, The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational.

We will be using the [**GWmodel**](https://www.jstatsoft.org/article/view/v063i17) package. It provides a collection of localised spatial statistical methods, namely: GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms. Commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis.

## Learning Outcome

-   Understand the basics of geographically weighted regression (GWR).
-   Build and evaluate hedonic pricing models using GWR.
-   Convert geospatial and aspatial data into appropriate formats for analysis.
-   Perform exploratory data analysis (EDA) using statistical graphics.
-   Visualize the model outputs and spatial patterns using various R packages.
-   Assess spatial autocorrelation and other statistical properties of model residuals.
-   Compare and interpret fixed and adaptive bandwidth GWR models.

## The Data

The following 2 datasets will be used in this study:

| **Data Set** | **Description** | **Format** |
|----------------|-----------------------------------------|----------------|
| MP14_SUBZONE_WEB_PL | URA Master Plan 2014's planning subzone boundaries represented as polygon features. | ESRI Shapefile |
| condo_resale_2015.csv | Data on condominium resale prices in 2015, including structural and locational attributes. | CSV |

## Installing and Launching the R Packages

The following R packages will be used in this exercise:

| **Package** | **Purpose** | **Use Case in Exercise** |
|-----------------|-----------------------------|--------------------------|
| **sf** | Manages, processes, and manipulates vector-based geospatial data. | Handling and converting geospatial data such as the URA Master Plan boundaries. |
| **GWmodel** | Calibrates geographically weighted models for local spatial analysis. | Building hedonic pricing models using fixed and adaptive bandwidth GWR methods. |
| **olsrr** | Performs diagnostics and builds better multiple linear regression models. | Testing for multicollinearity, normality, and linearity of the regression model. |
| **corrplot** | Provides visual tools to explore data correlation matrices. | Visualizing relationships between independent variables in the dataset. |
| **tmap** | Creates static and interactive thematic maps using cartographic quality elements. | Visualizing the geospatial distribution of condominium resale prices and other model outputs. |
| **tidyverse** | A collection of packages for data science tasks such as data manipulation, visualization, and modeling. | Importing CSV files, wrangling data, and performing data transformations and visualizations. |
| **ggpubr** | Enhances 'ggplot2' for easier 'publication-ready' plots. | Creating small multiple histograms and scatterplots for exploratory data analysis. |

To install and load these packages, use the following code:

```{r pacman}
pacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)
```

## Geospatial Data Wrangling

### Importing Geospatial Data

To import MP_SUBZONE_WEB_PL shapefile:

```{r}
mpsz = st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
```

The output above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called *mpsz* and it is a simple feature object. The geometry type is *multipolygon*. It is also important to note that **mpsz simple feature object does not have EPSG information**.

### Updating CRS Information

The code below updates the newly imported *mpsz* with the correct ESPG code (i.e. 3414)

```{r}
mpsz_svy21 <- st_transform(mpsz, 3414)
st_crs(mpsz_svy21)
```

Notice that the EPSG: is indicated as *3414* now.

### Revealing the Extent of mpsz_svy21

To reveal the extent of *mpsz_svy21*:

```{r}
st_bbox(mpsz_svy21) #view extent
```

## Aspatial Data Wrangling

### Importing Aspatial Data

The *condo_resale_2015* is in csv file format. The codes chunk below uses `read_csv()` function of **readr** package to import *condo_resale_2015* into R as a tibble data frame called *condo_resale*.

```{r}
condo_resale = read_csv("data/aspatial/Condo_resale_2015.csv")
glimpse(condo_resale)
```

To display summary statistics of *condo_resale*:

```{r}
summary(condo_resale)
```

### Converting an Aspatial Data Frame to an sf Object

In this step, we will:

-   Use the `st_as_sf()` function from the **sf** package to convert the aspatial data frame into a spatial (sf) object.
-   Apply `st_transform()` to reproject the coordinates from the WGS 84 coordinate system (CRS: 4326) to SVY21 (CRS: 3414), commonly used in Singapore.

```{r}
condo_resale.sf <- st_as_sf(condo_resale,
                            coords = c("LONGITUDE", "LATITUDE"),
                            crs = 4326) %>%
  st_transform(crs = 3414)

head(condo_resale.sf)
```

-   The resulting output is a point-based feature data frame.

## Exploratory Data Analysis

In the section, we will use statistical graphics functions of `ggplot2` package to perform EDA.

### EDA using Statistical Graphics

### 6.1.1 Plot Distribution

To plot the distribution of *SELLING_PRICE* by using histograms:

```{r selling_price_hist, fig.width=12, fig.height=8}
ggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

::: callout-note
**Observations:**

-   A right skewed distribution.
-   This means that more condominium units were transacted at relative lower prices.
-   Statistically, the skewed distribution **can be normalised by using log transformation**.
:::

```{r log_selling_price_hist, fig.width=12, fig.height=8}
condo_resale.sf <- condo_resale.sf %>%
  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))

ggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

Notice that the distribution is relatively **less skewed after the transformation.**

### Multiple Histogram Plots for Variable Distribution

In this section, we will create multiple histograms (also known as a trellis plot or small multiples) to visualize the distribution of several variables. We will use the `ggarrange()` function from the [**ggpubr**](https://cran.r-project.org/web/packages/ggpubr/index.html) package to organize these histograms into a 3-column by 4-row grid layout.

```{r, trellis_condo_resale, fig.width=12, fig.height=8}
#| code-fold: true
#| code-summary: "Show the code"

# List of variables to plot
variables <- c("AREA_SQM", "AGE", "PROX_CBD", "PROX_CHILDCARE", 
               "PROX_ELDERLYCARE", "PROX_URA_GROWTH_AREA", 
               "PROX_HAWKER_MARKET", "PROX_KINDERGARTEN", 
               "PROX_MRT", "PROX_PARK", "PROX_PRIMARY_SCH", 
               "PROX_TOP_PRIMARY_SCH")

histograms <- lapply(variables, function(var) {
  ggplot(condo_resale.sf, aes_string(x = var)) + 
    geom_histogram(bins = 20, color = "black", fill = "lightblue")
})

ggarrange(plotlist = histograms, ncol = 3, nrow = 4)
```

### Drawing a Statistical Point Map

In this section, we will visualize the geospatial distribution of condominium resale prices in Singapore.

-   The map will be prepared by using tmap package.
    -   `tmap_mode("view")` to use the interactive mode of tmap
-   Then, create an interactive point symbol map
    -   `tm_dots()` is used instead of `tm_bubbles()`
    -   `set.zoom.limits` argument of `tm_view()` sets the minimum and maximum zoom level to 11 and 14 respectively.
-   Lastly, `tmap_mode("plot")` to display plot mode

```{r}
#| code-fold: true
#| code-summary: "Show the code"

tmap_mode("view")
tmap_options(check.and.fix = TRUE)

tm_shape(mpsz_svy21)+
  tm_polygons() +
tm_shape(condo_resale.sf) +  
  tm_dots(col = "SELLING_PRICE",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))

tmap_mode("plot")
```

## Hedonic Pricing Model in R

In this section, we will build a hedonic pricing model for condominium resale units using the `lm()` function from base R.

### Simple Linear Regression

We start by modeling *SELLING_PRICE* as the dependent variable and *AREA_SQM* as the independent variable.

```{r}
condo.slr <- lm(SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)
summary(condo.slr)
```

::: callout-note
**Observations:**

-   The model equation is:\
    **SELLING_PRICE = -258121.1 + 14719 \* AREA_SQM**
-   **R-squared**: 0.4518, indicating the model explains 45% of the variation in resale prices.
-   **P-value**: The very small p-value (\< 0.0001) indicates strong evidence to reject the null hypothesis, suggesting the model is a good fit.
-   **Coefficients**: Both the intercept and slope have p-values \< 0.001, confirming that the parameters are significant predictors.
:::

To visualize the fit, we can plot the data and the regression line:

```{r linear_regression}
ggplot(data = condo_resale.sf, aes(x = AREA_SQM, y = SELLING_PRICE)) +
  geom_point() +
  geom_smooth(method = lm)
```

This scatterplot with a fitted regression line highlights some high-price outliers in the dataset.

### Multiple Linear Regression

#### Checking for Multicollinearity

Before building a multiple regression model, it is essential to ensure that the independent variables are not highly correlated, as this can lead to **multicollinearity**, which compromises the model's quality.

A correlation matrix is useful for visualizing relationships between variables. In this case, we use the [**corrplot**](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html) package to plot a correlation matrix for the independent variables.

```{r}
#| fig-width: 12
#| fig-height: 10
corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.5, method = "number", type = "upper")
```

::: callout-tip
Matrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named "AOE", "FPC", "hclust", "alphabet". In the code chunk above, AOE order is used. It orders the variables by using the *angular order of the eigenvectors* method suggested by [Michael Friendly](https://www.datavis.ca/papers/corrgram.pdf).
:::

::: callout-note
**Observations:**

-   From the matrix, we observe that **Freehold** and **LEASE_99YEAR** are highly correlated, so only **Freehold** will be included in the model.
:::

### Building the Multiple Linear Regression Model

We now build a hedonic pricing model using multiple linear regression. The model predicts *SELLING_PRICE* based on several property characteristics.

```{r}
condo.mlr <- lm(SELLING_PRICE ~ AREA_SQM + AGE + 
                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + 
                  PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + 
                  PROX_PRIMARY_SCH + PROX_TOP_PRIMARY_SCH + 
                  PROX_SHOPPING_MALL + PROX_SUPERMARKET + 
                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                data = condo_resale.sf)
summary(condo.mlr)
```

::: callout-note
**Observations:**

-   **Significant predictors**:
    -   *AREA_SQM* (positive): Larger units have higher selling prices.
    -   *AGE* (negative): Older units tend to sell for less.
    -   *PROX_CBD* (negative): Proximity to the central business district reduces selling prices.
    -   *PROX_PARK* (positive): Proximity to parks increases resale prices.
    -   *FREEHOLD* (positive): Freehold properties sell for more than leasehold properties.
-   **Non-significant predictors** (p \> 0.05):
    -   *PROX_HAWKER_MARKET*, *PROX_TOP_PRIMARY_SCH*, *PROX_SUPERMARKET* show weak or no significant relationship with *SELLING_PRICE*.
:::

### Revising the Hedonic Pricing Model

After reviewing the initial model, we will now remove non-significant variables to improve the model. The revised multiple linear regression model is calibrated as follows:

```{r}
condo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                   PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +
                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                 data = condo_resale.sf)
ols_regress(condo.mlr1)
```

### Publication-Ready Table with `gtsummary`

The **gtsummary** package provides an elegant way to create publication-ready regression tables. The following code generates a formatted regression report:

```{r}
tbl_regression(condo.mlr1, intercept = TRUE)
```

You can further enhance the report by adding model statistics using `add_glance_table()` or `add_glance_source_note()`:

```{r}
#| eval: false
tbl_regression(condo.mlr1, intercept = TRUE) %>%
  add_glance_source_note(
    label = list(sigma ~ "\U03C3"),
    include = c(r.squared, adj.r.squared, AIC, statistic, p.value, sigma))
```

#### Checking for Multicollinearity

We can check for multicollinearity using the **olsrr** packageâs `ols_vif_tol()` function:

```{r}
ols_vif_tol(condo.mlr1)
```

::: callout-note
**Observations:**

Since the VIF values are all below 10, there is no indication of multicollinearity among the independent variables.
:::

#### Test for Non-Linearity

In multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.

To test the linearity assumption, we use the `ols_plot_resid_fit()` function.

```{r resid_fit}
ols_plot_resid_fit(condo.mlr1)
```

::: callout-note
**Observations:**

Most points are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.
:::

#### Test for Normality Assumption

We can assess the normality of residuals with a histogram:

```{r, resid_hist}
ols_plot_resid_hist(condo.mlr1)
```

The residuals appear normally distributed. For a formal test, we can use `ols_test_normality()`:

```{r}
ols_test_normality(condo.mlr1)
```

::: callout-note
**Observations:**

The summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.
:::

#### Testing for Spatial Autocorrelation

Since the hedonic model involves geographically referenced data, it is important to visualize the residuals and test for spatial autocorrelation.

First, we export the residuals from the hedonic pricing model into a data frame.

```{r}
mlr.output <- as.data.frame(condo.mlr1$residuals)
```

Next, we join the residuals with the *condo_resale.sf* spatial data frame:

```{r}
condo_resale.res.sf <- cbind(condo_resale.sf, condo.mlr1$residuals) %>%
  rename(MLR_RES = condo.mlr1.residuals)
```

We convert the *condo_resale.res.sf* from an sf object to a **SpatialPointsDataFrame** for use with the **spdep** package:

```{r}
condo_resale.sp <- as_Spatial(condo_resale.res.sf)
condo_resale.sp
```

Using **tmap**, we visualize the spatial distribution of the residuals:

```{r}
tmap_mode("view")

tm_shape(mpsz_svy21) +
  tmap_options(check.and.fix = TRUE) +
  tm_polygons(alpha = 0.4) +
tm_shape(condo_resale.res.sf) +  
  tm_dots(col = "MLR_RES", alpha = 0.6, style = "quantile") +
  tm_view(set.zoom.limits = c(11, 14))

tmap_mode("plot")
```

::: callout-note
**Observations:**

The figure above reveal that there is sign of spatial autocorrelation.
:::

To formally test for spatial autocorrelation using **Moran's I Test**, we first compute a distance-based weight matrix:

```{r}
nb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)
summary(nb)
```

Convert the neighbor list into spatial weights:

```{r}
nb_lw <- nb2listw(nb, style = 'W')
summary(nb_lw)
```

Finally, perform Moran's I test on the model residuals:

```{r}
lm.morantest(condo.mlr1, nb_lw)
```

::: callout-note
**Observations:**

-   **P-value**: The p-value is extremely small (\< 0.05), leading us to reject the null hypothesis that residuals are randomly distributed.
-   **Observed Moranâs I**: The value of **0.1424418** (greater than 0) indicates that residuals show a clustered pattern, confirming the presence of spatial autocorrelation.
:::

## Building Hedonic Pricing Models using GWmodel

In this section, we will model hedonic pricing using both fixed and adaptive bandwidth schemes.

### Building Fixed Bandwidth GWR Model

#### Computing Fixed Bandwidth

We use the `bw.gwr()` function from the **GWModel** package to determine the optimal fixed bandwidth for the model.

Setting `adaptive = FALSE` ensures that we are calculating a fixed bandwidth. There are two possible approaches for determining the stopping rule: **CV cross-validation** and **AICc**. In this case, we use the cross-validation approach (`approach = "CV"`).

```{r}
bw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + 
                     PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + 
                     PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + 
                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + 
                     FAMILY_FRIENDLY + FREEHOLD, 
                   data = condo_resale.sp, 
                   approach = "CV", 
                   kernel = "gaussian", 
                   adaptive = FALSE, 
                   longlat = FALSE)
```

The recommended bandwidth is **971.34 meters**.

::: callout-note
**Quiz Answer:**\
The bandwidth is in meters because the model is using projected coordinates, SVY21, where distances are measured in meters.
:::

#### GWModel Method - Fixed Bandwidth

We can now calibrate the GWR model using a fixed bandwidth and a Gaussian kernel with the following code:

```{r}
gwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + 
                         PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + 
                         PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + 
                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + 
                         FAMILY_FRIENDLY + FREEHOLD, 
                       data = condo_resale.sp, 
                       bw = bw.fixed, 
                       kernel = 'gaussian', 
                       longlat = FALSE)
gwr.fixed
```

::: callout-note
**Observations:**

The **AICc** for this fixed bandwidth GWR model is **42263.61**, which is lower than the global multiple linear regression model (AICc = 42967.1), indicating a better fit.
:::

### Building Adaptive Bandwidth GWR Model

#### Computing the Adaptive Bandwidth

To compute the adaptive bandwidth, we set `adaptive = TRUE` in the `bw.gwr()` function:

```{r}
bw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + 
                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + 
                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                      data = condo_resale.sp, 
                      approach = "CV", 
                      kernel = "gaussian", 
                      adaptive = TRUE, 
                      longlat = FALSE)
```

::: callout-note
**Observations:**

The result suggests using **30 data points** for the adaptive bandwidth.
:::

#### Constructing the Adaptive Bandwidth GWR Model

We can now calibrate the GWR model with the adaptive bandwidth:

```{r}
gwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + 
                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + 
                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                          data = condo_resale.sp, 
                          bw = bw.adaptive, 
                          kernel = 'gaussian', 
                          adaptive = TRUE, 
                          longlat = FALSE)
gwr.adaptive
```

::: callout-note
**Observations:**

The **AICc** for the adaptive bandwidth GWR model is **41982.22**, which is even lower than the fixed bandwidth GWR model (AICc = 42263.61), indicating an improved model fit.
:::

### Visualizing GWR Output

The output from GWR includes fields for observed and predicted values, residuals, local RÂ², condition numbers, and explanatory variable coefficients:

-   **Condition Number**: Identifies areas with strong local collinearity. Values over 30 may indicate unreliable results.
-   **Local RÂ²**: Indicates how well the local model fits the observed values (ranges between 0.0 and 1.0). Mapping this can reveal where the model predicts well or poorly.
-   **Predicted Values**: The estimated y values (fitted) by GWR.
-   **Residuals**: Difference between observed and predicted values. Standardized residuals should have a mean of zero and a standard deviation of 1.
-   **Coefficient Standard Error**: Measures the reliability of coefficient estimates. Smaller standard errors relative to coefficients indicate greater confidence in estimates.

These fields are stored in the **SDF** object from the GWR output, which is a `SpatialPointsDataFrame` or `SpatialPolygonsDataFrame`.

### Converting SDF to sf Data Frame

We first convert the **SDF** into an **sf** data frame for visualization:

```{r}
condo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%
  st_transform(crs = 3414)

condo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)
condo_resale.sf.adaptive.svy21  

gwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)
condo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))
```

We can check the contents using `glimpse` and `summary`:

```{r}
glimpse(condo_resale.sf.adaptive)
```

```{r}
summary(gwr.adaptive$SDF$yhat)
```

### Visualizing Local R2

The following code creates an interactive map showing local R2 values:

```{r}
tmap_mode("view")

tm_shape(mpsz_svy21) +
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "Local_R2", border.col = "gray60", border.lwd = 1) +
  tm_view(set.zoom.limits = c(11, 14))

tmap_mode("plot")
```

### Visualizing Coefficient Estimates

We can visualize the standard errors and t-values of the `AREA_SQM` coefficient using the code below:

```{r}
tmap_mode("view")

AREA_SQM_SE <- tm_shape(mpsz_svy21) +
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "AREA_SQM_SE", border.col = "gray60", border.lwd = 1) +
  tm_view(set.zoom.limits = c(11, 14))

AREA_SQM_TV <- tm_shape(mpsz_svy21) +
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "AREA_SQM_TV", border.col = "gray60", border.lwd = 1) +
  tm_view(set.zoom.limits = c(11, 14))

tmap_arrange(AREA_SQM_SE, AREA_SQM_TV, asp = 1, ncol = 2, sync = TRUE)

tmap_mode("plot")
```

#### By URA Planning Region

```{r echo=TRUE, eval=TRUE, fig.height = 6, fig.width = 6, fig.align = "center"}
tm_shape(mpsz_svy21[mpsz_svy21$REGION_N == "CENTRAL REGION", ]) +
  tm_polygons() +
tm_shape(condo_resale.sf.adaptive) + 
  tm_bubbles(col = "Local_R2", size = 0.15, border.col = "gray60", border.lwd = 1)
```
