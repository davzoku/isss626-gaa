[
  {
    "objectID": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "title": "Walter Teng's Coursework for SMU ISSS626: Geospatial Analytics and Applications",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/index.html",
    "href": "In-class_Ex/index.html",
    "title": "In-Class Exercise",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nIn-Class Exercise 10\n\n\nIn this exercise, we will recap on the use of geocoding and learn how to work with Open Government Data.\n\n\n3 min\n\n\n\nNov 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 9\n\n\nIn this exercise, we will import geospatial data, create buffers for accessibility analysis, use spatial joins to assess facility proximity, visualize spatial data on maps, and calculate Hansen’s Accessibility metrics.\n\n\n7 min\n\n\n\nOct 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 8\n\n\nIn this exercise, we will go through a sample exercise for Take-Home Exercise 3B and In-Class Exercise 08, which supplement what we have learnt in Hands-On Exercise 8.\n\n\n23 min\n\n\n\nOct 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 7\n\n\nIn this exercise, we will explore Calibrating Hedonic Pricing Models for Private Highrise Property using the Geographically Weighted Regression (GWR) Method, focusing on spatially varying relationships in property pricing data.\n\n\n25 min\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 6\n\n\nIn this exercise, we will explore Emerging Hot Spot Analysis (EHSA), a spatio-temporal analysis method for identifying and categorizing hot and cold spot trends over time in a spatial dataset.\n\n\n12 min\n\n\n\nSep 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 5\n\n\nIn this exercise, we will perform global and local measures of spatial autocorrelation using sfdep package.\n\n\n14 min\n\n\n\nSep 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 4\n\n\n#todo\n\n\n17 min\n\n\n\nSep 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 3\n\n\nThis session reviews past Hands-on exercises and address questions from classmates on Piazza.\n\n\n5 min\n\n\n\nSep 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 2\n\n\nIn this exercise, we will learn to analyze spatial point patterns using spatstat methods, including installing necessary packages, creating spatial objects, performing kernel density estimation, and applying edge correction methods.\n\n\n11 min\n\n\n\nSep 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 1\n\n\nIn the exercise, we will learn to handle geospatial data in R, create various maps, and perform statistical analysis using sf, tmap, and ggstatsplot.\n\n\n23 min\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-Class Exercise 3",
    "section": "",
    "text": "This session reviews past Hands-on exercises and address questions from classmates on Piazza. We will use a combination of R packages and datasets introduced up to Hands-on Exercise 03. Prior knowledge of content covered up to this exercise is required."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#overview",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#overview",
    "title": "In-Class Exercise 3",
    "section": "",
    "text": "This session reviews past Hands-on exercises and address questions from classmates on Piazza. We will use a combination of R packages and datasets introduced up to Hands-on Exercise 03. Prior knowledge of content covered up to this exercise is required."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#import-the-r-packages",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#import-the-r-packages",
    "title": "In-Class Exercise 3",
    "section": "2 Import the R Packages",
    "text": "2 Import the R Packages\n\npacman::p_load(sf, spNetwork, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#tip-1-observe-data-dimension-carefully",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#tip-1-observe-data-dimension-carefully",
    "title": "In-Class Exercise 3",
    "section": "3 Tip 1: Observe data dimension carefully",
    "text": "3 Tip 1: Observe data dimension carefully\nRelevant Links: ISSS 626 | Piazza QA, Details about NKDE • spNetwork\nWhen computing NKDE, we may encounter error if the event contains 3D coordinates (XYZ). Typically, publicly accessible geospatial data from Singapore data portals are 2D. During data conversion from kml or other formats, XY coordinates may be unknowingly converted into a XYZ coordinates.\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\", \n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex03/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\nchildcare &lt;- st_read(dsn=\"data/geospatial\",\n                     layer=\"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex03/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\n\n\n\n\n\n\nNote\n\n\n\nObserve the output carefully. This dataset contains XYZ coordinates in where the z coordinate value is always 0. It is redundant.\n\n\n\n3.1 Solution: Use st_zm() to drop the Z dimension\n\nchildcare &lt;- st_zm(childcare, drop=TRUE, what = \"ZM\")\nchildcare\n\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n      Name                  geometry\n1   kml_10 POINT (36173.81 42550.33)\n2   kml_99 POINT (36479.56 42405.21)\n3  kml_100 POINT (36618.72 41989.13)\n4  kml_101 POINT (36285.37 42261.42)\n5  kml_122  POINT (35414.54 42625.1)\n6  kml_161 POINT (36545.16 42580.09)\n7  kml_172 POINT (35289.44 44083.57)\n8  kml_188 POINT (36520.56 42844.74)\n9  kml_205  POINT (36924.01 41503.6)\n10 kml_222 POINT (37141.76 42326.36)\n\n\nObserve that Z dimension is dropped for all points."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#tip-2-usage-of-st_geometry",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#tip-2-usage-of-st_geometry",
    "title": "In-Class Exercise 3",
    "section": "4 Tip 2: Usage of st_geometry()",
    "text": "4 Tip 2: Usage of st_geometry()\n\nNotice that network has 2 non-spatial columns and a geometry column\n\n\nnames(network)\n\n[1] \"LINK_ID\"  \"ST_NAME\"  \"geometry\"\n\n\n\nplot(network): Plots the entire network object, which might include non-spatial data. Each non-spatial column will create a separate plot. (This is typically not what we want to viz.)\n\n\nplot(network)\nplot(childcare,\n     add=T, # overlay: true\n     col='red',pch=19)\n\n\n\n\n\n\n\n\n\nplot(st_geometry(network)): Specifically plots only the geometric component of the network object if it is an sf object, which can be useful if you want to focus solely on spatial features. (This is usually what we want.)\n\n\nplot(st_geometry(network))\nplot(childcare,add=T,col='red',pch=19)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#tip-3-use-tmap-to-create-more-advanced-complex-maps",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#tip-3-use-tmap-to-create-more-advanced-complex-maps",
    "title": "In-Class Exercise 3",
    "section": "5 Tip 3: Use tmap to create more advanced, complex maps",
    "text": "5 Tip 3: Use tmap to create more advanced, complex maps\nIn Tip 2, we discussed map plotting using plot() from base R. It is fast for quick viz, but lacks customization as compared to libraries such as tmap\n\nUsing plotUsing tmap\n\n\n\nplot(st_geometry(network))\nplot(childcare,add=T,col='red',pch = 18)\n\n\n\n\n\n\n\n\n\n\nWe have more mapping options / control and ability to create interactive maps etc.\n\ntmap_mode('view')\ntm_shape(childcare) + \n  tm_dots(col = 'red') + \n  tm_shape(network) +\n  tm_lines()\n\n\n\n\ntmap_mode('plot')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#tip-4-preparing-lixel-objects",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#tip-4-preparing-lixel-objects",
    "title": "In-Class Exercise 3",
    "section": "6 Tip 4: Preparing Lixel Objects",
    "text": "6 Tip 4: Preparing Lixel Objects\n\nlixels &lt;- lixelize_lines(network,700,mindist=350)\n\nThe choice of 700m is based on NTU research on people’s willingness to walk. The values of lixel length and mindist varies, depending on your research area, eg. walking commuters, cars, etc."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#tip-5-difference-between-k-function-and-g-function",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#tip-5-difference-between-k-function-and-g-function",
    "title": "In-Class Exercise 3",
    "section": "7 Tip 5: Difference between K-Function and G-Function",
    "text": "7 Tip 5: Difference between K-Function and G-Function\nReference Link: Network k Functions\n\nK-Function (Disc-like): The K-function calculates the proportion of points within a distance r from a typical point. It tells us the “average number of neighbors” around each point within that radius. This measure is cumulative, meaning it looks at all points within growing circles (disks) around a point.\nG-Function (Pair Correlation Function, Ring-like): The G-function is a variation of the K-function that focuses on specific distances rather than cumulative distances. Instead of looking at all points within a growing circle, it examines points within a narrow ring at a specific distance. This allows it to analyze point concentrations at different geographic scales more precisely.\n\n\n\n7.1 When to Use K-Function vs. G-Function\n\nUse the K-Function:\n\nWhen you want to understand the overall pattern of clustering or dispersion of points across various distances.\nUseful for identifying general trends in the spatial arrangement, such as whether points tend to cluster together or spread out over a broad area.\nExample: Analyzing the general distribution of trees in a forest to see if they are randomly spaced, clustered, or regularly spaced.\n\nUse the G-Function:\n\nWhen you are interested in the point concentration at specific distances or scales.\nUseful for detecting specific scales of clustering or dispersion that might be hidden in the cumulative analysis of the K-function.\nExample: Studying the distribution of retail stores to understand if there is clustering at a specific distance (e.g., stores tend to cluster within 500 meters of each other but not at larger scales).\n\n\n\nkfun_childcare &lt;- kfunctions(network, \n                             childcare,\n                             start = 0, \n                             end = 1000, \n                             step = 50, \n                             width = 50, \n                             nsim = 50, \n                             resolution = 50,\n                             verbose = FALSE, \n                             conf_int = 0.05)\n\n\nkfun_childcare$plotk\n\n\n\n\n\n\n\n\n\nkfun_childcare$plotg"
  },
  {
    "objectID": "Take-home_Ex/index.html",
    "href": "Take-home_Ex/index.html",
    "title": "In-Class Exercise",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nTake Home Exercise 2\n\n\nIn this exercise, we will explore how COVID-19 affected Thailand’s tourism economy using spatial and spatio-temporal analysis, focusing on how the impacts varied across different provinces and examining recovery patterns.\n\n\n62 min\n\n\n\nSep 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake Home Exercise 1\n\n\nIn this exercise, we will apply spatial and spatio-temporal point pattern analysis methods to identify factors affecting road traffic accidents in the Bangkok Metropolitan Region (BMR), including visualizing spatio-temporal dynamics, conducting spatial analysis using Network Spatial Point Patterns, and analyzing spatio-temporal patterns using Temporal Network Spatial Point Patterns.\n\n\n64 min\n\n\n\nSep 5, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Exploration/CSDS/01-spatial-data-handling/index.html",
    "href": "Exploration/CSDS/01-spatial-data-handling/index.html",
    "title": "01 Spatial Data Handline",
    "section": "",
    "text": "Spatial Data Handling by Luc Anselin and Grant Morrison"
  },
  {
    "objectID": "Exploration/CSDS/01-spatial-data-handling/index.html#exercise-reference",
    "href": "Exploration/CSDS/01-spatial-data-handling/index.html#exercise-reference",
    "title": "01 Spatial Data Handline",
    "section": "",
    "text": "Spatial Data Handling by Luc Anselin and Grant Morrison"
  },
  {
    "objectID": "Exploration/CSDS/01-spatial-data-handling/index.html#introduction",
    "href": "Exploration/CSDS/01-spatial-data-handling/index.html#introduction",
    "title": "01 Spatial Data Handline",
    "section": "2 Introduction",
    "text": "2 Introduction\nIn this lab, we will use the City of Chicago open data portal to download data on abandoned vehicles. Our end goal is to create a choropleth map with abandoned vehicles per capita for Chicago community areas. Before we can create the maps, we will need to download the information, select observations, aggregate data, join different files and carry out variable transformations in order to obtain a so-called “spatially intensive” variable for mapping (i.e., not just a count of abandoned vehicles, but a per capita ratio)."
  },
  {
    "objectID": "Exploration/CSDS/01-spatial-data-handling/index.html#learning-outcome",
    "href": "Exploration/CSDS/01-spatial-data-handling/index.html#learning-outcome",
    "title": "01 Spatial Data Handline",
    "section": "3 Learning Outcome",
    "text": "3 Learning Outcome\nLearn how to carry out the following tasks:\n\nDownload data from any Socrata-driven open data portal, such as the City of Chicago open data portal\nFiltering a data frame for specific entries\nSelecting and renaming columns\nCreating a simple features spatial object\nChecking and adding/adjusting projection information\nDealing with missing data\nSpatial join\nSpatial aggregation\nParsing a pdf file\nMerging data sets\nCreating new variables\nBasic choropleth mapping"
  },
  {
    "objectID": "Exploration/CSDS/01-spatial-data-handling/index.html#r-packages-used",
    "href": "Exploration/CSDS/01-spatial-data-handling/index.html#r-packages-used",
    "title": "01 Spatial Data Handline",
    "section": "4 R Packages Used",
    "text": "4 R Packages Used\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\n\nRSocrata\nTo read data directly from a Socrata powered open data portal, such as the Chicago open data portal.\n\n\ntidyverse (includes dplyr)\nTo manipulate data frames, such as filtering data, selecting columns, and creating new variables.\n\n\nlubridate\nTo select information out of the date format when filtering the data.\n\n\nsf\nTo create and manipulate simple features spatial objects, to read in the boundary file, and perform point in polygon on the data set to fill in missing community area information.\n\n\npdftools\nTo read and parse a PDF for Chicago community area population information.\n\n\ntmap\nTo make nice-looking choropleth maps.\n\n\n\n\n4.1 R Commands Used\nBelow follows a list of the commands used in this notebook. For further details and a comprehensive list of options, please consult the R documentation. Here is the information in a markdown table format:\n\n\n\n\n\n\n\nPackage\nFunctions\n\n\n\n\nbase R\nsetwd, install.packages, library, head, dim, class, as.Date, names, !is.na, is.numeric, as.integer, is.integer, length, strsplit, unlist, for, vector, substr, gsub, as.numeric, data.frame\n\n\nRSocrata\nread.socrata\n\n\ntidyverse\nfilter, %&gt;% (pipe), select (with renaming), count, rename, mutate\n\n\nlubridate\nyear, month\n\n\nsf\nst_as_sf, plot, st_crs, read_sf, st_transform, st_join, st_geometry, st_write\n\n\npdftools\npdf_text\n\n\ntmap\ntm_shape, tm_polygons\n\n\n\nImport the required R packages mentioned above\n\npacman::p_load(tidyverse, lubridate, sf, tmap, pdftools, RSocrata)"
  },
  {
    "objectID": "Exploration/CSDS/01-spatial-data-handling/index.html#obtaining-data-from-the-chicago-open-data-portal",
    "href": "Exploration/CSDS/01-spatial-data-handling/index.html#obtaining-data-from-the-chicago-open-data-portal",
    "title": "01 Spatial Data Handline",
    "section": "5 Obtaining data from the Chicago Open Data portal",
    "text": "5 Obtaining data from the Chicago Open Data portal\nWe will use the specialized RSocrata package to download the file with 311 calls about abandoned vehicles from the City of Chicago open data portal. A list of different types of 311 nuisance calls is given by selecting the button for Service Requests. The abandoned vehicles data are contained in the entry for 311 Service Requests - Abandoned Vehicles.\nTo download the file, select the API button and copy the API Endpoint from the interface. This endpoint will be the target file URL. Instead of directly using the read.socrata function from the RSocrata package, we will first check if the file already exists in our local directory (../data). If it does not exist, we will download it from the City of Chicago open data portal and save it locally. If the file already exists, we will simply read it from the local directory, avoiding redundant downloads. ### Read using RSocrata\n\nsocrata.file &lt;- \"https://data.cityofchicago.org/resource/suj7-cg3j.csv\"\nlocal.file &lt;- \"../data/suj7-cg3j.csv\"\n\nif (!file.exists(local.file)) {\n  vehicle.data &lt;- read.socrata(socrata.file)\n  write_csv(vehicle.data, local.file)\n  print(\"Data downloaded and saved locally\")\n} else {\n  vehicle.data &lt;- read_csv(local.file)\n  print(\"Data loaded from local\")\n}\n\n[1] \"Data loaded from local\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you try other ways to obtain this file, you may obtain a different variant of this data.\nFor example, if you try to download the csv file direct via the URL path, you may only obtain 1000 rows as there is a rate limit on the API.\nIf you download the csv file directly from the web portal, the CSV is truncated and may contain different/missing columns.\n\n\n\ndim(vehicle.data)\n\n[1] 261486     26\n\n\nThe table has 261,486 observations on 26 variables.\nIn RStudio, the type of the variable in each column is listed under its name. For example, under creation_date, we see S3: POSIXct. You can also find out the same information by applying a class command to the variable vehicle.data$creation_date, as in\n\nclass(vehicle.data$creation_date)\n\n[1] \"POSIXct\" \"POSIXt\" \n\n\n\n\n\n\n\n\nTip\n\n\n\nAlternatively, to load the data with the correct class from a CSV, use tidyverse’s read_csv instead of base R’s read.csv. Without the correct data class, you may have to perform manual conversion before you can join data frame in downstream tasks.\n\n\n\n5.1 Extracting observations for the desired time period\nTo extract the observations for the selected year (2016) and month (9), we will use the year and month functions from the lubridate package. We will embed these expressions in a filter command (from tidyverse) to select the rows/observations that match the specified criterion. We will also use the pipe command %&gt;% to move the original data frame through the different filter stages and assign the end result to vehicle.sept16.\nWe again check the contents with a head command.\n\nvehicle.sept16 &lt;- vehicle.data %&gt;% filter(year(creation_date) == 2016) %&gt;%\n                  filter(month(creation_date) == 9)\nhead(vehicle.sept16)\n\n# A tibble: 6 × 26\n  creation_date       status          completion_date     service_request_number\n  &lt;dttm&gt;              &lt;chr&gt;           &lt;dttm&gt;              &lt;chr&gt;                 \n1 2016-09-01 16:00:00 Completed - Dup 2016-09-01 16:00:00 16-06219980           \n2 2016-09-01 16:00:00 Completed - Dup 2016-09-01 16:00:00 16-06220033           \n3 2016-09-01 16:00:00 Completed - Dup 2016-09-01 16:00:00 16-06220056           \n4 2016-09-01 16:00:00 Completed - Dup 2016-09-01 16:00:00 16-06220096           \n5 2016-09-01 16:00:00 Completed - Dup 2016-09-01 16:00:00 16-06221253           \n6 2016-09-01 16:00:00 Completed - Dup 2016-09-01 16:00:00 16-06225666           \n# ℹ 22 more variables: type_of_service_request &lt;chr&gt;, license_plate &lt;chr&gt;,\n#   vehicle_make_model &lt;chr&gt;, vehicle_color &lt;chr&gt;, current_activity &lt;chr&gt;,\n#   most_recent_action &lt;chr&gt;,\n#   how_many_days_has_the_vehicle_been_reported_as_parked_ &lt;dbl&gt;,\n#   street_address &lt;chr&gt;, zip_code &lt;dbl&gt;, x_coordinate &lt;dbl&gt;,\n#   y_coordinate &lt;dbl&gt;, ward &lt;dbl&gt;, police_district &lt;dbl&gt;,\n#   community_area &lt;dbl&gt;, ssa &lt;dbl&gt;, latitude &lt;dbl&gt;, longitude &lt;dbl&gt;, …\n\n\nand the dimension:\n\ndim(vehicle.sept16)\n\n[1] 2555   26\n\n\nThe filtered table now only has 2,637 observations.\n\n\n5.2 Selecting the variables for the final table\nThe current data frame contains 26 variables. Several of these are not really of interest to us, since we basically want the locations of the events. We will use the select command from tidyverse to pick out the columns that we want to keep. In addition, we will use the rename option in select to give new variable names. While this is not absolutely necessary at this stage (RSocrata has turned any weird variable names into proper R names), we may later want to save the data as a point shape file. The data associated with a shape file are store in a separate dBase file, and dBase only allows 10 characters for variable names.\nSo, in order to save ourselves some work later on, we will rename the selected variables to strings that do not exceed 10 characters.\nFirst, we check the variable names using the names command.\n\nnames(vehicle.sept16)\n\n [1] \"creation_date\"                                         \n [2] \"status\"                                                \n [3] \"completion_date\"                                       \n [4] \"service_request_number\"                                \n [5] \"type_of_service_request\"                               \n [6] \"license_plate\"                                         \n [7] \"vehicle_make_model\"                                    \n [8] \"vehicle_color\"                                         \n [9] \"current_activity\"                                      \n[10] \"most_recent_action\"                                    \n[11] \"how_many_days_has_the_vehicle_been_reported_as_parked_\"\n[12] \"street_address\"                                        \n[13] \"zip_code\"                                              \n[14] \"x_coordinate\"                                          \n[15] \"y_coordinate\"                                          \n[16] \"ward\"                                                  \n[17] \"police_district\"                                       \n[18] \"community_area\"                                        \n[19] \"ssa\"                                                   \n[20] \"latitude\"                                              \n[21] \"longitude\"                                             \n[22] \"location\"                                              \n[23] \"location_address\"                                      \n[24] \"location_city\"                                         \n[25] \"location_state\"                                        \n[26] \"location_zip\"                                          \n\n\nTo keep things simple, we will only keep community_area, latitude and longitude, and turn them into comm, lat and lon. The new data set is vehicles.final. Note that to rename a variable, the new name is listed first, on the left hand side of the equal sign, and the old name is on the right hand side. We check the result with the head command.\n\nvehicles.final &lt;- vehicle.sept16 %&gt;% select(comm = community_area, \n                          lat = latitude, lon = longitude)\nhead(vehicles.final)\n\n# A tibble: 6 × 3\n   comm   lat   lon\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    17  41.9 -87.8\n2    20  41.9 -87.7\n3    20  41.9 -87.7\n4     1  42.0 -87.7\n5    15  42.0 -87.7\n6    70  41.7 -87.7"
  },
  {
    "objectID": "Exploration/CSDS/01-spatial-data-handling/index.html#creating-a-point-layer",
    "href": "Exploration/CSDS/01-spatial-data-handling/index.html#creating-a-point-layer",
    "title": "01 Spatial Data Handline",
    "section": "6 Creating a Point Layer",
    "text": "6 Creating a Point Layer\nSo far, we have only dealt with a regular data frame, without taking advantage of any spatial features. However, the data frame contains fields with coordinates and R can turn these into an explicit spatial points layer that can be saved in a range of GIS formats. To accomplish this, we will use the (new) simple features or sf package functionality, which improves upon the older sp.\nWe will first use the lat and lon columns in the data frame to create a spatial points object. Note that lon is the x-coordinate and lat is the y-coordinate.\n\n6.1 Creating a point layer from coordinates in a table - principle\nIn sf, a simple features object is constructed by combining a geometry with the actual data (in a data frame). However, this is simplified for point objects when the data frame contains the coordinates as variables. This is the case in our example, where we have latitude and longitude. We also have x and y, but since we are not sure what projection these coordinates correspond with, they are not useful at this stage.\nThe advantage of lat-lon is that they are decimal degrees, and thus unprojected. However, we can provide the information on the datum, typically WGS84 (the standard used in most applications for decimal degrees) by passing the coordinate reference system argument (crs) set to the EPSG code 4326. After that, we can use the built-in projection transformation functionality in sf to turn the points into any projection we want.1\n\n6.1.1 Missing coordinates\nIn order to create a points layer, we need coordinates for every observation. However, as we can see from the head command above, there are (at least) two observations that do not have lat-lon information. Before we can proceed, we need to remove these from the data frame.\nWe again use a filter command, but now combine it with the !is.na expression, i.e., is not missing (na). We take a little short cut by assuming that if one of lat or lon is missing, the other one will be missing as well (although to keep it completely general, we would need to check each variable separately). We assign the result to the vehicle.coord data frame.\n\nvehicle.coord &lt;- vehicles.final %&gt;% filter(!(is.na(lat)))\ndim(vehicle.coord)\n\n[1] 2553    3\n\n\nThere are 2 records with missing coordinates, so we will omit them. The data records reduce from 2637 to 2635.\n\n\n\n6.2 Creating a spatial points object\nThe sf package turns a non-spatial object like a data frame into a simple features spatial object by means of the st_as_sf function. This function can take a large number of arguments, but for now we will only use a few:\n\nthe name of the data frame, i.e., vehicle.coord\ncoords: the variable names for x and y (given in parentheses)\ncrs: the coordinate reference system, here using the EPSG code of 4326\nagr: the so-called attibute-geometry-relationship which specifies how the attribute information (the data) relate to the geometry (the points); in our example, we will use “constant”\n\nIn our example, we create vehicle.points and check its class.\n\nvehicle.points = st_as_sf(vehicle.coord, coords = c(\"lon\", \"lat\"), crs = 4326, agr = \"constant\")\nclass(vehicle.points)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nEven though it is not that informative at this stage, we can also make a quick plot. Later, we will see how we can refine these plots using the tmap package.\n\nplot(vehicle.points)\n\n\n\n\n\n\n\n\nWe can also do a quick check of the projection information using the st_crs command.\n\nst_crs(vehicle.points)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]"
  },
  {
    "objectID": "Exploration/CSDS/01-spatial-data-handling/index.html#abandoned-vehicles-by-community-area",
    "href": "Exploration/CSDS/01-spatial-data-handling/index.html#abandoned-vehicles-by-community-area",
    "title": "01 Spatial Data Handline",
    "section": "7 Abandoned Vehicles by Community Area",
    "text": "7 Abandoned Vehicles by Community Area\nAt this point, we will go about things in a slightly different way from how they are illustrated in the GeoDa workbook example. As it turns out, some of the points have missing community area information, which is a critical element to compute the number of abandoned cars at that scale. In GeoDa, we used a visual approach to obtain the missing information. Here, we will exploit some of the GIS functionality in sf to carry out a spatial join. This boils down to identifying which points belong to each community area (a so-called point in polygon query) and assigning the corresponding community area identifier to each point.\nWe proceed in three steps. First, we create a simple features spatial polygon object with the boundaries of the community areas, which we download from the Chicago Open Data portal. Next, we carry out a spatial join between our points object and the polygon object to assign a community area code to each point. Finally, we compute the point count by community area.\n\nCommunity Area boundary file\nWe resort to the City of Chicago open data portal for the boundary file of the community areas. From the opening screen, select the button for Facilities & Geo Boundaries. This yields a list of different boundary files for a range of geographic areal units. The one for the community areas is Boundaries - Community Areas (current). This brings up an overview map of the geography of the community areas of Chicago. Of course, we could simply select one of the export buttons to download the files, but we want to do this programmatically. As it turns out, sf can read a geojson formatted file directly from the web, and we will exploit that functionality.\nFirst, we need the name for the file. We can check the Socrata API file name, but that contains a json file, and we want a specific geojson file. As it turns out, the latter is simply the same file name, but with the geojson file extension. We set our variable comm.file to this URL and then use sf_read to load the boundary information into chicago.comm. As before, we can do a quick check of the class using the class command.\n\ncomm.file &lt;- \"https://data.cityofchicago.org/resource/igwz-8jzy.geojson\"\ncomm.local &lt;- \"../data/igwz-8jzy.geojson\"\n\nif (!file.exists(comm.local)) {\n  download.file(comm.file, comm.local, method = \"curl\")\n  print(\"File downloaded and saved locally\")\n} else {\n  print(\"File exists locally. Reading locally\")\n}\n\n[1] \"File exists locally. Reading locally\"\n\nchicago.comm &lt;- read_sf(comm.local)\nclass(chicago.comm)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\nclass(chicago.comm$area_num_1)\n\n[1] \"character\"\n\n\nIn addition, we check the projection information using st_crs.\n\nst_crs(chicago.comm)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nAgain, the layer is unprojected in decimal degrees. Also, a quick plot. Note that, by default, sf draws a choropleth map for each variable included in the data frame. Since we won’t be using sf for mapping, we ignore that aspect for now.\n\nplot(chicago.comm)\n\n\n\n\n\n\n\n\nWe also use head to check on the types of the variables.\n\nhead(chicago.comm)\n\nSimple feature collection with 6 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -87.7069 ymin: 41.79448 xmax: -87.58001 ymax: 41.99076\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 10\n  community  area  shape_area perimeter area_num_1 area_numbe comarea_id comarea\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  \n1 DOUGLAS    0     46004621.… 0         35         35         0          0      \n2 OAKLAND    0     16913961.… 0         36         36         0          0      \n3 FULLER PA… 0     19916704.… 0         37         37         0          0      \n4 GRAND BOU… 0     48492503.… 0         38         38         0          0      \n5 KENWOOD    0     29071741.… 0         39         39         0          0      \n6 LINCOLN S… 0     71352328.… 0         4          4          0          0      \n# ℹ 2 more variables: shape_len &lt;chr&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n\n\n7.0.1 Changing projections\nBefore moving on to the spatial join operation, we will convert both the community area boundaries and the vehicle points to the same projection, using the st_transform command. We assign the UTM (Universal Tranverse Mercator) zone 16N, which the the proper one for Chicago, with an EPSG code of 32616. After the projection transformation, we check the result using st_crs.\n\nchicago.comm &lt;- st_transform(chicago.comm,32616)\nst_crs(chicago.comm)\n\nCoordinate Reference System:\n  User input: EPSG:32616 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 16N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 16N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-87,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Between 90°W and 84°W, northern hemisphere between equator and 84°N, onshore and offshore. Belize. Canada - Manitoba; Nunavut; Ontario. Costa Rica. Cuba. Ecuador - Galapagos. El Salvador. Guatemala. Honduras. Mexico. Nicaragua. United States (USA).\"],\n        BBOX[0,-90,84,-84]],\n    ID[\"EPSG\",32616]]\n\n\n\nvehicle.points &lt;- st_transform(vehicle.points,32616)\nst_crs(vehicle.points)\n\nCoordinate Reference System:\n  User input: EPSG:32616 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 16N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 16N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-87,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Between 90°W and 84°W, northern hemisphere between equator and 84°N, onshore and offshore. Belize. Canada - Manitoba; Nunavut; Ontario. Costa Rica. Cuba. Ecuador - Galapagos. El Salvador. Guatemala. Honduras. Mexico. Nicaragua. United States (USA).\"],\n        BBOX[0,-90,84,-84]],\n    ID[\"EPSG\",32616]]\n\n\n\n\n\n7.1 Spatial join\nIn essence, the spatial join operation finds the polygon to which each point belongs. Several points belong to the same polygon, so this is a many-to-one join. Instead of joining all the features of the polygon layer, we specify just area_num_1, which is the community area indicator. The command is st_join to which we pass the point layer as the first sf object, and the polygon layer as the second sf object (with only one column designated). We assign the result to the new spatial object comm.pts. We check the contents of the new object using a head command.\n\ncomm.pts &lt;- st_join(vehicle.points,chicago.comm[\"area_num_1\"])\nhead(comm.pts)\n\nSimple feature collection with 6 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 432913.8 ymin: 4621705 xmax: 443548.5 ymax: 4651818\nProjected CRS: WGS 84 / UTM zone 16N\n# A tibble: 6 × 3\n   comm           geometry area_num_1\n  &lt;dbl&gt;        &lt;POINT [m]&gt; &lt;chr&gt;     \n1    17 (432913.8 4642827) 17        \n2    20 (438997.5 4641020) 20        \n3    20 (438997.5 4641020) 20        \n4     1 (443548.5 4651818) 1         \n5    15 (438145.2 4645227) 15        \n6    70 (440657.5 4621705) 70        \n\n\nAs we can see, the community area in comm matches the entry in area_num_1. However, there is one more issue to deal with. Upon closer examination, we find that the area_num_1 variable is not numeric using the is.numeric check.\n\nis.numeric(comm.pts$area_num_1)\n\n[1] FALSE\n\n\nSo, we proceed to turn this variable into a numeric format using as.integer and then do a quick check by means of is.integer.\n\ncomm.pts$area_num_1 &lt;- as.integer(comm.pts$area_num_1)\nis.integer(comm.pts$area_num_1)\n\n[1] TRUE\n\n\nThe same problem occurs in the chicago.comm data set, which can cause trouble later on when we will join it with other data. Therefore, we turn it into an integer as well.\n\nchicago.comm$area_num_1 &lt;- as.integer(chicago.comm$area_num_1)\n\n\n\n7.2 Counts by community area\nWe now need to count the number of points in each polygon. We proceed in two steps. First, we illustrate how we can move back from the simple features spatial points object to a simple data frame by stripping the geometry column. This is accomplished by setting st_geometry to NULL. We check the class of the new object to make sure it is no longer a simple feature.\n\nst_geometry(comm.pts) &lt;- NULL\nclass(comm.pts)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nWe next take advantage of the tidyverse count function to create a new data frame with the identifier of the community area and the number of points contained in each community area.\n\nveh.cnts &lt;- comm.pts %&gt;% count(area_num_1)\nhead(veh.cnts)\n\n# A tibble: 6 × 2\n  area_num_1     n\n       &lt;int&gt; &lt;int&gt;\n1          1    63\n2          2    91\n3          3    22\n4          4    31\n5          5    18\n6          6    20\n\n\nThe new data frame has two fields: the original identifier area_num_1 and the count as n. We can change the variable names for the count to something more meaningful by means of the tidyverse rename command and turn it from n to AGG.COUNT (to use the same variable as in the GeoDa workbook). Similarly, we also shorten area_num_1 to comm. Again, the new name is on the LHS of the equal sign and the old name on the RHS.\n\nveh.cnts &lt;- veh.cnts %&gt;% rename(comm = area_num_1, AGG.COUNT = n)\nhead(veh.cnts)\n\n# A tibble: 6 × 2\n   comm AGG.COUNT\n  &lt;int&gt;     &lt;int&gt;\n1     1        63\n2     2        91\n3     3        22\n4     4        31\n5     5        18\n6     6        20\n\n\n\n\n7.3 Mapping the vehicle counts\nAt this point, we have a polygon layer with the community area boundaries and some identifiers (chicago.comm) and a data frame with the community identifier and the aggregate vehicle count (veh.cnts). In order to map the vehicle counts by community area, we need to join the two tables. We use the left_join command and use area_num_1 as the key for the first table (the community area boundaries), and comm as the key for the second table (the vehicle counts). Since we assured that both variables are now integers, the join will work (if one were a character and the other integer, there would be an error message). Note how in the command below, the two keys can have different variable names (but they must have the same values), which is made explicit in the by statement.\n\nchicago.comm &lt;- left_join(chicago.comm,veh.cnts, by = c(\"area_num_1\" = \"comm\"))\n\nWe can double check that the vehicle counts were added using the head command.\n\nhead(chicago.comm)\n\nSimple feature collection with 6 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 441440.4 ymin: 4627153 xmax: 451817.1 ymax: 4648971\nProjected CRS: WGS 84 / UTM zone 16N\n# A tibble: 6 × 11\n  community  area  shape_area perimeter area_num_1 area_numbe comarea_id comarea\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;          &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  \n1 DOUGLAS    0     46004621.… 0                 35 35         0          0      \n2 OAKLAND    0     16913961.… 0                 36 36         0          0      \n3 FULLER PA… 0     19916704.… 0                 37 37         0          0      \n4 GRAND BOU… 0     48492503.… 0                 38 38         0          0      \n5 KENWOOD    0     29071741.… 0                 39 39         0          0      \n6 LINCOLN S… 0     71352328.… 0                  4 4          0          0      \n# ℹ 3 more variables: shape_len &lt;chr&gt;, geometry &lt;MULTIPOLYGON [m]&gt;,\n#   AGG.COUNT &lt;int&gt;\n\n\n\n7.3.1 Basic choropleth map\nAs we saw earlier, we can construct rudimentary maps using the plot command in sf, but for further control, we will use the tmap package. This uses a logic similar to Wilkinson’s grammar of graphics, which is also the basis for the structure of the plot commands in the ggplot package.\nWe leave a detailed treatment of tmap for a future lab and just use the basic defaults in this example. The commands are layered and always start by specifying a layer using the tm_shape command. In our example, this is chicago.comm. Next (after the plus sign) follow one of more drawing commands that cover a wide range of geographic shapes. Here, we will just use tm_polygons and specify AGG.COUNT as the variable to determine the classification. We leave everything to the default and obtain a map that illustrates the spatial distribution of the abandoned vehicle counts by community area.\n\ntm_shape(chicago.comm) +\n  tm_polygons(\"AGG.COUNT\")"
  },
  {
    "objectID": "Exploration/CSDS/01-spatial-data-handling/index.html#community-area-population-data",
    "href": "Exploration/CSDS/01-spatial-data-handling/index.html#community-area-population-data",
    "title": "01 Spatial Data Handline",
    "section": "8 Community Area Population Data",
    "text": "8 Community Area Population Data\nThe Chicago Community Area 2010 population is contained in a pdf file, available from the City of Chicago web site.\nThis link is to a pdf file that contains a table with the neighborhood ID, the neighborhood name, the populations for 2010 and 2000, the difference between the two years and the percentage difference. The full path to the pdf file is https://www.cityofchicago.org/content/dam/city/depts/zlup/Zoning_Main_Page/Publications/Census_2010_Community_Area_Profiles/Census_2010_and_2000_CA_Populations.pdf\n\n8.1 Extracting a pdf file\nA pdf file is difficult to handle as a source of data, since it doesn’t contain tags like an html file. We will use the pdftools package that allows us to turn the contents of a pdf file into a list of long character strings.\nThe resulting data structure is somewhat complex and not necessarily easy to parse. However, in our case, the table has such a simple structure that we can extract the population values by doing some sleuthing on which columns contain those values. This will illustrate the power of the various parsing and text extraction functions available in R.\nWe use the pdf_text function from pdftools to turn the pdf file into a list of character strings, one for each page. We specify the URL of the file as the input source.\n\npdf.file &lt;- \"https://www.cityofchicago.org/content/dam/city/depts/zlup/Zoning_Main_Page/Publications/Census_2010_Community_Area_Profiles/Census_2010_and_2000_CA_Populations.pdf\"\nlocal.file &lt;- \"../data/Census_2010_and_2000_CA_Populations.pdf\"\n\nif (!file.exists(local.file)) {\n  download.file(pdf.file, local.file, method = \"curl\")\n  print(\"PDF file downloaded and saved locally\")\n} else {\n  print(\"PDF file exists locally. Reading from local\")\n}\n\n[1] \"PDF file exists locally. Reading from local\"\n\npop.dat &lt;- pdf_text(local.file)\nclass(pop.dat)\n\n[1] \"character\"\n\n\nWe check the length of the data object using the length command and find that indeed it has only two elements (one for each page).\n\nlength(pop.dat)\n\n[1] 2\n\n\n\n\nParsing the pdf file\nThe pop.dat object has two entries, one for each page. Each entry is a single string. So, when you check the length of each item, it may be surprising that its length is only 1. That is because the underlying structure is unknown, it is simply a collection of characters contained in the string. For example, the first element, pop.dat[[1]]:\n\nlength(pop.dat[[1]])\n\n[1] 1\n\n\nWe will parse this file by first turning each element into a separate list and then extracting the parts we are interested in.\nFirst, to illustrate in detail what is going on, we will go through each step one by one, but then, in order to reach some level of efficiency, we turn it into a loop over the two elements, for (i in 1:2).\nWe start by initializing a vector (nnlist) with an empty character, and confirm that it is indeed initialized.\n\nnnlist &lt;- \"\"\nnnlist\n\n[1] \"\"\n\n\nNext, we create a list of strings, one for each line in the table, by using the strsplit operation. This splits the long string into a list of one string for each line, by using the return character \\n as the separator (the value for the split argument).\nThe resulting list, ppage, contains a list of 44 elements, matching the contents of the first page of the pdf file.\n\nppage &lt;- strsplit(pop.dat[[1]],split=\"\\n\")\nppage[[1]]\n\n [1] \"                              CITY OF CHICAGO\"                                \n [2] \"                            CENSUS 2010 AND 2000\"                             \n [3] \"\"                                                                             \n [4] \"                                                Population\"                   \n [5] \"Num        Community Area       2010        2,000     Difference   Percentage\"\n [6] \" 1    Rogers Park                54,991     63,484      -8,493       -13.4%\"  \n [7] \" 2    West Ridge                 71,942     73,199      -1,257        -1.7%\"  \n [8] \" 3    Uptown                     56,362     63,551      -7,189       -11.3%\"  \n [9] \" 4    Lincoln Square             39,493     44,574      -5,081       -11.4%\"  \n[10] \" 5    North Center               31,867     31,895        -28         -0.1%\"  \n[11] \" 6    Lake View                  94,368     94,817       -449         -0.5%\"  \n[12] \" 7    Lincoln Park               64,116     64,320       -204         -0.3%\"  \n[13] \" 8    Near North Side            80,484     72,811      7,673         10.5%\"  \n[14] \" 9    Edison Park                11,187     11,259        -72         -0.6%\"  \n[15] \" 10   Norwood Park               37,023     37,669       -646         -1.7%\"  \n[16] \" 11   Jefferson Park             25,448     25,859       -411         -1.6%\"  \n[17] \" 12   Forest Glen                18,508     18,165        343         1.9%\"   \n[18] \" 13   North Park                 17,931     18,514       -583         -3.1%\"  \n[19] \" 14   Albany Park                51,542     57,655      -6,113       -10.6%\"  \n[20] \" 15   Portage Park               64,124     65,340      -1,216        -1.9%\"  \n[21] \" 16   Irving Park                53,359     58,643      -5,284        -9.0%\"  \n[22] \" 17   Dunning                    41,932     42,164       -232         -0.6%\"  \n[23] \" 18   Montclare                  13,426     12,646        780         6.2%\"   \n[24] \" 19   Belmont Cragin             78,743     78,144        599         0.8%\"   \n[25] \" 20   Hermosa                    25,010     26,908      -1,898        -7.1%\"  \n[26] \" 21   Avondale                   39,262     43,083      -3,821        -8.9%\"  \n[27] \" 22   Logan Square               73,595     82,715      -9,120       -11.0%\"  \n[28] \" 23   Humboldt Park              56,323     65,836      -9,513       -14.4%\"  \n[29] \" 24   West Town                  81,432     87,435      -6,003        -6.9%\"  \n[30] \" 25   Austin                     98,514    117,527     -19,013       -16.2%\"  \n[31] \" 26   West Garfield Park         18,001     23,019      -5,018       -21.8%\"  \n[32] \" 27   East Garfield Park         20,567     20,881       -314         -1.5%\"  \n[33] \" 28   Near West Side             54,881     46,419      8,462         18.2%\"  \n[34] \" 29   North Lawndale             35,912     41,768      -5,856       -14.0%\"  \n[35] \" 30   South Lawndale             79,288     91,071     -11,783       -12.9%\"  \n[36] \" 31   Lower West Side            35,769     44,031      -8,262       -18.8%\"  \n[37] \" 32   Loop                       29,283     16,388      12,895        78.7%\"  \n[38] \" 33   Near South Side            21,390     9,509       11,881       124.9%\"  \n[39] \" 34   Armour Square              13,391     12,032      1,359         11.3%\"  \n[40] \" 35   Douglas                    18,238     26,470      -8,232       -31.1%\"  \n[41] \" 36   Oakland                     5,918     6,110        -192         -3.1%\"  \n[42] \" 37   Fuller Park                 2,876     3,420        -544        -15.9%\"  \n[43] \" 38   Grand Boulevard            21,929     28,006      -6,077       -21.7%\"  \n[44] \" 39   Kenwood                    17,841     18,363       -522         -2.8%\"  \n[45] \" 40   Washington Park            11,717     14,146      -2,429       -17.2%\"  \n\n\nEach element is one long string, corresponding to a table row. We remove the first four lines (using the - operation on the list elements 1 through 4). These first rows appear on each page, so we are safe to repeat this procedure for the second page (string) as well.\n\nnni &lt;- ppage[[1]]\nnni &lt;- nni[-(1:4)]\nnni\n\n [1] \"Num        Community Area       2010        2,000     Difference   Percentage\"\n [2] \" 1    Rogers Park                54,991     63,484      -8,493       -13.4%\"  \n [3] \" 2    West Ridge                 71,942     73,199      -1,257        -1.7%\"  \n [4] \" 3    Uptown                     56,362     63,551      -7,189       -11.3%\"  \n [5] \" 4    Lincoln Square             39,493     44,574      -5,081       -11.4%\"  \n [6] \" 5    North Center               31,867     31,895        -28         -0.1%\"  \n [7] \" 6    Lake View                  94,368     94,817       -449         -0.5%\"  \n [8] \" 7    Lincoln Park               64,116     64,320       -204         -0.3%\"  \n [9] \" 8    Near North Side            80,484     72,811      7,673         10.5%\"  \n[10] \" 9    Edison Park                11,187     11,259        -72         -0.6%\"  \n[11] \" 10   Norwood Park               37,023     37,669       -646         -1.7%\"  \n[12] \" 11   Jefferson Park             25,448     25,859       -411         -1.6%\"  \n[13] \" 12   Forest Glen                18,508     18,165        343         1.9%\"   \n[14] \" 13   North Park                 17,931     18,514       -583         -3.1%\"  \n[15] \" 14   Albany Park                51,542     57,655      -6,113       -10.6%\"  \n[16] \" 15   Portage Park               64,124     65,340      -1,216        -1.9%\"  \n[17] \" 16   Irving Park                53,359     58,643      -5,284        -9.0%\"  \n[18] \" 17   Dunning                    41,932     42,164       -232         -0.6%\"  \n[19] \" 18   Montclare                  13,426     12,646        780         6.2%\"   \n[20] \" 19   Belmont Cragin             78,743     78,144        599         0.8%\"   \n[21] \" 20   Hermosa                    25,010     26,908      -1,898        -7.1%\"  \n[22] \" 21   Avondale                   39,262     43,083      -3,821        -8.9%\"  \n[23] \" 22   Logan Square               73,595     82,715      -9,120       -11.0%\"  \n[24] \" 23   Humboldt Park              56,323     65,836      -9,513       -14.4%\"  \n[25] \" 24   West Town                  81,432     87,435      -6,003        -6.9%\"  \n[26] \" 25   Austin                     98,514    117,527     -19,013       -16.2%\"  \n[27] \" 26   West Garfield Park         18,001     23,019      -5,018       -21.8%\"  \n[28] \" 27   East Garfield Park         20,567     20,881       -314         -1.5%\"  \n[29] \" 28   Near West Side             54,881     46,419      8,462         18.2%\"  \n[30] \" 29   North Lawndale             35,912     41,768      -5,856       -14.0%\"  \n[31] \" 30   South Lawndale             79,288     91,071     -11,783       -12.9%\"  \n[32] \" 31   Lower West Side            35,769     44,031      -8,262       -18.8%\"  \n[33] \" 32   Loop                       29,283     16,388      12,895        78.7%\"  \n[34] \" 33   Near South Side            21,390     9,509       11,881       124.9%\"  \n[35] \" 34   Armour Square              13,391     12,032      1,359         11.3%\"  \n[36] \" 35   Douglas                    18,238     26,470      -8,232       -31.1%\"  \n[37] \" 36   Oakland                     5,918     6,110        -192         -3.1%\"  \n[38] \" 37   Fuller Park                 2,876     3,420        -544        -15.9%\"  \n[39] \" 38   Grand Boulevard            21,929     28,006      -6,077       -21.7%\"  \n[40] \" 39   Kenwood                    17,841     18,363       -522         -2.8%\"  \n[41] \" 40   Washington Park            11,717     14,146      -2,429       -17.2%\"  \n\n\nTo streamline the resulting data structure for further operations, we turn it into a simple vector by means of unlist. This then allows us to concatenate the result to the current nnlist vector (initially, this contains just a single element with an empty character, after the first step it contains the empty character and the first page).\n\nnnu &lt;- unlist(nni)\nnnlist &lt;- c(nnlist,nnu)\nnnlist\n\n [1] \"\"                                                                             \n [2] \"Num        Community Area       2010        2,000     Difference   Percentage\"\n [3] \" 1    Rogers Park                54,991     63,484      -8,493       -13.4%\"  \n [4] \" 2    West Ridge                 71,942     73,199      -1,257        -1.7%\"  \n [5] \" 3    Uptown                     56,362     63,551      -7,189       -11.3%\"  \n [6] \" 4    Lincoln Square             39,493     44,574      -5,081       -11.4%\"  \n [7] \" 5    North Center               31,867     31,895        -28         -0.1%\"  \n [8] \" 6    Lake View                  94,368     94,817       -449         -0.5%\"  \n [9] \" 7    Lincoln Park               64,116     64,320       -204         -0.3%\"  \n[10] \" 8    Near North Side            80,484     72,811      7,673         10.5%\"  \n[11] \" 9    Edison Park                11,187     11,259        -72         -0.6%\"  \n[12] \" 10   Norwood Park               37,023     37,669       -646         -1.7%\"  \n[13] \" 11   Jefferson Park             25,448     25,859       -411         -1.6%\"  \n[14] \" 12   Forest Glen                18,508     18,165        343         1.9%\"   \n[15] \" 13   North Park                 17,931     18,514       -583         -3.1%\"  \n[16] \" 14   Albany Park                51,542     57,655      -6,113       -10.6%\"  \n[17] \" 15   Portage Park               64,124     65,340      -1,216        -1.9%\"  \n[18] \" 16   Irving Park                53,359     58,643      -5,284        -9.0%\"  \n[19] \" 17   Dunning                    41,932     42,164       -232         -0.6%\"  \n[20] \" 18   Montclare                  13,426     12,646        780         6.2%\"   \n[21] \" 19   Belmont Cragin             78,743     78,144        599         0.8%\"   \n[22] \" 20   Hermosa                    25,010     26,908      -1,898        -7.1%\"  \n[23] \" 21   Avondale                   39,262     43,083      -3,821        -8.9%\"  \n[24] \" 22   Logan Square               73,595     82,715      -9,120       -11.0%\"  \n[25] \" 23   Humboldt Park              56,323     65,836      -9,513       -14.4%\"  \n[26] \" 24   West Town                  81,432     87,435      -6,003        -6.9%\"  \n[27] \" 25   Austin                     98,514    117,527     -19,013       -16.2%\"  \n[28] \" 26   West Garfield Park         18,001     23,019      -5,018       -21.8%\"  \n[29] \" 27   East Garfield Park         20,567     20,881       -314         -1.5%\"  \n[30] \" 28   Near West Side             54,881     46,419      8,462         18.2%\"  \n[31] \" 29   North Lawndale             35,912     41,768      -5,856       -14.0%\"  \n[32] \" 30   South Lawndale             79,288     91,071     -11,783       -12.9%\"  \n[33] \" 31   Lower West Side            35,769     44,031      -8,262       -18.8%\"  \n[34] \" 32   Loop                       29,283     16,388      12,895        78.7%\"  \n[35] \" 33   Near South Side            21,390     9,509       11,881       124.9%\"  \n[36] \" 34   Armour Square              13,391     12,032      1,359         11.3%\"  \n[37] \" 35   Douglas                    18,238     26,470      -8,232       -31.1%\"  \n[38] \" 36   Oakland                     5,918     6,110        -192         -3.1%\"  \n[39] \" 37   Fuller Park                 2,876     3,420        -544        -15.9%\"  \n[40] \" 38   Grand Boulevard            21,929     28,006      -6,077       -21.7%\"  \n[41] \" 39   Kenwood                    17,841     18,363       -522         -2.8%\"  \n[42] \" 40   Washington Park            11,717     14,146      -2,429       -17.2%\"  \n\n\nWe now repeat this operation for pop.dat[[2]]. More efficiently, we implement it as a loop, replacing i in turn by 1 and 2. This yields:\n\nnnlist &lt;- \"\"\nfor (i in 1:2) {\n  ppage &lt;- strsplit(pop.dat[[i]],split=\"\\n\")\n  nni &lt;- ppage[[1]]\n  nni &lt;- nni[-(1:4)]\n  nnu &lt;- unlist(nni)\n  nnlist &lt;- c(nnlist,nnu)\n}\n\nAt the end of the loop, we check the contents of the vector nnlist.\n\nnnlist\n\n [1] \"\"                                                                                 \n [2] \"Num        Community Area       2010        2,000     Difference   Percentage\"    \n [3] \" 1    Rogers Park                54,991     63,484      -8,493       -13.4%\"      \n [4] \" 2    West Ridge                 71,942     73,199      -1,257        -1.7%\"      \n [5] \" 3    Uptown                     56,362     63,551      -7,189       -11.3%\"      \n [6] \" 4    Lincoln Square             39,493     44,574      -5,081       -11.4%\"      \n [7] \" 5    North Center               31,867     31,895        -28         -0.1%\"      \n [8] \" 6    Lake View                  94,368     94,817       -449         -0.5%\"      \n [9] \" 7    Lincoln Park               64,116     64,320       -204         -0.3%\"      \n[10] \" 8    Near North Side            80,484     72,811      7,673         10.5%\"      \n[11] \" 9    Edison Park                11,187     11,259        -72         -0.6%\"      \n[12] \" 10   Norwood Park               37,023     37,669       -646         -1.7%\"      \n[13] \" 11   Jefferson Park             25,448     25,859       -411         -1.6%\"      \n[14] \" 12   Forest Glen                18,508     18,165        343         1.9%\"       \n[15] \" 13   North Park                 17,931     18,514       -583         -3.1%\"      \n[16] \" 14   Albany Park                51,542     57,655      -6,113       -10.6%\"      \n[17] \" 15   Portage Park               64,124     65,340      -1,216        -1.9%\"      \n[18] \" 16   Irving Park                53,359     58,643      -5,284        -9.0%\"      \n[19] \" 17   Dunning                    41,932     42,164       -232         -0.6%\"      \n[20] \" 18   Montclare                  13,426     12,646        780         6.2%\"       \n[21] \" 19   Belmont Cragin             78,743     78,144        599         0.8%\"       \n[22] \" 20   Hermosa                    25,010     26,908      -1,898        -7.1%\"      \n[23] \" 21   Avondale                   39,262     43,083      -3,821        -8.9%\"      \n[24] \" 22   Logan Square               73,595     82,715      -9,120       -11.0%\"      \n[25] \" 23   Humboldt Park              56,323     65,836      -9,513       -14.4%\"      \n[26] \" 24   West Town                  81,432     87,435      -6,003        -6.9%\"      \n[27] \" 25   Austin                     98,514    117,527     -19,013       -16.2%\"      \n[28] \" 26   West Garfield Park         18,001     23,019      -5,018       -21.8%\"      \n[29] \" 27   East Garfield Park         20,567     20,881       -314         -1.5%\"      \n[30] \" 28   Near West Side             54,881     46,419      8,462         18.2%\"      \n[31] \" 29   North Lawndale             35,912     41,768      -5,856       -14.0%\"      \n[32] \" 30   South Lawndale             79,288     91,071     -11,783       -12.9%\"      \n[33] \" 31   Lower West Side            35,769     44,031      -8,262       -18.8%\"      \n[34] \" 32   Loop                       29,283     16,388      12,895        78.7%\"      \n[35] \" 33   Near South Side            21,390     9,509       11,881       124.9%\"      \n[36] \" 34   Armour Square              13,391     12,032      1,359         11.3%\"      \n[37] \" 35   Douglas                    18,238     26,470      -8,232       -31.1%\"      \n[38] \" 36   Oakland                     5,918     6,110        -192         -3.1%\"      \n[39] \" 37   Fuller Park                 2,876     3,420        -544        -15.9%\"      \n[40] \" 38   Grand Boulevard            21,929     28,006      -6,077       -21.7%\"      \n[41] \" 39   Kenwood                    17,841     18,363       -522         -2.8%\"      \n[42] \" 40   Washington Park            11,717     14,146      -2,429       -17.2%\"      \n[43] \"Num       Community Area           2010         2,000     Difference   Percentage\"\n[44] \" 41   Hyde Park                      25,681     29,920       -4,239      -14.2%\"  \n[45] \" 42   Woodlawn                       25,983     27,086       -1,103       -4.1%\"  \n[46] \" 43   South Shore                    49,767     61,556      -11,789      -19.2%\"  \n[47] \" 44   Chatham                        31,028     37,275       -6,247      -16.8%\"  \n[48] \" 45   Avalon Park                    10,185     11,147        -962        -8.6%\"  \n[49] \" 46   South Chicago                  31,198     38,596       -7,398      -19.2%\"  \n[50] \" 47   Burnside                        2,916     3,294         -378       -11.5%\"  \n[51] \" 48   Calumet Heights                13,812     15,974       -2,162      -13.5%\"  \n[52] \" 49   Roseland                       44,619     52,723       -8,104      -15.4%\"  \n[53] \" 50   Pullman                         7,325     8,921        -1,596      -17.9%\"  \n[54] \" 51   South Deering                  15,109     16,990       -1,881      -11.1%\"  \n[55] \" 52   East Side                      23,042     23,653        -611        -2.6%\"  \n[56] \" 53   West Pullman                   29,651     36,649       -6,998      -19.1%\"  \n[57] \" 54   Riverdale                       6,482     9,809        -3,327      -33.9%\"  \n[58] \" 55   Hegewisch                       9,426     9,781         -355        -3.6%\"  \n[59] \" 56   Garfield Ridge                 34,513     36,101       -1,588       -4.4%\"  \n[60] \" 57   Archer Heights                 13,393     12,644        749         5.9%\"   \n[61] \" 58   Brighton Park                  45,368     44,912        456         1.0%\"   \n[62] \" 59   McKinley Park                  15,612     15,962        -350        -2.2%\"  \n[63] \" 60   Bridgeport                     31,977     33,694       -1,717       -5.1%\"  \n[64] \" 61   New City                       44,377     51,721       -7,344      -14.2%\"  \n[65] \" 62   West Elsdon                    18,109     15,921       2,188       13.7%\"   \n[66] \" 63   Gage Park                      39,894     39,193        701         1.8%\"   \n[67] \" 64   Clearing                       23,139     22,331        808         3.6%\"   \n[68] \" 65   West Lawn                      33,355     29,235       4,120       14.1%\"   \n[69] \" 66   Chicago Lawn                   55,628     61,412       -5,784       -9.4%\"  \n[70] \" 67   West Englewood                 35,505     45,282       -9,777      -21.6%\"  \n[71] \" 68   Englewood                      30,654     40,222       -9,568      -23.8%\"  \n[72] \" 69   Greater Grand Crossing         32,602     38,619       -6,017      -15.6%\"  \n[73] \" 70   Ashburn                        41,081     39,584       1,497        3.8%\"   \n[74] \" 71   Auburn Gresham                 48,743     55,928       -7,185      -12.8%\"  \n[75] \" 72   Beverly                        20,034     21,992       -1,958       -8.9%\"  \n[76] \" 73   Washington Heights             26,493     29,843       -3,350      -11.2%\"  \n[77] \" 74   Mount Greenwood                19,093     18,820        273         1.5%\"   \n[78] \" 75   Morgan Park                    22,544     25,226       -2,682      -10.6%\"  \n[79] \" 76   O'Hare                         12,756     11,956        800         6.7%\"   \n[80] \" 77   Edgewater                      56,521     62,198       -5,677       -9.1%\"  \n[81] \"      Total                       2,695,598   2,896,016    -200,418       -6.9%\"  \n\n\nThis is now a vector of 79 elements, each of which is a string. To clean things up, strip the first (empty) element, and the last element, which is nothing but the totals. We thus extract the elements from 2 to length - 1.\n\nnnlist &lt;- nnlist[2:(length(nnlist)-1)]\n\n\n\n8.2 Extracting the population values\nWe first initialize a vector of zeros to hold the population values. It is the preferred approach to initialize a vector first if one knows its size, rather than having it grow by appending rows or columns. We use the vector command and specify the mode=\"numeric\" and give the length as the length of the list.\n\nnnpop &lt;- vector(mode=\"numeric\",length=length(nnlist))\n\nWe again will use a loop to process each element of the list (each line of the table) one by one. We use the substr command to extract the characters between position 27 and 39 (these values were determined after taking a careful look at the structure of the table). However, there is still a problem, since the population values contain commas. We now do two things in one line of code. First, we use gsub to substitute the comma character by an empty ““. We turn the result into a numeric value by means of as.numeric. We then assign this number to position i of the vector. The resulting vector nnpop contains the population for each of the community areas.\n\nfor (i in (1:length(nnlist))) {\n     popchar &lt;- substr(nnlist[i],start=27,stop=39)\n     popval &lt;- as.numeric(gsub(\",\",\"\",popchar))\n     nnpop[i] &lt;- popval\n}\nnnpop\n\n [1]  2010 54991 71942 56362 39493 31867 94368 64116 80484 11187 37023 25448\n[13] 18508 17931 51542 64124 53359 41932 13426 78743 25010 39262 73595 56323\n[25] 81432 98514 18001 20567 54881 35912 79288 35769 29283 21390 13391 18238\n[37]  5918  2876 21929 17841 11717  2010    25    25    49    31    10    31\n[49]     2    13    44     7    15    23    29     6     9    34    13    45\n[61]    15    31    44    18    39    23    33    55    35    30    NA    41\n[73]    48    20    26    19    22    12    56\n\n\n\n\nCreating a data frame with population values\nAs a final step in the process of collecting the community area population information, we combine the vector with the population counts and a vector with community ID information into a data frame.\nSince the community area indicators are simple sequence numbers, we create such a vector to serve as the ID, again using the length of the vector to determine the extent.\n\nnnid &lt;- (1:length(nnlist))\nnnid\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n[26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n[51] 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75\n[76] 76 77 78 79\n\n\nWe turn the vectors nnid and nnpop into a data frame using the data.frame command. Since the variable names assigned automatically are not that informative, we next force them to NID and POP2010 using the names command. Also, as we did before, we make sure the ID variable is an integer (for merging in GeoDa) by means of as.integer.\n\nneighpop &lt;- data.frame(as.integer(nnid),nnpop)\nnames(neighpop) &lt;- c(\"NID\",\"POP2010\")\nhead(neighpop)\n\n  NID POP2010\n1   1    2010\n2   2   54991\n3   3   71942\n4   4   56362\n5   5   39493\n6   6   31867"
  },
  {
    "objectID": "Exploration/CSDS/01-spatial-data-handling/index.html#mapping-community-area-abandoned-vehicles-per-capita",
    "href": "Exploration/CSDS/01-spatial-data-handling/index.html#mapping-community-area-abandoned-vehicles-per-capita",
    "title": "01 Spatial Data Handline",
    "section": "Mapping Community Area Abandoned Vehicles Per Capita",
    "text": "Mapping Community Area Abandoned Vehicles Per Capita\n\nComputing abandoned vehicles per capita\nBefore proceeding further, we left_join the community population data to the community area layer, in the same way as we did for the vehicle counts.\n\nchicago.comm &lt;- left_join(chicago.comm,neighpop, by = c(\"area_num_1\" = \"NID\"))\nhead(chicago.comm)\n\nSimple feature collection with 6 features and 11 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 441440.4 ymin: 4627153 xmax: 451817.1 ymax: 4648971\nProjected CRS: WGS 84 / UTM zone 16N\n# A tibble: 6 × 12\n  community  area  shape_area perimeter area_num_1 area_numbe comarea_id comarea\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;          &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  \n1 DOUGLAS    0     46004621.… 0                 35 35         0          0      \n2 OAKLAND    0     16913961.… 0                 36 36         0          0      \n3 FULLER PA… 0     19916704.… 0                 37 37         0          0      \n4 GRAND BOU… 0     48492503.… 0                 38 38         0          0      \n5 KENWOOD    0     29071741.… 0                 39 39         0          0      \n6 LINCOLN S… 0     71352328.… 0                  4 4          0          0      \n# ℹ 4 more variables: shape_len &lt;chr&gt;, geometry &lt;MULTIPOLYGON [m]&gt;,\n#   AGG.COUNT &lt;int&gt;, POP2010 &lt;dbl&gt;\n\n\nWe will now create a new variable using the tidyverse mutate command as the ratio of vehicle counts per 1000 population.\n\nchicago.comm &lt;- chicago.comm %&gt;% mutate(vehpcap = (AGG.COUNT / POP2010) * 1000) \nhead(chicago.comm)\n\nSimple feature collection with 6 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 441440.4 ymin: 4627153 xmax: 451817.1 ymax: 4648971\nProjected CRS: WGS 84 / UTM zone 16N\n# A tibble: 6 × 13\n  community  area  shape_area perimeter area_num_1 area_numbe comarea_id comarea\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;          &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;  \n1 DOUGLAS    0     46004621.… 0                 35 35         0          0      \n2 OAKLAND    0     16913961.… 0                 36 36         0          0      \n3 FULLER PA… 0     19916704.… 0                 37 37         0          0      \n4 GRAND BOU… 0     48492503.… 0                 38 38         0          0      \n5 KENWOOD    0     29071741.… 0                 39 39         0          0      \n6 LINCOLN S… 0     71352328.… 0                  4 4          0          0      \n# ℹ 5 more variables: shape_len &lt;chr&gt;, geometry &lt;MULTIPOLYGON [m]&gt;,\n#   AGG.COUNT &lt;int&gt;, POP2010 &lt;dbl&gt;, vehpcap &lt;dbl&gt;\n\n\n\n\nFinal choropleth map\nFor our final choropleth, we use the same procedure as for the vehicle counts, but take vehpcap as the variable instead.\n\ntm_shape(chicago.comm) +\n  tm_polygons(\"vehpcap\")\n\n\n\n\n\n\n\n\nWhen compared to the total counts, we see quite a different spatial distribution. In particular, the locations of the highest ratios are quite different from those of the highest counts. As a rule, one should never create a choropleth map of a spatially extensive variable, unless the size of the areal units is somehow controlled for (e.g., equal area grid cells, or equal population zones).\n\n8.2.1 Optional - save the community area file as a shape file\nFinally, we can write the community area layer to the working directory. Note that, so far, all operations have been carried out in memory, and when you close the program, everything will be lost (unless you save your workspace).\nWe can write the community area to a shape file (actually, four files contained in a directory) by means of the sf command st_write. This command has many options, but we just use the minimal ones. The chicago.comm object will be written to a set of files in the directory chicago_vehicles using the ESRI Shapefile format. Note that if the directory already exists, it should be deleted or renamed first, since st_write only creates a new directory. Otherwise, there will be an error message.\n\nst_write(chicago.comm,\"chicago_vehicles\",driver=\"ESRI Shapefile\")\n\nWriting layer `chicago_vehicles' to data source \n  `chicago_vehicles' using driver `ESRI Shapefile'\nWriting 77 features with 12 fields and geometry type Multi Polygon.\n\n\nHowever, this map can be highly misleading since it pertains to a so-called spatially extensive variable, such as a count. Even if every area had the same risk of having abandoned vehicles, larger community areas would have higher counts. In other words, since the count is directly related to the size of the area, it does not provide a proper indication of the risk.\nInstead, we should map a spatially intensive variable, which is corrected for the size of the unit. For example, this can be achieved by expressing the variable as a density (counts per area), or as some other ratio, such as the counts per capita. In order to calculate this ratio, we first need to obtain the population for each community area."
  },
  {
    "objectID": "Exploration/CSDS/01-spatial-data-handling/index.html#footnotes",
    "href": "Exploration/CSDS/01-spatial-data-handling/index.html#footnotes",
    "title": "01 Spatial Data Handline",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA good resource on coordinate reference systems is the spatialreference.org site, which contains thousands of references in a variety of commonly used formats.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "️ Welcome to the ISSS626 Geospatial Analytics and Applications",
    "section": "",
    "text": "This website contains the coursework by Teng Kok Wai (Walter). It features a collection of projects, assignments, and notes from the class, complete with geospatial visualizations and analytical insights."
  },
  {
    "objectID": "index.html#hands-on-exercise",
    "href": "index.html#hands-on-exercise",
    "title": "️ Welcome to the ISSS626 Geospatial Analytics and Applications",
    "section": "✍️ Hands-on Exercise",
    "text": "✍️ Hands-on Exercise\n\n\n\n\n\n\n\n\n9A: Modelling Geographical Accessibility\n\n\n10 min\n\n\n\nSep 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n10B: Calibrating Spatial Interaction Models with R\n\n\n16 min\n\n\n\nSep 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n10A: Processing and Visualising Flow Data\n\n\n6 min\n\n\n\nSep 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n8A: Geographically Weighted Predictive Models\n\n\n23 min\n\n\n\nSep 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n7A: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method\n\n\n21 min\n\n\n\nSep 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n6A: Geographical Segmentation with Spatially Constrained Clustering Techniques\n\n\n37 min\n\n\n\nSep 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n5B: Local Measures of Spatial Autocorrelation\n\n\n26 min\n\n\n\nSep 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n5A: Global Measures of Spatial Autocorrelation\n\n\n24 min\n\n\n\nSep 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n4A: Spatial Weights and Applications\n\n\n22 min\n\n\n\nSep 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n3A: Network Constrained Spatial Point Patterns Analysis\n\n\n14 min\n\n\n\nSep 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n2B: 2nd Order Spatial Point Patterns Analysis\n\n\n28 min\n\n\n\nAug 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n2A: 1st Order Spatial Point Patterns Analysis\n\n\n27 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n1B: Thematic Mapping and GeoVisualisation with R\n\n\n24 min\n\n\n\nAug 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n1A: Geospatial Data Wrangling with R\n\n\n15 min\n\n\n\nAug 24, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#in-class-exercise",
    "href": "index.html#in-class-exercise",
    "title": "️ Welcome to the ISSS626 Geospatial Analytics and Applications",
    "section": "🏫 In-class Exercise",
    "text": "🏫 In-class Exercise\n\n\n\n\n\n\n\n\nIn-Class Exercise 10\n\n\n3 min\n\n\n\nNov 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 9\n\n\n7 min\n\n\n\nOct 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 8\n\n\n23 min\n\n\n\nOct 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 7\n\n\n25 min\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 6\n\n\n12 min\n\n\n\nSep 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 5\n\n\n14 min\n\n\n\nSep 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 4\n\n\n17 min\n\n\n\nSep 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 3\n\n\n5 min\n\n\n\nSep 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 2\n\n\n11 min\n\n\n\nSep 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 1\n\n\n23 min\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#take-home-exercise",
    "href": "index.html#take-home-exercise",
    "title": "️ Welcome to the ISSS626 Geospatial Analytics and Applications",
    "section": "🏠 Take-home Exercise",
    "text": "🏠 Take-home Exercise\n\n\n\n\n\n\n\n\nTake Home Exercise 2\n\n\n62 min\n\n\n\nSep 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake Home Exercise 1\n\n\n64 min\n\n\n\nSep 5, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "title": "1B: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 2  Thematic Mapping and GeoVisualisation with R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#exercise-1b-reference",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#exercise-1b-reference",
    "title": "1B: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 2  Thematic Mapping and GeoVisualisation with R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#overview",
    "title": "1B: Thematic Mapping and GeoVisualisation with R",
    "section": "2 Overview",
    "text": "2 Overview\nIn general, thematic mapping involves the use of map symbols to visualize selected properties of geographic features that are not naturally visible, such as population, temperature, crime rate, and property prices.\nMeanwhile, geovisualization leverages graphical representation to make places, phenomena, or processes visible, tapping into our spatial cognition and visual processing abilities."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#learning-outcome",
    "title": "1B: Thematic Mapping and GeoVisualisation with R",
    "section": "3 Learning Outcome",
    "text": "3 Learning Outcome\n\nUnderstanding thematic mapping and geovisualization concepts.\nInstalling and using the tmap package for creating choropleth maps.\nImporting and preparing geospatial and attribute data using sf and readr packages.\nWrangling data with dplyr and tidyr to prepare for mapping.\nPerforming georelational joins between geospatial and attribute data.\nCreating quick and advanced thematic maps using tmap elements and functions.\nCustomizing map layouts, color schemes, and data classification methods.\nPlotting small multiple maps and mapping spatial objects meeting specific criteria."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#the-data",
    "title": "1B: Thematic Mapping and GeoVisualisation with R",
    "section": "4 The Data",
    "text": "4 The Data\nThe following data sources will be used in this exercise:\n\n\n\nDataset\nSource\nDescription\nFormat\n\n\n\n\nMaster Plan 2014 Subzone Boundary (Web) (MP14_SUBZONE_WEB_PL)\ndata.gov.sg\nGeospatial data representing the geographical boundaries of Singapore’s planning subzones based on URA Master Plan 2014.\nESRI Shapefile\n\n\nSingapore Residents by Planning Area / Subzone, Age Group, Sex, and Type of Dwelling (2011-2020) (respopagesextod2011to2020.csv)\nDepartment of Statistics, Singapore\nAspatial data containing demographic information; fields PA and SZ can be used to link to the MP14_SUBZONE_WEB_PL shapefile.\nCSV\n\n\n\nThis table summarizes the datasets required, including their descriptions, sources, and formats."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#installing-and-loading-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#installing-and-loading-the-r-packages",
    "title": "1B: Thematic Mapping and GeoVisualisation with R",
    "section": "5 Installing and Loading the R Packages",
    "text": "5 Installing and Loading the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\n\ntmap\nThematic mapping for visualizing geospatial data.\nCreating and customizing thematic maps.\n\n\nsf\nHandling geospatial data in simple features format.\nImporting, managing, and processing geospatial data.\n\n\nreadr\nImporting delimited text files (part of tidyverse).\nLoading CSV data files.\n\n\ntidyr\nTidying data into a usable format (part of tidyverse).\nReshaping and organizing data.\n\n\ndplyr\nData wrangling and transformation tasks (part of tidyverse).\nManipulating and transforming datasets.\n\n\n\nTo install and load these packages in R, use the following code:\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#import-geospatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#import-geospatial-data-into-r",
    "title": "1B: Thematic Mapping and GeoVisualisation with R",
    "section": "6 Import Geospatial Data into R",
    "text": "6 Import Geospatial Data into R\nThe code block below uses st_read() function of sf package to import the MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame.\n\nmpsz = st_read(dsn = \"data/geospatial\",\n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWhen you display mpsz, only the first ten records are shown because R, by default, limits the number of printed rows to make output more manageable and readable.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n6.1 Importing Attribute Data into R\nNext, respopagsex2011to2020.csv file is imported into RStudio and save the file into an R dataframe called popdata.\nThe task will be performed by using read_csv() function of readr package as shown in the code block below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n6.2 Data Preparation\nBefore a thematic map can be prepared, it is required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n6.2.1 Data wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\n# Step 1: Filter the data for the year 2020\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020)\n\n# Step 2: Group the data by PA (Planning Area), SZ (Subzone), and AG (Age Group)\npopdata2020 &lt;- popdata2020 %&gt;%\n  group_by(PA, SZ, AG)\n\n# Step 3: Summarize the data by calculating the total population (POP) for each group\npopdata2020 &lt;- popdata2020 %&gt;%\n  summarise(POP = sum(Pop)) %&gt;%\n  ungroup()\n\n# Step 4: Reshape the data from long to wide format, with age groups as column names\npopdata2020 &lt;- popdata2020 %&gt;%\n  pivot_wider(names_from = AG, values_from = POP)\n\n# Step 5: Calculate the YOUNG population (sum of selected age groups)\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate(YOUNG = rowSums(.[3:6]) + rowSums(.[14]))\n\n# Step 6: Calculate the ECONOMICALLY ACTIVE population (sum of selected age groups)\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:11]) + rowSums(.[13:15]))\n\n# Step 7: Calculate the AGED population (sum of selected age groups)\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate(AGED = rowSums(.[16:21]))\n\n# Step 8: Calculate the TOTAL population (sum of all age groups)\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate(TOTAL = rowSums(.[3:21]))\n\n# Step 9: Calculate the DEPENDENCY ratio (ratio of YOUNG and AGED to ECONOMY ACTIVE)\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate(DEPENDENCY = (YOUNG + AGED) / `ECONOMY ACTIVE`)\n\n# Step 10: Select the relevant columns to be retained in the final dataset\npopdata2020 &lt;- popdata2020 %&gt;%\n  select(PA, SZ, YOUNG, `ECONOMY ACTIVE`, AGED, TOTAL, DEPENDENCY)\n\n\n\n6.2.2 Joining the attribute data and geospatial data\nBefore performing a georelational join, one additional step is necessary: converting the values in the PA and SZ fields to uppercase. This is because the PA and SZ fields contain both upper- and lowercase letters, whereas the SUBZONE_N and PLN_AREA_N fields are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ),\n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, the left_join() function from the dplyr package is used to merge the geographic data and attribute table, using the planning subzone names (e.g. SUBZONE_N and SZ) as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\n\n\n\n\n\nNote\n\n\n\nKey Takeaway:\nThe left_join() function from the dplyr package is applied to ensure that the resulting output remains a simple features data frame, with mpsz as the left table.\n\n\n\ndir.create(\"data/rds/\", recursive = TRUE)\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "1B: Thematic Mapping and GeoVisualisation with R",
    "section": "7 Choropleth Mapping Geospatial Data Using tmap",
    "text": "7 Choropleth Mapping Geospatial Data Using tmap\nChoropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nThere are two methods for creating thematic maps using tmap:\n\nUsing qtm() for quick thematic map plotting.\nUsing individual tmap elements for creating highly customizable maps.\n\n\n7.1 Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe following code draws a standard choropleth map:\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020,\n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nKey Takeaway:\n\ntmap_mode(“plot”) is used to generate a static map. To enable interactive mode, use the “view” option.\nThe fill argument is used to map the attribute to be visualized (in this case, DEPENDENCY).\n\n\n\n\n\n7.2 Creating a choropleth map by using tmap’s elements\nWhile qtm() is useful for quickly and easily drawing choropleth maps, its drawback is the limited control over the aesthetics of individual layers. To create a high-quality, cartographic choropleth map like the one shown below, it’s recommended to use the individual elements provided by tmap.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn the following sub-section, more tmap functions will be used to plot these elements.\n\n7.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code block below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n7.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nKey takeaways from tm_polygons():\n\nThe default method for interval binning when creating a choropleth map is “pretty.” A detailed explanation of the data classification methods available in tmap will be covered in sub-section 4.3.\nThe default color palette used is YlOrRd from ColorBrewer. More information on color schemes will be explored in sub-section 4.4.\nMissing values are automatically represented with a grey shade by default.\n\n\n\n\n\n7.2.3 Drawing a choropleth map using tm_fill() and *tm_border()**\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code block below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code block below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nNote that light-gray border lines have been added on the choropleth map.\nThe alpha option specifies a transparency value ranging from 0 (completely transparent) to 1 (not transparent). By default, the col’s alpha value is used (usually 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n7.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n7.3.1 Plotting choropleth maps with built-in classification methods\nThe code block below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code block below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservation: The distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWarning: Maps Lie!\n\n\nExercise: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\nThe tabs below shows the choropleth maps drawn using different classifications methods with the same number of classes (n=5).\n\nquantileequalprettyjenkssdhclustfisherbclustkmeans\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservation: Different data classification methods produce varying color patterns. Methods like pretty, equal, and sd are more sensitive to outliers, often resulting in fewer distinct areas on the map. In contrast, methods like quantile, jenks, and kmeans create more evenly distributed colors. Therefore, choosing the right classification method based on data distribution is crucial to avoid misleading representations in choropleth maps.\n\n\nExercise: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\nThe tabs below show choropleth maps with kmeans classification method. The numbers of classes used are (2, 6, 10, 20).\n\nn=2n=6n=10n=20\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservation: Using different class numbers within the same classification method affects the map’s coloring. With n=2, outliers dominate, resulting in only one distinct area. Increasing the class count distributes the data more evenly across the map.\n\n\n\n\n7.3.2 Plotting choropleth map with custom break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code block below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6751  0.7288  0.8084  0.8092 19.0000      92 \n\n\nBased on the results, we choose breakpoints at 0.60, 0.70, 0.80, and 0.90, with the minimum at 0 and maximum at 1. Our breaks vector is c(0, 0.60, 0.70, 0.80, 0.90, 1.00).\nNow, we will plot the choropleth map with the following code:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n7.4 Colour Scheme\ntmap supports colour ramps either user-defined or a set of predefined colour ramps from the RColorBrewer package.\n\n7.4.1 Using ColourBrewer palette\nTo apply a specific color palette, assign it to the palette argument in tm_fill() as shown below:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n7.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n7.5.1 Map Legend\nIn tmap, there are several legend options for adjusting the placement, format, and style of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"jenks\",\n          palette = \"Blues\",\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n7.5.2 Map style\ntmap allows extensive customization of layout settings, accessible through the tmap_style() function. The code below demonstrates the use of the classic style.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n7.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines. In the following example, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, use the code below:\n\ntmap_style(\"white\")\n\n\n\n\n7.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be created through three methods:\n\nAssigning multiple values to an aesthetic argument.\nDefining a grouping variable with tm_facets().\nCreating multiple stand-alone maps with tmap_arrange().\n\n\n7.6.1 Assigning Multiple Values to an Aesthetic Argument\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nThis example creates small multiple choropleth maps by assigning multiple values to at least one of the aesthetic arguments:\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"),\n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n7.6.2 Grouping by a Variable with tm_facets()\nThis example generates multiple small maps by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) +\n  tm_facets(by=\"REGION_N\",\n            free.coords=TRUE,\n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"),\n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n7.6.3 Creating Stand-alone Maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+\n  tm_polygons(\"YOUNG\",\n              style = \"quantile\",\n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+\n  tm_polygons(\"AGED\",\n              style = \"quantile\",\n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n7.7 Mapping Spatial Object by Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection function to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45,\n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#references",
    "title": "1B: Thematic Mapping and GeoVisualisation with R",
    "section": "8 References",
    "text": "8 References\n\n8.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n8.2 Geospatial Data Wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n8.3 Data Wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/index.html",
    "href": "Hands-on_Ex/index.html",
    "title": "Hands-on Exercise",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n9A: Modelling Geographical Accessibility\n\n\nIn this exercise, we will learn to model geographical accessibility using Hansen’s potential model, Spatial Accessibility Measure (SAM), and other methods in R.\n\n\n10 min\n\n\n\nSep 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n10B: Calibrating Spatial Interaction Models with R\n\n\nIn this exercise, we will learn to calibrate Spatial Interaction Models (SIMs) using various regression methods to determine factors affecting public bus passenger flows during the morning peak in Singapore.\n\n\n16 min\n\n\n\nSep 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n10A: Processing and Visualising Flow Data\n\n\nIn this exercise, we will explore the concept of spatial interaction, and learn how to build an OD (origin/destination) matrix.\n\n\n6 min\n\n\n\nSep 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n8A: Geographically Weighted Predictive Models\n\n\nIn this exercise, we will learn how to build predictive models using the geographical random forest method to predict outcomes based on geospatial factors and historical geospatial locations.\n\n\n23 min\n\n\n\nSep 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n7A: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method\n\n\nIn this exercise, we will learn to build hedonic pricing models for private high-rise property using Geographically Weighted Regression (GWR) methods to account for non-stationary variables.\n\n\n21 min\n\n\n\nSep 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n6A: Geographical Segmentation with Spatially Constrained Clustering Techniques\n\n\nIn this exercise, we will learn to delineate homogeneous regions using hierarchical and spatially constrained clustering techniques on geographically referenced multivariate data.\n\n\n37 min\n\n\n\nSep 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n5B: Local Measures of Spatial Autocorrelation\n\n\nIn this exercise, we will learn to compute Local Measures of Spatial Autocorrelation (LMSA) using the spdep package, including Local Moran’s I, Getis-Ord’s Gi-statistics, and their visualizations.\n\n\n26 min\n\n\n\nSep 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n5A: Global Measures of Spatial Autocorrelation\n\n\nIn this exercise, we will learn to compute Global Measures of Spatial Autocorrelation using the spdep package, including Moran’s I and Geary’s C tests, spatial correlograms, and their statistical interpretation.\n\n\n24 min\n\n\n\nSep 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n4A: Spatial Weights and Applications\n\n\nIn this exercise, we will learn to compute spatial weights, visualize spatial distributions, and create spatially lagged variables using various functions from R packages such as sf,spdep, and tmap.\n\n\n22 min\n\n\n\nSep 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n3A: Network Constrained Spatial Point Patterns Analysis\n\n\nIn this exercise, we will learn to use R and the spNetwork package for analyzing network-constrained spatial point patterns, focusing on kernel density estimation and G- and K-function analysis.\n\n\n14 min\n\n\n\nSep 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n2B: 2nd Order Spatial Point Patterns Analysis\n\n\nIn this exercise, we will learn to apply 2nd-order spatial point pattern analysis methods in R, including G, F, K, and L functions, to evaluate spatial point distributions and perform hypothesis testing using the spatstat package.\n\n\n28 min\n\n\n\nAug 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n2A: 1st Order Spatial Point Patterns Analysis\n\n\nIn this exercise, we will learn to analyze spatial point patterns in R, including importing geospatial data, performing kernel density estimation and nearest neighbor analysis, and visualizing results using spatstat, sf, and tmap packages.\n\n\n27 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n1B: Thematic Mapping and GeoVisualisation with R\n\n\nIn this exercise, we will learn to create thematic maps and perform geovisualization in R using the tmap package, including data preparation, classification, color schemes, and advanced mapping techniques.\n\n\n24 min\n\n\n\nAug 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n1A: Geospatial Data Wrangling with R\n\n\nIn this exercise, we will learn to use R for geospatial data handling, including importing, transforming, wrangling, and visualizing data with sf, tidyverse, and ggplot2.\n\n\n15 min\n\n\n\nAug 24, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html",
    "title": "5A: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 9  Global Measures of Spatial Autocorrelation"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#exercise-5a-reference",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#exercise-5a-reference",
    "title": "5A: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 9  Global Measures of Spatial Autocorrelation"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#overview",
    "title": "5A: Global Measures of Spatial Autocorrelation",
    "section": "2 Overview",
    "text": "2 Overview\nIn this exercise, we will learn to compute Global Measures of Spatial Autocorrelation using the spdep package, including Moran’s I and Geary’s C tests, spatial correlograms, and their statistical interpretation."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#learning-outcome",
    "title": "5A: Global Measures of Spatial Autocorrelation",
    "section": "3 Learning Outcome",
    "text": "3 Learning Outcome\n\nImport geospatial data using the sf package\nImport CSV data using the readr package\nPerform relational joins using the dplyr package\nCompute Global Spatial Autocorrelation (GSA) statistics using the spdep package\n\nMoran’s I test and Monte Carlo simulation\nGeary’s C test and Monte Carlo simulation\n\nPlot Moran scatterplot and spatial correlograms\nInterpret GSA statistics correctly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#the-analytical-question",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#the-analytical-question",
    "title": "5A: Global Measures of Spatial Autocorrelation",
    "section": "4 The Analytical Question",
    "text": "4 The Analytical Question\nIn spatial policy planning, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. In this study, we will apply spatial statistical methods to examine the distribution of development in Hunan Province, China, using a selected indicator (e.g., GDP per capita).\n\nOur key questions are:\n\nIs development evenly distributed geographically?\nIf not, is there evidence of spatial clustering?\nIf clustering exists, where are these clusters located?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#the-data",
    "title": "5A: Global Measures of Spatial Autocorrelation",
    "section": "5 The Data",
    "text": "5 The Data\nThe following 2 datasets will be used in this exercise.\n\n\n\n\n\n\n\n\nData Set\nDescription\nFormat\n\n\n\n\nHunan county boundary layer\nGeospatial data set representing the county boundaries of Hunan\nESRI Shapefile\n\n\nHunan_2012.csv\nContains selected local development indicators for Hunan in 2012\nCSV"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#installing-and-launching-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#installing-and-launching-the-r-packages",
    "title": "5A: Global Measures of Spatial Autocorrelation",
    "section": "6 Installing and Launching the R Packages",
    "text": "6 Installing and Launching the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\n\nsf\nImports, manages, and processes vector-based geospatial data.\nHandling vector geospatial data such as the Hunan county boundary layer in shapefile format.\n\n\nspdep\nProvides functions for spatial dependence analysis, including spatial weights and spatial autocorrelation.\nComputing spatial weights and creating spatially lagged variables.\n\n\ntmap\nCreates static and interactive thematic maps using cartographic quality elements.\nVisualizing regional development indicators and plotting maps showing spatial relationships and patterns.\n\n\ntidyverse\nA collection of packages for data science tasks such as data manipulation, visualization, and modeling.\nImporting CSV files, wrangling data, and performing relational joins.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#import-data-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#import-data-and-preparation",
    "title": "5A: Global Measures of Spatial Autocorrelation",
    "section": "7 Import Data and Preparation",
    "text": "7 Import Data and Preparation\nIn this section, we will perform 3 necessary steps to prepare the data for analysis.\n\n\n\n\n\n\nNote\n\n\n\nThe data preparation is the same as previous exercise such as Exercise 4A.\n\n\n\n7.1 Import Geospatial Shapefile\nFirstly, we will use st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex05/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n7.2 Import Aspatial csv File\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n7.3 Perform Relational Join\nThen, we will perform a left_join() to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n\n7.4 Visualizing Regional Development Indicator\nTo visualize the regional development indicator, we can prepare a base map and a choropleth map to show the distribution of GDPPC 2012 (GDP per capita) by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(col = \"grey\") +\n  tm_layout(main.title = \"Equal Interval Classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(col = \"grey\") +\n  tm_layout(main.title = \"Equal Quantile Classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations\nOn the left plot, we perform equal interval classification which divides the range of GDPPC into five equal-sized intervals. This method ensures that the difference between the maximum and minimum value within each class is the same.\nThe equal interval classification method is best used for continuous datasets such as precipitation or temperature.\nThe advantage of the equal interval classification method is that it creates a legend that is easy to interpret and present to a nontechnical audience. The primary disadvantage is that certain datasets will end up with most of the data values falling into only one or two classes, while few to no values will occupy the other classes.\n\nOn the right plot, we perform equal quantile classification which divides the regions into five classes such that each class contains approximately the same number of regions. This method adjusts the intervals to ensure an equal number of regions per class, which might result in unequal interval sizes.\nThe equal quantile classification is best for data that is evenly distributed across its range.\nAs there are 88 counties in Hunan, each class in the quantile classification methodology will contain 88 / 5 = 17.6 different counties. The advantage to this method is that it often excels at emphasizing the relative position of the data values (i.e., which counties contain the top 20 percent of the Hunan population). The primary disadvantage of the quantile classification methodology is that features placed within the same class can have wildly differing values, particularly if the data are not evenly distributed across its range. In addition, the opposite can also happen whereby values with small range differences can be placed into different classes, suggesting a wider difference in the dataset than actually exists.\nFor more info, see Data Classification"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#global-measures-of-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#global-measures-of-spatial-autocorrelation",
    "title": "5A: Global Measures of Spatial Autocorrelation",
    "section": "8 Global Measures of Spatial Autocorrelation",
    "text": "8 Global Measures of Spatial Autocorrelation\nIn this section, we will compute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.\n\n8.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code block below, the poly2nb() function from the spdep package calculates contiguity weight matrices for the study area by identifying regions that share boundaries.\nBy default, poly2nb() uses the “Queen” criteria, which considers any shared boundary or corner as a neighbor (equivalent to setting queen = TRUE). If we want to restrict the criteria to shared boundaries only (excluding corners), set queen = FALSE.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.\n\n\n8.2 Row-standardised Weights Matrix\nNext, we need to assign weights to each neighboring polygon. In this case, we’ll use equal weights (style=“W”), where each neighboring polygon gets a weight of 1/(number of neighbors). This means we take the value for each neighbor and divide it by the total number of neighbors, then sum these weighted values to calculate a summary measure, such as weighted income.\nWhile this equal weighting approach is straightforward and easy to understand, it has a limitation: polygons on the edges of the study area have fewer neighbors, which can lead to over- or underestimation of the actual spatial relationships (spatial autocorrelation) in the data.\n\n\n\n\n\n\nTip\n\n\n\nFor simplicity, we use the style=“W” option in this example, but keep in mind that other, potentially more accurate methods are available, such as style=“B”.\n\n\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#global-measures-of-spatial-autocorrelation-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#global-measures-of-spatial-autocorrelation-morans-i",
    "title": "5A: Global Measures of Spatial Autocorrelation",
    "section": "9 Global Measures of Spatial Autocorrelation: Moran’s I",
    "text": "9 Global Measures of Spatial Autocorrelation: Moran’s I\nIn this section, you will learn how to perform Moran’s I statistics testing by using moran.test() of spdep.\n\n\n\n\n\n\nNote\n\n\n\nSpatial Autocorrelation, specifically Global Moran’s I, is a statistical measure used to evaluate the degree to which similar values in a dataset are clustered together or dispersed across a geographic space.\nIn simpler terms, it measures whether similar values occur near each other (positive autocorrelation) or if dissimilar values are found near each other (negative autocorrelation).\nGlobal Moran’s I takes into account both the locations of features and the values associated with those features. It computes an index value (Moran’s I), a z-score, and a p-value to determine the statistical significance of the observed spatial pattern\nIntepreting Moran’s I index\nThe Moran’s I index ranges from -1 to +1. A value close to +1 indicates clustering of similar values, a value close to -1 indicates dispersion of similar values, and a value near 0 suggests a random spatial pattern2.\n\nPositive Moran’s I: Indicates that high values are near other high values, and low values are near other low values.\nNegative Moran’s I: Indicates that high values are near low values and vice versa.\nZero Moran’s I: Suggests no spatial autocorrelation, implying a random distribution.\n\nFor more info, see How Spatial Autocorrelation (Global Moran’s I) works—ArcGIS Pro | Documentation\n\n\n\n9.1 Moran’s I test\nTo assess whether there is significant spatial autocorrelation in the GDP per capita (GDPPC) across regions, we use Moran’s I test. The test is performed using the moran.test() function from the spdep package.\n\nNull Hypothesis (\\(H_0\\)): There is no spatial autocorrelation in GDP per capita across the regions (Moran’s I = 0).\nAlternative Hypothesis (\\(H_1\\)): There is positive spatial autocorrelation in GDP per capita (Moran’s I &gt; 0).\n\nWe will use an alpha value (α) of 0.05 (95% confidence level) to determine the statistical significance.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\nThe value of Moran’s I is 0.3007, a positive number, indicating positive spatial autocorrelation. This means that regions with similar GDP per capita (GDPPC) values tend to be geographically close to each other.\nThe p-value is 1.095e-06, which is much smaller than our alpha value of 0.05. This provides strong evidence against the null hypothesis of no spatial autocorrelation.\n\nTherefore, We will reject the null hypothesis at 95% confidence interval because the p-value is smaller than our chosen alpha value.\n\n\n\n\n9.2 Computing Monte Carlo Moran’s I\nIn this example, we explore the spatial distribution of Hunan GDPPC by county for the state of Hunan using the Monte Carlo approach. A total of 1000 simulation will be performed. We will perform the same hypothesis testing described above.\n\nset.seed(1234)\n\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\nThe value of Moran’s I is 0.30075, which is a positive number, indicating positive spatial autocorrelation. This suggests that regions with similar GDP per capita (GDPPC) values are geographically close to each other.\nThe p-value obtained from the Monte Carlo simulation is 0.001, which is much smaller than our alpha value of 0.05. This provides strong evidence against the null hypothesis of no spatial autocorrelation.\n\nTherefore, we will reject the null hypothesis at 95% confidence interval because the p-value is smaller than our chosen alpha value.\n\n\n\n\n9.3 Visualising Monte Carlo Moran’s I\nIt is always a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code block below.\nWe will first observe the summary report of the Monte Carlo Moran’s I output before visualizing the plots using ggplot2 and base R.\n\n# Calculate the mean of the first 999 simulated Moran's I values\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n# Calculate the variance of the first 999 simulated Moran's I values\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nggplot2base R\n\n\n\nggplot(data.frame(x = bperm$res), aes(x = x)) + \n  geom_histogram(binwidth = diff(range(bperm$res)) / 20,\n                 fill = \"grey\",\n                 color = \"black\") +\n  geom_vline(xintercept = 0,\n             color = \"red\", \n             linetype = \"solid\") +\n  labs(x = \"Simulated Moran's I\",\n       y = \"Frequency\",\n       title = \"Histogram of Simulated Moran's I Values\")\n\n\n\n\n\n\n\n\n\n\n\nhist(bperm$res, \n     freq = TRUE,         # Show the frequency (count) on y-axis\n     breaks = 20,         # Set the number of bins\n     xlab = \"Simulated Moran's I\")\n\n# Add vertical red line at 0 to indicate the mean under the null hypothesis of no autocorrelation\nabline(v = 0, \n       col = \"red\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\nThe observed Moran’s I value (0.30075) lies outside the range of most simulated values, indicating that it is an outlier compared to the expected distribution under the null hypothesis, which are centered around the expected value of 0.0 under the null hypothesis of no spatial autocorrelation. The histogram shows that most of the simulated values of Moran’s I are clustered around the mean of -0.01504572, with a variance of 0.004371574.\nSince the observed Moran’s I value is significantly greater than the bulk of the simulated values and given the p-value from the test is very small (p &lt; 0.05), there is strong evidence against the null hypothesis.\nThere is significant positive spatial autocorrelation in the GDP per capita (GDPPC) across regions, as indicated by the Moran’s I test. This suggests that regions with similar GDPPC values are more likely to be geographically clustered."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "title": "5A: Global Measures of Spatial Autocorrelation",
    "section": "10 Global Measures of Spatial Autocorrelation: Geary’s C",
    "text": "10 Global Measures of Spatial Autocorrelation: Geary’s C\nIn this section, we will perform Geary’s C statistics testing by using appropriate functions of spdep package.\n\n10.1 Geary’s C test\nAnother popular index of global spatial autocorrelation is Geary’s C which is a cousin to the Moran’s I.\n\n\n\n\n\n\nNote\n\n\n\nGeary’s C, also known as Geary’s contiguity ratio, is used to assess the degree of spatial autocorrelation in a dataset.\nIt is particularly sensitive to local variations in spatial data, making it suitable for analyzing patterns within smaller areas.\nInterpreting Geary’s C Values\nGeary’s C values range from 0 to 2. Under the null hypothesis of no spatial autocorrelation, the expected value of Geary’s C is 1.\n\nValues &lt; 1: Indicate positive spatial autocorrelation, meaning similar values are clustered together.\nValues = 1: Suggest a random spatial pattern with no autocorrelation.\nValues &gt; 1: Indicate negative spatial autocorrelation, meaning dissimilar values are clustered together.\n\n\n\n\nWhile Moran’s I and Geary’s C are both measures of global spatial autocorrelation, they are slightly different. Geary’s C uses the sum of squared distances whereas Moran’s I uses standardized spatial covariance.\nUnlike Moran’s I, which focuses on global patterns, Geary’s C emphasizes local variations and can reveal nuances in spatial relationships.\nFor more info: Geary’s C, Geary’s C\n\nSimilarly, to assess whether there is significant spatial autocorrelation in the GDP per capita (GDPPC) across regions, we can performGeary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\nNull Hypothesis (\\(H_o\\)): There is no spatial autocorrelation in GDP per capita across the regions (Geary’s C = 1).\nAlternative Hypothesis (\\(H_1\\)): There is positive spatial autocorrelation in GDP per capita (Geary’s C &lt; 1).\n\nWe will use an alpha value (α) of 0.05 (95% confidence level) to determine the statistical significance.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\nThe value of Geary’s C statistic is 0.6907, which is less than the expected value of 1.0. This indicates positive spatial autocorrelation, meaning regions with similar GDP per capita (GDPPC) values tend to be geographically close to each other.\nThe p-value is 0.0001526, which is much smaller than our alpha value of 0.05. This provides strong evidence against the null hypothesis of no spatial autocorrelation.\n\nTherefore, we will reject the null hypothesis at 95% confidence interval because the p-value is smaller than our chosen alpha value.\n\n\n\n\n10.2 Computing Monte Carlo Geary’s C\nSimilar to Moran’s I, it is best to test the statistical significance of Geary’s C using a Monte Carlo simulation.\nTo perform permutation test for Geary’s C statistic by using geary.mc() of spdep:\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\nThe value of Geary’s C statistic is 0.6907, which is less than the expected value of 1.0. This indicates positive spatial autocorrelation, meaning regions with similar GDP per capita (GDPPC) values tend to be geographically close to each other.\nThe p-value from the Monte Carlo simulation is 0.001, which is much smaller than our alpha value of 0.05. This provides strong evidence against the null hypothesis of no spatial autocorrelation.\n\nTherefore, we will reject the null hypothesis at 95% confidence because the p-value is smaller than our chosen alpha value.\n\n\n\n\n10.3 Visualising the Monte Carlo Geary’s C\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code block below.\nWe will first observe the summary report of the Geary’s C output before visualizing the plots using ggplot2 and base R.\n\n# Calculate the mean of the first 999 simulated geary's c values\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n# Calculate the variance of the first 999 simulated geary's c values\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nggplot2base R\n\n\n\nggplot(data.frame(x = bperm$res), aes(x = x)) + \n  geom_histogram(binwidth = diff(range(bperm$res)) / 20,\n                 color = \"black\", \n                 fill = \"grey\") + \n  geom_vline(xintercept = 1, \n             color = \"red\") + \n  labs(x = \"Simulated Geary's C\", \n       y = \"Frequency\",\n       title = \"Histogram of Simulated Geary's C Values\")       \n\n\n\n\n\n\n\n\n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary's C\")\nabline(v=1, col=\"red\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\nThe observed Geary’s C value (0.69072) lies outside the range of most simulated values, which are centered around the expected value of 1.0 under the null hypothesis of no spatial autocorrelation. The histogram shows that most of the simulated values of Geary’s C are clustered around the mean of 1.0044, with a variance of 0.0074.\nSince the observed Geary’s C value is significantly lower than the bulk of the simulated values and the p-value from the test is very small (p &lt; 0.05), there is strong evidence against the null hypothesis.\nThere is significant positive spatial autocorrelation in the GDP per capita (GDPPC) across regions, as indicated by the Geary’s C test. This suggests that regions with similar GDPPC values are more likely to be geographically clustered."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#spatial-correlogram",
    "title": "5A: Global Measures of Spatial Autocorrelation",
    "section": "11 Spatial Correlogram",
    "text": "11 Spatial Correlogram\nSpatial correlograms are useful for examining patterns of spatial autocorrelation in your data or model residuals. They show how the correlation between pairs of spatial observations changes as the distance (lag) between them increases. Essentially, they are plots of a spatial autocorrelation index (such as Moran’s I or Geary’s C) against distance.\nWhile correlograms are not as fundamental as variograms—a core concept in geostatistics—they serve as powerful exploratory and descriptive tools. In fact, for examining spatial patterns, correlograms can provide more detailed insights than variograms.\n\n11.1 Compute Moran’s I Correlogram\nIn the code below, we use the sp.correlogram() function from the spdep package to compute a 6-lag spatial correlogram for GDP per capita (GDPPC). This function calculates global spatial autocorrelation using Moran’s I. The base R plot() function is then used to visualize the correlogram.\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order = 6, \n                          method = \"I\", \n                          style = \"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nHowever, simply plotting the output does not provide a complete interpretation because not all autocorrelation values may be statistically significant. Therefore, it is important to examine the full analysis report by printing the results.\n\n\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical observation can you draw from the plot above?\nThe spatial correlogram shows Moran’s I values for different distance lags, which indicate how spatial autocorrelation in GDP per capita (GDPPC) changes as the distance between regions increases.\n\nSignificant Positive Spatial Autocorrelation at Shorter Distances:\n\nFor lags 1 and 2, Moran’s I values are significantly positive (0.30075 and 0.20601, respectively). The p-values for these lags are very small (p &lt; 0.001). This suggests that regions with similar GDPPC values tend to be clustered together at these shorter distances.\n\nDecreasing and Insignificant Spatial Autocorrelation at Moderate Distances:\n\nAt lag 3, Moran’s I value is 0.06683, with the confidence interval still above zero, indicating weak but significant positive spatial autocorrelation (p &lt; 0.05).\nAt lag 4, Moran’s I value further decreases to 0.02995. The p-value (0.226) is not significant, suggesting that spatial autocorrelation is not statistically significant at this distance.\n\nSignificant Negative Spatial Autocorrelation at Longer Distances:\n\nFor lags 5 and 6, Moran’s I values become negative (-0.15305 and -0.11871, respectively). The p-values for these lags are very small (p &lt; 0.001 and p &lt; 0.01, respectively), indicating statistically significant negative spatial autocorrelation. This means that regions with dissimilar GDPPC values tend to be found farther apart.\n\n\n\n\n\n\n11.2 Compute Geary’s C Correlogram and Plot\nSimilarly, we can use sp.correlogram() of spdep package to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C and the plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code block below.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical observation can you draw from the plot above?\nThe spatial correlogram shows Geary’s C values for different distance lags, illustrating how spatial autocorrelation in GDP per capita (GDPPC) changes with distance:\n\nSignificant Positive Spatial Autocorrelation at Shorter Distances:\n\nFor lags 1 and 2, Geary’s C values (0.6907 and 0.7630, respectively). This indicates significant positive spatial autocorrelation, suggesting that similar GDPPC values are clustered together at shorter distances (p &lt; 0.05).\n\nInsignificant Autocorrelation at Moderate Distances:\n\nAt lags 3 and 4, Geary’s C values are close to 1.0 (0.9397 and 1.0098), and their confidence intervals include 1, indicating no significant spatial autocorrelation (p &gt; 0.05).\n\nSignificant Negative Spatial Autocorrelation at Longer Distances:\n\nAt lag 5, Geary’s C value (1.2008) is significantly greater than 1.0, with the confidence interval not crossing 1, indicating significant negative spatial autocorrelation (p &lt; 0.05). This suggests that dissimilar GDPPC values are more likely to be found at longer distances.\n\nNo Significant Spatial Autocorrelation at the Furthest Distance:\n\nAt lag 6, Geary’s C value (1.0773) is slightly above 1, but the confidence interval includes 1, indicating no significant spatial autocorrelation (p &gt; 0.05)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html",
    "title": "2A: 1st Order Spatial Point Patterns Analysis",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 4  1st Order Spatial Point Patterns Analysis Methods"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#exercise-2a-reference",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#exercise-2a-reference",
    "title": "2A: 1st Order Spatial Point Patterns Analysis",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 4  1st Order Spatial Point Patterns Analysis Methods"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#overview",
    "title": "2A: 1st Order Spatial Point Patterns Analysis",
    "section": "2 Overview",
    "text": "2 Overview\nSpatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be location of:\n\nevents such as crime, traffic accident and disease onset, or\nbusiness services (coffee and fastfood outlets) or facilities such as childcare and eldercare.\n\nUsing appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\n\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#learning-outcome",
    "title": "2A: 1st Order Spatial Point Patterns Analysis",
    "section": "3 Learning Outcome",
    "text": "3 Learning Outcome\n\nImporting and managing geospatial data using sf and spatstat packages.\nConverting simple feature data frames to various spatial data formats.\nPerforming kernel density estimation (KDE) using different methods and bandwidths.\nConducting nearest neighbor analysis to test spatial point distribution.\nVisualizing spatial patterns and KDE results using tmap and spatstat.\nHandling duplicate spatial points and creating point patterns for analysis.\nApplying appropriate statistical methods for confirmatory spatial point pattern analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#the-data",
    "title": "2A: 1st Order Spatial Point Patterns Analysis",
    "section": "4 The Data",
    "text": "4 The Data\n\n\n\n\n\n\n\n\n\nDataset\nDescription\nSource\nFormat\n\n\n\n\nCHILDCARE\nPoint data containing location and attributes of childcare centers.\nData.gov.sg\nGeoJSON\n\n\nMP14_SUBZONE_WEB_PL\nPolygon data with URA 2014 Master Plan Planning Subzone boundaries.\nData.gov.sg\nESRI Shapefile\n\n\nCoastalOutline\nPolygon data representing Singapore’s national boundary.\nSingapore Land Authority (SLA)\nESRI Shapefile"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#installing-and-loading-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#installing-and-loading-the-r-packages",
    "title": "2A: 1st Order Spatial Point Patterns Analysis",
    "section": "5 Installing and Loading the R Packages",
    "text": "5 Installing and Loading the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\n\nsf\nImports, manages, and processes vector-based geospatial data.\nHandling vector geospatial data in R.\n\n\nspatstat\nProvides tools for point pattern analysis.\nPerforming 1st- and 2nd-order spatial point pattern analysis and deriving kernel density estimation (KDE).\n\n\nraster\nReads, writes, and manipulates gridded spatial data (raster).\nConverting image outputs from spatstat into raster format.\n\n\nmaptools\nOffers tools for manipulating geographic data.\nConverting spatial objects into ppp format for use with spatstat.\n\n\ntmap\nCreates static and interactive thematic maps using cartographic quality elements.\nPlotting static and interactive point pattern maps.\n\n\n\nTo install and load these packages in R, use the following code:\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#reproducibility",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#reproducibility",
    "title": "2A: 1st Order Spatial Point Patterns Analysis",
    "section": "6 Reproducibility",
    "text": "6 Reproducibility\nAs this document involves Monte Carlo simulations, we will set the seed to ensure reproducibility\n\nset.seed(1234)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#spatial-data-wrangling",
    "title": "2A: 1st Order Spatial Point Patterns Analysis",
    "section": "7 Spatial Data Wrangling",
    "text": "7 Spatial Data Wrangling\n\n7.1 Importing the Spatial Data\nTo import the three geographical datasets, we will use st_read() from sf.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\")\n\nReading layer `child-care-services-geojson' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex02/data/child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex02/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex02/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n7.2 Inspect and Reproject to Same Projection System\nBefore we can use these data for analysis, it is important for us to ensure that they are projected in same projection system.\nFirst, we check the childcare dataset.\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nThis dataset is using the WGS84 crs. We will reproject all the dataset to SVY21 crs for standardization and analysis.\n\nchildcare_sf &lt;- st_transform(childcare_sf , crs = 3414)\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nThe childcare dataset has been reprojected to SVY21 successfully.\nNext, we inspect the Coastal Outline dataset.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nNotice that this dataset is using SVY21 crs, however the ID provided is EPSG:9001 does not match the intended ID, EPSG:3414 of SVY21. In this case, we will set the crs to the correct ID using the code block below.\n\nsg_sf &lt;- st_set_crs(sg_sf, 3414)\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nSimilarly, we will inspect the Master Plan Subzone Dataset.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nSince the ID is also EPSG:9001, we will set the crs to EPSG:3414 too.\n\nmpsz_sf &lt;- st_set_crs(mpsz_sf, 3414)\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#mapping-the-geospatial-datasets",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#mapping-the-geospatial-datasets",
    "title": "2A: 1st Order Spatial Point Patterns Analysis",
    "section": "8 Mapping the Geospatial Datasets",
    "text": "8 Mapping the Geospatial Datasets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\n\n8.1 Static Map\n\ntmap_options(check.and.fix = TRUE)\n# add polygon layer of the coastal outline of sg island\ntm_shape(sg_sf)+ tm_polygons() +\n# add polygon layer of the subzone based on sg masterplan\ntm_shape(mpsz_sf) + tm_polygons() +\n# add dot layer to show the locations of childcare centres\ntm_shape(childcare_sf) + tm_dots() +\ntm_layout()\n\n\n\n\n\n\n\n\nWhen all the 3 datasets are overlayed together, it shows the locations of childcare centres on the Singapore island. Since all the geospatial layers are within the same map context, it means their referencing system and coordinate values are referred to similar spatial context. This consistency is crucial for accurate geospatial analysis.\n\n\n8.2 Interactive Map\nAlternatively, we can also prepare a pin map by using the code block below.\n\ntmap_mode('view')\n\n# tm_basemap(\"Esri.WorldGrayCanvas\") +\n# tm_basemap(\"OpenStreetMap\") +\ntm_basemap(\"Esri.WorldTopoMap\") +\ntm_shape(childcare_sf) +\n  tm_dots(alpha = 0.5)\n\n\n\n\n\n\ntmap_mode('plot')\n\nIn interactive mode, tmap uses the Leaflet for R API, allowing you to freely navigate, zoom, and click on features for detailed information. You can also change the map’s background using layers like ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap, with ESRI.WorldGrayCanvas as the default.\n\n\n\n\n\n\nTip\n\n\n\nRemember to switch back to plot mode after interacting to avoid connection issues and limit interactive maps to fewer than 10 in RMarkdown documents for Netlify publishing."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#geospatial-data-wrangling",
    "title": "2A: 1st Order Spatial Point Patterns Analysis",
    "section": "9 Geospatial Data Wrangling",
    "text": "9 Geospatial Data Wrangling\nWhile simple feature data frames are becoming more popular compared to sp’s Spatial* classes, many geospatial analysis packages still require data in the Spatial* format. This section will show you how to convert a simple feature data frame to sp’s Spatial* class.\n\n9.1 Converting sf data frames to sp’s Spatial* class\nThe code block below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nAfter the sf dataframe to sp Spatial* conversion, let’s inspect the Spatial* classes.\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\nThe geospatial data have been converted into their respective sp’s Spatial* classes.\n\n\n9.2 Converting the Spatial* Class into Generic sp Format\nspatstat requires the analytical data in ppp object form. There is no straightforward way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\n\n\n\n\n\n\nTip\n\n\n\nppp refers to planar point pattern. It is used to represent spatial point patterns in spatstat; it contains the event locations with possibly associated marks, and the observation window where the events occur.\nsee Chapter 18 The spatstat package | Spatial Statistics for Data Science: Theory and Practice with R\n\n\nThe codes block below converts the Spatial* classes into generic sp objects.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nNext, we can display the sp objects properties.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\nLet’s further inspect the differences between Spatial* classes and generic sp object with the example of childcare and childcare_sp object.\n\nhead(childcare)\n\n   Name\n1 kml_1\n2 kml_2\n3 kml_3\n4 kml_4\n5 kml_5\n6 kml_6\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Description\n1 &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;760742&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;742, YISHUN AVENUE 5, #01 - 470, SINGAPORE 760742&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;AVERBEL CHILD DEVELOPMENT CENTRE PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;AEA27114446235CE&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n2                                    &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;159053&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;20, LENGKOK BAHRU, #02 - 05, SINGAPORE 159053&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;AWWA LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;86B24416FB1663C6&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n3        &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;556912&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;22, LI HWAN VIEW, GOLDEN HILL ESTATE, SINGAPORE 556912&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;BABIES BY-THE-PARK PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;F971CBBA973E1AE5&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n4 &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;569139&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;3, ANG MO KIO STREET 62, #01 - 36, LINK@AMK, SINGAPORE 569139&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;Baby Elk Infant Care Pte Ltd&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;86A4F25D1C7C9D85&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n5                           &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;467961&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;22A, KEW DRIVE, SINGAPORE 467961&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;BABYPLANET MONTESSORI PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;CFE3F056F8171C7B&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n6                       &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;598523&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;3 Jalan Kakatua, JURONG PARK, SINGAPORE 598523&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;BAMBINI CHILDCARE LLP&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;2B4F0B285ED28C4A&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n\n\n\nhead(childcare_sp)\n\nclass       : SpatialPoints \nfeatures    : 1 \nextent      : 27976.73, 27976.73, 45716.7, 45716.7  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\nNote that the Spatial* classes contain more attribute data as compared its generic sp object counterpart.\n\n\n\n\n\n\nTip\n\n\n\nDifferences between Spatial* classes and generic sp object\n\nData Storage: SpatialPoints stores only the coordinates, while SpatialPointsDataFrame stores both coordinates and additional attribute data\nFunctionality: SpatialPointsDataFrame allows for more complex operations and analyses due to the additional data it holds\n\nsee Introduction to spatial points in R - Michael T. Hallworth, Ph.D.\n\n\n\n\n9.3 Converting the Generic sp Format into spatstat’s ppp Format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nLet’s examine the difference by plotting childcare_ppp:\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nWe can also view the summary statistics of the newly created ppp object by using the code block below.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\n\n\n\n\nTip\n\n\n\nBe aware of the warning message regarding duplicates. In spatial point pattern analysis, duplicates can be a significant issue. The statistical methods used for analyzing spatial point patterns often assume that the points are distinct and non-coincident.\n\n\n\n\n9.4 Handling Duplicated Points\nWe can check the duplication in a ppp object by using the duplicated function with different configurations.\n\n\n\n\n\n\nTip\n\n\n\nThe duplicated function has an argument rule:\n\nDefault Behavior (rule = \"spatstat\"):\n\nPoints are considered identical if both their coordinates (like x and y positions) and their marks (additional data or labels attached to the points) are exactly the same.\nThis is the strictest check, requiring everything about the points to match.\n\nOnly Checking Coordinates (rule = \"unmark\"):\n\nPoints are considered duplicates if their coordinates are the same, regardless of their marks.\nMarks are ignored, so only the positions are compared.\n\nUsing deldir Package (rule = \"deldir\"):\n\nPoints are considered duplicates based on their coordinates, but the comparison is done using a specific method (duplicatedxy) from the deldir package.\nThis approach ensures the check is consistent with other functions in the deldir package, which is often used for spatial data analysis (like creating Delaunay triangulations).\n\n\nIn other words,\n\nrule = \"spatstat\": Strict check (coordinates and marks).\nrule = \"unmark\": Less strict (coordinates only).\nrule = \"deldir\": Coordinate check, consistent with the deldir package methods.\n\nsee R: Determine Duplicated Points in a Spatial Point Pattern\n\n\n\n# duplicated(childcare_ppp)\n# any(duplicated(childcare_ppp))\nrules &lt;- c(\"spatstat\", \"deldir\", \"unmark\")\n\nduplicate_counts &lt;- list()\nfor (rule in rules) {\n  duplicates &lt;- duplicated(childcare_ppp, rule = rule)\n  num_duplicates &lt;- sum(duplicates)\n  duplicate_counts[[rule]] &lt;- num_duplicates\n}\n\nprint(duplicate_counts)\n\n$spatstat\n[1] 0\n\n$deldir\n[1] 0\n\n$unmark\n[1] 74\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that this behavior happens because the data contains marked points with the same coordinates but different properties.\nUpon manual inspection, a set of example is “39, WOODLANDS CLOSE, #01 - 62, MEGA@WOODLANDS, SINGAPORE 737856” and “39, WOODLANDS CLOSE, #01 - 59, MEGA@WOODLANDS, SINGAPORE 737856”.\nThese are 2 childcare centres that resides in the same building. Thus, it can only be picked up using the “unmark” rule which only examine for exact match of the point coordinate only.\n\n\nTo count the number of coincident points, we will use the multiplicity() function as shown in the code block below. see R: Multiplicity for more info.\n\nmultiplicity(childcare_ppp)\n\nIf we want to know how many locations have more than one point event:\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\n\n# double check\ncoincident_points &lt;- duplicated(childcare_ppp,  rule=\"unmark\")\ncoincident_coordinates &lt;- childcare_ppp[coincident_points]\nprint(coincident_coordinates)\n\nMarked planar point pattern: 74 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nThe output shows that there are 74 duplicated point events.\n\n\n9.5 How to Spot Duplicate Points on the Map\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\n\n9.5.1 Jittering\nThe code block below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp,\n                             retry=TRUE,\n                             nsim=1,\n                             drop=TRUE)\n\nplot(childcare_ppp_jit, pch = 16, cex = 0.5, main = \"Jittered Points\")\n\n\n\n\n\n\n\n\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n\n9.6 Creating owin Object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code block below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe output object can be displayed by using plot() function:\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\nAnd using summary() function of Base R:\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#combining-point-events-object-and-owin-object",
    "title": "2A: 1st Order Spatial Point Patterns Analysis",
    "section": "10 Combining Point Events Object and Owin Object",
    "text": "10 Combining Point Events Object and Owin Object\nFor the last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code block below.\n\n\n\n\n\n\nImportant\n\n\n\nSince the dataset contains duplicated points, we will use the jittered ppp object for downstream analysis.\n\n\n\nchildcareSG_ppp &lt;- childcare_ppp_jit[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#first-order-spatial-point-patterns-analysis",
    "title": "2A: 1st Order Spatial Point Patterns Analysis",
    "section": "11 First-order Spatial Point Patterns Analysis",
    "text": "11 First-order Spatial Point Patterns Analysis\nIn this section, you will learn how to perform first-order SPPA by using spatstat package. The hands-on exercise will focus on:\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes,\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\n\n\n11.1 Kernel Density Estimation\nIn this section, you will learn how to compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n11.1.1 Computing Kernel Density Estimation Using Automatic Bandwidth Selection Method\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\n\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\n\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\")\n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nThe density values of the output range from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of SVY21 is in meter. As a result, the density values computed is in “number of points per square meter”.\nBefore we move on to next section, it is good to know that you can retrieve the bandwidth used to compute the kde layer by using the code block below.\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n414.4576 \n\n\n\n\n11.1.2 Rescaling KDE values\nrescale.ppp() is used below to convert the unit of measurement from meter to kilometer:\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the resale data set and plot the output kde map.\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\nSince we just did a rescaling operation, the output image looks identical to the earlier version with the only changes in terms of data values.\n\n\n\n11.2 Working with Different Automatic Bandwidth Methods\nBeside bw.diggle(), there are 3 other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\nLet us take a look at the bandwidth return by these automatic bandwidth calculation methods by using:\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n5.009037 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224958 1.451103 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n   sigma \n0.273598 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.4144576 \n\n\nBaddeley et al. (2016) suggest using the bw.ppl() algorithm, as it tends to produce more appropriate values when the pattern consists predominantly of tight clusters. However, they also note that if the aim of a study is to detect a single tight cluster amidst random noise, the bw.diggle() method is likely to be more effective.\nTo compare the output of using bw.diggle and bw.ppl methods:\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km,\n                               sigma=bw.ppl,\n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\n\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#working-with-different-kernel-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#working-with-different-kernel-methods",
    "title": "2A: 1st Order Spatial Point Patterns Analysis",
    "section": "12 6.3 Working with Different Kernel Methods",
    "text": "12 6.3 Working with Different Kernel Methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics. Let us take a look at what they look like:\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Gaussian\")\n\nplot(density(childcareSG_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"epanechnikov\"),\n     main=\"Epanechnikov\")\n\nplot(density(childcareSG_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"quartic\"),\n     main=\"Quartic\")\n\nplot(density(childcareSG_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"disc\"),\n     main=\"Disc\")\n\n\n\n\n\n\n\n\nObservations: In this dataset, the choice of kernel function has only a minor impact on the overall density plots. The Gaussian, Epanechnikov, and Quartic kernels produce smoother transitions and distribute the density over a broader area. In contrast, the Disc kernel provides a more localized density estimation with sharper boundaries and less smoothness."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#fixed-and-adaptive-kde",
    "title": "2A: 1st Order Spatial Point Patterns Analysis",
    "section": "13 Fixed and Adaptive KDE",
    "text": "13 Fixed and Adaptive KDE\n\n13.1 Computing KDE by using Fixed Bandwidth\nNext, we will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code block below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\nIn this section, we will learn how to derive adaptive kernel density estimation by using density.adaptive() of spatstat.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using:\n\npar(mfrow=c(1,2))\n\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n13.2 Converting KDE Output into Grid Object\nTo achieve the same result, we convert the object to a format suitable for mapping:\n\ngridded_kde_childcareSG_bw &lt;- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n13.2.1 Converting Grided Output into Raster\nNext, we will convert the gridded kernel density objects into RasterLayer object by using raster() of raster package.\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\n\nLet us take a look at the properties of kde_childcareSG_bw_raster RasterLayer.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -1.006362e-14, 21.11878  (min, max)\n\n\nNote that the crs property is NA.\n\n\n13.2.2 Assigning Projection Systems\nTo include the CRS information on kde_childcareSG_bw_raster RasterLayer, we will do the following:\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -1.006362e-14, 21.11878  (min, max)\n\n\nNow, the crs property is completed.\n\n\n\n13.3 Visualising the output in tmap\nFinally, we will display the raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_raster) +\n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\n\nvalues(kde_childcareSG_bw_raster)\n\nNote that the raster values are encoded explicitly onto the raster pixel using the values in “v” field.\n\n\n13.4 Comparing Spatial Point Patterns using KDE\nIn this section, we will learn how to compare KDE of childcare at Punggol, Tampines, Chua Chu Kang and Jurong West planning areas.\n\n13.4.1 Extracting Study Area\nThe code block below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting the target planning areas:\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n13.4.2 Creating owin object\nNow, we will convert these sf objects into owin objects that is required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n13.4.3 Combining Childcare Points and the Study Area\nTo extract childcare that is within the specific region for analysis, we can use:\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to transform the unit of measurement from meter to kilometer.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code block below is used to plot the four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\n\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n13.4.4 Computing KDE\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each area.\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km,\n             sigma=bw.diggle,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km,\n             sigma=bw.diggle,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Tampines\")\nplot(density(childcare_ck_ppp.km,\n             sigma=bw.diggle,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km,\n             sigma=bw.diggle,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n13.4.5 Computing Fixed Bandwidth KDE\nWe will set the bandwidth as 250m for comparison purposes.\n\npar(mfrow=c(2,2))\n\nplot(density(childcare_ck_ppp.km,\n             sigma=0.25,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\n\nplot(density(childcare_jw_ppp.km,\n             sigma=0.25,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\nplot(density(childcare_pg_ppp.km,\n             sigma=0.25,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Punggol\")\n\nplot(density(childcare_tm_ppp.km,\n             sigma=0.25,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#nearest-neighbour-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#nearest-neighbour-analysis",
    "title": "2A: 1st Order Spatial Point Patterns Analysis",
    "section": "14 Nearest Neighbour Analysis",
    "text": "14 Nearest Neighbour Analysis\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\n\n\n\n\n\n\nNote\n\n\n\nClarks-Evans Test\nThe Clark-Evans test is a statistical test used to determine whether points in a given space are randomly distributed, clustered, or regularly spaced.\nThe Clark-Evans test is a statistical test used to determine whether points in a given space are randomly distributed, clustered, or regularly spaced. It is commonly used in spatial analysis, particularly in nearest neighbor analysis, to understand the pattern of points (such as locations of trees, animals, or buildings) in a study area.\nHow the Clark-Evans Test Works:\n\nThe test calculates the average distance from each point in the dataset to its nearest neighbor.\nThis observed average distance is compared to the expected average distance for a random distribution of points in the same area.\nThe result is a Clark-Evans ratio (R):\n\nR = 1: Points are randomly distributed.\nR &lt; 1: Points are clustered together.\nR &gt; 1: Points are more evenly spaced or regularly distributed.\n\n\nThe alternative argument: The null hypothesis is Complete Spatial Randomness, i.e. a uniform Poisson process. The alternative hypothesis is specified by the argument alternative:\n\nalternative=\"less\" or alternative=\"clustered\": the alternative hypothesis is that corresponding to a clustered point pattern;\nalternative=\"greater\" or alternative=\"regular\": the alternative hypothesis is that corresponding to a regular or ordered point pattern;\nalternative=\"two.sided\": the alternative hypothesis is that corresponding to a clustered or regular pattern.\n\nsee Tests for Spatial Randomness - The R Book [Book]\n\n\n\n14.1 Testing Spatial Point Patterns using Clark and Evans Test\nThe test hypotheses are:\n\\(H_o\\) = The distribution of childcare services are randomly distributed.\n\\(H_1\\) = The distribution of childcare services are not randomly distributed.\nThe 95% confidence interval will be used.\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=39)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.56703, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n\n\n\n\nNote\n\n\n\nResult Interpretation\n\nGiven that R, the Clark-Evans ratio, is 0.56703, it indicates that the childcare services are clustered rather than randomly distributed. The further R is from 1 (and closer to 0), the stronger the clustering.\nThe p-value is extremely small (much less than the standard significance level of 0.05).\nAt a 95% confidence level, we can reject the null hypothesis of random distribution and accept the alternative hypothesis that the services are clustered.\n\n\n\n\n\n14.2 Clark and Evans Test: Choa Chu Kang Planning Area\nNow, we perform the similar test on individual subzone areas. We will analyse the Choa Chu Kang area first.\n\n\n\n\n\n\nNote\n\n\n\nChoice of nsim: The choice of 39 simulations (nsim = 39) in Monte Carlo techniques for spatial analysis is often a practical compromise between computational efficiency and statistical robustness.\n\nComputational Efficiency: Running a large number of simulations can be computationally expensive, especially for complex spatial analyses. We can strike a balance between obtaining reliable results and keeping computational costs manageable by selecting absolute minimum sample size.\n\nThe minimum number of simulations \\(m\\) required for a Monte Carlo test at a particular significance level can be determined by:\n\\(\\alpha = \\frac{1}{m+1}\\)\nfor a one-tailed test and\n\\(\\alpha = \\frac{2}{m+1}\\)\nThus, a one-tailed test at a significance level of 5% would require a minimum of 19 simulations, a two-tailed test at a significance level of 5% would require a minimum of 39 simulations.\nsee Going beyond the required number of simulations required for a particular significance level when conducting a Monte Carlo test - Cross Validated, spatial statistics - Simulation envelopes and significance levels - Geographic Information Systems Stack Exchange\n\n\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=39)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.95041, p-value = 0.4587\nalternative hypothesis: two-sided\n\n\n\n\n\n\n\n\nNote\n\n\n\nResult Interpretation\n\nGiven that R, the Clark-Evans ratio, is 0.95041, it indicates that the distribution of childcare services is closer to random with minimal clustering. Since R is close to 1 and not significantly less, there is little evidence of clustering or regular spacing.\n\nThe p-value is 0.4587, which is much larger than the standard significance level of 0.05.\nAt a 95% confidence level, we fail to reject the null hypothesis of random distribution. The two-sided alternative hypothesis suggests that the distribution could be either clustered or regularly spaced, but the data does not provide enough evidence to support significant clustering or regularity.\n\n\n\n\n14.3 Clark and Evans Test: Tampines Planning Area\nNext, we will analyse the spatial point patterns of childcare centre in Tampines planning area using the Clark-Evans test\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=39)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.80393, p-value = 0.0004022\nalternative hypothesis: two-sided\n\n\n\n\n\n\n\n\nNote\n\n\n\nResult Interpretation\nGiven that R, the Clark-Evans ratio, is 0.80393, it indicates that the distribution of childcare services shows a significant level of clustering. Since R is notably less than 1, there is strong evidence of clustering.\nThe p-value is 0.0004022, which is much smaller than the standard significance level of 0.05.\nAt a 95% confidence level, we reject the null hypothesis of random distribution and accept the alternative hypothesis that the distribution is not random. The two-sided alternative hypothesis suggests that the distribution could be either clustered or regularly spaced, but in this case, the significantly lower R value supports the conclusion of clustering."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html",
    "title": "4A: Spatial Weights and Applications",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 8  Spatial Weights and Applications"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#exercise-4a-reference",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#exercise-4a-reference",
    "title": "4A: Spatial Weights and Applications",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 8  Spatial Weights and Applications"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#overview",
    "title": "4A: Spatial Weights and Applications",
    "section": "2 Overview",
    "text": "2 Overview\nIn this exercise, we will learn to compute spatial weights, visualize spatial distributions, and create spatially lagged variables using various functions from R packages such as sf, spdep, and tmap."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#learning-outcome",
    "title": "4A: Spatial Weights and Applications",
    "section": "3 Learning Outcome",
    "text": "3 Learning Outcome\n\nImport geospatial data using functions from the sf package.\nImport CSV data using functions from the readr package.\nPerform relational joins using functions from the dplyr package.\nCompute spatial weights with functions from the spdep package.\nCalculate spatially lagged variables using functions from the spdep package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#the-data",
    "title": "4A: Spatial Weights and Applications",
    "section": "4 The Data",
    "text": "4 The Data\nThe following 2 datasets will be used in this exercise.\n\n\n\n\n\n\n\n\nData Set\nDescription\nFormat\n\n\n\n\nHunan county boundary layer\nGeospatial data set representing the county boundaries of Hunan\nESRI Shapefile\n\n\nHunan_2012.csv\nContains selected local development indicators for Hunan in 2012\nCSV"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#installing-and-loading-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#installing-and-loading-the-r-packages",
    "title": "4A: Spatial Weights and Applications",
    "section": "5 Installing and Loading the R Packages",
    "text": "5 Installing and Loading the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\n\nsf\nImports, manages, and processes vector-based geospatial data.\nHandling vector geospatial data such as the Hunan county boundary layer in shapefile format.\n\n\nspdep\nProvides functions for spatial dependence analysis, including spatial weights and spatial autocorrelation.\nComputing spatial weights and creating spatially lagged variables.\n\n\ntmap\nCreates static and interactive thematic maps using cartographic quality elements.\nVisualizing regional development indicators and plotting maps showing spatial relationships and patterns.\n\n\ntidyverse\nA collection of packages for data science tasks such as data manipulation, visualization, and modeling.\nImporting CSV files, wrangling data, and performing relational joins.\n\n\nknitr\nEnables dynamic report generation and integration of R code with documents.\nFormatting output, creating tables, and generating reports for the exercise.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#import-data-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#import-data-and-preparation",
    "title": "4A: Spatial Weights and Applications",
    "section": "6 Import Data and Preparation",
    "text": "6 Import Data and Preparation\nIn this section, we will perform 3 necessary steps to prepare the data for analysis.\n\n6.1 Import Geospatial Shapefile\nFirstly, we will use st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex04/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\ndim(hunan)\n\n[1] 88  8\n\n\n\n\n6.2 Import Aspatial csv File\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\ndim(hunan2012)\n\n[1] 88 29\n\n\n\n\n6.3 Perform Relational Join\nBefore we perform relational join, let’s observe the columns in each dataset and only select the columns that we need.\n\nhunan columns:\n\n\nprint(colnames(hunan))\n\n[1] \"NAME_2\"     \"ID_3\"       \"NAME_3\"     \"ENGTYPE_3\"  \"Shape_Leng\"\n[6] \"Shape_Area\" \"County\"     \"geometry\"  \n\n\n\nhunan2012 columns:\n\n\nprint(colnames(hunan2012))\n\n [1] \"County\"      \"City\"        \"avg_wage\"    \"deposite\"    \"FAI\"        \n [6] \"Gov_Rev\"     \"Gov_Exp\"     \"GDP\"         \"GDPPC\"       \"GIO\"        \n[11] \"Loan\"        \"NIPCR\"       \"Bed\"         \"Emp\"         \"EmpR\"       \n[16] \"EmpRT\"       \"Pri_Stu\"     \"Sec_Stu\"     \"Household\"   \"Household_R\"\n[21] \"NOIP\"        \"Pop_R\"       \"RSCG\"        \"Pop_T\"       \"Agri\"       \n[26] \"Service\"     \"Disp_Inc\"    \"RORP\"        \"ROREmp\"     \n\n\nAfter merging:\n\nhunan_joined &lt;- left_join(hunan,hunan2012)\nprint(colnames(hunan_joined))\n\n [1] \"NAME_2\"      \"ID_3\"        \"NAME_3\"      \"ENGTYPE_3\"   \"Shape_Leng\" \n [6] \"Shape_Area\"  \"County\"      \"City\"        \"avg_wage\"    \"deposite\"   \n[11] \"FAI\"         \"Gov_Rev\"     \"Gov_Exp\"     \"GDP\"         \"GDPPC\"      \n[16] \"GIO\"         \"Loan\"        \"NIPCR\"       \"Bed\"         \"Emp\"        \n[21] \"EmpR\"        \"EmpRT\"       \"Pri_Stu\"     \"Sec_Stu\"     \"Household\"  \n[26] \"Household_R\" \"NOIP\"        \"Pop_R\"       \"RSCG\"        \"Pop_T\"      \n[31] \"Agri\"        \"Service\"     \"Disp_Inc\"    \"RORP\"        \"ROREmp\"     \n[36] \"geometry\"   \n\n\nThen only select the columns that we need:\n\nhunan &lt;- hunan_joined %&gt;%\n  select(1:4, 7, 15)\n\nprint(colnames(hunan))\n\n[1] \"NAME_2\"    \"ID_3\"      \"NAME_3\"    \"ENGTYPE_3\" \"County\"    \"GDPPC\"    \n[7] \"geometry\" \n\n\nIn the code above, we use the left_join() function to merge the hunan SpatialPolygonsDataFrame with the hunan2012 dataframe. The join is based on the column named County, which is common to both datasets. This allows us to match rows by their corresponding counties.\nAfter the join, the select() function is used to retain a subset of columns from the merged dataset. We can briefly observe the joined output below.\n\nhead(hunan)\n\nSimple feature collection with 6 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667\n2 Changde 21100 Hanshou      County Hanshou 20981\n3 Changde 21101  Jinshi County City  Jinshi 34592\n4 Changde 21102      Li      County      Li 24473\n5 Changde 21103   Linli      County   Linli 25554\n6 Changde 21104  Shimen      County  Shimen 27137\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-regional-development-indicator",
    "title": "4A: Spatial Weights and Applications",
    "section": "7 Visualising Regional Development Indicator",
    "text": "7 Visualising Regional Development Indicator\nTo visualize the regional development indicator, we can prepare a base map and a choropleth map to show the distribution of GDPPC 2012 (GDP per capita) by using qtm() of tmap package.\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIntepretation The choropleth map on the right visualizes the distribution of GDP per capita (GDPPC) for the year 2012 across the different counties in Hunan.\nThe counties are shaded in varying colors, ranging from light to dark, to represent different GDP per capita ranges. Darker shades indicate higher GDP per capita values, while lighter shades represent lower values. This visualization helps to identify regional economic disparities and highlights areas with higher or lower economic activity within Hunan province.\nFor example, we can observe that Changsha has the highest GDP per capital values in the Hunan region."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#computing-contiguity-spatial-weights",
    "title": "4A: Spatial Weights and Applications",
    "section": "8 Computing Contiguity Spatial Weights",
    "text": "8 Computing Contiguity Spatial Weights\nIn this section, we will use poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries.\n\n\n\n\n\n\nNote\n\n\n\nContiguity means that two spatial units share a common border of non-zero length.\nOperationally, we can further distinguish between a rook and a queen criterion of contiguity, in analogy to the moves allowed for the such-named pieces on a chess board.\nThe rook criterion defines neighbors by the existence of a common edge between two spatial units. The queen criterion is somewhat more encompassing and defines neighbors as spatial units sharing a common edge or a common vertex.\nUsing poly2nb() we can use the queen flag to toggle between queen and rook criteria.\nFor more info, see Chapter 6 Contiguity-Based Spatial Weights | Hands-On Spatial Data Science with R\n\n\n\nThe number of neighbors according to the queen criterion will always be at least as large as for the rook criterion.\n\nFirst, we will compute the Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\n\n\n\n\n\n\nNote\n\n\n\nIntepretation of Summary Reports\n\nBoth reports shows that there are 88 area units in Hunan.\nAs expected, the total number of links (neighbor relationships) is slightly higher for the queen criterion (448) than for the rook criterion (440).\nBased on both criteria, the most connected region is Region 85 with 11 links (using Queen criteria) and 10 links (using Rook criteria)\nSimilarly, based on both criteria, the least connected region is Region 30 and 65 with 1 links (using Queen and Rook criteria)\n\n\n\nFor each polygon in the polygon object, wm_q and wm_r lists all neighboring polygons. For example, we can identify the most connected region.\n\ncat(\"The most connected county is\", hunan$County[85])\n\nThe most connected county is Taoyuan\n\n\nTo reveal the county names of the neighboring polygons, we can do the following:\n\nneighbour_counties &lt;- wm_q[[85]]\nprint(neighbour_counties)\n\n [1]  1  2  3  5  6 32 56 57 69 75 78\n\ncat(\"Using Queen's method, the neighbours of \", hunan$County[85],\" is\", hunan$NAME_3[neighbour_counties])\n\nUsing Queen's method, the neighbours of  Taoyuan  is Anxiang Hanshou Jinshi Linli Shimen Yuanling Anhua Nan Cili Sangzhi Taojiang\n\n\nWe can also retrieve the GDPPC of these counties:\n\nhunan$GDPPC[neighbour_counties]\n\n [1] 23667 20981 34592 25554 27137 24194 14567 21311 18714 14624 19509\n\n\nThe printed output above shows that the GDPPC of Taoyuan’s neighbouring counties.\nTo display the complete weight matrix, we can use str().\n\nstr(wm_q)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-contiguity-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-contiguity-weights",
    "title": "4A: Spatial Weights and Applications",
    "section": "9 Visualising Contiguity Weights",
    "text": "9 Visualising Contiguity Weights\nTo create a connectivity graph, we need points that represent each polygon, and we’ll draw lines to connect neighboring points. Since we’re working with polygons, we first need to find their central points, called centroids. We’ll calculate these centroids using the sf package before creating the connectivity graph.\nGetting Latitude and Longitude of Polygon Centroids\nTo make the connectivity graph, we must first obtain the points (centroids) for each polygon. This is more than just running st_centroid on our spatial object (us.bound). We need to store the coordinates in a separate data frame.\nWe’ll use a mapping function to achieve this. The mapping function applies a specific function to each element in a vector and returns a vector of the same length. In this case, our input vector will be the geometry column of us.bound, and the function will be st_centroid. We’ll use the map_dbl function from the purrr package to do this.\nFor longitude, we access the first coordinate value using [[1]], and for latitude, we access the second coordinate value using [[2]].\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nThen, we use cbind() to combine longitude and lattude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nTo verify that, the data is formatted correctly, we can observe the first few instances.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\nTo plot the continguity-based neighbours map, we can do the following:\n\npar(mfrow=c(1,2))\n\nplot(hunan$geometry, \n     main=\"Queen Contiguity\")\nplot(wm_q, \n     coords, \n     pch = 19, \n     cex = 0.6, \n     add = TRUE, \n     col= \"red\")\n\nplot(hunan$geometry, \n     main=\"Rook Contiguity\")\nplot(wm_r, \n     coords, \n     pch = 19, \n     cex = 0.6, \n     add = TRUE, \n     col = \"red\")\n\n\n\n\n\n\n\n\n ::: callout-note As observed from the previous sections, we understand that more links will be formed with the Queen’s method. This is evident in the plot above.Some of these differences has been marked with blue boxes for better visualization. :::"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#computing-distance-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#computing-distance-based-neighbours",
    "title": "4A: Spatial Weights and Applications",
    "section": "10 Computing Distance-based Neighbours",
    "text": "10 Computing Distance-based Neighbours\nIn this section, we will create distance-based weight matrices using the dnearneigh() function from the spdep package.\nThis function identifies neighboring region points based on their Euclidean distance. We can specify a range for the distances using the bounds argument, which takes lower (d1=) and upper (d2=) limits.\nIf the coordinates are not projected (i.e., in latitude and longitude) and are specified in the x object or provided as a two-column matrix with longlat=TRUE, the function will calculate great circle distances in kilometers, assuming the WGS84 reference ellipsoid.\n\n10.1 Determine the Cut-off Distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nUse the knearneigh() function from the spdep package to create a matrix with the indices of the k nearest neighbors for each point.\n\n\n# get k nearest neighbour where k = 1 (default)\nknearneigh(coords, k=1)\n\n$nn\n      [,1]\n [1,]    3\n [2,]   78\n [3,]    1\n [4,]    5\n [5,]    4\n [6,]   69\n [7,]   67\n [8,]   46\n [9,]   84\n[10,]   70\n[11,]   72\n[12,]   63\n[13,]   12\n[14,]   17\n[15,]   13\n[16,]   22\n[17,]   16\n[18,]   20\n[19,]   21\n[20,]   82\n[21,]   19\n[22,]   16\n[23,]   41\n[24,]   54\n[25,]   81\n[26,]   81\n[27,]   29\n[28,]   49\n[29,]   27\n[30,]   33\n[31,]   24\n[32,]   50\n[33,]   28\n[34,]   45\n[35,]   47\n[36,]   34\n[37,]   42\n[38,]   44\n[39,]   43\n[40,]   39\n[41,]   23\n[42,]   37\n[43,]   44\n[44,]   43\n[45,]   34\n[46,]   47\n[47,]   46\n[48,]   51\n[49,]   28\n[50,]   52\n[51,]   48\n[52,]   54\n[53,]   55\n[54,]   52\n[55,]   50\n[56,]   36\n[57,]   58\n[58,]   57\n[59,]   87\n[60,]   13\n[61,]   63\n[62,]   61\n[63,]   12\n[64,]   57\n[65,]   76\n[66,]   68\n[67,]    7\n[68,]   66\n[69,]    6\n[70,]   10\n[71,]   74\n[72,]   11\n[73,]   70\n[74,]   71\n[75,]   55\n[76,]   65\n[77,]   38\n[78,]    2\n[79,]   45\n[80,]   34\n[81,]   25\n[82,]   21\n[83,]   12\n[84,]    9\n[85,]    5\n[86,]   74\n[87,]   61\n[88,]   87\n\n$np\n[1] 88\n\n$k\n[1] 1\n\n$dimension\n[1] 2\n\n$x\n      longitude latitude\n [1,]  112.1531 29.44362\n [2,]  112.0372 28.86489\n [3,]  111.8917 29.47107\n [4,]  111.7031 29.74499\n [5,]  111.6138 29.49258\n [6,]  111.0341 29.79863\n [7,]  113.7065 28.23215\n [8,]  112.3460 28.13081\n [9,]  112.8169 28.28918\n[10,]  113.3534 26.57906\n[11,]  113.8942 25.98122\n[12,]  112.4006 25.63215\n[13,]  112.5542 25.33880\n[14,]  113.6636 25.54967\n[15,]  112.9206 25.26722\n[16,]  113.1883 26.21248\n[17,]  113.4521 25.93480\n[18,]  112.4209 26.36132\n[19,]  113.0152 27.08120\n[20,]  112.6350 26.75969\n[21,]  112.7087 27.27930\n[22,]  112.9095 26.42079\n[23,]  111.9522 26.80117\n[24,]  110.2606 27.89384\n[25,]  110.0921 27.54115\n[26,]  109.7985 26.91321\n[27,]  109.5765 26.54507\n[28,]  109.7211 27.78801\n[29,]  109.7339 26.21157\n[30,]  109.1537 27.22941\n[31,]  110.6442 27.83407\n[32,]  110.5916 28.57282\n[33,]  109.5984 27.39828\n[34,]  111.4783 27.67997\n[35,]  112.1745 27.46256\n[36,]  111.2315 27.86930\n[37,]  110.3149 26.32113\n[38,]  111.3248 26.48991\n[39,]  110.5859 27.10164\n[40,]  110.9593 27.34884\n[41,]  111.8296 27.18765\n[42,]  110.1926 26.70972\n[43,]  110.7334 26.78494\n[44,]  110.9123 26.54354\n[45,]  111.4599 27.42910\n[46,]  112.5268 27.92456\n[47,]  112.3406 27.77407\n[48,]  109.5602 28.66808\n[49,]  109.5071 28.01142\n[50,]  109.9954 28.60033\n[51,]  109.4273 28.42749\n[52,]  109.7587 28.31518\n[53,]  109.5044 29.21940\n[54,]  109.9899 28.16053\n[55,]  109.9664 29.01206\n[56,]  111.3785 28.28449\n[57,]  112.4350 29.23817\n[58,]  112.5558 28.97135\n[59,]  111.7379 24.97087\n[60,]  112.1831 25.31559\n[61,]  111.9743 25.65101\n[62,]  111.7009 25.91101\n[63,]  112.2196 25.88615\n[64,]  112.6472 29.48614\n[65,]  113.5102 29.49285\n[66,]  113.1172 28.79707\n[67,]  113.7089 28.76024\n[68,]  112.7963 28.71653\n[69,]  110.9276 29.39439\n[70,]  113.6420 26.80361\n[71,]  113.4577 27.66123\n[72,]  113.8404 26.37989\n[73,]  113.4758 27.17064\n[74,]  113.1428 27.62875\n[75,]  110.3017 29.39053\n[76,]  113.1957 29.25343\n[77,]  111.7410 26.36035\n[78,]  112.1831 28.49854\n[79,]  111.3390 27.01465\n[80,]  111.8208 27.75124\n[81,]  110.0753 27.23539\n[82,]  112.3965 27.08323\n[83,]  112.7683 25.82828\n[84,]  113.1679 28.30074\n[85,]  111.4495 28.95406\n[86,]  112.7956 27.68910\n[87,]  111.5896 25.49530\n[88,]  111.2393 25.19355\n\nattr(,\"class\")\n[1] \"knn\"\nattr(,\"call\")\nknearneigh(x = coords, k = 1)\n\n\n\nConvert the knn object returned by knearneigh() into a neighbor list (nb class) using the knn2nb() function. This list contains integer vectors representing the IDs of neighboring regions.\n\n\n# convert knn matrix to neighbour list for k = 1\nk1 &lt;- knn2nb(knearneigh(coords))\nk1\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 88 \nPercentage nonzero weights: 1.136364 \nAverage number of links: 1 \n25 disjoint connected subgraphs\nNon-symmetric neighbours list\n\n\n\nCalculate the length of neighbor relationship edges with the nbdists() function from spdep. The distances will be in the units of the coordinates if projected, or in kilometers if not.\n\n\nnbdists(k1, coords, longlat = TRUE)\n\n[[1]]\n[1] 25.53398\n\n[[2]]\n[1] 43.03114\n\n[[3]]\n[1] 25.53398\n\n[[4]]\n[1] 29.2848\n\n[[5]]\n[1] 29.2848\n\n[[6]]\n[1] 45.98097\n\n[[7]]\n[1] 58.52704\n\n[[8]]\n[1] 28.95985\n\n[[9]]\n[1] 34.45062\n\n[[10]]\n[1] 37.99885\n\n[[11]]\n[1] 44.49442\n\n[[12]]\n[1] 33.48816\n\n[[13]]\n[1] 35.98123\n\n[[14]]\n[1] 47.65184\n\n[[15]]\n[1] 37.73556\n\n[[16]]\n[1] 36.16613\n\n[[17]]\n[1] 40.53569\n\n[[18]]\n[1] 49.02492\n\n[[19]]\n[1] 37.47543\n\n[[20]]\n[1] 42.97316\n\n[[21]]\n[1] 37.47543\n\n[[22]]\n[1] 36.16613\n\n[[23]]\n[1] 44.51898\n\n[[24]]\n[1] 39.7744\n\n[[25]]\n[1] 33.9218\n\n[[26]]\n[1] 45.03425\n\n[[27]]\n[1] 40.15056\n\n[[28]]\n[1] 32.50795\n\n[[29]]\n[1] 40.15056\n\n[[30]]\n[1] 47.83345\n\n[[31]]\n[1] 38.35439\n\n[[32]]\n[1] 58.39365\n\n[[33]]\n[1] 44.85211\n\n[[34]]\n[1] 27.85864\n\n[[35]]\n[1] 38.2151\n\n[[36]]\n[1] 32.12293\n\n[[37]]\n[1] 44.74688\n\n[[38]]\n[1] 41.53815\n\n[[39]]\n[1] 38.02669\n\n[[40]]\n[1] 46.029\n\n[[41]]\n[1] 44.51898\n\n[[42]]\n[1] 44.74688\n\n[[43]]\n[1] 32.1334\n\n[[44]]\n[1] 32.1334\n\n[[45]]\n[1] 27.85864\n\n[[46]]\n[1] 24.79082\n\n[[47]]\n[1] 24.79082\n\n[[48]]\n[1] 29.66852\n\n[[49]]\n[1] 32.50795\n\n[[50]]\n[1] 39.19375\n\n[[51]]\n[1] 29.66852\n\n[[52]]\n[1] 28.43598\n\n[[53]]\n[1] 50.50645\n\n[[54]]\n[1] 28.43598\n\n[[55]]\n[1] 45.721\n\n[[56]]\n[1] 48.22649\n\n[[57]]\n[1] 31.82332\n\n[[58]]\n[1] 31.82332\n\n[[59]]\n[1] 59.98421\n\n[[60]]\n[1] 37.44866\n\n[[61]]\n[1] 35.83248\n\n[[62]]\n[1] 39.77577\n\n[[63]]\n[1] 33.48816\n\n[[64]]\n[1] 34.34758\n\n[[65]]\n[1] 40.45791\n\n[[66]]\n[1] 32.58547\n\n[[67]]\n[1] 58.52704\n\n[[68]]\n[1] 32.58547\n\n[[69]]\n[1] 45.98097\n\n[[70]]\n[1] 37.99885\n\n[[71]]\n[1] 31.27538\n\n[[72]]\n[1] 44.49442\n\n[[73]]\n[1] 43.88878\n\n[[74]]\n[1] 31.27538\n\n[[75]]\n[1] 53.12656\n\n[[76]]\n[1] 40.45791\n\n[[77]]\n[1] 43.93382\n\n[[78]]\n[1] 43.03114\n\n[[79]]\n[1] 47.45858\n\n[[80]]\n[1] 34.68711\n\n[[81]]\n[1] 33.9218\n\n[[82]]\n[1] 37.80739\n\n[[83]]\n[1] 42.81869\n\n[[84]]\n[1] 34.45062\n\n[[85]]\n[1] 61.79116\n\n[[86]]\n[1] 34.90929\n\n[[87]]\n[1] 42.32891\n\n[[88]]\n[1] 48.59005\n\nattr(,\"class\")\n[1] \"nbdist\"\nattr(,\"call\")\nnbdists(nb = k1, coords = coords, longlat = TRUE)\n\n\n\nSimplify the list structure of the returned object using the unlist() function from the base R package.\n\n\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\n\n\n\n\n\nNote\n\n\n\nUsing the summary report, we can observe that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\n\n10.2 Plotting Fixed Distance Weight Matrix\n\n# get max dist from k1dists rounded up to integer\nmax_dist &lt;- as.integer(ceiling(max(k1dists)))\n\nwm_d62 &lt;- dnearneigh(x=coords, d1=0, d2=max_dist, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\n\n\n\n\n\nNote\n\n\n\nOutput Intepretation\n\nThe weight matrix shows 88 regions (counties).\nThere are a total of 324 connections between all regions.\nThe formula for Percentage nonzero weights:\n\n\\(\\text{Percentage nonzero weights} = \\left( \\frac{\\text{Number of nonzero links}}{\\text{Total possible links}} \\right) \\times 100\\)\nand the total possible links can be computed as \\(n \\times n=88 \\times 88 = 7744\\)\nPlugging in the numbers, we will get \\(\\text{Percentage nonzero weights} = \\left( \\frac{324}{7744} \\right) \\times 100 \\approx 4.18\\%\\)\n\nThe formula for average number of links: \\(\\text{Average number of links} = \\frac{\\text{Total number of nonzero links}}{\\text{Number of regions}} = \\frac{324}{88} \\approx 3.68\\)\n\n\n\nWe can also use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\ntable(hunan$County, \n      card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\nn.comp.nb() finds the number of disjoint connected subgraphs in the graph depicted by nb.obj see Graph Components function - RDocumentation\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\nAbove shows the number of connected components in the spatial neighbour network. The output of 1 indicates that is 1 connected component.\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\nAnd this connected component comprises of 88 regions, indicating all regions are part of a single interconnected group.\n\n\n10.3 Plotting Fixed Distance Weight Matrix\nWe can plot the distance weight matrix as shown below:\n\npar(mfrow=c(1,2))\n\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st Nearest Neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance Link\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\nOn the left plot, the red lines show the links of 1st nearest neighbours.\nOn the right plot, the red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\n\n\n10.4 Computing Adaptive Distance Weight Matrix\nA fixed distance weight matrix typically shows that densely populated areas (like urban regions) have more neighbors, while sparsely populated areas (such as rural counties) have fewer neighbors. When there are many neighbors, the relationships between them are spread across a larger number of connections, creating a smoother effect.\nTo control the number of neighbours, we can set the k value.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nEach county has exactly 6 neighbours.\n\nstr(knn6)\n\n\n10.4.1 Computing Adaptive Distance Weight Matrix\n\nplot(hunan$geometry, border=\"lightgrey\", main=\"6 Nearest Neighbours\")\nplot(knn6, coords, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#weights-based-on-inversed-distance-weight-idw-method",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#weights-based-on-inversed-distance-weight-idw-method",
    "title": "4A: Spatial Weights and Applications",
    "section": "11 Weights based on Inversed Distance Weight (IDW) Method",
    "text": "11 Weights based on Inversed Distance Weight (IDW) Method\nIn this section, you will learn how to derive a spatial weight matrix based on Inversed Distance Weights method.\n\n\n\n\n\n\nNote\n\n\n\nIn order to conform to Tobler’s first law of geography, a distance decay effect must be respected.\nThe inverse distance weight method assigns weights to neighbors based on their distance: closer neighbors get higher weights, and further ones get lower weights.\nIt works by taking the distance between two locations and calculating the weight as 1 divided by that distance.\nFor more info, see Spatial Weights as Distance Functions.\n\n\n\ndist &lt;- nbdists(wm_q, \n                coords, \n                longlat = TRUE)\n# apply 1/x on every element on list objects\nids &lt;- lapply(dist, function(x) 1/(x))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#row-standardised-weights-matrix",
    "title": "4A: Spatial Weights and Applications",
    "section": "12 Row-standardised Weights Matrix",
    "text": "12 Row-standardised Weights Matrix\nNext, we need to assign weights to each neighboring polygon. In this case, we’ll use equal weights (style=“W”), where each neighboring polygon gets a weight of 1/(number of neighbors). This means we take the value for each neighbor and divide it by the total number of neighbors, then sum these weighted values to calculate a summary measure, such as weighted income.\nWhile this equal weighting approach is straightforward and easy to understand, it has a limitation: polygons on the edges of the study area have fewer neighbors, which can lead to over- or underestimation of the actual spatial relationships (spatial autocorrelation) in the data.\n\n\n\n\n\n\nTip\n\n\n\nFor simplicity, we use the style=“W” option in this example, but keep in mind that other, potentially more accurate methods are available, such as style=“B”.\n\n\n\n# note we are using queen's method here\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.\n\n\nTo see the weight of the 85th polygon’s 11 neighbors type:\n\nrswm_q$weights[85]\n\n[[1]]\n [1] 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n [7] 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n\n\nEach neighbor is assigned a 0.0909 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.0909 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code block below.\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[85]\n\n[[1]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n\nNotice that the output has different weight of each neighbour. We can use summary report to observe the differences.\n\nsummary(unlist(rswm_q$weights))\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.09091 0.14286 0.20000 0.19643 0.20000 1.00000 \n\ncat(\"\\n-----------------------------\\n\")\n\n\n-----------------------------\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#application-of-spatial-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#application-of-spatial-weight-matrix",
    "title": "4A: Spatial Weights and Applications",
    "section": "13 Application of Spatial Weight Matrix",
    "text": "13 Application of Spatial Weight Matrix\nIn this section, we will create 4 different spatial lagged variables:\n\nspatial lag with row-standardized weights,\nspatial lag as a sum of neighbouring values,\nspatial window average, and\nspatial window sum.\n\n\n13.1 Spatial Lag with Row-standardized Weights\nWe’ll compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nIn the previous section, we retrieved the GDPPC of these 11 counties by using the code block below.\n\nnb1 &lt;- wm_q[[85]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n [1] 23667 20981 34592 25554 27137 24194 14567 21311 18714 14624 19509\n\n\n\nQuestion: Can you see the meaning of Spatial lag with row-standardized weights now? Spatial lag represents the average or sum of a variable (GDPPC) for a region’s neighbors. In this context, the spatial lag for a region gives an idea of how that region’s GDPPC relates to the GDPPC of its neighboring regions.\nWith row-standardized weights (style=“W”), each neighboring region is assigned an equal weight of 1/(number of neighbors). This ensures that the weights for all neighbors of a region sum to 1.\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code block below:\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code block below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nRecall that in our previous observation, we made the statement that Changsha has the highest GDP per capital values in the Hunan region.\nUsing spatial lag values, we can observe that Yueyang has the highest spatial lag GDP per capita, meaning its neighbors (on average) have the highest GDP per capita.\n\n\n13.2 Spatial Lag as a Sum of Neighboring Values\nTo calculate spatial lag as the sum of neighboring values, we can assign binary weights (where each neighbor gets a weight of 1).\nTo do this, we go back to our list of neighbors and use a function to assign these binary weights. We then use the glist argument in the nb2listw function to set these weights explicitly.\nWe start by using lapply to assign a weight of 1 to each neighbor. lapply is a function we have been using to work with the neighbors list in previous notebooks; it applies a specified function to each value in the neighbors list.\n\n# Create binary weights for each neighbor\n# uses lapply to go through each element of the neighbors list (wm_q).\n# The function '0 * x + 1' assigns a weight of 1 to each neighbor.\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\n\n# Convert the neighbor list to a spatial weights list object\n# 'nb2listw' converts the neighbors list (wm_q) into a weights list.\n# 'glist = b_weights' explicitly sets the weights to the binary weights created above.\n# 'style = \"B\"' specifies binary weighting style, where each neighbor has equal weight (1).\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\n\nQuestion: Can you understand the meaning of Spatial lag as a sum of neighboring values now?\nBy assigning binary weights (where each neighbor is given a weight of 1), we calculate the spatial lag by summing the values of this variable for all neighbors. This means that the spatial lag reflects the combined influence or total value contributed by the neighboring regions, providing an idea of the overall regional context or neighborhood effect around a specific area.\n\nNext, we will append the lag_sum GDPPC field into hunan sf data frame by using the code block below.\n\nhunan &lt;- left_join(hunan, lag.res)\n\nNow, we can plot the GDPPC, Spatial Lag GDPPC, Spatial Lag Sum GDPPC for comparison using the code block below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, lag_sum_gdppc, asp=1, ncol=3)\n\n\n\n\n\n\n\n\n\n\n13.3 Spatial Window Average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\nLet us take a good look at the neighbour list of area 85 by using the code block below.\n\nwm_qs[[85]]\n\n [1]  1  2  3  5  6 32 56 57 69 75 78 85\n\n\nNotice that now region 85 has 12 neighbours instead of 11.\nNow we obtain weights with nb2listw().\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\n\n\n\n\n\n\nNote\n\n\n\nThe third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\n\n\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor more effective comparison, it is advisable to use the core tmap mapping functions.\n\n\n\n\n13.4 Spatial Window Sum\n\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\n\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nNotice that now region 85 has 12 neighbours instead of 11.\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nNote: The second command line on the code chunk above renames the field names of w_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html",
    "title": "3A: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 7  Network Constrained Spatial Point Patterns Analysis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#exercise-3a-reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#exercise-3a-reference",
    "title": "3A: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 7  Network Constrained Spatial Point Patterns Analysis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#overview",
    "title": "3A: Network Constrained Spatial Point Patterns Analysis",
    "section": "2 Overview",
    "text": "2 Overview\n\n\n\n\n\n\nNote\n\n\n\nWhat is NetKDE and Why is it important? Network Constrained Kernel Density Estimation (NetKDE) is an advanced spatial analysis technique used to estimate the density of spatial events (such as crime incidents, traffic accidents, wildlife sightings, etc.) while accounting for the underlying network structure, such as roads, railways, or rivers. Unlike traditional Kernel Density Estimation (KDE), which assumes that events are distributed freely in a 2D plane, NetKDE restricts the analysis to a network, providing a more accurate representation when events are constrained to specific pathways or routes.\nNetKDE provides a more realistic density estimation for data constrained to a network, avoiding misleading results that might arise from traditional KDE. For example, traffic accidents or crime hotspots along a road network are better analyzed using NetKDE since it restricts the analysis to the roads themselves.\n\n\nNetwork constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods special developed for analysing spatial point event occurs on or alongside network. The spatial point event can be locations of traffic accident or childcare centre for example. The network, on the other hand can be a road network or river network.\nIn this hands-on exercise, you are going to gain hands-on experience on using appropriate functions of spNetwork package:\n\nto derive network kernel density estimation (NKDE), and\nto perform network G-function and k-function analysis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#learning-outcome",
    "title": "3A: Network Constrained Spatial Point Patterns Analysis",
    "section": "3 Learning Outcome",
    "text": "3 Learning Outcome\n\nUnderstand and perform Network Constrained Spatial Point Patterns Analysis (NetSPAA) for events on networks (e.g., traffic accidents, childcare centers).\nUse spNetwork to derive network kernel density estimation (NKDE) for spatial analysis.\nConduct network G- and K-function analyses to test for complete spatial randomness (CSR).\nVisualize geospatial data using tmap for interactive and high-quality mapping.\nPrepare data by importing geospatial datasets using the sf package and managing CRS information.\nUse lixelize_lines() to cut lines into lixels for NKDE analysis.\nApply NKDE methods (simple, discontinuous, continuous) to analyze point patterns on networks.\nVisualize NKDE results by rescaling densities for effective mapping.\nPerform CSR tests using the kfunctions() from spNetwork to analyze spatial interactions among events."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#the-data",
    "title": "3A: Network Constrained Spatial Point Patterns Analysis",
    "section": "4 The Data",
    "text": "4 The Data\nThis study will analyze the spatial distribution of childcare centers in the Punggol planning area using the following geospatial datasets:\n\n\n\n\n\n\n\n\nDataset\nDescription\nFormat\n\n\n\n\nPunggol_St\nLine feature data representing the road network within Punggol Planning Area.\nESRI Shapefile\n\n\nPunggol_CC\nPoint feature data representing the location of childcare centers within Punggol Planning Area.\nESRI Shapefile"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#installing-and-launching-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#installing-and-launching-the-r-packages",
    "title": "3A: Network Constrained Spatial Point Patterns Analysis",
    "section": "5 Installing and Launching the R Packages",
    "text": "5 Installing and Launching the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\n\nspNetwork\nProvides functions for Spatial Point Patterns Analysis (e.g., KDE, K-function) on networks and spatial matrix building for spatial analysis.\nConducting spatial point pattern analysis and building spatial weights based on network distances.\n\n\nsf\nOffers functions to manage, process, and manipulate Simple Features for geospatial data handling.\nHandling and processing geospatial data in Simple Features format.\n\n\ntmap\nCreates cartographic quality static and interactive maps using the Leaflet API.\nPlotting high-quality static and interactive maps for spatial analysis.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(sf, spNetwork, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#import-data-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#import-data-and-preparation",
    "title": "3A: Network Constrained Spatial Point Patterns Analysis",
    "section": "6 Import Data and Preparation",
    "text": "6 Import Data and Preparation\nThe code block below uses st_read() of sf package to important Punggol_St and Punggol_CC geospatial data sets into RStudio as sf data frames.\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\", \n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex03/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\n\nchildcare &lt;- st_read(dsn=\"data/geospatial\",\n                     layer=\"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex03/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\n\n6.1 Examine Data Content\nWe can examine the structure of the output simple features data tables in RStudio. Alternatively, we can print basic information on the data as shown below.\n\nNetworkChildcare\n\n\n\nnetwork\n\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     LINK_ID                   ST_NAME                       geometry\n1  116130894                PUNGGOL RD LINESTRING (36546.89 44574....\n2  116130897 PONGGOL TWENTY-FOURTH AVE LINESTRING (36546.89 44574....\n3  116130901   PONGGOL SEVENTEENTH AVE LINESTRING (36012.73 44154....\n4  116130902   PONGGOL SEVENTEENTH AVE LINESTRING (36062.81 44197....\n5  116130907           PUNGGOL CENTRAL LINESTRING (36131.85 42755....\n6  116130908                PUNGGOL RD LINESTRING (36112.93 42752....\n7  116130909           PUNGGOL CENTRAL LINESTRING (36127.4 42744.5...\n8  116130910               PUNGGOL FLD LINESTRING (35994.98 42428....\n9  116130911               PUNGGOL FLD LINESTRING (35984.97 42407....\n10 116130912            EDGEFIELD PLNS LINESTRING (36200.87 42219....\n\n\n\ndim(network)\n\n[1] 2642    3\n\n\n\nstr(network)\n\nClasses 'sf' and 'data.frame':  2642 obs. of  3 variables:\n $ LINK_ID : num  1.16e+08 1.16e+08 1.16e+08 1.16e+08 1.16e+08 ...\n $ ST_NAME : chr  \"PUNGGOL RD\" \"PONGGOL TWENTY-FOURTH AVE\" \"PONGGOL SEVENTEENTH AVE\" \"PONGGOL SEVENTEENTH AVE\" ...\n $ geometry:sfc_LINESTRING of length 2642; first list element:  'XY' num [1:2, 1:2] 36547 36559 44575 44614\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA\n  ..- attr(*, \"names\")= chr [1:2] \"LINK_ID\" \"ST_NAME\"\n\n\n\nst_crs(network)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nchildcare\n\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n      Name                      geometry\n1   kml_10 POINT Z (36173.81 42550.33 0)\n2   kml_99 POINT Z (36479.56 42405.21 0)\n3  kml_100 POINT Z (36618.72 41989.13 0)\n4  kml_101 POINT Z (36285.37 42261.42 0)\n5  kml_122  POINT Z (35414.54 42625.1 0)\n6  kml_161 POINT Z (36545.16 42580.09 0)\n7  kml_172 POINT Z (35289.44 44083.57 0)\n8  kml_188 POINT Z (36520.56 42844.74 0)\n9  kml_205  POINT Z (36924.01 41503.6 0)\n10 kml_222 POINT Z (37141.76 42326.36 0)\n\n\n\ndim(childcare)\n\n[1] 61  2\n\n\n\nstr(childcare)\n\nClasses 'sf' and 'data.frame':  61 obs. of  2 variables:\n $ Name    : chr  \"kml_10\" \"kml_99\" \"kml_100\" \"kml_101\" ...\n $ geometry:sfc_POINT of length 61; first list element:  'XYZ' num  36174 42550 0\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA\n  ..- attr(*, \"names\")= chr \"Name\"\n\n\n\nst_crs(childcare)\n\nCoordinate Reference System:\n  User input: SVY21 / Singapore TM \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#visualising-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#visualising-geospatial-data",
    "title": "3A: Network Constrained Spatial Point Patterns Analysis",
    "section": "7 Visualising Geospatial Data",
    "text": "7 Visualising Geospatial Data\nTo visualise geospatial data, we can use plot() from base R. Alternatively, we can visualise the geospatial data with high cartographic quality and interactive manner using the tmap package.\n\nUsing PlotUsing Tmap\n\n\n\nplot(st_geometry(network))\n\nplot(childcare,\n     add=T,\n     col='red',\n     pch = 19)\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode('view')\n\ntm_shape(childcare) + \n  tm_dots(col = 'red') + \n  tm_shape(network) +\n  tm_lines()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#network-constrained-kde-nkde-analysis-using-spnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#network-constrained-kde-nkde-analysis-using-spnetwork",
    "title": "3A: Network Constrained Spatial Point Patterns Analysis",
    "section": "8 Network Constrained KDE (NKDE) Analysis using spNetwork",
    "text": "8 Network Constrained KDE (NKDE) Analysis using spNetwork\nIn this section, we will perform NKDE analysis by using appropriate functions provided in spNetwork package.\n\n8.1 Preparing the Lixels Objects\nBefore computing NKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance. This task can be performed by using with lixelize_lines() of spNetwork as shown in the code block below.\n\nlixels &lt;- lixelize_lines(lines=network, \n                         lx_length=700, \n                         mindist = 375)\n\n\n\n\n\n\n\nNote\n\n\n\nArguments\n\nlines: The sf object with linestring geometry type to modify\nlx_length: The length of a lixel\nmindist: The minimum length of a lixel. After cut, if the length of the final lixel is shorter than the minimum distance, then it is added to the previous lixel. if NULL, then mindist = maxdist/10. Note that the segments that are already shorter than the minimum distance are not modified\n\nThere is another function called lixelize_lines.mc() which provide multicore support.\n\n\n\n\n8.2 Generating Line Centre Points\nNext, we will use lines_center() of spNetwork to generate a SpatialPointsDataFrame (i.e. samples) with line centre points.\n\nsamples &lt;- lines_center(lixels)\n\nThe points are located at center of the line based on the length of the line.\n\n\n8.3 Performing NKDE\nTo compute the NKDE:\n\ndensities &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  # agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\n\n\n\nNote\n\n\n\n\nspNetwork supports various kernel methods, including quartic, triangle, gaussian, scaled gaussian, tricube, cosine, triweight, epanechnikov, or uniform. In this case, quartic kernel is used.\nmethod argument indicates that simple method is used to calculate the NKDE. Currently, spNetwork support three popular methods, they are:\n\nmethod=“simple”. This first method was presented by Xie et al. (2008) and proposes an intuitive solution. The distances between events and sampling points are replaced by network distances, and the formula of the kernel is adapted to calculate the density over a linear unit instead of an areal unit.\nmethod=“discontinuous”. The method is proposed by Okabe et al (2008), which equally “divides” the mass density of an event at intersections of lixels.\nmethod=“continuous”. If the discontinuous method is unbiased, it leads to a discontinuous kernel function which is a bit counter-intuitive. Okabe et al (2008) proposed another version of the kernel, that divide the mass of the density at intersection but adjusts the density before the intersection to make the function continuous.\n\n\nFor more info, refer to the user guide of spNetwork package.\n\n\n\n\n8.4 Visualising NKDE\nTo visualise the NKDE values, we have to perform a few preparation steps.\n\nInsert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\n\nrescale the density values if required.\n\nSince svy21 projection system is in meter, the computed density values are very small i.e. 0.0000005. We should rescale the density values from number of events per meter to number of events per kilometer.\n\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\n\nUse tmap to plot interactive map\n\n\ntmap_mode('view')\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nRoad segments with relatively higher density of childcare centres is shown in darker color (refer to legend). Road segments with relatively lower density of childcare centre is shown in lighter color."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#network-constrained-g--and-k-function-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03a.html#network-constrained-g--and-k-function-analysis",
    "title": "3A: Network Constrained Spatial Point Patterns Analysis",
    "section": "9 Network Constrained G- and K-Function Analysis",
    "text": "9 Network Constrained G- and K-Function Analysis\nIn this section, we are going to perform Complete Spatial Randomness (CSR) test by using kfunctions() of spNetwork package.\nThe CSR test is based on the assumption of the binomial point process which implies the hypothesis that the childcare centres are randomly and independently distributed over the street network.\nNull Hypothesis (\\(H_0\\)): The observed spatial point events (i.e., distribution of childcare centres) exhibit a uniform distribution over a street network in Punggol Planning Area.\nIf this hypothesis is rejected, we may infer that the distribution of childcare centres are spatially interacting and dependent on each other; as a result, they may form non-random patterns.\n\n# set seed for reproducibility\nset.seed(1234)\nkfun_childcare &lt;- kfunctions(network, \n                             childcare,\n                             start = 0, \n                             end = 1000, \n                             step = 50, \n                             width = 50, \n                             nsim = 39, \n                             resolution = 50,\n                             verbose = FALSE, \n                             conf_int = 0.05)\n\n\n\n\n\n\n\nNote\n\n\n\nExplanation on Arguments used\n\nlines: A SpatialLinesDataFrame with sampling points.\npoints: A SpatialPointsDataFrame representing points on the network.\nstart: Start value for evaluating the k and g functions.\nend: Last value for evaluating the k and g functions.\nstep: Jump between two evaluations of the k and g functions.\nwidth: Width of each donut for the g-function.\nnsim: Number of Monte Carlo simulations (39 simulations in this example, more simulation may be required for inference).\nresolution: Resolution for simulating random points on the network.\nconf_int: Width of the confidence interval (default = 0.05).\nFor additional arguments, refer to the user guide of the spNetwork package.\n\n\n\nWe can visualise the ggplot2 object of k-function by using the code chunk below.\n\nkfun_childcare$plotk + \n  labs(title =\"K-Function\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIntepretation of kfunctions() outputs\n\nplotk: A ggplot2 object representing the values of the k-function\nplotg: A ggplot2 object representing the values of the g-function\nvalues: A DataFrame with the values used to build the plots\n\nsee kfunctions function - RDocumentation\nIntepretation of the graph output\nThe blue line is the empirical network K-function of the childcare centres in Punggol planning area. The gray envelope represents the results of the 39 simulations in the interval 2.5% - 97.5%.\nSince the blue line between the distance of 250m-400m are below the gray area, we can infer that the childcare centres in Punggol planning area resemble regular pattern at the distance of 250m-400m."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html",
    "title": "2B: 2nd Order Spatial Point Patterns Analysis",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 5  2nd Order Spatial Point Patterns Analysis Methods"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#exercise-2b-reference",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#exercise-2b-reference",
    "title": "2B: 2nd Order Spatial Point Patterns Analysis",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 5  2nd Order Spatial Point Patterns Analysis Methods"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#overview",
    "title": "2B: 2nd Order Spatial Point Patterns Analysis",
    "section": "2 Overview",
    "text": "2 Overview\nSpatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be location of:\n\nevents such as crime, traffic accident and disease onset, or\nbusiness services (coffee and fastfood outlets) or facilities such as childcare and eldercare.\n\nUsing appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\n\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?\n\nThis hands-on exercise continues from Hands-on Exercise 2A"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#learning-outcome",
    "title": "2B: 2nd Order Spatial Point Patterns Analysis",
    "section": "3 Learning Outcome",
    "text": "3 Learning Outcome\n\nImporting and managing geospatial data using sf and spatstat packages.\nConverting spatial data formats from sf to spatstat’s ppp format.\nHandling and correcting duplicate spatial points in datasets.\nDefining and applying spatial windows (owin objects) for focused analysis.\nConducting 2nd-order spatial point pattern analyses using G, F, K, and L functions.\nPerforming Monte Carlo simulations and hypothesis testing to assess spatial randomness.\nVisualizing spatial patterns and statistical results using appropriate plotting functions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#the-data",
    "title": "2B: 2nd Order Spatial Point Patterns Analysis",
    "section": "4 The Data",
    "text": "4 The Data\n\n\n\n\n\n\n\n\n\nDataset\nDescription\nSource\nFormat\n\n\n\n\nCHILDCARE\nPoint data containing location and attributes of childcare centers.\nData.gov.sg\nGeoJSON\n\n\nMP14_SUBZONE_WEB_PL\nPolygon data with URA 2014 Master Plan Planning Subzone boundaries.\nData.gov.sg\nESRI Shapefile\n\n\nCoastalOutline\nPolygon data representing Singapore’s national boundary.\nSingapore Land Authority (SLA)\nESRI Shapefile"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#installing-and-loading-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#installing-and-loading-the-r-packages",
    "title": "2B: 2nd Order Spatial Point Patterns Analysis",
    "section": "5 Installing and Loading the R Packages",
    "text": "5 Installing and Loading the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\n\nsf\nImports, manages, and processes vector-based geospatial data.\nHandling vector geospatial data in R.\n\n\nspatstat\nProvides tools for point pattern analysis.\nPerforming 1st- and 2nd-order spatial point pattern analysis and deriving kernel density estimation (KDE).\n\n\nraster\nReads, writes, and manipulates gridded spatial data (raster).\nConverting image outputs from spatstat into raster format.\n\n\nmaptools\nOffers tools for manipulating geographic data.\nConverting spatial objects into ppp format for use with spatstat.\n\n\ntmap\nCreates static and interactive thematic maps using cartographic quality elements.\nPlotting static and interactive point pattern maps.\n\n\n\nTo install and load these packages in R, use the following code:\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#reproducibility",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#reproducibility",
    "title": "2B: 2nd Order Spatial Point Patterns Analysis",
    "section": "6 Reproducibility",
    "text": "6 Reproducibility\nAs this document involves Monte Carlo simulations, we will set the seed to ensure reproducibility\n\nset.seed(1234)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#spatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#spatial-data-wrangling",
    "title": "2B: 2nd Order Spatial Point Patterns Analysis",
    "section": "7 Spatial Data Wrangling",
    "text": "7 Spatial Data Wrangling\n\n7.1 Importing the Spatial Data\nTo import the three geographical datasets, we will use st_read() from sf.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\")\n\nReading layer `child-care-services-geojson' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex02/data/child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex02/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex02/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n7.2 Inspect and Reproject to Same Projection System\nBefore we can use these data for analysis, it is important for us to ensure that they are projected in same projection system.\nFirst, we check the childcare dataset.\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nThis dataset is using the WGS84 crs. We will reproject all the dataset to SVY21 crs for standardization and analysis.\n\nchildcare_sf &lt;- st_transform(childcare_sf , crs = 3414)\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nThe childcare dataset has been reprojected to SVY21 successfully.\nNext, we inspect the Coastal Outline dataset.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nNotice that this dataset is using SVY21 crs, however the ID provided is EPSG:9001 does not match the intended ID, EPSG:3414 of SVY21. In this case, we will set the crs to the correct ID using the code block below.\n\nsg_sf &lt;- st_set_crs(sg_sf, 3414)\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nSimilarly, we will inspect the Master Plan Subzone Dataset.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nSince the ID is also EPSG:9001, we will set the crs to EPSG:3414 too.\n\nmpsz_sf &lt;- st_set_crs(mpsz_sf, 3414)\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#mapping-the-geospatial-datasets",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#mapping-the-geospatial-datasets",
    "title": "2B: 2nd Order Spatial Point Patterns Analysis",
    "section": "8 Mapping the Geospatial Datasets",
    "text": "8 Mapping the Geospatial Datasets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\n\n8.1 Static Map\n\n# add polygon layer of the coastal outline of sg island\ntm_shape(sg_sf)+ tm_polygons() +\n# add polygon layer of the subzone based on sg masterplan\ntm_shape(mpsz_sf) + tm_polygons() +\n# add dot layer to show the locations of childcare centres\ntm_shape(childcare_sf) + tm_dots() +\ntm_layout()\n\n\n\n\n\n\n\n\nWhen all the 3 datasets are overlayed together, it shows the locations of childcare centres on the Singapore island. Since all the geospatial layers are within the same map context, it means their referencing system and coordinate values are referred to similar spatial context. This consistency is crucial for accurate geospatial analysis.\n\n\n8.2 Interactive Map\nAlternatively, we can also prepare a pin map by using the code block below.\n\ntmap_mode('view')\n\n# tm_basemap(\"Esri.WorldGrayCanvas\") +\n# tm_basemap(\"OpenStreetMap\") +\ntm_basemap(\"Esri.WorldTopoMap\") +\ntm_shape(childcare_sf) +\n  tm_dots(alpha = 0.5)\n\n\n\n\n\n\ntmap_mode('plot')\n\nIn interactive mode, tmap uses the Leaflet for R API, allowing you to freely navigate, zoom, and click on features for detailed information. You can also change the map’s background using layers like ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap, with ESRI.WorldGrayCanvas as the default.\n\n\n\n\n\n\nTip\n\n\n\nRemember to switch back to plot mode after interacting to avoid connection issues and limit interactive maps to fewer than 10 in RMarkdown documents for Netlify publishing."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#geospatial-data-wrangling",
    "title": "2B: 2nd Order Spatial Point Patterns Analysis",
    "section": "9 Geospatial Data Wrangling",
    "text": "9 Geospatial Data Wrangling\nWhile simple feature data frames are becoming more popular compared to sp’s Spatial* classes, many geospatial analysis packages still require data in the Spatial* format. This section will show you how to convert a simple feature data frame to sp’s Spatial* class.\n\n9.1 Converting sf data frames to sp’s Spatial* class\nThe code block below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nAfter the sf dataframe to sp Spatial* conversion, let’s inspect the Spatial* classes.\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\nThe geospatial data have been converted into their respective sp’s Spatial* classes.\n\n\n9.2 Converting the Spatial* Class into Generic sp Format\nspatstat requires the analytical data in ppp object form. There is no straightforward way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\n\n\n\n\n\n\nTip\n\n\n\nppp refers to planar point pattern. It is used to represent spatial point patterns in spatstat; it contains the event locations with possibly associated marks, and the observation window where the events occur.\nsee Chapter 18 The spatstat package | Spatial Statistics for Data Science: Theory and Practice with R\n\n\nThe codes block below converts the Spatial* classes into generic sp objects.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nNext, we can display the sp objects properties.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\nLet’s further inspect the differences between Spatial* classes and generic sp object with the example of childcare and childcare_sp object.\n\nhead(childcare)\n\n   Name\n1 kml_1\n2 kml_2\n3 kml_3\n4 kml_4\n5 kml_5\n6 kml_6\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Description\n1 &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;760742&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;742, YISHUN AVENUE 5, #01 - 470, SINGAPORE 760742&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;AVERBEL CHILD DEVELOPMENT CENTRE PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;AEA27114446235CE&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n2                                    &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;159053&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;20, LENGKOK BAHRU, #02 - 05, SINGAPORE 159053&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;AWWA LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;86B24416FB1663C6&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n3        &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;556912&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;22, LI HWAN VIEW, GOLDEN HILL ESTATE, SINGAPORE 556912&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;BABIES BY-THE-PARK PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;F971CBBA973E1AE5&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n4 &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;569139&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;3, ANG MO KIO STREET 62, #01 - 36, LINK@AMK, SINGAPORE 569139&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;Baby Elk Infant Care Pte Ltd&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;86A4F25D1C7C9D85&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n5                           &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;467961&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;22A, KEW DRIVE, SINGAPORE 467961&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;BABYPLANET MONTESSORI PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;CFE3F056F8171C7B&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n6                       &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;598523&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;3 Jalan Kakatua, JURONG PARK, SINGAPORE 598523&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;BAMBINI CHILDCARE LLP&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;2B4F0B285ED28C4A&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n\n\n\nhead(childcare_sp)\n\nclass       : SpatialPoints \nfeatures    : 1 \nextent      : 27976.73, 27976.73, 45716.7, 45716.7  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\nNote that the Spatial* classes contain more attribute data as compared its generic sp object counterpart.\n\n\n\n\n\n\nTip\n\n\n\nDifferences between Spatial* classes and generic sp object\n\nData Storage: SpatialPoints stores only the coordinates, while SpatialPointsDataFrame stores both coordinates and additional attribute data\nFunctionality: SpatialPointsDataFrame allows for more complex operations and analyses due to the additional data it holds\n\nsee Introduction to spatial points in R - Michael T. Hallworth, Ph.D.\n\n\n\n\n9.3 Converting the Generic sp Format into spatstat’s ppp Format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nLet’s examine the difference by plotting childcare_ppp:\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nWe can also view the summary statistics of the newly created ppp object by using the code block below.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\n\n\n\n\nTip\n\n\n\nBe aware of the warning message regarding duplicates. In spatial point pattern analysis, duplicates can be a significant issue. The statistical methods used for analyzing spatial point patterns often assume that the points are distinct and non-coincident.\n\n\n\n\n9.4 Handling Duplicated Points\nWe can check the duplication in a ppp object by using the duplicated function with different configurations.\n\n\n\n\n\n\nTip\n\n\n\nThe duplicated function has an argument rule:\n\nDefault Behavior (rule = \"spatstat\"):\n\nPoints are considered identical if both their coordinates (like x and y positions) and their marks (additional data or labels attached to the points) are exactly the same.\nThis is the strictest check, requiring everything about the points to match.\n\nOnly Checking Coordinates (rule = \"unmark\"):\n\nPoints are considered duplicates if their coordinates are the same, regardless of their marks.\nMarks are ignored, so only the positions are compared.\n\nUsing deldir Package (rule = \"deldir\"):\n\nPoints are considered duplicates based on their coordinates, but the comparison is done using a specific method (duplicatedxy) from the deldir package.\nThis approach ensures the check is consistent with other functions in the deldir package, which is often used for spatial data analysis (like creating Delaunay triangulations).\n\n\nIn other words,\n\nrule = \"spatstat\": Strict check (coordinates and marks).\nrule = \"unmark\": Less strict (coordinates only).\nrule = \"deldir\": Coordinate check, consistent with the deldir package methods.\n\nsee R: Determine Duplicated Points in a Spatial Point Pattern\n\n\n\n# duplicated(childcare_ppp)\n# any(duplicated(childcare_ppp))\nrules &lt;- c(\"spatstat\", \"deldir\", \"unmark\")\n\nduplicate_counts &lt;- list()\nfor (rule in rules) {\n  duplicates &lt;- duplicated(childcare_ppp, rule = rule)\n  num_duplicates &lt;- sum(duplicates)\n  duplicate_counts[[rule]] &lt;- num_duplicates\n}\n\nprint(duplicate_counts)\n\n$spatstat\n[1] 0\n\n$deldir\n[1] 0\n\n$unmark\n[1] 74\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that this behavior happens because the data contains marked points with the same coordinates but different properties.\nUpon manual inspection, a set of example is “39, WOODLANDS CLOSE, #01 - 62, MEGA@WOODLANDS, SINGAPORE 737856” and “39, WOODLANDS CLOSE, #01 - 59, MEGA@WOODLANDS, SINGAPORE 737856”.\nThese are 2 childcare centres that resides in the same building. Thus, it can only be picked up using the “unmark” rule which only examine for exact match of the point coordinate only.\n\n\nTo count the number of coincident points, we will use the multiplicity() function as shown in the code block below. see R: Multiplicity for more info.\n\nmultiplicity(childcare_ppp)\n\nIf we want to know how many locations have more than one point event:\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\n\n# double check\ncoincident_points &lt;- duplicated(childcare_ppp,  rule=\"unmark\")\ncoincident_coordinates &lt;- childcare_ppp[coincident_points]\nprint(coincident_coordinates)\n\nMarked planar point pattern: 74 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nThe output shows that there are 74 duplicated point events.\n\n\n9.5 How to Spot Duplicate Points on the Map\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\n\n9.5.1 Jittering\nThe code block below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp,\n                             retry=TRUE,\n                             nsim=1,\n                             drop=TRUE)\n\nplot(childcare_ppp_jit, pch = 16, cex = 0.5, main = \"Jittered Points\")\n\n\n\n\n\n\n\n\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n\n9.6 Creating owin Object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code block below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe output object can be displayed by using plot() function:\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\nAnd using summary() function of Base R:\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#combining-point-events-object-and-owin-object",
    "title": "2B: 2nd Order Spatial Point Patterns Analysis",
    "section": "10 Combining Point Events Object and Owin Object",
    "text": "10 Combining Point Events Object and Owin Object\nFor the last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code block below.\n\n\n\n\n\n\nImportant\n\n\n\nSince the dataset contains duplicated points, we will use the jittered ppp object for downstream analysis.\n\n\n\nchildcareSG_ppp &lt;- childcare_ppp_jit[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#first-order-spatial-point-patterns-analysis",
    "title": "2B: 2nd Order Spatial Point Patterns Analysis",
    "section": "11 First-order Spatial Point Patterns Analysis",
    "text": "11 First-order Spatial Point Patterns Analysis\nIn this section, you will learn how to perform first-order SPPA by using spatstat package. The hands-on exercise will focus on:\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes,\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\n\n\n11.1 Kernel Density Estimation\nIn this section, you will learn how to compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n11.1.1 Computing Kernel Density Estimation Using Automatic Bandwidth Selection Method\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\n\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\n\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\")\n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nThe density values of the output range from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of SVY21 is in meter. As a result, the density values computed is in “number of points per square meter”.\nBefore we move on to next section, it is good to know that you can retrieve the bandwidth used to compute the kde layer by using the code block below.\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n414.4576 \n\n\n\n\n11.1.2 Rescaling KDE values\nrescale.ppp() is used below to convert the unit of measurement from meter to kilometer:\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the resale data set and plot the output kde map.\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\nSince we just did a rescaling operation, the output image looks identical to the earlier version with the only changes in terms of data values.\n\n\n\n11.2 Working with Different Automatic Bandwidth Methods\nBeside bw.diggle(), there are 3 other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\nLet us take a look at the bandwidth return by these automatic bandwidth calculation methods by using:\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n5.009037 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224958 1.451103 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n   sigma \n0.273598 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.4144576 \n\n\nBaddeley et al. (2016) suggest using the bw.ppl() algorithm, as it tends to produce more appropriate values when the pattern consists predominantly of tight clusters. However, they also note that if the aim of a study is to detect a single tight cluster amidst random noise, the bw.diggle() method is likely to be more effective.\nTo compare the output of using bw.diggle and bw.ppl methods:\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km,\n                               sigma=bw.ppl,\n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\n\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#working-with-different-kernel-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#working-with-different-kernel-methods",
    "title": "2B: 2nd Order Spatial Point Patterns Analysis",
    "section": "12 6.3 Working with Different Kernel Methods",
    "text": "12 6.3 Working with Different Kernel Methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics. Let us take a look at what they look like:\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Gaussian\")\n\nplot(density(childcareSG_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"epanechnikov\"),\n     main=\"Epanechnikov\")\n\nplot(density(childcareSG_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"quartic\"),\n     main=\"Quartic\")\n\nplot(density(childcareSG_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"disc\"),\n     main=\"Disc\")\n\n\n\n\n\n\n\n\nObservations: In this dataset, the choice of kernel function has only a minor impact on the overall density plots. The Gaussian, Epanechnikov, and Quartic kernels produce smoother transitions and distribute the density over a broader area. In contrast, the Disc kernel provides a more localized density estimation with sharper boundaries and less smoothness."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#fixed-and-adaptive-kde",
    "title": "2B: 2nd Order Spatial Point Patterns Analysis",
    "section": "13 Fixed and Adaptive KDE",
    "text": "13 Fixed and Adaptive KDE\n\n13.1 Computing KDE by using Fixed Bandwidth\nNext, we will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code block below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\nIn this section, we will learn how to derive adaptive kernel density estimation by using density.adaptive() of spatstat.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using:\n\npar(mfrow=c(1,2))\n\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n13.2 Converting KDE Output into Grid Object\nTo achieve the same result, we convert the object to a format suitable for mapping:\n\ngridded_kde_childcareSG_bw &lt;- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n13.2.1 Converting Grided Output into Raster\nNext, we will convert the gridded kernel density objects into RasterLayer object by using raster() of raster package.\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\n\nLet us take a look at the properties of kde_childcareSG_bw_raster RasterLayer.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -1.006362e-14, 21.11878  (min, max)\n\n\nNote that the crs property is NA.\n\n\n13.2.2 Assigning Projection Systems\nTo include the CRS information on kde_childcareSG_bw_raster RasterLayer, we will do the following:\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -1.006362e-14, 21.11878  (min, max)\n\n\nNow, the crs property is completed.\n\n\n\n13.3 Visualising the output in tmap\nFinally, we will display the raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_raster) +\n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\n\nvalues(kde_childcareSG_bw_raster)\n\nNote that the raster values are encoded explicitly onto the raster pixel using the values in “v” field.\n\n\n13.4 Comparing Spatial Point Patterns using KDE\nIn this section, we will learn how to compare KDE of childcare at Punggol, Tampines, Chua Chu Kang and Jurong West planning areas.\n\n13.4.1 Extracting Study Area\nThe code block below will be used to extract the target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting the target planning areas:\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n13.4.2 Creating owin object\nNow, we will convert these sf objects into owin objects that is required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n13.4.3 Combining Childcare Points and the Study Area\nTo extract childcare that is within the specific region for analysis, we can use:\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to transform the unit of measurement from meter to kilometer.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code block below is used to plot the four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\n\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#second-order-spatial-point-pattern-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#second-order-spatial-point-pattern-analysis",
    "title": "2B: 2nd Order Spatial Point Patterns Analysis",
    "section": "14 Second-Order Spatial Point Pattern Analysis",
    "text": "14 Second-Order Spatial Point Pattern Analysis\nIn this section, we will analyze spatial point patterns using various functions: G-Function, F-Function, K-Function, and L-Function.\n\n14.1 Analysing Spatial Point Process Using G-Function\nThe G function measures the distribution of the distances from an arbitrary event to its nearest event. In this section, we will learn how to compute G-function estimation by using Gest() of spatstat package. We will also learn how to perform monte carlo simulation test using envelope() of spatstat package.\n\n14.1.1 Choa Chu Kang Planning Area\n\n14.1.1.1 Computing G-function Estimation\nTo compute G-function using Gest() of spatstat package:\n\n\n\n\n\n\nNote\n\n\n\ncorrection is an optional argument in Gest()\nOptional. The edge correction(s) to be used to estimate . A vector of character strings selected from “none”, “rs”, “km”, “Hanisch” and “best”. Alternatively correction=“all” selects all options.\nsee Gest function - RDocumentation\n\n\n\n# rs and border has the same effect\nG_CK = Gest(childcare_ck_ppp, correction = \"rs\")\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\nWe can also use the “all” option in correction to display all forms of edge corrections from “none”, “rs”, “km”, “Hanisch” and “best”.\n\nG_CK_all = Gest(childcare_ck_ppp, correction = \"all\")\nplot(G_CK_all, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n14.1.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\\(H_0\\) = The distribution of childcare services at Choa Chu Kang are randomly distributed.\n\\(H_1\\)= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function:\n\n\n\n\n\n\nNote\n\n\n\nThe envelope function calculates overall and pointwise confidence envelopes for a curve based on bootstrap replicates of the curve evaluated at a number of fixed points.\nIn other words, It helps you determine if your observed spatial pattern (e.g., locations of points in a study area) is significantly different from what you would expect under a random or theoretical distribution.\nHow It Works: 1. Simulate Data: It generates multiple simulated datasets (often by randomizing the locations of points) based on the null hypothesis (e.g., complete spatial randomness). 2. Compute Statistics: For each simulated dataset, it computes a spatial statistic (e.g., G-function, F-function) and creates a distribution of these statistics. 3. Compare: It compares the observed statistic from your actual data to the distribution of statistics from the simulated datasets. 4. Envelope Plot: It plots the range (envelope) of the simulated statistics along with the observed statistic, allowing you to see if your observed statistic falls outside the range of what is expected under the null hypothesis.\nWhen to Use It? Use the envelope function when you want to:\n\nTest if the observed spatial pattern deviates significantly from a random pattern or other theoretical patterns.\nAssess the statistical significance of spatial features or clustering in your data.\n\n\nChoice of nsim: The choice of 39 simulations (nsim = 39) in Monte Carlo techniques for spatial analysis is often a practical compromise between computational efficiency and statistical robustness.\n\nComputational Efficiency: Running a large number of simulations can be computationally expensive, especially for complex spatial analyses. We can strike a balance between obtaining reliable results and keeping computational costs manageable by selecting absolute minimum sample size.\n\nThe minimum number of simulations \\(m\\) required for a Monte Carlo test at a particular significance level can be determined by:\n\\(\\alpha = \\frac{1}{m+1}\\)\nfor a one-tailed test and\n\\(\\alpha = \\frac{2}{m+1}\\)\nThus, a one-tailed test at a significance level of 5% would require a minimum of 19 simulations, a two-tailed test at a significance level of 5% would require a minimum of 39 simulations.\nsee Going beyond the required number of simulations required for a particular significance level when conducting a Monte Carlo test - Cross Validated, spatial statistics - Simulation envelopes and significance levels - Geographic Information Systems Stack Exchange\n\n\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim=39)\n\nGenerating 39 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, \n39.\n\nDone.\n\n\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\n14.1.2 Tampines Planning Area\n\n14.1.2.1 Computing G-function Estimation\nWe will use the best edge correction for this example.\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\nG_tm_all = Gest(childcare_tm_ppp, correction = \"all\")\nplot(G_tm_all)\n\n\n\n\n\n\n\n\n\n\n\n\n14.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\\(H_0\\) = The distribution of childcare services at Tampines are randomly distributed.\n\\(H_1\\) = The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code block below is used to perform the hypothesis testing.\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim=39)\n\nGenerating 39 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, \n39.\n\nDone.\n\n\n\nplot(G_tm.csr)\n\n\n\n\n\n\n\n\n\n\n14.3 Analysing Spatial Point Process Using F-Function\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape. In this section, we will learn how to compute F-function estimation by using Fest() of spatstat package. We will also learn how to perform monte carlo simulation test using envelope() of spatstat package.\n\n14.3.1 Choa Chu Kang Planning Area\n\n14.3.1.1 Computing F-function estimation\n\n\n\n\n\n\nNote\n\n\n\nFest() has the same correction option as Gest().\n\n\n\nF_CK_all = Fest(childcare_ck_ppp, correction = \"all\")\nplot(F_CK_all)\n\n\n\n\n\n\n\n\n\n\n14.3.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\\(H_0\\) = The distribution of childcare services at Choa Chu Kang are randomly distributed.\n\\(H_1\\) = The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-function:\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim=39)\n\nGenerating 39 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, \n39.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\n14.3.2 Tampines Planning Area\n\n14.3.2.1 Computing F-function estimation\nMonte Carlo test with F-function:\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\n14.3.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\\(H_0\\) = The distribution of childcare services at Tampines are randomly distributed.\n\\(H_1\\) = The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code block below is used to perform the hypothesis testing.\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim=39)\n\nGenerating 39 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, \n39.\n\nDone.\n\n\n\nplot(F_tm.csr)\n\n\n\n\n\n\n\n\n\n\n\n\n14.4 Analysing Spatial Point Process Using K-Function\nK-function measures the number of events found up to a given distance of any particular event. In this section, you will learn how to compute K-function estimates by using Kest() of spatstat package. We will also learn how to perform monte carlo simulation test using envelope() of spatstat package.\n\n\n\n\n\n\nNote\n\n\n\nKest()’s correction option is different fromGest()andFest()`.\ncorrection: Optional. A character vector containing any selection of the options “none”, “border”, “bord.modif”, “isotropic”, “Ripley”, “translate”, “translation”, “rigid”, “none”, “good” or “best”. It specifies the edge correction(s) to be applied. Alternatively correction=“all” selects all options.\nsee Kest function - RDocumentation\n\n\n\n14.4.1 Choa Chu Kang Planning Area\n\n14.4.1.1 Computing K-Function Estimate\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n14.4.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\\(H_0\\) = The distribution of childcare services at Choa Chu Kang are randomly distributed.\n\\(H_1\\) = The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code block below is used to perform the hypothesis testing.\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim=39, rank = 1, glocal=TRUE)\n\nGenerating 39 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, \n39.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n14.4.2 Tampines Planning Area\n\n14.4.2.1 Computing K-function Estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r,\n     ylab= \"K(d)-r\", xlab = \"d(m)\",\n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n\n\n14.5 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\\(H_0\\) = The distribution of childcare services at Tampines are randomly distributed.\n\\(H_1\\) = The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code block below is used to perform the hypothesis testing.\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim=39, rank = 1, glocal=TRUE)\n\nGenerating 39 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, \n39.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r,\n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n14.6 Analysing Spatial Point Process Using L-Function\nIn this section, you will learn how to compute L-function estimation by using Lest() of spatstat package. We will also learn how to perform monte carlo simulation test using envelope() of spatstat package.\n\n14.6.1 Choa Chu Kang Planning Area\n\n14.6.1.1 Computing L-function Estimation\n\n\n\n\n\n\nNote\n\n\n\nLest() has the same correction options as Kest().\n\n\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r,\n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n14.6.1.2 Performing Complete Spatial Randomness Test\n\\(H_0\\) = The distribution of childcare services at Choa Chu Kang are randomly distributed.\n\\(H_1\\) = The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code block below is used to perform the hypothesis testing.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim=39, rank = 1, glocal=TRUE)\n\nGenerating 39 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, \n39.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n14.6.2 Tampines Planning Area\n\n14.6.2.1 Computing L-function Estimate\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r,\n     ylab= \"L(d)-r\", xlab = \"d(m)\",\n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n\n\n14.7 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\n\\(H_0\\) = The distribution of childcare services at Tampines are randomly distributed.\n\\(H_1\\) = The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below will be used to perform the hypothesis testing\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim=39, rank = 1, glocal=TRUE)\n\nGenerating 39 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, \n39.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r,\n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html",
    "title": "5B: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 10  Local Measures of Spatial Autocorrelation"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#exercise-5b-reference",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#exercise-5b-reference",
    "title": "5B: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 10  Local Measures of Spatial Autocorrelation"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#overview",
    "title": "5B: Local Measures of Spatial Autocorrelation",
    "section": "2 Overview",
    "text": "2 Overview\nLocal Measures of Spatial Autocorrelation (LMSA) analyze the relationships between each observation and its surroundings, rather than summarizing these relationships across an entire map. They provide scores that reveal the spatial structure of the data, similar in concept to global measures, and are often mathematically connected, as global measures can be decomposed into local ones.\nIn this exercise, we will learn to compute Local Measures of Spatial Autocorrelation (LMSA) using the spdep package, including Local Moran’s I, Getis-Ord’s Gi-statistics, and their visualizations."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#learning-outcome",
    "title": "5B: Local Measures of Spatial Autocorrelation",
    "section": "3 Learning Outcome",
    "text": "3 Learning Outcome\n\nImport geospatial data using the sf package\nImport CSV data using the readr package\nPerform relational joins using the dplyr package\nCompute Local Indicator of Spatial Association (LISA) statistics using spdep\n\nDetect clusters and outliers with Local Moran’s I\nIdentify hot and cold spots with Getis-Ord’s Gi-statistics\n\nVisualize analysis outputs using the tmap package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#the-analytical-question",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#the-analytical-question",
    "title": "5B: Local Measures of Spatial Autocorrelation",
    "section": "4 The Analytical Question",
    "text": "4 The Analytical Question\nIn spatial policy planning, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. In this study, we will apply spatial statistical methods to examine the distribution of development in Hunan Province, China, using a selected indicator (e.g., GDP per capita).\n\nOur key questions are:\n\nIs development evenly distributed geographically?\nIf not, is there evidence of spatial clustering?\nIf clustering exists, where are these clusters located?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#the-data",
    "title": "5B: Local Measures of Spatial Autocorrelation",
    "section": "5 The Data",
    "text": "5 The Data\nThe following 2 datasets will be used in this exercise.\n\n\n\n\n\n\n\n\nData Set\nDescription\nFormat\n\n\n\n\nHunan county boundary layer\nGeospatial data set representing the county boundaries of Hunan\nESRI Shapefile\n\n\nHunan_2012.csv\nContains selected local development indicators for Hunan in 2012\nCSV"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#installing-and-launching-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#installing-and-launching-the-r-packages",
    "title": "5B: Local Measures of Spatial Autocorrelation",
    "section": "6 Installing and Launching the R Packages",
    "text": "6 Installing and Launching the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\n\nsf\nHandles spatial data, particularly vector-based geospatial data.\nImporting and managing township boundary data for Myanmar.\n\n\nrgdal\nProvides bindings to the Geospatial Data Abstraction Library (GDAL) for reading and writing spatial data.\nReading and writing geospatial data in various formats, including shapefiles.\n\n\nspdep\nAnalyzes spatial dependence and provides tools for spatial econometrics.\nPerforming spatially constrained clustering and other spatial dependence analyses.\n\n\ntidyverse\nA collection of packages for data science tasks like data manipulation and visualization.\nHandling attribute data, reading CSV files, and data wrangling with readr, dplyr, and ggplot2.\n\n\ntmap\nCreates static and interactive thematic maps.\nVisualizing data using choropleth maps to display spatial patterns and relationships.\n\n\ncorrplot\nVisualizes correlation matrices.\nCreating correlation plots to explore relationships between different ICT measures.\n\n\nggpubr\nProvides functions to create and customize ‘ggplot2’-based publication-ready plots.\nEnhancing multivariate data visualizations for clearer presentation of results.\n\n\nheatmaply\nGenerates interactive heatmaps.\nVisualizing multivariate data through interactive heatmaps for deeper insights.\n\n\ncluster\nPerforms cluster analysis.\nConducting hierarchical clustering to group similar regions based on ICT measures.\n\n\nClustGeo\nPerforms spatially constrained hierarchical clustering.\nApplying spatial constraints to hierarchical clustering for identifying homogeneous regions.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#import-data-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#import-data-and-preparation",
    "title": "5B: Local Measures of Spatial Autocorrelation",
    "section": "7 Import Data and Preparation",
    "text": "7 Import Data and Preparation\nIn this section, we will perform 3 necessary steps to prepare the data for analysis.\n\n\n\n\n\n\nNote\n\n\n\nThe data preparation is the same as previous exercise such as Exercise 4A.\n\n\n\n7.1 Import Geospatial Shapefile\nFirstly, we will use st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex05/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n7.2 Import Aspatial csv File\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n7.3 Perform Relational Join\nThen, we will perform a left_join() to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n\n7.4 Visualizing Regional Development Indicator\nTo visualize the regional development indicator, we can prepare a base map and a choropleth map to show the distribution of GDPPC 2012 (GDP per capita) by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#local-indicators-of-spatial-associationlisa",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#local-indicators-of-spatial-associationlisa",
    "title": "5B: Local Measures of Spatial Autocorrelation",
    "section": "8 Local Indicators of Spatial Association(LISA)",
    "text": "8 Local Indicators of Spatial Association(LISA)\nLocal Indicators of Spatial Association (LISA) are statistics used to identify clusters and outliers in the spatial distribution of a variable. For example, if we are analyzing the GDP per capita in Hunan Province, China, LISA can help detect areas (counties) where GDP values are significantly higher or lower than expected by chance. This means that these values deviate from what would be seen in a random distribution across space.\nIn this section, we will apply appropriate Local Indicators for Spatial Association (LISA), particularly the Local Moran’s I statistic, to identify clusters and outliers in the 2012 GDP per capita data for Hunan Province.\n\n8.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code block below, the poly2nb() function from the spdep package calculates contiguity weight matrices for the study area by identifying regions that share boundaries.\nBy default, poly2nb() uses the “Queen” criteria, which considers any shared boundary or corner as a neighbor (equivalent to setting queen = TRUE). If we want to restrict the criteria to shared boundaries only (excluding corners), set queen = FALSE.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.\n\n\n8.2 Row-standardised Weights Matrix\nNext, we need to assign weights to each neighboring polygon. In this case, we’ll use equal weights (style=“W”), where each neighboring polygon gets a weight of 1/(number of neighbors). This means we take the value for each neighbor and divide it by the total number of neighbors, then sum these weighted values to calculate a summary measure, such as weighted income.\nWhile this equal weighting approach is straightforward and easy to understand, it has a limitation: polygons on the edges of the study area have fewer neighbors, which can lead to over- or underestimation of the actual spatial relationships (spatial autocorrelation) in the data.\n\n\n\n\n\n\nTip\n\n\n\nFor simplicity, we use the style=“W” option in this example, but keep in mind that other, potentially more accurate methods are available, such as style=“B”.\n\n\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.\n\n\n\n\n\n8.3 Computing Local Moran’s I\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nFirst, we compute a vector fips that contains the indexes to sort the County column of the hunan dataset in ascending alphabetical order.\n\nfips &lt;- order(hunan$County)\nglimpse(hunan$County[fips])\n\n chr [1:88] \"Anhua\" \"Anren\" \"Anxiang\" \"Baojing\" \"Chaling\" \"Changning\" ...\n\n\nThen, we compute local Moran’s I of GDPPC2012 at the county level.\n\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\n\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\n\n\n\n\n\n\nTip\n\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\n\n\nNext, we list the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n8.3.1 Mapping the Local Moran’s I\nBefore mapping the local Moran’s I map, we append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame, hunan.localMI.\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\nhead(hunan.localMI)\n\nSimple feature collection with 6 features and 11 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC           Ii          E.Ii\n1 Changde 21098 Anxiang      County Anxiang 23667 -0.001468468 -2.815006e-05\n2 Changde 21100 Hanshou      County Hanshou 20981  0.025878173 -6.061953e-04\n3 Changde 21101  Jinshi County City  Jinshi 34592 -0.011987646 -5.366648e-03\n4 Changde 21102      Li      County      Li 24473  0.001022468 -2.404783e-07\n5 Changde 21103   Linli      County   Linli 25554  0.014814881 -6.829362e-05\n6 Changde 21104  Shimen      County  Shimen 27137 -0.038793829 -3.860263e-04\n        Var.Ii        Z.Ii     Pr.Ii                       geometry\n1 4.723841e-04 -0.06626904 0.9471636 POLYGON ((112.0625 29.75523...\n2 1.016664e-02  0.26266425 0.7928094 POLYGON ((112.2288 29.11684...\n3 1.133362e-01 -0.01966705 0.9843090 POLYGON ((111.8927 29.6013,...\n4 5.105969e-06  0.45259801 0.6508382 POLYGON ((111.3731 29.94649...\n5 1.449949e-03  0.39085814 0.6959021 POLYGON ((111.6324 29.76288...\n6 6.475559e-03 -0.47728835 0.6331568 POLYGON ((110.8825 30.11675...\n\n\n\n\n8.3.2 Mapping local Moran’s I values\nWe can plot the local Moran’s I values using choropleth mapping functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n8.3.3 Mapping local Moran’s I p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values\nThe code block below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n8.3.4 Mapping both local Moran’s I values and p-values\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code block below will be used to create such visualisation.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n# find county with max Ii and observe its Ii, p-value\nmax_row &lt;- hunan.localMI[which.max(hunan.localMI$Ii), , drop = FALSE]\nmax_row\n\nSimple feature collection with 1 feature and 11 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 112.8907 ymin: 27.91915 xmax: 113.506 ymax: 28.66025\nGeodetic CRS:  WGS 84\n     NAME_2  ID_3   NAME_3 ENGTYPE_3   County GDPPC       Ii       E.Ii\n84 Changsha 21107 Changsha  District Changsha 88656 4.902202 -0.2134796\n     Var.Ii    Z.Ii        Pr.Ii                       geometry\n84 2.319447 3.35901 0.0007822232 POLYGON ((112.9421 28.03722...\n\n\n\n# find county with max Ii and observe its Ii, p-value\nmin_row &lt;- hunan.localMI[which.min(hunan.localMI$Ii), , drop = FALSE]\nmin_row\n\nSimple feature collection with 1 feature and 11 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 111.3138 ymin: 27.53506 xmax: 111.6069 ymax: 27.81732\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3        NAME_3   ENGTYPE_3        County GDPPC        Ii\n34  Loudi 21143 Lengshuijiang County City Lengshuijiang 64257 -1.790335\n          E.Ii   Var.Ii      Z.Ii    Pr.Ii                       geometry\n34 -0.08212937 2.159843 -1.162329 0.245102 POLYGON ((111.5307 27.81472...\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe plot above consists of two maps: one showing the Local Moran’s I statistics (Ii) and the other displaying the corresponding p-values for Local Moran’s I statistics.\n\n8.3.4.1 Left Plot: Local Moran’s I Statistics\nColor Scale: - The color scale ranges from light yellow to dark green, representing different ranges of Local Moran’s I values (Ii).\n\nDark Green Areas: Represent counties with high positive Local Moran’s I values (between 3 and 5). These areas show strong positive spatial autocorrelation, indicating clusters where counties have similar high GDP per capita values compared to their neighbors.\nLight Yellow Areas: Represent counties with lower Local Moran’s I values (around 0 to 1). These areas have weaker spatial autocorrelation, suggesting less significant clustering or similarity with their neighbors.\nOrange Areas: Represent negative Local Moran’s I values (between -2 to 0). These are areas where counties have significantly different GDP per capita values from their neighbors (spatial outliers).\n\n\n\n8.3.4.2 Right Plot: Local Moran’s I p-values\nColor Scale: - The color scale ranges from light blue to dark blue, representing different ranges of p-values for Local Moran’s I statistics.\n\nDark Blue Areas: Represent counties with very low p-values (less than 0.001), indicating that the observed spatial clustering is statistically significant at a very high confidence level.\nLighter Blue Areas: Represent counties with higher p-values (e.g., between 0.01 and 0.10), suggesting that the clustering is less statistically significant.\nVery Light Blue Areas: Represent counties with p-values greater than 0.10, indicating that there is no statistically significant spatial autocorrelation.\n\n\n\n8.3.4.3 Observations:\n\nThe map shows that the central-eastern region (around the Changsha county) has several dark blue counties with very low p-values, indicating strong evidence of significant spatial clustering of similar GDP per capita values."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#creating-a-lisa-cluster-map",
    "title": "5B: Local Measures of Spatial Autocorrelation",
    "section": "9 Creating a LISA Cluster Map",
    "text": "9 Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation.\nBefore we can generate the LISA cluster map, we have to plot the Moran scatterplot.\n\n9.1 Plotting Moran scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code block below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations The plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This are the high-high locations in the lesson slide, recall:\n\n\n\n\n\n9.2 Plotting Moran scatterplot with Standardised Variable\nTo plot Moran scatterplot with standardised variable:\n\nUse scale() to center and scale the variable. Centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\nUse as.vector() to ensure that the standardized output is treated as a vector, which is necessary for proper mapping into the output data frame.\nPlot the Moran scatterplot\n\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the plot is similar to the previous plot. After scaling it, the cut off axis for x and y-axis is at 0.\n\n\n\n\n9.3 Preparing LISA map classes\nThe code block below show the steps to prepare a LISA cluster map.\n\nConvert to Vector\n\n\nquadrant &lt;- vector(mode=\"numeric\",\n                   length=nrow(localMI))\n\n\nderive the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, \n                             hunan$GDPPC)\n\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\n\ncenter the local Moran’s variable around the mean.\n\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\n\nset a statistical significance level (alpha value) for the local Moran.\n\n\nsignif &lt;- 0.05       \n\n\ndefine quadrants. The four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4      \n\n\nplace non-significant Moran in the category 0.\n\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\n\n9.4 Plotting LISA map\nNow, we can build the LISA map:\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nTo create such visualisation:\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\nWe can also include the local Moran’s I map and p-value map as shown below for easy comparison.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical observations can you draw from the LISA map above?\nFrom the LISA map and GDPPC map, there is a significant “high-high” cluster in the central-eastern part of the province, where counties with high GDP per capita are surrounded by similar counties.\nThis pattern is reinforced by the Local Moran’s I statistics map, which show the same region in a deep green shade, indicating strong positive spatial autocorrelation. The corresponding low p-values further confirm the statistical significance of this economic clustering.\nNotably, the high-high cluster on the LISA map extends over more counties than those highlighted by the Local Moran’s I statistics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#hot-spot-and-cold-spot-area-analysis",
    "title": "5B: Local Measures of Spatial Autocorrelation",
    "section": "10 Hot Spot and Cold Spot Area Analysis",
    "text": "10 Hot Spot and Cold Spot Area Analysis\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\n10.1 Getis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\n10.2 Deriving Distance-based Weight Matrix\nFirst, we need to define a new set of neighbors. Unlike spatial autocorrelation, which considers units sharing borders, the Getis-Ord method defines neighbors based on distance.\nThere are two types of distance-based proximity matrices:\n\nFixed Distance Weight Matrix: Neighbors are defined within a fixed distance.\nAdaptive Distance Weight Matrix: Neighbors are defined based on a varying distance that adapts to include a specified number of nearest neighbors.\n\n\n10.2.1 Deriving the Centroid\nTo create a connectivity graph, we first need to associate points (centroids) with each polygon in our spatial data. This process involves more than simply running st_centroid() on the us.bound sf object; we need to extract coordinates into a separate data frame.\nWe achieve this using a mapping function, which applies a specific function to each element of a vector and returns a new vector of the same length. Here, the input vector is the geometry column of us.bound, and the function applied is st_centroid(). We’ll use the map_dbl function from the purrr package to do this. For more details, refer to the map documentation.\nTo extract longitude values, we map the st_centroid() function over the geometry column of us.bound and access the longitude using double bracket notation [[ ]] and 1, which retrieves the first value (longitude) from each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n10.2.2 Determine the Cut-off Distance\nTo determine the upper limit for the distance band:\n\nUse the knearneigh() function from spdep to create a matrix containing the indices of the k nearest neighbors for each point.\nConvert the knn object from knearneigh() into a neighbor list (nb class) using knn2nb(). This list contains integer vectors representing the neighbor region numbers.\nUse nbdists() from spdep to calculate the lengths of the neighbor relationships (distances). If coordinates are projected, the distances are in the units of the coordinates; otherwise, they are in kilometers.\nFlatten the list structure of the returned distances using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\n\n\n\n\n\nNote\n\n\n\nUsing the summary report, we can observe that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\n\n10.2.3 Computing Fixed Distance Weight Matrix\nUse dnearneigh() to compute distance weight matrix:\n\n# get max dist from k1dists rounded up to integer\nmax_dist &lt;- as.integer(ceiling(max(k1dists)))\n\nwm_d62 &lt;- dnearneigh(x=coords, d1=0, d2=max_dist, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\nThe output spatial weights object is called wm62_lw.\n\n\n\n10.3 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code block below.\n\n# set nearest neighbour as 8\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-gi-statistics",
    "title": "5B: Local Measures of Spatial Autocorrelation",
    "section": "11 Computing Gi statistics",
    "text": "11 Computing Gi statistics\n\n11.1 Gi statistics using fixed distance\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistic is expressed as a Z-score, where higher values indicate stronger clustering. The direction (positive or negative) shows whether the clusters are high or low.\nNext, we’ll join the Gi values to the corresponding hunan sf data frame using the following code:\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nThis code performs three tasks: 1. Converts the output vector (gi.fixed) to an R matrix using as.matrix(). 2. Combines the hunan data and the gi.fixed matrix into a new spatial data frame (hunan.gi) using cbind(). 3. Renames the Gi values column to gstat_fixed using rename().\n\n\n11.2 Mapping Gi Values with Fixed Distance Weights\nThe code block below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap_fd &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(title = \"Gi Map using Fixed Distance Weight Matrix\")\n\n\ntmap_arrange(gdppc, Gimap_fd, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical observation can you draw from the Gi map above?\nsee below with adaptive weight distance matrix viz.\n\n\n\n\n11.3 Gi statistics using adaptive distance\nNext, we use similar steps to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw) and compare the methodology.\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n# adaptive distance\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap_ad &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)+ \n  tm_layout(title = \"Gi Map using Adaptive Distance Weight Matrix\")\n\n\ntmap_arrange(gdppc, \n             Gimap_ad, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical observation can you draw from the Gi maps (comparing between Fixed and Adaptive Weight matrix) above?\nBoth methods identify similar clusters in the central-eastern (hot spots), and western regions (cold spots), confirming consistent spatial patterns.\nThe fixed distance approach captures more localized clusters, while the adaptive distance approach reveals broader patterns (smoothing effect discussed above), adjusting dynamically to neighborhood density.\nAlso note that the range of legend is slightly different across the 2 methods."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html",
    "title": "6A: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 12  Geographical Segmentation with Spatially Constrained Clustering Techniques"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#exercise-6a-reference",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#exercise-6a-reference",
    "title": "6A: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 12  Geographical Segmentation with Spatially Constrained Clustering Techniques"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#overview",
    "title": "6A: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "2 Overview",
    "text": "2 Overview\nIn this exercise, we will learn to delineate homogeneous regions using hierarchical and spatially constrained clustering techniques on geographically referenced multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#learning-outcome",
    "title": "6A: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "3 Learning Outcome",
    "text": "3 Learning Outcome\n\nConvert GIS polygon data to R’s simple feature data frame.\nConvert simple feature data frame to R’s SpatialPolygonDataFrame object.\nPerform cluster analysis with hclust().\nConduct spatially constrained cluster analysis using skater().\nVisualize analysis outputs using ggplot2 and tmap."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#the-analytical-question",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#the-analytical-question",
    "title": "6A: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "4 The Analytical Question",
    "text": "4 The Analytical Question\nIn geobusiness and spatial policy, delineating market or planning areas into homogeneous regions using multivariate data is a common approach.\n\nIn this exercise, we aim to divide Shan State, Myanmar into homogeneous regions based on various Information and Communication Technology (ICT) indicators, such as radio, television, landline phones, mobile phones, computers, and home internet access."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#the-data",
    "title": "6A: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "5 The Data",
    "text": "5 The Data\nThe following 2 datasets will be used in this study.\n\n\n\n\n\n\n\n\nData Set\nDescription\nFormat\n\n\n\n\nmyanmar_township_boundaries\nGIS data in ESRI shapefile format containing township boundary information of Myanmar, represented as polygon features.\nESRI Shapefile\n\n\nShan-ICT.csv\nExtract of the 2014 Myanmar Population and Housing Census at the township level.\nCSV\n\n\n\nBoth datasets are downloaded from the Myanmar Information Management Unit (MIMU)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#installing-and-launching-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#installing-and-launching-the-r-packages",
    "title": "6A: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6 Installing and Launching the R Packages",
    "text": "6 Installing and Launching the R Packages\nTo install and load these packages, use the following code:\n\npacman::p_load(spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally, plotly, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#import-data-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#import-data-and-preparation",
    "title": "6A: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7 Import Data and Preparation",
    "text": "7 Import Data and Preparation\n\n7.1 Import Geospatial Shapefile\nFirstly, we will use st_read() of sf package to import Myanmar Township Boundary shapefile into R. The imported shapefile will be simple features Object of sf.\n\nshan_sf &lt;- st_read(dsn = \"data/geospatial\", layer = \"myanmar_township_boundaries\")\n\nReading layer `myanmar_township_boundaries' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex06/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOBJECTID\nST\nST_PCODE\nDT\nDT_PCODE\nTS\nTS_PCODE\nST_2\nLABEL2\nSELF_ADMIN\nST_RG\nT_NAME_WIN\nT_NAME_M3\nAREA\ngeometry\n\n\n\n\n250\nKachin\nMMR001\nMohnyin\nMMR001D002\nHpakant\nMMR001009\nKachin State\nHpakant\n\n\n\n\n\n\n\n\n169795\nNA\nState\nzm;uefU\nဖားကန့်\n5761.2964\nMULTIPOLYGON (((96.15953 26…\n\n\n\n\n\n\n\n\n\n\n163\nShan (North)\nMMR015\nMongmit\nMMR015D008\nMongmit\nMMR015017\nShan State (North)\nMongmit\n\n\n\n\n\n\n\n\n61072\nNA\nState\nrdk;rdwf\nမိုးမိတ်\n2703.6114\nMULTIPOLYGON (((96.96001 23…\n\n\n\n\n\n\n\n\n\n\n96\nBago (East)\nMMR007\nBago\nMMR007D001\nWaw\nMMR007004\nBago Region (East)\nWaw\n\n\n\n\n\n\n\n\n199032\nNA\nRegion\na0g\nဝေါ\n952.4398\nMULTIPOLYGON (((96.61505 17…\n\n\n\n\n\n\n\n\n\n\n147\nBago (West)\nMMR008\nPyay\nMMR008D001\nPaukkhaung\nMMR008002\nBago Region (West)\nPaukkhaung\n\n\n\n\n\n\n\n\n117164\nNA\nRegion\naygufacgif;\nပေါက်ခေါင်း\n1918.6734\nMULTIPOLYGON (((95.82708 19…\n\n\n\n\n\n\n\n\n\n\n263\nMandalay\nMMR010\nPyinoolwin\nMMR010D002\nMogoke\nMMR010011\nMandalay Region\nMogoke\n\n\n\n\n\n\n\n\n191775\nNA\nRegion\nrdk;ukwf\nမိုးကုတ်\n1178.5076\nMULTIPOLYGON (((96.22371 23…\n\n\n\n\n\n\n\n\n\n\n167\nKachin\nMMR001\nBhamo\nMMR001D003\nShwegu\nMMR001011\nKachin State\nShwegu\n\n\n\n\n\n\n\n\n84750\nNA\nState\na&Tul\nရွှေကူ\n3088.8291\nMULTIPOLYGON (((96.68573 24…\n\n\n\n\n\n\n\n\n\n\n\n\n\nSince our study area is the Shan state, we will examine the state list in the dataframe for the relevant state names (keys) for filtering.\n\n# Display unique values in the \"ST\" column sorted in ascending order\nsort(unique(shan_sf$ST))\n\n [1] \"Ayeyarwady\"   \"Bago (East)\"  \"Bago (West)\"  \"Chin\"         \"Kachin\"      \n [6] \"Kayah\"        \"Kayin\"        \"Magway\"       \"Mandalay\"     \"Mon\"         \n[11] \"Nay Pyi Taw\"  \"Rakhine\"      \"Sagaing\"      \"Shan (East)\"  \"Shan (North)\"\n[16] \"Shan (South)\" \"Tanintharyi\"  \"Yangon\"      \n\n\n\nshan_sf &lt;- \n  shan_sf %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;% \n  select(c(2:7))\n\nshan_sf\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\n\nThen, we filter the dataframe to contain only the Shan states.\n\n\n7.2 Import Aspatial csv File\nNext, we will import Shan-ICT.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nict &lt;- read_csv (\"data/aspatial/Shan-ICT.csv\")\n\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\nThere are a total of 11 fields and 55 observation in the dataframe.\n\n\n7.3 Deriving New Variables Using the dplyr Package\nThe values in the dataset represent the number of households, which can be biased by the total number of households in each township. Townships with more households will naturally have higher numbers of households owning items like radios or TVs.\nTo address this bias, we will calculate the penetration rate for each ICT variable by dividing the number of households owning each item by the total number of households, then multiplying by 1000. This will normalize the data, allowing for a fair comparison between townships. Here is the code to perform this calculation:\n\nict_derived &lt;- ict %&gt;%\n  # feature engineering: normalize data\n  mutate(\n    RADIO_PR = Radio / `Total households` * 1000,\n    TV_PR = Television / `Total households` * 1000,\n    LLPHONE_PR = `Land line phone` / `Total households` * 1000,\n    MPHONE_PR = `Mobile phone` / `Total households` * 1000,\n    COMPUTER_PR = Computer / `Total households` * 1000,\n    INTERNET_PR = `Internet at home` / `Total households` * 1000\n  ) %&gt;%\n  # improve readability of col names\n  rename(\n    DT_PCODE = `District Pcode`, DT = `District Name`,\n    TS_PCODE = `Township Pcode`, TS = `Township Name`,\n    TT_HOUSEHOLDS = `Total households`,\n    RADIO = Radio, TV = Television,\n    LLPHONE = `Land line phone`, MPHONE = `Mobile phone`,\n    COMPUTER = Computer, INTERNET = `Internet at home`\n  )\n\nWe can then review the summary statistics of the newly derived penetration rates using:\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\nThis process adds six new fields to the data frame: RADIO_PR, TV_PR, LLPHONE_PR, MPHONE_PR, COMPUTER_PR, and INTERNET_PR, representing the penetration rates for each ICT variable."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#exploratory-data-analysis-eda",
    "title": "6A: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8 Exploratory Data Analysis (EDA)",
    "text": "8 Exploratory Data Analysis (EDA)\n\n8.1 Statistical Graphics\nHistogram is useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution)\n\np &lt;- ggplot(data = ict_derived, aes(x = RADIO)) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"lightblue\") +\n  labs(\n    title = \"Distribution of Radio Ownership\",\n    x = \"Number of Households with Radio\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()\n\nggplotly(p)\n\n\n\n\n\nBoxplot is useful to detect if there are outliers.\n\nplot_ly(data = ict_derived, \n        x = ~RADIO,\n        type = 'box', \n        fillcolor = 'lightblue', \n        marker = list(color = 'lightblue'),\n        notched = TRUE\n       ) %&gt;%\n  layout(\n    title = \"Distribution of Radio Ownership\",\n    xaxis = list(title = \"Number of Households with Radio\")\n  )\n\n\n\n\n\nWe will also plotting the distribution of the newly derived variables (i.e. Radio penetration rate).\n\n\nShow the code\nmean_pr &lt;- round(mean(ict_derived$`RADIO_PR`, na.rm = TRUE), 1)\n\n# Define common axis properties\naxis_settings &lt;- list(\n  title = \"\",\n  zeroline = FALSE,\n  showline = FALSE,\n  showgrid = FALSE\n)\n\naax_b &lt;- list(\n  title = \"\",\n  zeroline = FALSE,\n  showline = FALSE,\n  showticklabels = FALSE,\n  showgrid = FALSE\n)\n\n# Plot Histogram\nhistogram_plot &lt;- plot_ly(\n  ict_derived,\n  x = ~`RADIO_PR`,\n  type = 'histogram',\n  histnorm = \"count\",\n  marker = list(color = 'lightblue'), \n  hovertemplate = 'Radio Penetration Rate: %{x}&lt;br&gt;Frequency: %{y}&lt;extra&gt;&lt;/extra&gt;'\n) %&gt;%\n  add_lines(\n    x = mean_pr, y = c(0, 15),\n    line = list(width = 3, color = \"black\"),  \n    showlegend = FALSE\n  ) %&gt;%\n  add_annotations(\n    text = paste(\"Mean: \", mean_pr),\n    x = mean_pr, y = 15,\n    showarrow = FALSE,\n    font = list(size = 12)\n  ) %&gt;%\n  layout(\n    xaxis = list(title = \"Radio Penetration Rate\"),\n    yaxis = axis_settings,\n    bargap = 0.1\n  )\n\n# Plot Boxplot\nboxplot_plot &lt;- plot_ly(\n  ict_derived,\n  x = ~`RADIO_PR`,\n  type = \"box\",\n  boxpoints = \"all\",\n  jitter = 0.3,\n  pointpos = -1.8,\n  notched = TRUE,\n  fillcolor = 'lightblue', \n  marker = list(color = 'lightblue'),\n  showlegend = FALSE\n) %&gt;%\n  layout(\n    xaxis = axis_settings,\n    yaxis = aax_b\n  )\n\n# Combine Histogram and Boxplot\nsubplot(\n  boxplot_plot, histogram_plot,\n  nrows = 2, heights = c(0.2, 0.8), shareX = TRUE\n) %&gt;%\n  layout(\n    showlegend = FALSE,\n    title = \"Distribution of Radio Penetration Rate\",\n    xaxis = list(range = c(0, 500))\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen we compare the distribution of radio ownership vs radio penetration rate, the distribution of radio penetration rate is less skewed.\n\n\nWe can also plot multiple histograms to get a sense of the feature engineered fields.\n\n\nShow the code\nradio &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv &lt;- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone &lt;- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone &lt;- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer &lt;- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet &lt;- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nggarrange(radio, tv, llphone, mphone, computer, internet, ncol = 3, nrow = 2)\n\n\n\n\n\n\n\n\n\n\n\n8.2 EDA using Choropleth Map\n\n8.2.1 Joining Geospatial Data with Aspatial Data\nBefore we can prepare the choropleth map, we need to combine both the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived) into one. This will be performed by using the left_join function of dplyr package. The shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table.\nTo join the data objects, we use the unique identifier, TS_PCODE.\n\nfile_path &lt;- \"data/rds/shan_sf.rds\"\n\nif (!file.exists(file_path)) {\n  shan_sf &lt;- left_join(shan_sf, ict_derived, by = c(\"TS_PCODE\" = \"TS_PCODE\"))\n  write_rds(shan_sf, file_path)\n  \n} else {\n  shan_sf &lt;- read_rds(file_path)\n}\n\nkable(head(shan_sf))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nST\nST_PCODE\nDT.x\nDT_PCODE.x\nTS.x\nTS_PCODE\nDT_PCODE.y\nDT.y\nTS.y\nTT_HOUSEHOLDS.x\nRADIO.x\nTV.x\nLLPHONE.x\nMPHONE.x\nCOMPUTER.x\nINTERNET.x\nRADIO_PR.x\nTV_PR.x\nLLPHONE_PR.x\nMPHONE_PR.x\nCOMPUTER_PR.x\nINTERNET_PR.x\nDT_PCODE.x.x\nDT.x.x\nTS.x.x\nTT_HOUSEHOLDS.y\nRADIO.y\nTV.y\nLLPHONE.y\nMPHONE.y\nCOMPUTER.y\nINTERNET.y\nRADIO_PR.y\nTV_PR.y\nLLPHONE_PR.y\nMPHONE_PR.y\nCOMPUTER_PR.y\nINTERNET_PR.y\nDT_PCODE.y.y\nDT.y.y\nTS.y.y\nTT_HOUSEHOLDS\nRADIO\nTV\nLLPHONE\nMPHONE\nCOMPUTER\nINTERNET\nRADIO_PR\nTV_PR\nLLPHONE_PR\nMPHONE_PR\nCOMPUTER_PR\nINTERNET_PR\ngeometry\n\n\n\n\nShan (North)\nMMR015\nMongmit\nMMR015D008\nMongmit\nMMR015017\nMMR015D003\nKyaukme\nMongmit\n13652\n3907\n7565\n482\n3559\n166\n321\n286.1852\n554.1313\n35.30618\n260.6944\n12.15939\n23.513038\nMMR015D003\nKyaukme\nMongmit\n13652\n3907\n7565\n482\n3559\n166\n321\n286.1852\n554.1313\n35.30618\n260.6944\n12.15939\n23.513038\nMMR015D003\nKyaukme\nMongmit\n13652\n3907\n7565\n482\n3559\n166\n321\n286.1852\n554.1313\n35.30618\n260.6944\n12.15939\n23.513038\nMULTIPOLYGON (((96.96001 23…\n\n\nShan (South)\nMMR014\nTaunggyi\nMMR014D001\nPindaya\nMMR014006\nMMR014D001\nTaunggyi\nPindaya\n17544\n7324\n8862\n348\n2849\n226\n136\n417.4647\n505.1300\n19.83584\n162.3917\n12.88190\n7.751938\nMMR014D001\nTaunggyi\nPindaya\n17544\n7324\n8862\n348\n2849\n226\n136\n417.4647\n505.1300\n19.83584\n162.3917\n12.88190\n7.751938\nMMR014D001\nTaunggyi\nPindaya\n17544\n7324\n8862\n348\n2849\n226\n136\n417.4647\n505.1300\n19.83584\n162.3917\n12.88190\n7.751938\nMULTIPOLYGON (((96.7731 21….\n\n\nShan (South)\nMMR014\nTaunggyi\nMMR014D001\nYwangan\nMMR014007\nMMR014D001\nTaunggyi\nYwangan\n18348\n8890\n4781\n219\n2207\n81\n152\n484.5215\n260.5734\n11.93591\n120.2856\n4.41465\n8.284282\nMMR014D001\nTaunggyi\nYwangan\n18348\n8890\n4781\n219\n2207\n81\n152\n484.5215\n260.5734\n11.93591\n120.2856\n4.41465\n8.284282\nMMR014D001\nTaunggyi\nYwangan\n18348\n8890\n4781\n219\n2207\n81\n152\n484.5215\n260.5734\n11.93591\n120.2856\n4.41465\n8.284282\nMULTIPOLYGON (((96.78483 21…\n\n\nShan (South)\nMMR014\nTaunggyi\nMMR014D001\nPinlaung\nMMR014009\nMMR014D001\nTaunggyi\nPinlaung\n25504\n5908\n13816\n728\n6363\n351\n737\n231.6499\n541.7189\n28.54454\n249.4903\n13.76255\n28.897428\nMMR014D001\nTaunggyi\nPinlaung\n25504\n5908\n13816\n728\n6363\n351\n737\n231.6499\n541.7189\n28.54454\n249.4903\n13.76255\n28.897428\nMMR014D001\nTaunggyi\nPinlaung\n25504\n5908\n13816\n728\n6363\n351\n737\n231.6499\n541.7189\n28.54454\n249.4903\n13.76255\n28.897428\nMULTIPOLYGON (((96.49518 20…\n\n\nShan (North)\nMMR015\nMongmit\nMMR015D008\nMabein\nMMR015018\nMMR015D003\nKyaukme\nMabein\n8632\n3880\n6117\n628\n3389\n142\n165\n449.4903\n708.6423\n72.75255\n392.6089\n16.45042\n19.114921\nMMR015D003\nKyaukme\nMabein\n8632\n3880\n6117\n628\n3389\n142\n165\n449.4903\n708.6423\n72.75255\n392.6089\n16.45042\n19.114921\nMMR015D003\nKyaukme\nMabein\n8632\n3880\n6117\n628\n3389\n142\n165\n449.4903\n708.6423\n72.75255\n392.6089\n16.45042\n19.114921\nMULTIPOLYGON (((96.66306 24…\n\n\nShan (South)\nMMR014\nTaunggyi\nMMR014D001\nKalaw\nMMR014005\nMMR014D001\nTaunggyi\nKalaw\n41341\n11607\n25285\n1739\n16900\n1225\n1741\n280.7624\n611.6204\n42.06478\n408.7951\n29.63160\n42.113156\nMMR014D001\nTaunggyi\nKalaw\n41341\n11607\n25285\n1739\n16900\n1225\n1741\n280.7624\n611.6204\n42.06478\n408.7951\n29.63160\n42.113156\nMMR014D001\nTaunggyi\nKalaw\n41341\n11607\n25285\n1739\n16900\n1225\n1741\n280.7624\n611.6204\n42.06478\n408.7951\n29.63160\n42.113156\nMULTIPOLYGON (((96.49518 20…\n\n\n\n\n\n\n\n8.2.2 Preparing a Choropleth Map\nTo have a quick look at the distribution of Radio penetration rate of Shan State at township level, a choropleth map will be prepared.\nThe code below is used to prepare the choropleth map by using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\n\n\n\n\nIn order to reveal the distribution shown in the choropleth map above are bias to the underlying total number of households at the townships, we will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) by using the code below.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\n\n\n\n\nNotice that the choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\nNow let us plot the choropleth maps showing the distribution of total number of households and Radio penetration rate by using the code below.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAt first glance, for the Distribution of total number of households and radios plot, it reveals that township with relative larger number of households also exhibit relatively higher number of radio ownership.\nThe penetration rate plot provides more nuanced insight into radio ownership, highlighting regions where radios are more common among households, regardless of the total number of households in the region. This may suggest radio ownership rate is no sole dependent on the total population but also on socio-economic factors, or policies etc."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#correlation-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#correlation-analysis",
    "title": "6A: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "9 Correlation Analysis",
    "text": "9 Correlation Analysis\nBefore we perform cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated.\nIn this section, we will use corrplot.mixed() function of corrplot package to visualise and analyse the correlation of the input variables.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nThe correlation plot above shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis instead of both."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#hierarchy-cluster-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#hierarchy-cluster-analysis",
    "title": "6A: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "10 Hierarchy Cluster Analysis",
    "text": "10 Hierarchy Cluster Analysis\nIn this section, we will perform hierarchical cluster analysis.\n\n10.1 Extracting Clustering Variables\nThe code below will be used to extract the clustering variables from the shan_sf simple feature object into data.frame.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  # we dont select INTERNET_PR\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the final clustering variables list does not include variable INTERNET_PR because it is highly correlated with variable COMPUTER_PR.\nNext, we need to change the rows by township name instead of row number by using the code below.\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the row number has been replaced into the township name.\nThen, we will delete the TS.x field.\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n10.2 Data Standardisation\nIn general, multiple variables will be used in cluster analysis. It is not unusual their values range are different. In order to avoid cluster analysis result to be biased due to the clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.\n\n\n10.3 Min-Max standardisation\nIn the code below, we use:\n\nnormalize() of heatmaply package to standardise the clustering variables by using Min-Max method.\nsummary() is then used to display the summary statistics of the standardised clustering variables.\n\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\nThe value range of the Min-max standardised clustering variables are now 0 - 1.\n\n\n10.4 Z-score standardisation\nZ-score standardisation can be performed easily by using scale() of Base R. The code below will be used to stadardisation the clustering variables by using Z-score method.\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nThe mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.\n\n\n\n\n\n\nTip\n\n\n\nNote: describe() of psych package is used here instead of summary() of Base R because the earlier provides standard deviation.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWarning: Z-score standardisation method should only be used if we would assume all variables come from some normal distribution.\n\n\n\n\n10.5 Visualising the Standardised Clustering Variables\n\n\n\n\n\n\nTip\n\n\n\nIt is a good practice to visualize the standardised clustering variables.\n\n\nTo plot the scaled Radio_PR field:\n\n\nShow the code\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat statistical conclusion can you draw from the histograms above?\nThe overall distribution of the clustering variables changes after the data standardisation.\n\n\n\n\nShow the code\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n10.6 Calculating the Proximity Matrix\nR offers several packages to compute distance matrices, and we will use the dist() function from the base package for this purpose.\nThe dist() function supports 6 types of distance calculations: - Euclidean, - Maximum, - Manhattan, - Canberra, - Binary, and - Minkowsk\nBy default, it uses the Euclidean distance.\nBelow is the code to compute the proximity matrix using the Euclidean method:\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\nTo view the contents of the computed proximity matrix (proxmat), you can use the following code:\n\nproxmat\n\n\n\n10.7 Performing Hierarchical Clustering\nIn R, several packages offer hierarchical clustering functions. We will use the hclust() function from the stats package.\n\nMethod: hclust() uses an agglomerative approach to compute clusters.\n8 Supported Clustering Algorithms:\n\nward.D\nward.D2\nsingle\ncomplete\naverage (UPGMA)\nmcquitty (WPGMA)\nmedian (WPGMC)\ncentroid (UPGMC)\n\n\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\nWe can then plot the tree by using plot() of R Graphics.\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n10.8 Choosing the Optimal Clustering Algorithm\nOne of the challenges in hierarchical clustering is identifying the method that provides the strongest clustering structure. This can be addressed by using the agnes() function from the cluster package. Unlike hclust(), the agnes() function also calculates the agglomerative coefficient—a measure of clustering strength (values closer to 1 indicate a stronger clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\n\n\n\n\n\n\nNote\n\n\n\nThe output shows that Ward’s method has the highest agglomerative coefficient, indicating the strongest clustering structure among the methods evaluated. Therefore, Ward’s method will be used for the subsequent analysis.\n\n\n\n\n10.9 Determining Optimal Clusters\nAnother technical challenge faced by data analysts in performing clustering analysis is to determine the optimal clusters to retain.\nThere are 3 commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n\n10.10 Gap Statistic Method\nThe gap statistic helps determine the optimal number of clusters by comparing the total within-cluster variation for different values of k against their expected values under a random reference distribution. The optimal number of clusters is identified by the value of k that maximizes the gap statistic, indicating that the clustering structure is far from random.\nTo compute the gap statistic, use the clusGap() function from the cluster package:\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# use firstmax to get the location of the first local maximum.\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nThe hcut function is from the factoextra package.\nTo visualize the gap statistic, use the fviz_gap_stat() function from the factoextra package:\n\nfviz_gap_stat(gap_stat)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFrom the gap statistic plot, the suggested number of clusters is 1. However, retaining only one cluster is not meaningful in most contexts. Examining the plot further, the 6-cluster solution has the largest gap statistic after 1, making it the next best choice.\n\n\n\n\n\n\n\n\nTip\n\n\n\nAdditional Note: The NbClust package offers 30 indices for determining the appropriate number of clusters. It helps users select the best clustering scheme by considering different combinations of cluster numbers, distance measures, and clustering methods (Charrad et al., 2014).\n\n\n\n\n10.11 Interpreting the Dendrograms\nA dendrogram visually represents the clustering of observations in hierarchical clustering:\n\nLeaves (Bottom of the Dendrogram): Each leaf represents a single observation.\nBranches and Fusions (Moving Up the Tree): Similar observations are grouped into branches. As we move up the tree, these branches merge at different heights.\nHeight of Fusion (Vertical Axis): Indicates the level of (dis)similarity between merged observations or clusters. A greater height means the observations or clusters are less similar.\n\n\nThe similarity between two observations can only be assessed by the vertical height where their branches first merge. The horizontal distance between observations does not indicate their similarity.\n\nTo highlight specific clusters, use the rect.hclust() function to draw borders around clusters. The border argument specifies the colors for the rectangles.\nThe following code plots the dendrogram and draws borders around the 6 clusters:\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\nThis visualization helps to easily identify and interpret the selected clusters in the dendrogram.\n\n\n10.12 Visually-driven Hierarchical Clustering Analysis\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n10.12.1 Transforming the Data Frame into a Matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make the heatmap.\nThe code below will be used to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\nclass(shan_ict)\n\n[1] \"data.frame\"\n\nclass(shan_ict_mat)\n\n[1] \"matrix\" \"array\" \n\n\n\n\n10.12.2 Plotting Interactive Cluster Heatmap using heatmaply()\nIn the code below, the heatmaply() of heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\n\n\n\n10.13 Mapping the Clusters Formed\nUpon close examination of the dendrogram above, we have decided to retain 6 clusters.\n\nuse cutree() of R Base to derive a 6-cluster model\n\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\nclass(groups)\n\n[1] \"factor\"\n\nlength(groups)\n\n[1] 55\n\n\nThe output is called groups. It is a factor object.\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map showing the cluster formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#spatially-constrained-clustering-skater-approach",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#spatially-constrained-clustering-skater-approach",
    "title": "6A: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "11 Spatially Constrained Clustering: SKATER approach",
    "text": "11 Spatially Constrained Clustering: SKATER approach\nIn this section, we will derive spatially constrained cluster by using skater() method of spdep package.\n\n11.1 Converting into SpatialPolygonsDataFrame\nFirst, we need to convert shan_sf into SpatialPolygonsDataFrame. This is because SKATER function only support sp objects such as SpatialPolygonDataFrame.\nThe code below uses as_Spatial() of sf package to convert shan_sf into a SpatialPolygonDataFrame called shan_sp.\n\nshan_sp &lt;- as_Spatial(shan_sf)\n\n\n\n11.2 Computing Neighbour List\nTo compute the list of neighboring polygons, use the poly2nb() function from the spdep package.\n\nshan.nb &lt;- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nTo visualize the neighbors on the map, you can plot the community area boundaries and the neighbor network together. Here’s how:\n\nPlot the Boundaries: Use the plot() function to draw the boundaries of the spatial polygons (shan_sf).\nCompute Centroids: Extract the centroids of the polygons using the st_centroid() function, which will serve as the nodes for the neighbor network.\n\n\ncoords &lt;- st_coordinates(\n  st_centroid(st_geometry(shan_sf)))\n\n\nplot(st_geometry(shan_sf),\n     border=grey(.5))\nplot(shan.nb,\n     coords, \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nPlot Order Matters: Always plot the boundaries first, followed by the network. If the network is plotted first, some areas may be clipped because the plotting area is determined by the first plot’s extent. Plotting the boundaries first ensures the entire map area is visible.\n\n\n\n\n11.3 Calculating Edge Costs\nNext, nbcosts() of spdep package is used to compute the cost of each edge. It is the distance between it nodes. This function compute this distance using a data.frame with observations vector in each node.\nThe code below is used to compute the cost of each edge.\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\nFor each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighbouring observation (from the neighbour list). Basically, this is the notion of a generalised weight for a spatial weights matrix.\nNext, we will incorporate these costs into a weights object in the same way as we did in the calculation of inverse of distance weights. In other words, we convert the neighbour list to a list weights object by specifying the just computed lcosts as the weights.\nIn order to achieve this, nb2listw() of spdep package is used as shown in the code chunk below.\nNote that we specify the style as B to make sure the cost values are not row-standardised.\n\nshan.w &lt;- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\n\n11.4 Computing Minimum Spanning Tree\nThe minimum spanning tree is computed by mean of the mstree() of spdep package as shown in the code chunk below.\n\nshan.mst &lt;- mstree(shan.w)\n\nAfter computing the MST, we can check its class and dimension by using the code below.\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\ndim(shan.mst)\n\n[1] 54  3\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe dimension is 54 and not 55.\nThis is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.\n\n\nWe can display the content of shan.mst by using head() as shown in the code below.\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   54   48  47.79331\n[2,]   54   17 109.08506\n[3,]   54   45 127.42203\n[4,]   45   52 146.78891\n[5,]   52   13 110.55197\n[6,]   13   28  92.79567\n\n\nThe plot method for the MST include a way to show the observation numbers of the nodes in addition to the edge. As before, we plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\nplot(st_geometry(shan_sf), \n                 border=gray(.5))\nplot.mst(shan.mst, \n         coords, \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)\n\n\n\n\n\n\n\n\n\n\n11.5 Computing Spatially Constrained Clusters using SKATER Method\nThe code below compute the spatially constrained cluster using skater() of spdep package.\n\nclust6 &lt;- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\nThe skater() function requires three mandatory arguments:\n\nFirst two columns of the MST matrix: These columns represent the edges of the Minimum Spanning Tree (MST) without the cost.\nData matrix: This is used to update the costs dynamically as units are grouped together.\nNumber of cuts: This is set to one less than the desired number of clusters. Remember, this value represents the number of cuts in the graph, not the total number of clusters.\n\nThe output of skater() is an object of class skater. You can examine its contents using the following code:\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label itself is arbitary). This is followed by a detailed summary for each of the clusters in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\nWe can check the cluster assignment by using the code:\n\nccs6 &lt;- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nWe can find out how many observations are in each cluster by means of the table command.\nParenthetially, we can also find this as the dimension of each vector in the lists contained in edges.groups. For example, the first list has node with dimension 12, which is also the number of observations in the first cluster.\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nLastly, we can also plot the pruned tree that shows the five clusters on top of the townshop area.\n\nplot(st_geometry(shan_sf), \n     border=gray(.5))\nplot(clust6, \n     coords, \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)\n\n\n\n\n\n\n\n\n\n\n11.6 Visualising the Clusters in Choropleth Map\nThe code below is used to plot the newly derived clusters by using SKATER method.\n\ngroups_mat &lt;- as.matrix(clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\n\n\n\n\nFor easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.\n\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#spatially-constrained-clustering-clustgeo-method",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#spatially-constrained-clustering-clustgeo-method",
    "title": "6A: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "12 Spatially Constrained Clustering: ClustGeo Method",
    "text": "12 Spatially Constrained Clustering: ClustGeo Method\nIn this section, we will perform both non-spatially constrained and spatially constrained hierarchical cluster analysis with the ClustGeo package.\n\n12.1 Overview of the ClustGeo Package\nThe ClustGeo package in R is designed specifically for spatially constrained cluster analysis. It offers a Ward-like hierarchical clustering algorithm called hclustgeo(), which incorporates spatial or geographical constraints:\n\nDissimilarity Matrices (D0 and D1):\n\nD0: Represents dissimilarities in the attribute/clustering variable space. It can be non-Euclidean, and the weights of the observations can be non-uniform.\nD1: Represents dissimilarities in the constraint space (e.g., spatial/geographical constraints).\n\nMixing Parameter (alpha):\n\nA value between [0, 1] that balances the importance of the attribute dissimilarity (D0) and the spatial constraint dissimilarity (D1). The objective is to find an alpha value that enhances spatial continuity without significantly compromising the quality of clustering based on the attributes of interest. This can be achieved using the choicealpha() function.\n\n\n\n\n12.2 Ward-like Hierarchical Clustering with ClustGeo\nThe hclustgeo() function from the ClustGeo package performs a Ward-like hierarchical clustering, similar to the hclust() function.\nTo perform non-spatially constrained hierarchical clustering, provide the function with a dissimilarity matrix, as demonstrated in the code example below:\n\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe dissimilarity matrix must be an object of class dist, i.e. an object obtained with the function dist().\n\n\n\n12.2.1 Mapping Clusters\nWe can plot the clusters on a categorical area shaded map.\n\ngroups &lt;- as.factor(cutree(nongeo_cluster, k=6))\n\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\n\n\n\n12.3 Spatially Constrained Hierarchical Clustering\nBefore we can performed spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using st_distance() of sf package.\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\nclass(distmat)\n\n[1] \"dist\"\n\n\nas.dist() is needed to convert the data frame into matrix.\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha.\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith reference to the graphs above, alpha = 0.3 will be used since it is the intersection point between D0 and D1.\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.3)\n\nNext, cutree() is used to derive the cluster objecct.\n\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\nWe will then join back the group list with shan_sf polygon feature data frame by using the code below.\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nWe can now plot the map of the newly delineated spatially constrained clusters.\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#visual-interpretation-of-clusters",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06a.html#visual-interpretation-of-clusters",
    "title": "6A: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "13 Visual Interpretation of Clusters",
    "text": "13 Visual Interpretation of Clusters\n\n13.1 Visualising individual clustering variable\nTo reveal the distribution of a clustering variable (i.e RADIO_PR) by cluster.\n\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe boxplot reveals Cluster 3 displays the highest mean Radio Ownership Per Thousand Household. This is followed by Cluster 2, 1, 4, 6 and 5.\n\n\n\n\n13.2 Multivariate Visualisation\nParallel coordinate plot can be used to reveal clustering variables by cluster very effectively.\nggparcoord() of **GGally* package is used in the code below.\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservation\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone.\nOn the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.\n\nNote\nThe scale argument of ggparcoor() provide several methods to scale the clustering variables. They are:\n\nstd: univariately, subtract mean and divide by standard deviation.\nrobust: univariately, subtract median and divide by median absolute deviation.\nuniminmax: univariately, scale so the minimum of the variable is zero, and the maximum is one.\nglobalminmax: no scaling is done; the range of the graphs is defined by the global minimum and the global maximum.\ncenter: use uniminmax to standardize vertical height, then center each variable at a value specified by the scaleSummary param.\ncenterObs: use uniminmax to standardize vertical height, then center each variable at the value of the observation specified by the centerObsID param\n\nThe suitability of scale argument is dependent on your use case.\n\n\nTo complement the visual interpretation, use group_by() and summarise() of dplyr are used to derive mean values of the clustering variables:\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html",
    "title": "1A: Geospatial Data Wrangling with R",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 1  Geospatial Data Science with R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#exercise-1a-reference",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#exercise-1a-reference",
    "title": "1A: Geospatial Data Wrangling with R",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 1  Geospatial Data Science with R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#learning-outcome",
    "title": "1A: Geospatial Data Wrangling with R",
    "section": "2 Learning Outcome",
    "text": "2 Learning Outcome\n\ninstalling and loading sf and tidyverse packages into R environment,\nimporting geospatial data by using appropriate functions of sf package,\nimporting aspatial data by using appropriate function of readr package,\nexploring the content of simple feature data frame by using appropriate Base R and sf functions,\nassigning or transforming coordinate systems by using using appropriate sf functions,\nconverting an aspatial data into a sf data frame by using appropriate function of sf package,\nperforming geoprocessing tasks by using appropriate functions of sf package,\nperforming data wrangling tasks by using appropriate functions of dplyr package and\nperforming Exploratory Data Analysis (EDA) by using appropriate functions from ggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#the-data",
    "title": "1A: Geospatial Data Wrangling with R",
    "section": "3 The Data",
    "text": "3 The Data\n\n\n\nDataset\nSource\nDescription\n\n\n\n\nMaster Plan 2014 Subzone Boundary (Web)\ndata.gov.sg\nGeospatial boundaries for Singapore’s planning subzones.\n\n\nPre-Schools Location\ndata.gov.sg\nLocation data for pre-schools in Singapore.\n\n\nCycling Path\nLTA DataMall\nGeospatial data for cycling paths in Singapore.\n\n\nSingapore Airbnb Listings\nInside Airbnb\nLatest listing data for Airbnb properties in Singapore."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#installing-and-loading-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#installing-and-loading-the-r-packages",
    "title": "1A: Geospatial Data Wrangling with R",
    "section": "4 Installing and Loading the R Packages",
    "text": "4 Installing and Loading the R Packages\nTwo main R packages will be used in this exercise:\n\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\n\nsf\nImporting, managing, and processing geospatial data.\nHandling and processing geospatial data in R.\n\n\ntidyverse\nComprehensive set of tools for data science tasks.\nImporting, wrangling, and visualizing data.\n\n\n\n\n4.1 Tidyverse Sub-packages\nThe tidyverse package includes the following sub-packages used in this exercise:\n\n\n\nSub-package\nPurpose\n\n\n\n\nreadr\nImporting CSV data.\n\n\nreadxl\nImporting Excel worksheets.\n\n\ntidyr\nManipulating and tidying data.\n\n\ndplyr\nTransforming and wrangling data.\n\n\nggplot2\nVisualizing data.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#import-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#import-geospatial-data",
    "title": "1A: Geospatial Data Wrangling with R",
    "section": "5 Import Geospatial Data",
    "text": "5 Import Geospatial Data\nThe code block below uses st_read() function of sf package to import the MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame.\n\ndsn refers to data source name\nlayer points to the file name.\nmore details: st_read function - RDocumentation\n\n\n5.1 Import polygon feature data in shapefile format\n\nmpsz = st_read(dsn = \"data/geospatial\",\n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\n\n\nNote\n\n\n\nOutput Explanation: The geospatial objects are multipolygon features. There are a total of 323 multipolygon features and 15 fields in mpsz simple feature data frame. mpsz is in svy21 projected coordinates systems. The bounding box provides the x extend and y extend of the data.\n\n\n\n\n5.2 Import polyline feature data in shapefile format\nThe code block below uses st_read() function of sf package to import CyclingPath shapefile into R as line feature data frame.\n\ncyclingpath = st_read(dsn = \"data/geospatial\",\n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n\n\n\n\nNote\n\n\n\nOutput Explanation: There are a total of 3138 features and 2 fields in cyclingpath linestring feature data frame and it is in svy21 projected coordinates system too.\n\n\n\n\n5.3 Import GIS data in kml format\nAs compared to st_read for shapefiles, we need to pass the file extension when importing kml files.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex01/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\nNote\n\n\n\nOutput Explanation: The preschool is a point feature data frame. There are a total of 2290 features and 2 fields. Different from the previous two simple feature data frame, preschool is in wgs84 coordinates system."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "1A: Geospatial Data Wrangling with R",
    "section": "6 Checking the Content of A Simple Feature Data Frame",
    "text": "6 Checking the Content of A Simple Feature Data Frame\nThere are different ways to retrieve information related to the content of a simple feature data frame.\n\n6.1 Working with st_geometry()\nThe column in the sf data.frame that contains the geometries is a list, of class sfc.\nThe code block below shows the general way to use st_geometry(). Alternative is mpsz$geom or mpsz[[1]] to retrieve the geometry list-column.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n\n\n\n\n\n\nNote\n\n\n\nOutput Explanation: The print only displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\n\n\n\n6.2 Working with glimpse()\nTo learn more about the associated attribute information in the data frame, we can use glimpse from dplyr.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n\n\n\n\nNote\n\n\n\nOutput Explanation: glimpse() report reveals the data type of each fields. For example FMEL-UPD_D field is in date data type and X_ADDR, Y_ADDR, SHAPE_L and SHAPE_AREA fields are all in double-precision values.\n\n\n\n\n6.3 Working with head()\nTo reveal complete information of a feature object, we can use head() from R.\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\n\n\n\n\n\nNote\n\n\n\nOutput Explanation: It shows the top 5 rows from mpsz."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#plotting-the-geospatial-data",
    "title": "1A: Geospatial Data Wrangling with R",
    "section": "7 Plotting the Geospatial Data",
    "text": "7 Plotting the Geospatial Data\nThis section covers visualization of geospatial features using plot() of R graphic.\n\nplot(mpsz)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nOutput Explanation: The default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum as shown above.\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code block below.\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor high cartographic quality plot, other R package such as tmap should be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#working-with-map-projection",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#working-with-map-projection",
    "title": "1A: Geospatial Data Wrangling with R",
    "section": "8 Working with Map Projection",
    "text": "8 Working with Map Projection\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\nProjection transformation is a method to project a simple feature data frame from one coordinate system to another coordinate system.\n\n8.1 Assigning EPSG code to a simple feature data frame\nOne of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code block below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code block below.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nOutput Explanation: Note that the EPSG code is 3414 now.\n\n\n8.2 Transforming the projection of preschool from wgs84 to svy21.\nIt is very common in geospatial analytics to transform the original data from geographic coordinate system (gcs) to projected coordinate system (pcs). This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nLet us take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\n\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nThis is a scenario that st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nLet us perform the projection transformation by using the code block below.\n\npreschool3414 &lt;- st_transform(preschool,\n                              crs = 3414)\n\n\nNote: In practice, we need find out the appropriate project coordinate system to use before performing the projection transformation.\n\nNext, let us display the content of preschool3414 sf data frame as shown below.\n\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\n\n\n\n\n\n\nNote\n\n\n\nOutput Explanation: Note that it is in svy21 projected coordinate system now. Furthermore, for the Bounding box:, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#importing-and-converting-an-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#importing-and-converting-an-aspatial-data",
    "title": "1A: Geospatial Data Wrangling with R",
    "section": "9 Importing and Converting An Aspatial Data",
    "text": "9 Importing and Converting An Aspatial Data\nIn this section, we will learn how to process aspatial data such as listing of Inside Airbnb. It is not a geospatial data but among the data fields, there are two fields that capture the x- and y-coordinates of the data points.\nWe will first import the aspatial data and save it as a tibble dataframe and convert it into a simple feature dataframe.\n\n9.1 Import the aspatial data\nSince listings data set is in csv file format, we will use read_csv() of readr package to import listing.csv as shown the code block below.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nOutput Explanation: The output R object is called listings and it is a tibble data frame.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code block below shows list() of Base R instead of glimpse() is used to do the job.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 75\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Ensu… For 3 room…\n 2  71896 https://www.airbnb.co…   2.02e13 2024-06-29   city … B&B … &lt;NA&gt;       \n 3  71903 https://www.airbnb.co…   2.02e13 2024-06-29   city … Room… Like your …\n 4 275343 https://www.airbnb.co…   2.02e13 2024-06-29   city … 10mi… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.02e13 2024-06-29   city … 15 m… Lovely hom…\n 6 289234 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Book… This whole…\n 7 294281 https://www.airbnb.co…   2.02e13 2024-06-29   city … 5 mi… I have 3 b…\n 8 324945 https://www.airbnb.co…   2.02e13 2024-06-29   city … Comf… **IMPORTAN…\n 9 330095 https://www.airbnb.co…   2.02e13 2024-06-29   city … Rela… **IMPORTAN…\n10 344803 https://www.airbnb.co…   2.02e13 2024-06-29   city … Budg… Direct bus…\n# ℹ 3,530 more rows\n# ℹ 68 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\n\n\n\n\n\n\n\nNote\n\n\n\nOutput Explanation: The. listing tibble data frame consists of 4252 rows and 16 columns. We will use the latitude and longtitude fields. Note that they are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System.\n\n\nThe code block below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings,\n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords: argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs: argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;%: is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nLet us examine the content of this newly created simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 74\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.024063e+13, 2.024063e+1…\n$ last_scraped                                 &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ source                                       &lt;chr&gt; \"previous scrape\", \"city …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1 …\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"99%…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ host_total_listings_count                    &lt;dbl&gt; 11, 11, 11, 73, 73, 11, 8…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 3, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; NA, 0.5, 0.5, 2.0, 2.5, N…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, 1, 1, 1, 1, 3, 2, 1, 1…\n$ beds                                         &lt;dbl&gt; NA, 1, 2, 1, 1, NA, 1, 1,…\n$ amenities                                    &lt;chr&gt; \"[\\\"Free parking on premi…\n$ price                                        &lt;chr&gt; NA, \"$80.00\", \"$80.00\", \"…\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 30, 30, 28, 0, 29, 30…\n$ availability_60                              &lt;dbl&gt; 59, 53, 60, 58, 0, 58, 60…\n$ availability_90                              &lt;dbl&gt; 89, 83, 90, 62, 0, 88, 90…\n$ availability_365                             &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 3…\n$ calendar_last_scraped                        &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 1…\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 6, 49…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…\n\n\n\n\n\n\n\n\nNote\n\n\n\nOutput Explanation:: The table above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#geoprocessing-with-sf",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#geoprocessing-with-sf",
    "title": "1A: Geospatial Data Wrangling with R",
    "section": "10 Geoprocessing with sf",
    "text": "10 Geoprocessing with sf\nIn addition to offering tools for managing geospatial data (such as importing, exporting, assigning, and transforming projections), the sf package also includes a wide range of geoprocessing functions for GIS analysis.\nScenario:\nThe authority is planning to upgrade the existing cycling path. To do so, they need to acquire 5 meters of reserved land on both sides of the current cycling path. You are tasked with determining the extent of the land that needs to be acquired and its total area.\nSolution:\nFirstly, the st_buffer() function of the sf package is used to compute the 5-meter buffers around the cycling paths.\n\nbuffer_cycling &lt;- st_buffer(cyclingpath,\n                               dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code block below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\n\n10.1 Point-in-polygon count\nScenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nSolution:\nThe code block below performs two operations at one go.\n\nidentify pre-schools located inside each Planning Subzone by using st_intersects().\nlength() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nWarning: You should not confuse with st_intersection().\n\nThe summary statistics of the newly derived PreSch Count field by using summary() is shown in the code block below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nNext top_n() from dplyr package is used with n=1 to list the planning subzone with the highest number of pre-school.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nExercise: Calculate the density of pre-school by planning subzone.\nTo determine the density of pre-schools by planning subzone, the st_area() function from the sf package is used to calculate the area of each planning subzone, and the result is stored in a new Area column.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code block below.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#exploratory-data-analysis-eda",
    "title": "1A: Geospatial Data Wrangling with R",
    "section": "11 Exploratory Data Analysis (EDA)",
    "text": "11 Exploratory Data Analysis (EDA)\nIn this section, we will learn how to use ggplot2 to create functional and yet truthful statistical graphs for EDA purposes.\n\nWe will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code block below.\n\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code block below, appropriate ggplot2 functions will be used.\n\nggplot(data=mpsz3414,\n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20,\n                 color=\"black\",\n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\nExercise: Using ggplot2 method, plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nggplot(data=mpsz3414,\n       aes(y = `PreSch Count`,\n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\",\n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nOutput Explanation: The scatterplot shows a positive relationship between pre-school density (per km²) and pre-school count, showing that areas with higher density tend to have a greater number of pre-schools."
  },
  {
    "objectID": "Exploration/index.html",
    "href": "Exploration/index.html",
    "title": "Exploration",
    "section": "",
    "text": "This page shows additional exploration using online resources as follows:"
  },
  {
    "objectID": "Exploration/index.html#introduction-to-spatial-data-science",
    "href": "Exploration/index.html#introduction-to-spatial-data-science",
    "title": "Exploration",
    "section": "Introduction to Spatial Data Science",
    "text": "Introduction to Spatial Data Science\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n01 Spatial Data Handling\n\n\nIn this exercise, we will handle spatial data to create a choropleth map of abandoned vehicles per capita in Chicago by downloading, filtering, transforming data, and using spatial join and aggregation techniques.\n\n\n33 min\n\n\n\nSep 5, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "Refer to: ISSS626 Geospatial Analytics and Applications - Take-home Exercise 1: Geospatial Analytics for Public Good"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#assignment-task",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#assignment-task",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "Refer to: ISSS626 Geospatial Analytics and Applications - Take-home Exercise 1: Geospatial Analytics for Public Good"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#overview",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#overview",
    "title": "Take Home Exercise 1",
    "section": "2 Overview",
    "text": "2 Overview\nIn this exercise, we will apply spatial and spatio-temporal point pattern analysis methods to identify factors affecting road traffic accidents in the Bangkok Metropolitan Region (BMR), including:\n\nvisualizing spatio-temporal dynamics,\nconducting spatial analysis using Network Spatial Point Patterns, and\nanalyzing spatio-temporal patterns using Temporal Network Spatial Point Patterns."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-analytical-questions",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-analytical-questions",
    "title": "Take Home Exercise 1",
    "section": "3 The Analytical Questions",
    "text": "3 The Analytical Questions\nThis study seeks to uncover the factors influencing road traffic accidents in the Bangkok Metropolitan Region (BMR) by utilizing both spatial and spatio-temporal point patterns analysis methods.\n\nOur key questions are:\n\nWhat behavioral, environmental, and temporal factors contribute to these accidents?\nWhat are the spatial and temporal patterns of road traffic accidents in BMR?\nAre traffic accidents in the BMR randomly distributed throughout the region?\nIf the distribution is not random, where are the areas with higher concentrations of accidents?"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-data",
    "title": "Take Home Exercise 1",
    "section": "4 The Data",
    "text": "4 The Data\nThe following 3 datasets will be used in this exercise.\n\n\n\nDataset Name\nDescription\nFormat\nSource\n\n\n\n\nThailand Road Accident [2019-2022]\nData on road accidents in Thailand, including details on location, severity, and date of incidents.\nCSV\nKaggle\n\n\nThailand Roads (OpenStreetMap Export)\nGeospatial data showing the complete road network of Thailand, extracted from OpenStreetMap.\nESRI Shapefile\nHumanitarian Data Exchange (HDX)\n\n\nThailand - Subnational Administrative Boundaries\nGeospatial dataset detailing the administrative boundaries of Thailand’s provinces and districts.\nESRI Shapefile\nHumanitarian Data Exchange (HDX)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#installing-and-launching-the-r-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#installing-and-launching-the-r-packages",
    "title": "Take Home Exercise 1",
    "section": "5 Installing and Launching the R Packages",
    "text": "5 Installing and Launching the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\n\ntidyverse\nA collection of packages for data manipulation, visualization, and data analysis.\nImporting, cleaning, and transforming data for analysis.\n\n\nsf\nImports, manages, and processes vector-based geospatial data.\nHandling and analyzing geospatial data such as road networks and administrative boundaries.\n\n\ntmap\nCreates both static and interactive thematic maps with high cartographic quality.\nVisualizing road traffic accident locations and spatial patterns in Thailand.\n\n\nspNetwork\nProvides tools for network-constrained spatial data analysis, such as point pattern analysis on road networks.\nConducting network spatial point pattern analysis to study traffic accident patterns along road networks.\n\n\nspatstat\nA toolkit for spatial point pattern analysis.\nPerforming advanced spatial analysis, such as identifying hotspots of road traffic accidents.\n\n\nplotly\nCreates interactive and web-ready visualizations.\nBuilding interactive charts and maps to explore the spatio-temporal dynamics of traffic accidents.\n\n\ngtsummary\nGenerates publication-ready summary tables of statistical results.\nSummarizing descriptive statistics and results from the analysis of road traffic accidents.\n\n\nsparr\nProvides tools for spatio-temporal analysis of point patterns, including kernel density estimation.\nPerforming spatio-temporal analysis to assess the spread and dynamics of road traffic accidents over time.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(tidyverse, sf, tmap, spNetwork, spatstat, plotly, gtsummary, sparr)\n\n\n5.1 Reproducibilty\nFor reproducible results of this exercise, we will use seed value, 1234.\n\nset.seed(1234)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#import-data-and-preparation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#import-data-and-preparation",
    "title": "Take Home Exercise 1",
    "section": "6 Import Data and Preparation",
    "text": "6 Import Data and Preparation\nIn this section, we will perform sanity checks on the raw data from from the official data sources and identify useful data for our case study area.\n\n6.1 Thai Road Accident Data\nFirstly, we will import the Thai Road Accident dataset from 2019-2022 using read_csv() of readr package.\n\nrdacc_sf &lt;- read_csv(\"data/raw_data/thai_road_accident_2019_2022.csv\")\nrdacc_sf\n\n# A tibble: 81,735 × 18\n   acc_code incident_datetime   report_datetime     province_th province_en     \n      &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;              &lt;chr&gt;       &lt;chr&gt;           \n 1   571905 2019-01-01 00:00:00 2019-01-02 06:11:00 ลพบุรี        Loburi          \n 2  3790870 2019-01-01 00:03:00 2020-02-20 13:48:00 อุบลราชธานี   Ubon Ratchathani\n 3   599075 2019-01-01 00:05:00 2019-01-01 10:35:00 ประจวบคีรีขันธ์ Prachuap Khiri …\n 4   571924 2019-01-01 00:20:00 2019-01-02 05:12:00 เชียงใหม่     Chiang Mai      \n 5   599523 2019-01-01 00:25:00 2019-01-04 09:42:00 นครสวรรค์    Nakhon Sawan    \n 6   571982 2019-01-01 00:30:00 2019-01-07 12:46:00 แม่ฮ่องสอน    Mae Hong Son    \n 7   612782 2019-01-01 00:30:00 2019-10-25 14:25:00 ชุมพร        Chumphon        \n 8   599235 2019-01-01 00:35:00 2019-01-02 16:23:00 สิงห์บุรี       Sing Buri       \n 9   600643 2019-01-01 00:40:00 2019-01-11 10:01:00 สงขลา       Songkhla        \n10   599105 2019-01-01 00:45:00 2019-01-01 10:11:00 ตราด        Trat            \n# ℹ 81,725 more rows\n# ℹ 13 more variables: agency &lt;chr&gt;, route &lt;chr&gt;, vehicle_type &lt;chr&gt;,\n#   presumed_cause &lt;chr&gt;, accident_type &lt;chr&gt;,\n#   number_of_vehicles_involved &lt;dbl&gt;, number_of_fatalities &lt;dbl&gt;,\n#   number_of_injuries &lt;dbl&gt;, weather_condition &lt;chr&gt;, latitude &lt;dbl&gt;,\n#   longitude &lt;dbl&gt;, road_description &lt;chr&gt;, slope_description &lt;chr&gt;\n\n\nFrom the output above, we can observe that there are 18 columns in this dataset and there are 81,735 accidents recorded in this dataset.\n\n\n\n\n\n\nWe can check data dictionary from Kaggle to understand this dataset.\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nDescription\n\n\n\n\nacc_code\nThe accident code or identifier.\n\n\nincident_datetime\nThe date and time of the accident occurrence.\n\n\nreport_datetime\nThe date and time when the accident was reported.\n\n\nprovince_th\nThe name of the province in Thailand, written in Thai.\n\n\nprovince_en\nThe name of the province in Thailand, written in English.\n\n\nagency\nThe government agency responsible for the road and traffic management.\n\n\nroute\nThe route or road segment where the accident occurred.\n\n\nvehicle_type\nThe type of vehicle involved in the accident.\n\n\npresumed_cause\nThe presumed cause or reason for the accident.\n\n\naccident_type\nThe type or nature of the accident.\n\n\nnumber_of_vehicles_involved\nThe number of vehicles involved in the accident.\n\n\nnumber_of_fatalities\nThe number of fatalities resulting from the accident.\n\n\nnumber_of_injuries\nThe number of injuries resulting from the accident.\n\n\nweather_condition\nThe weather condition at the time of the accident.\n\n\nlatitude\nThe latitude coordinate of the accident location.\n\n\nlongitude\nThe longitude coordinate of the accident location.\n\n\nroad_description\nThe description of the road type or configuration where the accident occurred.\n\n\nslope_description\nThe description of the slope condition at the accident location.\n\n\n\n\n\n\nNext, we check for null values.\n\nnull_counts &lt;- sapply(rdacc_sf, function(x) sum(is.na(x)))\nnull_counts\n\n                   acc_code           incident_datetime \n                          0                           0 \n            report_datetime                 province_th \n                          0                           0 \n                province_en                      agency \n                          0                           0 \n                      route                vehicle_type \n                          0                           0 \n             presumed_cause               accident_type \n                          0                           0 \nnumber_of_vehicles_involved        number_of_fatalities \n                          0                           0 \n         number_of_injuries           weather_condition \n                          0                           0 \n                   latitude                   longitude \n                        359                         359 \n           road_description           slope_description \n                          0                           0 \n\ndata.frame(Column = names(null_counts), Null_Count = null_counts)\n\n                                                 Column Null_Count\nacc_code                                       acc_code          0\nincident_datetime                     incident_datetime          0\nreport_datetime                         report_datetime          0\nprovince_th                                 province_th          0\nprovince_en                                 province_en          0\nagency                                           agency          0\nroute                                             route          0\nvehicle_type                               vehicle_type          0\npresumed_cause                           presumed_cause          0\naccident_type                             accident_type          0\nnumber_of_vehicles_involved number_of_vehicles_involved          0\nnumber_of_fatalities               number_of_fatalities          0\nnumber_of_injuries                   number_of_injuries          0\nweather_condition                     weather_condition          0\nlatitude                                       latitude        359\nlongitude                                     longitude        359\nroad_description                       road_description          0\nslope_description                     slope_description          0\n\n\nFrom the output above, we can notice that are 359 missing data in the latitude (lat) and longitude (lon) columns. We will remove these rows as they make up &lt;5% of the total records.\nNext, we check for duplicate values.\n\nduplicate_count &lt;- sum(duplicated(rdacc_sf))\nduplicate_count\n\n[1] 0\n\n\nThere are no exact duplicates in this dataset.\nNext, we observe the provinces available in this dataset.\n\n# Display unique values in the \"ST\" column sorted in ascending order\nsort(unique(rdacc_sf$province_en))\n\n [1] \"Amnat Charoen\"            \"Ang Thong\"               \n [3] \"Bangkok\"                  \"buogkan\"                 \n [5] \"Buri Ram\"                 \"Chachoengsao\"            \n [7] \"Chai Nat\"                 \"Chaiyaphum\"              \n [9] \"Chanthaburi\"              \"Chiang Mai\"              \n[11] \"Chiang Rai\"               \"Chon Buri\"               \n[13] \"Chumphon\"                 \"Kalasin\"                 \n[15] \"Kamphaeng Phet\"           \"Kanchanaburi\"            \n[17] \"Khon Kaen\"                \"Krabi\"                   \n[19] \"Lampang\"                  \"Lamphun\"                 \n[21] \"Loburi\"                   \"Loei\"                    \n[23] \"Mae Hong Son\"             \"Maha Sarakham\"           \n[25] \"Mukdahan\"                 \"Nakhon Nayok\"            \n[27] \"Nakhon Pathom\"            \"Nakhon Phanom\"           \n[29] \"Nakhon Ratchasima\"        \"Nakhon Sawan\"            \n[31] \"Nakhon Si Thammarat\"      \"Nan\"                     \n[33] \"Narathiwat\"               \"Nong Bua Lam Phu\"        \n[35] \"Nong Khai\"                \"Nonthaburi\"              \n[37] \"Pathum Thani\"             \"Pattani\"                 \n[39] \"Phangnga\"                 \"Phatthalung\"             \n[41] \"Phayao\"                   \"Phetchabun\"              \n[43] \"Phetchaburi\"              \"Phichit\"                 \n[45] \"Phitsanulok\"              \"Phra Nakhon Si Ayutthaya\"\n[47] \"Phrae\"                    \"Phuket\"                  \n[49] \"Prachin Buri\"             \"Prachuap Khiri Khan\"     \n[51] \"Ranong\"                   \"Ratchaburi\"              \n[53] \"Rayong\"                   \"Roi Et\"                  \n[55] \"Sa Kaeo\"                  \"Sakon Nakhon\"            \n[57] \"Samut Prakan\"             \"Samut Sakhon\"            \n[59] \"Samut Songkhram\"          \"Saraburi\"                \n[61] \"Satun\"                    \"Si Sa Ket\"               \n[63] \"Sing Buri\"                \"Songkhla\"                \n[65] \"Sukhothai\"                \"Suphan Buri\"             \n[67] \"Surat Thani\"              \"Surin\"                   \n[69] \"Tak\"                      \"Trang\"                   \n[71] \"Trat\"                     \"Ubon Ratchathani\"        \n[73] \"Udon Thani\"               \"unknown\"                 \n[75] \"Uthai Thani\"              \"Uttaradit\"               \n[77] \"Yala\"                     \"Yasothon\"                \n\n\nFrom the output above, we can notice that the dataset contains data from across 78 provinces in Thailand. Since our study area is only in Bangkok Metropolitan Region (BMR), we will filter the data for records in “Bangkok”, “Nonthaburi”, “Nakhon Pathom”, “Pathum Thani”, “Samut Prakan”, “Samut Sakhon” only.\n\n# list province names in BMR\nbmr_regions &lt;- c(\"Bangkok\", \"Nonthaburi\", \"Nakhon Pathom\", \"Pathum Thani\", \"Samut Prakan\", \"Samut Sakhon\")\n\n\n\n\n\n\n\nNote\n\n\n\nWe will perform the data preprocessing steps as follows:\n\nfilter data for 6 provinces in BMR by province_en\nremove null lat, lon rows\nconvert filtered data into a sf spatial object, using the lat, lon columns and setting the coordinate reference system (CRS) to EPSG 4326\nreproject spatial data to EPSG 32647 used in Thailand. This format is in metres.\n\n\n\n\naccidents_bmr &lt;- rdacc_sf %&gt;%\n  filter(province_en %in% bmr_regions) %&gt;%\n  filter (!is.na(longitude) & longitude != \"\",\n          !is.na(latitude ) & latitude != \"\") %&gt;%  \n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %&gt;%\n  st_transform(crs=32647)\n\n\n\n6.2 Thailand Subnational Administration Boundary\nThe Thailand subnational administrative boundaries dataset includes four levels: - country (level 0), - province (level 1), - district (level 2), and - sub-district (level 3).\nFor this analysis, we will focus on the 6 provinces in the Bangkok Metropolitan Region (BMR) using level 2 boundaries as it provides a finer level of detail and allows for a more granular understanding of spatial patterns and accident hotspots within the Bangkok Metropolitan Region (BMR).\nThe data will be loaded with st_read() and transformed to EPSG:32647 (UTM Zone 47N, meters).\n\nadmin_boundary &lt;- st_read(dsn = \"data/raw_data\", \n                # try different layer\n                # 0 country\n                # layer = \"tha_admbnda_adm0_rtsd_20220121\") %&gt;%      \n                # 1 province\n                #layer = \"tha_admbnda_adm1_rtsd_20220121\") %&gt;% \n                # 2 district\n                layer = \"tha_admbnda_adm2_rtsd_20220121\") %&gt;% \n  st_transform(crs = 32647)\n\nReading layer `tha_admbnda_adm2_rtsd_20220121' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Take-home_Ex/Take-home_Ex01/data/raw_data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 928 features and 19 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\n\nst_crs(admin_boundary)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\nLet’s observe this dataset for useful attributes to filter for BMR region from the national boundary data.\n\nglimpse(admin_boundary)\n\nRows: 928\nColumns: 20\n$ Shape_Leng &lt;dbl&gt; 0.08541733, 0.13413177, 0.67634217, 0.08588647, 0.30172202,…\n$ Shape_Area &lt;dbl&gt; 0.0004504685, 0.0009501914, 0.0198588627, 0.0003369561, 0.0…\n$ ADM2_EN    &lt;chr&gt; \"Phra Nakhon\", \"Dusit\", \"Nong Chok\", \"Bang Rak\", \"Bang Khen…\n$ ADM2_TH    &lt;chr&gt; \"พระนคร\", \"ดุสิต\", \"หนองจอก\", \"บางรัก\", \"บางเขน\", \"บางกะปิ\", \"ป…\n$ ADM2_PCODE &lt;chr&gt; \"TH1001\", \"TH1002\", \"TH1003\", \"TH1004\", \"TH1005\", \"TH1006\",…\n$ ADM2_REF   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM2ALT1EN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM2ALT2EN &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM2ALT1TH &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM2ALT2TH &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1_EN    &lt;chr&gt; \"Bangkok\", \"Bangkok\", \"Bangkok\", \"Bangkok\", \"Bangkok\", \"Ban…\n$ ADM1_TH    &lt;chr&gt; \"กรุงเทพมหานคร\", \"กรุงเทพมหานคร\", \"กรุงเทพมหานคร\", \"กรุงเทพมหาน…\n$ ADM1_PCODE &lt;chr&gt; \"TH10\", \"TH10\", \"TH10\", \"TH10\", \"TH10\", \"TH10\", \"TH10\", \"TH…\n$ ADM0_EN    &lt;chr&gt; \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\",…\n$ ADM0_TH    &lt;chr&gt; \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศ…\n$ ADM0_PCODE &lt;chr&gt; \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\",…\n$ date       &lt;date&gt; 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18…\n$ validOn    &lt;date&gt; 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22…\n$ validTo    &lt;date&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((662263.2 15..., MULTIPOLYGON (…\n\n\nSimilar to the road accident csv file, we can filter for the BMR region using ADM1_EN.\n\nadmin_boundary_bmr &lt;- admin_boundary %&gt;% \n  select(\"ADM1_EN\") %&gt;% \n  filter(ADM1_EN %in% bmr_regions)\n\nNext, we save the filtered data in RDS format for quick loading in future analyses.\n\nwrite_rds(admin_boundary_bmr, file = \"data/rds/admin_boundary_bmr.rds\")\n\n\nadmin_boundary_bmr &lt;-read_rds(\"data/rds/admin_boundary_bmr.rds\")\n\nLet’s visualize the administrative boundaries map using tmap.\n\ntmap_mode('plot')\n\ntm_shape(admin_boundary_bmr) +\n  tm_fill(col = \"ADM1_EN\", title = \"Region\") +\n  tm_borders() +\n  tm_layout(main.title = \"BMR Administrative Boundaries\",\n            main.title.position = \"center\")\n\n\n\n\n\n\n\n\n\n\n6.3 Road Lines\nNext, we will use st_read() import the Thailand Roads dataset\n\nroads &lt;- st_read(dsn = \"data/raw_data\", \n                layer = \"hotosm_tha_roads_lines_shp\")\n\n\n\n\n\n\n\nNote\n\n\n\nWe observed that this dataset has over 2 million features.\nThe geospatial data is in the form of MULTILINESTRING, representing multiple connected line segments. Using st_cast(\"LINESTRING\") simplifies the geometry by converting these into single line segments (LINESTRING), making spatial operations, such as length calculations and spatial joins, easier for analysis.\nWe also assigned the correct CRS with st_set_crs() before transforming the data to the desired EPSG:32647 projection.\n\n\n\nroads_sf &lt;- st_set_crs(roads, 4326) %&gt;% \n  st_transform(crs = 32647) %&gt;% \n  st_cast(\"LINESTRING\")\n\n\nst_crs(roads_sf)\n\nNext, we can observe some data attributes of this dataset such as highway types.\n\n# Display unique values in the \"highway\" column sorted in ascending order\nsort(unique(roads_sf$highway))\n\n\nFor the purpose of this study, we will focus on the 6 Intercity highway classifications: see WikiProject Thailand - OpenStreetMap Wiki.\n\nhighway_types &lt;- c(\"motorway\", # controlled-access\n                  \"trunk\", # uncontrolled-access\n                  \"primary\", # 3-digit national highway\n                  \"secondary\", # 4-digit national highway\n                  \"tertiary\", # all rural roads\n                  \"unclassified\" # lowest rank of usable public roads\n                  ) \n\nroads_sf_filtered &lt;- roads_sf %&gt;%\n  select(\"highway\") %&gt;% \n  filter(highway %in% highway_types)\n\nAfter filtering for Intercity highway types, we use st_intersection() to find the roads within BMR region.\n\nroads_bmr &lt;- st_intersection(roads_sf_filtered,\n                            admin_boundary_bmr)\n\n\n\nShow the code\n# raw roads rows\nraw_size &lt;- dim(roads_sf)[1]\n# roads rows after filter for 6 intercity types\nfiltered_size &lt;- dim(roads_sf_filtered)[1]\n# roads size after filter for bmr region only\nbmr_size &lt;- dim(roads_bmr)[1]   \n\nreduction_filtered &lt;- raw_size - filtered_size\nreduction_bmr &lt;- raw_size - bmr_size \n\nreduction_filtered_percent &lt;- (reduction_filtered / raw_size) * 100\nreduction_bmr_percent &lt;- (reduction_bmr / raw_size) * 100\n\ncat(\"Raw Size:\", raw_size, \"\\n\")\ncat(\"Filtered Size:\", filtered_size, \"\\n\")\ncat(\"BMR Size:\", bmr_size, \"\\n\\n\")\n\ncat(\"Reduction from roads_sf to roads_sf_filtered:\\n\")\ncat(\"Percentage reduction:\", round(reduction_filtered_percent, 2), \"%\\n\\n\")\n\ncat(\"Reduction from roads_sf to roads_bmr:\\n\")\ncat(\"Percentage reduction:\", round(reduction_bmr_percent, 2), \"%\\n\")\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn this study, we focus on the 6 intercity highway types within the Bangkok Metropolitan Region (BMR).\nFirst, we filter the data by highway types and then narrow it down to the BMR region. This method results in a 99.01% reduction in data size, from 2,792,362 road features to 27,760.\nAlternatively, we could have first isolated the BMR region and then analyzed the distribution of highway types before filtering. However, we chose not to use this approach, as the st_intersection() step would be significantly more time-consuming.\n\n\n\nwrite_rds(roads_bmr, \"data/rds/roads_bmr.rds\")\n\n\nroads_bmr &lt;- read_rds(\"data/rds/roads_bmr.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#feature-engineering",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#feature-engineering",
    "title": "Take Home Exercise 1",
    "section": "7 Feature Engineering",
    "text": "7 Feature Engineering\nAfter going through all the 3 datasets, we have a better sense of the dataset that we are working with. In this section, we will transform certain columns to more usable formats and feature engineer new columns to aid our analysis:\n\nbreak down incident_datetime to various factors\nadd season column to capture 3 seasons: Refer to Bangkok - Wikipedia\n\nMarch to May: Hot\nJun to Oct: Rainy\nNov to Feb: Cool\n\nadd peak_period to capture peak hour patterns: Refer to How Do You Beat Bangkok Traffic?\n\nMorning Peak: 7-9 am\nEvening Peak: 4-7 pm\n\nadd songkran_7_dead_days columns to capture 7 deadly days of songkran period: Refer to: 25 deaths in 234 road accidents recorded on 1st of Songkran’s ‘7 dangerous days’,\n\n7 Deadly Days of Songkran: 11-17 Apr each year\n\nRemove unused columns such as province_th and so on.\n\n\n\nShow the code\naccidents_bmr_ft &lt;- accidents_bmr %&gt;%\n  # extract month number (1 = January, 12 = December)\n  mutate(month_number = month(incident_datetime)) %&gt;%\n  \n  # extract month as factor (\"Jan\", \"Feb\")\n  mutate(month_factor = month(incident_datetime, label = TRUE, abbr = TRUE)) %&gt;%\n  \n  # extract day of month\n  mutate(day_of_month = day(incident_datetime)) %&gt;%\n  \n  # extract the day of the week (1 = Mon)\n  mutate(day_of_week = wday(incident_datetime, week_start = 1)) %&gt;%\n  \n  # extract year\n  mutate(year = year(incident_datetime)) %&gt;%\n  \n  # extract time (HH:MM:SS)\n  mutate(time = format(incident_datetime, format = \"%H:%M:%S\")) %&gt;%\n  \n  # add season col\n  mutate(season = case_when(\n    month_number %in% c(3, 4, 5) ~ \"Hot\",          # March to May\n    month_number %in% c(6, 7, 8, 9, 10) ~ \"Rainy\", # June to October\n    month_number %in% c(11, 12, 1, 2) ~ \"Cool\"     # November to February\n  )) %&gt;%\n  \n  # add peak period col (7-9 am or 4-7 pm)\n  mutate(peak_period = case_when(\n    format(incident_datetime, \"%H:%M:%S\") &gt;= \"07:00:00\" & format(incident_datetime, \"%H:%M:%S\") &lt;= \"09:00:00\" ~ \"Morning Peak\",\n    format(incident_datetime, \"%H:%M:%S\") &gt;= \"16:00:00\" & format(incident_datetime, \"%H:%M:%S\") &lt;= \"19:00:00\" ~ \"Evening Peak\",\n    TRUE ~ \"Off-Peak\"\n  )) %&gt;%\n  \n  # Add column to identify Songkran's \"7 Deadly Days\"\n  mutate(songkran_7_dead_days = month_number == 4 & day_of_month &gt;= 11 & day_of_month &lt;= 17) %&gt;%\n  # drop unused columns\n  select(-c(\"province_th\", \n            \"incident_datetime\", \n            \"report_datetime\",\n            \"route\",\n            \"agency\"))  \n\naccidents_bmr_ft\n\n\nThen, we save this processed accident data in RDS data format for future analysis.\n\nwrite_rds(accidents_bmr_ft, \"data/rds/accidents_bmr_ft.rds\")\n\n\naccidents_bmr_ft &lt;- read_rds(\"data/rds/accidents_bmr_ft.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis-eda",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis-eda",
    "title": "Take Home Exercise 1",
    "section": "8 Exploratory Data Analysis (EDA)",
    "text": "8 Exploratory Data Analysis (EDA)\nIn this section, we conduct an Exploratory Data Analysis (EDA) to visualize the trends and distribution of road accidents in Thailand from 2019 to 2022. A combination of plots and choropleth maps will be used to reveal key patterns and insights.\n\n8.1 Overall Plot\nFirst, we will plot the 3 datasets onto a single choropleth map to gain a general understanding.\n\n\nShow the code\ntmap_mode('plot')\n\ntm_shape(admin_boundary_bmr) + \n  tm_polygons(col = \"ADM1_EN\", alpha = 0.6, border.col = \"black\", lwd = 0.7, title = \"Region\") +\n  tm_shape(roads_bmr) +\n  tm_lines(col = \"darkgreen\", lwd = 1.5, alpha = 0.8) +                                       \n  tm_shape(accidents_bmr_ft) + \n  tm_dots(col = \"red\", size = 0.05, alpha = 0.5) +                                                \n  tm_layout(\n    main.title = \"Road Traffic Accidents in Bangkok Metropolitan Region (2019-2022)\",\n    main.title.position = c(\"center\", \"top\"), \n    frame = FALSE,\n    legend.outside = TRUE,               \n    legend.position = c(\"right\", \"bottom\"), \n    title.size = 0.8,     \n    legend.text.size = 1, \n    legend.title.size = 1 \n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nThe majority of accidents are concentrated along the Intercity road network.\nThis suggests that the 6 existing Intercity highway types provide sufficient coverage, and we don’t require to add more highway types from the original roads dataset for this study.\n\n\n\n\n\n8.2 Visualize Geographic Distribution of Accidents by Year\nNext, we use choropleth maps and stacked bar charts to explore the distribution of road traffic accidents across the BMR from 2019 to 2022.\n\n\nShow the code\ntmap_mode('plot')\n\ntm_shape(admin_boundary_bmr) + \n  tm_polygons(border.col = \"darkgray\", alpha = 0.5) +\ntm_shape(roads_bmr) + \n  tm_lines(col = \"darkgreen\", lwd = 0.7) +\ntm_shape(accidents_bmr_ft) + \n  tm_dots(size = 0.2, col = \"red\", alpha = 0.6) +\n# facet by year\ntm_facets(by = \"year\") +\ntm_layout(\n  main.title = \"Accident Trends by Year in Bangkok Metropolitan Region (2019-2022)\",\n  main.title.size = 1.5, \n  main.title.position = c(\"center\", \"top\"), \n  frame = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Calculate total accidents by year\naccidents_by_year &lt;- accidents_bmr_ft %&gt;%\n  st_drop_geometry() %&gt;%                  \n  group_by(year) %&gt;%\n  summarize(total_accidents = n())\n\n# Calculate total accidents by province and year\naccidents_by_province_year &lt;- accidents_bmr_ft %&gt;%\n  st_drop_geometry() %&gt;%                  \n  group_by(year, province_en) %&gt;%\n  summarize(total_accidents = n()) %&gt;%\n  ungroup()\n\n# Summarize total accidents for each year (for trendline)\ntotal_accidents_by_year &lt;- accidents_by_province_year %&gt;%\n  group_by(year) %&gt;%\n  summarize(total_accidents = sum(total_accidents))\n\n# create stacked bar chart with trendline\nfig_accidents_by_year_province &lt;- plot_ly() %&gt;%\n  # add stack bar chart\n  add_trace(\n    data = accidents_by_province_year,\n    x = ~year,\n    y = ~total_accidents,\n    color = ~province_en,\n    type = 'bar',\n    text = ~paste(province_en, \": \", total_accidents), \n    hoverinfo = 'text', \n    name = ~province_en \n  ) %&gt;%\n  # add trendline\n  add_trace(\n    data = total_accidents_by_year,\n    x = ~year,\n    y = ~total_accidents,\n    type = 'scatter',\n    mode = 'lines+markers',\n    line = list(color = 'black', dash = 'dash'),\n    marker = list(color = 'black', size = 6), \n    name = 'Total Accidents Trend'\n  ) %&gt;%\n  layout(\n    barmode = 'stack',\n    title = \"Total Accidents by Year and Province with Trendline\",\n    xaxis = list(title = \"Year\"),\n    yaxis = list(title = \"Total Accidents\"),\n    legend = list(title = list(text = \"Province\")) \n  )\n\nfig_accidents_by_year_province\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nOverall, accident trends indicate a general upward trajectory over the years.\nThe total number of accidents increased from 2019 to 2022, with a slight dip in 2021.\nBangkok consistently recorded the highest number of accidents each year.\nPathum Thani and Samut Prakan also contributed significantly to the accident counts.\nThe number of accidents in 2022 saw a noticeable rise, particularly in Bangkok and Samut Sakhon.\n\n\n\n\n\n8.3 Visualize Geographic Distribution of Accidents by Month\nNext, we visualize the distribution of accidents by months and seasons.\n\n\nShow the code\ntmap_mode('plot')\n\ntm_shape(admin_boundary_bmr) + \n  tm_polygons(border.col = \"darkgray\", alpha = 0.5) +\ntm_shape(roads_bmr) + \n  tm_lines(col = \"darkgreen\", lwd = 0.7) +\ntm_shape(accidents_bmr_ft) + \n  tm_dots(size = 0.2, col = \"red\", alpha = 0.6) +\n# facet by month_factor\ntm_facets(by = \"month_factor\") +\ntm_layout(\n  main.title = \"Accident Trends by Month in Bangkok Metropolitan Region (2019-2022)\",\n  main.title.size = 1.5, \n  main.title.position = c(\"center\", \"top\"), \n  frame = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# compute accidents by month, season\naccidents_by_month &lt;- accidents_bmr_ft %&gt;%\n  st_drop_geometry() %&gt;%                  \n  group_by(month_factor, season) %&gt;%\n  summarize(total_accidents = n()) %&gt;%\n  ungroup()\n\n\nfig_accidents_by_month_bar &lt;- plot_ly() %&gt;%\n  # add bar chart\n  add_trace(\n    data = accidents_by_month,\n    x = ~month_factor,                   \n    y = ~total_accidents,                \n    color = ~season,                     \n    # Assign colors to each season\n    colors = c('Cool' = 'lightblue', 'Hot' = 'red3', 'Rainy' = 'royalblue3'), \n    type = 'bar',                        \n    name = ~season                       \n  ) %&gt;%\n  # Add  trendline\n  add_trace(\n    data = accidents_by_month,\n    x = ~month_factor,\n    y = ~total_accidents,\n    type = 'scatter',\n    mode = 'lines+markers',              \n    line = list(color = 'black', dash = 'dash'), \n    marker = list(color = 'black', size = 6), \n    name = 'Trendline'                  \n  ) %&gt;%\n  layout(\n    title = \"Accidents by Month in Bangkok Metropolitan Region (2019-2022)\",\n    xaxis = list(title = \"Month\"),\n    yaxis = list(title = \"Total Accidents\"),\n    barmode = 'group',                 \n    legend = list(title = list(text = \"Season\"))\n  )\nfig_accidents_by_month_bar\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nThe cool season (January, November, and December) also shows relatively high accident counts, particularly in December, which concide with the holidays season.\nThe rainy season (June to October) has a relatively steady trend of accidents, with no significant peaks or drops.\nApril stands out with the highest number of accidents, potentially influenced by the Songkran festival.\n\n\n\n\n8.3.1 Special Mention: Songkran\nIn this special section, we highlight the impact of the Songkran festival on road accidents in April, a period that is known for increased travel and, consequently, heightened risk on the roads. For meaningful comparison, we compute the average daily accident rate during the 7 “deadly days” of Songkran versus the rest of April (non-Songkran days) from 2019 to 2022.\n\n\nShow the code\ncompute_average_daily_accident_rate &lt;- function(data) {\n  # filter data for April\n  april_data &lt;- data %&gt;%\n    st_drop_geometry() %&gt;%\n    filter(month_factor == \"Apr\") %&gt;%\n    group_by(year, songkran_7_dead_days) %&gt;%\n    summarize(total_accidents = n(), .groups = 'drop') %&gt;%\n    mutate(\n      days_count = ifelse(songkran_7_dead_days, 7, 30 - 7),\n      # Compute the average daily accident rate\n      average_daily_accidents = total_accidents / days_count,  \n      songkran_label = ifelse(songkran_7_dead_days, \"Songkran\", \"Non-Songkran Days\")\n    ) %&gt;%\n    select(year, songkran_label, average_daily_accidents) \n\n  return(april_data)\n}\n\naverage_daily_accident_rate &lt;- compute_average_daily_accident_rate(accidents_bmr_ft)\n\nfig_accidents_songkran &lt;- plot_ly(\n  data = average_daily_accident_rate,\n  x = ~year,                          \n  y = ~average_daily_accidents,       \n  color = ~songkran_label,         \n  # Color by Songkran label (During Songkran vs. Non-Songkran Days)\n  colors = c('Songkran' = 'tomato1', 'Non-Songkran Days' = 'royalblue3'), \n  type = 'bar',                        \n  name = ~songkran_label              \n) %&gt;%\n  layout(\n    title = \"Average Daily Accident Rate in April During Songkran vs. Non-Songkran Days (2019-2022)\",\n    xaxis = list(title = \"Year\"),\n    yaxis = list(title = \"Average Daily Accidents\"),\n    barmode = 'group',              \n    legend = list(title = list(text = \"Day Type\"))\n  )\n\nfig_accidents_songkran\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nSongkran days (in red) consistently show a higher average daily accident rate compared to non-Songkran days (in blue) across all years (2019-2022).\nNon-Songkran days have a relatively steady accident rate across all years, remaining below 10 accidents per day.\nIn 2020, due to the COVID-19 pandemic restrictions, Songkran celebrations were suspended. This likely explains the significantly lower accident rates for both day types in 2020.\n\n\n\n\n\n\n8.4 Visualize Geographic Distribution of Accidents by Day of Week\nNext, we visualize the distribution of accidents by day of week to observe the accident trends.\n\n\nShow the code\ntmap_mode('plot')\n\ntm_shape(admin_boundary_bmr) + \n  tm_polygons(border.col = \"darkgray\", alpha = 0.5) +\ntm_shape(roads_bmr) + \n  tm_lines(col = \"darkgreen\", lwd = 0.7) +\ntm_shape(accidents_bmr_ft) + \n  tm_dots(size = 0.2, col = \"red\", alpha = 0.6) +\n# facet by day of week\ntm_facets(by = \"day_of_week\") +\ntm_layout(\n  main.title = \"Accident Trends by Days of Week in BMR (2019-2022)\",\n  main.title.size = 1.5, \n  main.title.position = c(\"center\", \"top\"), \n  frame = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Compute accidents by day of the week and group by weekday or weekend\naccidents_by_day &lt;- accidents_bmr_ft %&gt;%\n  st_drop_geometry() %&gt;%\n  mutate(\n    day_type = case_when(\n      day_of_week %in% c(6, 7) ~ \"Weekend\",\n      TRUE ~ \"Weekday\"\n    )\n  ) %&gt;%\n  group_by(day_of_week, day_type) %&gt;%\n  summarize(total_accidents = n()) %&gt;%\n  ungroup()\n\nfig_accidents_by_day_bar &lt;- plot_ly() %&gt;%\n  # Add the bar chart\n  add_trace(\n    data = accidents_by_day,\n    x = ~day_of_week,                    \n    y = ~total_accidents,               \n    color = ~day_type,                   \n    # assign color by weekday, weekend\n    colors = c('Weekday' = 'orange', 'Weekend' = 'seagreen'), \n    type = 'bar',                        \n    name = ~day_type                     \n  ) %&gt;%\n  # Add a trendline\n  add_trace(\n    data = accidents_by_day,\n    x = ~day_of_week,\n    y = ~total_accidents,\n    type = 'scatter',\n    mode = 'lines+markers',              \n    line = list(color = 'black', dash = 'dash'), \n    marker = list(color = 'black', size = 6), \n    name = 'Trendline'                  \n  ) %&gt;%\n  layout(\n    title = \"Accidents by Day of the Week in Bangkok Metropolitan Region (2019-2022)\",\n    xaxis = list(title = \"Day of the Week\", tickvals = 1:7, ticktext = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")),\n    yaxis = list(title = \"Total Accidents\"),\n    barmode = 'group',                 \n    legend = list(title = list(text = \"Day Type\"))\n  )\n\nfig_accidents_by_day_bar\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nWeekdays (in orange) show a relatively consistent number of total accidents across Monday to Thursday, with a slight increase towards Friday.\nBoth Fridays and Saturdays show high accident numbers suggesting a potential rise in traffic volume or risky driving behavior leading into the weekend.\nThe trendline reflects an upward trend from Monday, peaking on Friday, and then declining over the weekend, particularly on Sunday.\n\n\n\n\n\n8.5 Visualize Geographic Distribution of Accidents by Peak Period\nNext, we visualize the distribution of accidents by peak period.\n\n\nShow the code\ntmap_mode('plot')\n\ntm_shape(admin_boundary_bmr) + \n  tm_polygons(border.col = \"darkgray\", alpha = 0.5) +\ntm_shape(roads_bmr) + \n  tm_lines(col = \"darkgreen\", lwd = 0.7) +\ntm_shape(accidents_bmr_ft) + \n  tm_dots(size = 0.2, col = \"red\", alpha = 0.6) +\n# facet by peak_period\ntm_facets(by = \"peak_period\") +\ntm_layout(\n  main.title = \"Accident Trends by Peak Period in BMR (2019-2022)\",\n  main.title.size = 1.5, \n  main.title.position = c(\"center\", \"top\"), \n  frame = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Group data by year and peak period type\naccidents_by_year_peak_period &lt;- accidents_bmr_ft %&gt;%\n  st_drop_geometry() %&gt;%\n  group_by(year, peak_period) %&gt;%\n  summarize(total_accidents = n(), .groups = 'drop') %&gt;%\n  mutate(\n    # Calculate the number of hours for each peak period type\n    hours_count = case_when(\n      peak_period == \"Morning Peak\" ~ 2,  # 7-9 AM (2 hours)\n      peak_period == \"Evening Peak\" ~ 3,  # 4-7 PM (3 hours)\n      peak_period == \"Off-Peak\" ~ 19      # Remaining hours in a day\n    ),\n    average_accidents_per_hour = total_accidents / hours_count  # Compute average accident rate per hour\n  )\n\n\nfig_accidents_trend &lt;- plot_ly(\n  data = accidents_by_year_peak_period,\n  x = ~year,                              \n  y = ~average_accidents_per_hour,        \n  color = ~peak_period,                    \n  colors = c('Morning Peak' = 'tomato1', 'Evening Peak' = 'orange', 'Off-Peak' = 'lightblue'),\n  type = 'bar',                       \n  mode = 'lines+markers',                 \n  name = ~peak_period                      \n) %&gt;%\n  layout(\n    title = \"Average Accident Rate per Hour by Peak Period Type Over the Years\",\n    xaxis = list(title = \"Year\"),\n    yaxis = list(title = \"Average Accidents per Hour\"),\n    legend = list(title = list(text = \"Peak Period\"))\n  )\n\n# Display the plot\nfig_accidents_trend\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nThe Morning Peak consistently shows the highest average accident rate per hour across all years, peaking sharply in 2020.\nEvening Peak follows closely, with slightly lower accident rates compared to the Morning Peak but remaining higher than Off-Peak periods.\nOff-Peak accident rates are consistently lower across all years.\nThe year 2020 stands out with the highest accident rates across all peak periods, especially in the Morning Peak.\nOverall, both Morning and Evening Peak periods exhibit higher accident rates compared to Off-Peak periods, highlighting rush hours as critical times for road accidents.\n\n\n\n\n\n8.6 Visualize Geographic Distribution of Accidents by Weather Conditions\nNext, we visualize the distribution of accidents by weak conditions.\n\n\nShow the code\ntmap_mode('plot')\n\ntm_shape(admin_boundary_bmr) + \n  tm_polygons(border.col = \"darkgray\", alpha = 0.5) +\ntm_shape(roads_bmr) + \n  tm_lines(col = \"darkgreen\", lwd = 0.7) +\ntm_shape(accidents_bmr_ft) + \n  tm_dots(size = 0.2, col = \"red\", alpha = 0.6) +\n# facet by weather\ntm_facets(by = \"weather_condition\") +\ntm_layout(\n  main.title = \"Accident Trends by Weather in BMR (2019-2022)\",\n  main.title.size = 1.5, \n  main.title.position = c(\"center\", \"top\"), \n  frame = FALSE\n)\n\n\n\n\n\n\n\n\n\nWe noticed that most of accident data is recorded during clear conditions, followed by rainy conditions. We will discuss our observations in the following section with other factors.\n\n\n8.7 Visualize Other Factors\nIn this section, we consolidated our remaining observations of the accident dataset.\n\n\nShow the code\nselected_data &lt;- accidents_bmr_ft %&gt;%\n  st_drop_geometry() %&gt;%\n  select(presumed_cause, accident_type, road_description, weather_condition, vehicle_type)\n\ntheme_gtsummary_compact()\n\nselected_data %&gt;% \n  tbl_summary(missing_text = \"NA\", sort=all_categorical(FALSE) ~ \"frequency\") %&gt;% \n  add_n() %&gt;% \n  modify_caption(\"**Table of Variable Summary**\") %&gt;%\n  bold_labels()\n\n\n\n\n\n\nTable of Variable Summary\n\n\n\n\n\n\n\nCharacteristic\nN\nN = 12,986\n1\n\n\n\n\npresumed_cause\n12,986\n\n\n\n\n    speeding\n\n\n10,143 (78%)\n\n\n    other\n\n\n957 (7.4%)\n\n\n    cutting in closely by people/vehicles/animals\n\n\n621 (4.8%)\n\n\n    vehicle equipment failure\n\n\n365 (2.8%)\n\n\n    falling asleep\n\n\n221 (1.7%)\n\n\n    driving under the influence of alcohol\n\n\n118 (0.9%)\n\n\n    running red lights/traffic signals\n\n\n96 (0.7%)\n\n\n    tailgating\n\n\n83 (0.6%)\n\n\n    abrupt lane change\n\n\n59 (0.5%)\n\n\n    unfamiliarity with the route/unskilled driving\n\n\n53 (0.4%)\n\n\n    illegal overtaking\n\n\n50 (0.4%)\n\n\n    failure to yield/signal\n\n\n33 (0.3%)\n\n\n    debris/obstruction on the road\n\n\n29 (0.2%)\n\n\n    failure to yield right of way\n\n\n21 (0.2%)\n\n\n    worn-out/tire blowout\n\n\n19 (0.1%)\n\n\n    overloaded vehicle\n\n\n18 (0.1%)\n\n\n    reversing vehicle\n\n\n15 (0.1%)\n\n\n    dangerous curve\n\n\n14 (0.1%)\n\n\n    sudden stop\n\n\n14 (0.1%)\n\n\n    slippery road\n\n\n8 (&lt;0.1%)\n\n\n    brake/anti-lock brake system failure\n\n\n7 (&lt;0.1%)\n\n\n    driving in the wrong lane\n\n\n6 (&lt;0.1%)\n\n\n    loss of control\n\n\n6 (&lt;0.1%)\n\n\n    failure to signal enter/exit parking\n\n\n5 (&lt;0.1%)\n\n\n    using mobile phone while driving\n\n\n4 (&lt;0.1%)\n\n\n    disabled vehicle without proper signals/signs\n\n\n3 (&lt;0.1%)\n\n\n    insufficient light\n\n\n3 (&lt;0.1%)\n\n\n    road in poor condition\n\n\n2 (&lt;0.1%)\n\n\n    straddling lanes\n\n\n2 (&lt;0.1%)\n\n\n    disabled vehicle without proper signals\n\n\n1 (&lt;0.1%)\n\n\n    ignoring stop sign while leaving intersection\n\n\n1 (&lt;0.1%)\n\n\n    inadequate visibility\n\n\n1 (&lt;0.1%)\n\n\n    medical condition\n\n\n1 (&lt;0.1%)\n\n\n    no presumed cause related to driver\n\n\n1 (&lt;0.1%)\n\n\n    no road divider lines\n\n\n1 (&lt;0.1%)\n\n\n    no traffic signs\n\n\n1 (&lt;0.1%)\n\n\n    obstruction in sight\n\n\n1 (&lt;0.1%)\n\n\n    repair/construction on the road\n\n\n1 (&lt;0.1%)\n\n\n    using psychoactive substances\n\n\n1 (&lt;0.1%)\n\n\n    vehicle electrical system failure\n\n\n1 (&lt;0.1%)\n\n\naccident_type\n12,986\n\n\n\n\n    rear-end collision\n\n\n6,877 (53%)\n\n\n    rollover/fallen on straight road\n\n\n3,916 (30%)\n\n\n    other\n\n\n859 (6.6%)\n\n\n    collision with obstruction (on road surface)\n\n\n459 (3.5%)\n\n\n    rollover/fallen on curved road\n\n\n415 (3.2%)\n\n\n    side collision\n\n\n139 (1.1%)\n\n\n    pedestrian collision\n\n\n121 (0.9%)\n\n\n    head-on collision (not overtaking)\n\n\n102 (0.8%)\n\n\n    collision at intersection corner\n\n\n75 (0.6%)\n\n\n    collision during overtaking\n\n\n12 (&lt;0.1%)\n\n\n    turning/retreating collision\n\n\n11 (&lt;0.1%)\n\n\nroad_description\n12,986\n\n\n\n\n    straight road\n\n\n11,084 (85%)\n\n\n    other\n\n\n1,004 (7.7%)\n\n\n    wide curve\n\n\n488 (3.8%)\n\n\n    grade-separated intersection/ramps\n\n\n150 (1.2%)\n\n\n    y-intersection\n\n\n73 (0.6%)\n\n\n    t-intersection\n\n\n66 (0.5%)\n\n\n    connecting to public/commercial area\n\n\n43 (0.3%)\n\n\n    sharp curve\n\n\n41 (0.3%)\n\n\n    merge lane\n\n\n11 (&lt;0.1%)\n\n\n    connecting to private area\n\n\n8 (&lt;0.1%)\n\n\n    four-way intersection\n\n\n6 (&lt;0.1%)\n\n\n    u-turn area\n\n\n5 (&lt;0.1%)\n\n\n    connecting to school area\n\n\n4 (&lt;0.1%)\n\n\n    roundabout\n\n\n3 (&lt;0.1%)\n\n\nweather_condition\n12,986\n\n\n\n\n    clear\n\n\n11,711 (90%)\n\n\n    rainy\n\n\n1,166 (9.0%)\n\n\n    dark\n\n\n81 (0.6%)\n\n\n    other\n\n\n22 (0.2%)\n\n\n    foggy\n\n\n4 (&lt;0.1%)\n\n\n    land slide\n\n\n1 (&lt;0.1%)\n\n\n    natural disaster\n\n\n1 (&lt;0.1%)\n\n\nvehicle_type\n12,986\n\n\n\n\n    private/passenger car\n\n\n4,486 (35%)\n\n\n    4-wheel pickup truck\n\n\n3,522 (27%)\n\n\n    motorcycle\n\n\n1,687 (13%)\n\n\n    other\n\n\n1,088 (8.4%)\n\n\n    large truck with trailer\n\n\n998 (7.7%)\n\n\n    6-wheel truck\n\n\n472 (3.6%)\n\n\n    7-10-wheel truck\n\n\n389 (3.0%)\n\n\n    van\n\n\n154 (1.2%)\n\n\n    large passenger vehicle\n\n\n76 (0.6%)\n\n\n    passenger pickup truck\n\n\n63 (0.5%)\n\n\n    bicycle\n\n\n18 (0.1%)\n\n\n    pedestrian\n\n\n18 (0.1%)\n\n\n    motorized tricycle\n\n\n14 (0.1%)\n\n\n    tractor/agricultural vehicle\n\n\n1 (&lt;0.1%)\n\n\n\n1\nn (%)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nTop Causes of Accidents: Behavioral Factors\n\nSpeeding is the leading presumed cause, responsible for 78% of accidents (10,143 cases). This is a clear indication that driver behavior is the primary factor.\nOther behavioral causes include cutting in closely (4.8%), driving under the influence of alcohol (0.9%), and tailgating (0.6%).\n\nMinor Contribution from Road Conditions\n\nRoad conditions such as slippery roads, debris, and road in poor condition account for a very small portion of the accidents (&lt;1%).\n\nWeather Conditions\n\nClear weather dominates in 90% of cases (as visualized in earlier section), while rainy conditions account for only 9% of accidents. Adverse weather such as foggy or dark conditions plays a negligible role.\n\nAccident Types\n\nMost accidents are rear-end collisions (53%) and rollovers on straight roads (30%), again pointing towards driver behavior on straightforward road networks.\n\nRoad Types\n\nStraight roads are where the vast majority (85%) of accidents occur.\n\nVehicle Types\n\nThe majority of accidents involve private/passenger cars (35%) and 4-wheel pickup trucks (27%), followed by Motorcycles (13%)\n\n\nIn summary, based on this dataset, we can observe that behavioral factors like speeding are overwhelmingly the top causes of accidents, while road conditions and weather play a much smaller role."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-measures-of-central-tendency",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-measures-of-central-tendency",
    "title": "Take Home Exercise 1",
    "section": "9 Spatial Measures of Central Tendency",
    "text": "9 Spatial Measures of Central Tendency\nIn this section, we are interested in identifying the centrality of road traffic accidents within the Bangkok Metropolitan Region (BMR) by computing two key spatial measures: the mean center and the median center.\nThe mean centre represents the average location of all accident points in the region while the median center which is less influenced by outliers, provides a more robust indication of where accidents tend to cluster, unaffected by unusually high or low values in specific areas.\n\n# Extract coordinates\naccidents_xy &lt;- st_coordinates(accidents_bmr_ft)\n\nmean_center &lt;- accidents_xy %&gt;%\n  colMeans()\n\nmean_center\n\n        X         Y \n 668399.5 1523495.8 \n\n\n\nmedian_center &lt;- accidents_xy %&gt;%\n  apply(2, median)\n\nmedian_center\n\n        X         Y \n 673446.1 1520755.0 \n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe similarity between the mean center and median center suggests that the distribution of road accidents in the Bangkok Metropolitan Region is relatively balanced, with no significant outliers skewing the spatial patterns.\n\n\n\n9.1 Spatial Measures of Central Tendency Over the Years\nIn this section, we are interested to observe in what direction has the mean centre of the Thailand road accidents moved over the years.\n\n\nShow the code\nmean_median_by_year &lt;- accidents_bmr_ft %&gt;%\n  group_by(year) %&gt;%\n  summarise(\n    mean_center_x = mean(st_coordinates(geometry)[, 1]),\n    mean_center_y = mean(st_coordinates(geometry)[, 2]),\n    median_center_x = median(st_coordinates(geometry)[, 1]),\n    median_center_y = median(st_coordinates(geometry)[, 2])\n  )\n\nplot(st_geometry(admin_boundary_bmr), main = \"Mean Centers of Accidents in BMR over the Years\")\n\npoints(accidents_xy[, 1], accidents_xy[, 2], cex = 0.7, pch = 21)\n\ncolors &lt;- c(\"goldenrod2\", \"sienna2\", \"hotpink1\", \"red1\")\nyears &lt;- unique(accidents_bmr_ft$year)\n\nfor (i in 1:nrow(mean_median_by_year)) {\n  points(mean_median_by_year$mean_center_x[i], mean_median_by_year$mean_center_y[i], \n         pch = '*', col = colors[i], cex = 4, lwd = 2)\n}\n\nlegend(\"topright\", legend = paste0(\"Year: \", years), col = colors, pch = '*', \n       pt.cex = 1.5, title = \"Centers\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nThe mean centers of accidents in BMR over the years from 2019 to 2022 are relatively close to each other within the Bangkok province, indicating that the central tendency of accidents has not shifted dramatically during this period.\nThe points show a slight progression towards the southeast over time. This may suggest a gradual shift in the concentration of accidents towards a different district of the Bangkok province."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-point-pattern-analysis-sppa",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-point-pattern-analysis-sppa",
    "title": "Take Home Exercise 1",
    "section": "10 Spatial Point Pattern Analysis (SPPA)",
    "text": "10 Spatial Point Pattern Analysis (SPPA)\nIn this section, we will conduct Spatial Point Pattern Analysis (SPPA) using the spatstat package to quantify the spatial distribution of road traffic accidents in the Bangkok Metropolitan Region (BMR). This method determines whether accidents are randomly distributed, clustered, or follow a regular pattern.\nTo explore this, we will test the Complete Spatial Randomness (CSR) hypothesis, which assumes accidents occur independently and uniformly across the region.\nWe will apply three SPPA methods:\n\nFirst-Order SPPA: This examines broader trends in accident intensity using techniques like Kernel Density Estimation (KDE) to identify “hot spots” and assess clustering or regularity.\nSecond-Order SPPA: Tools like Ripley’s K-function, G, F, and L functions will be applied to assess spatial dependence at varying distances, helping to detect clustering or dispersion.\nNetwork-Constrained SPPA: This method analyzes accident patterns along road networks, recognizing that accidents are restricted to roads. It offers a more realistic view of clustering based on the actual network structure.\n\n\nThe key questions in this section are:\n\nAre the road accidents in BMR randomly distributed throughout the region?\nIf not, where are the areas with higher accident concentrations?\n\n\n\n10.1 Converting sf Format into ppp format\nBefore we can perform spatial point analysis with spatstat, we will convert the sf objects into ppp object using as.ppp().\n\n# convert to ppp and rescale from m to km)\naccidents_ppp.km &lt;- rescale(as.ppp(accidents_bmr_ft), 1000, \"km\")\n\nNext, we check for duplicated entries within the point pattern object. Using unmark, we are only comparing the coordinates, regardless of marks.\n\nany(duplicated(accidents_ppp.km, rule=\"unmark\"))\n\n[1] TRUE\n\n\nSince there may be overlapping points due to accidents occurring at the same location, we apply a random jitter to the points. This reduces overlap by introducing slight random shifts, and we summarize the jittered point pattern to verify the changes.\n\naccidents_ppp_jit.km &lt;- rjitter(accidents_ppp.km, \n                                        retry=TRUE, \n                                        nsim=1, \n                                        drop=TRUE)\n\nsummary(accidents_ppp_jit.km)\n\nMarked planar point pattern:  12986 points\nAverage intensity 1.218049 points per square km\n\nCoordinates are given to 13 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 571882 3788970 3834532 4314457 6092694 7570954 \n\nWindow: rectangle = [591.2775, 710.1661] x [1486.8457, 1576.5205] km\n                    (118.9 x 89.67 km)\nWindow area = 10661.3 square km\nUnit of length: 1 km\n\n\nNext we create the owin object which is the administrative boundary of the Bangkok Metropolitan Region (BMR). We also rescale the boundary to match the units used in the point pattern (kilometers).\n\nowin_bmr.km &lt;- rescale(as.owin(admin_boundary_bmr), 1000)\nowin_bmr.km\n\nwindow: polygonal boundary\nenclosing rectangle: [587.8935, 712.4405] x [1484.4137, 1579.0763] units\n\n\nAfter defining the observation window, we subset the jittered point pattern to include only the accident points that fall within the boundary of the BMR.\nWe then summarize the resulting point pattern to ensure that the filtering was successful.\n\naccidents_owin.km &lt;- accidents_ppp_jit.km[owin_bmr.km]\nsummary(accidents_owin.km)\n\nMarked planar point pattern:  12981 points\nAverage intensity 1.69266 points per square km\n\nCoordinates are given to 13 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 571882 3788970 3835196 4314334 6092693 7570954 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587.8935, 712.4405] x [1484.4137, 1579.0763] km\n                     (124.5 x 94.66 km)\nWindow area = 7668.99 square km\nUnit of length: 1 km\nFraction of frame area: 0.65\n\n\nNext, we generate the plot of the spatial distribution of road accidents within the BMR boundary.\n\nplot(accidents_owin.km)\n\n\n\n\n\n\n\n\n\n\n10.2 First Order Spatial Point Pattern Analysis\nIn this section, we conduct first-order Spatial Point Pattern Analysis (SPPA) using the spatstat package to explore the intensity of traffic accidents. The analysis will include:\n\nKernel Density Estimation (KDE): Estimating accident intensity for visualizing and understanding spatial concentration of accident points.\nNearest Neighbour Analysis: To confirm spatial patterns by calculating nearest-neighbour statistics.\n\n\n10.2.1 Kernel Density Estimation (KDE)\nKernel Density Estimation (KDE) provides a smooth estimate of the intensity of point processes, allowing us to visualize accident density hotspots. In this step, we experiment with different automatic bandwidth selection methods to determine the most suitable one for our analysis.\n\nbw.CvL(accidents_ppp_jit.km)\n\n  sigma \n31.4123 \n\nbw.scott(accidents_ppp_jit.km)\n\n sigma.x  sigma.y \n4.530017 3.322396 \n\nbw.ppl(accidents_ppp_jit.km)\n\n    sigma \n0.4197952 \n\nbw.diggle(accidents_ppp_jit.km)\n\n     sigma \n0.04745292 \n\n\n\n\nShow the code\n# try different bandwidth methods\n# par(mfrow=c(2,2))\npar(mfrow=c(1,2))\nkde_accidents_bw_km &lt;- density(accidents_ppp_jit.km, \n                               sigma = bw.diggle,\n                               edge=TRUE,kernel='gaussian')\n\nkde_accidents_ppl_km &lt;- density(accidents_ppp_jit.km, \n                               sigma = bw.ppl,\n                               edge=TRUE,kernel='gaussian')\n\n# kde_accidents_cvl_km &lt;- density(accidents_ppp_jit.km, \n#                               sigma = bw.CvL,\n#                               edge=TRUE,kernel='gaussian')\n\n#kde_accidents_scott_km &lt;- density(accidents_ppp_jit.km, \n#                               sigma = bw.scott,\n#                               edge=TRUE,kernel='gaussian')\n\nplot(kde_accidents_bw_km)\nplot(kde_accidents_ppl_km)\n\n\n\n\n\n\n\n\n\nShow the code\n#plot(kde_accidents_cvl_km)\n#plot(kde_accidents_scott_km)\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nThe Diggle algorithm give the narrower bandwidth, making it ideal for identifying precise accident clusters in this study, as it captures spatial details without excessive smoothing.\n\n\n\n\n\n10.2.2 Comparing Spatial Point Patterns using KDE\nIn this section, we will compare KDE of road accidents across provinces in BMR. This comparison allows us to visually explore the variation in accident intensity across the provinces using KDE.\nWe first create a list of owin objects for each province, rescaling the spatial windows to kilometers. Then we subset the jittered point pattern of road accidents for each province and compute the KDE for each region using bw.diggle.\n\n\nShow the code\n# make individual owins\nbmr_owins &lt;- lapply(bmr_regions, function(region) {\n  rescale(as.owin(admin_boundary_bmr %&gt;% filter(ADM1_EN == region)), 1000)\n})\n\nnames(bmr_owins) &lt;- bmr_regions\n\n\naccidents_ppps &lt;- lapply(bmr_owins, function(owin) {\n  accidents_ppp_jit.km[owin]\n})\n\ndensities &lt;- lapply(seq_along(bmr_regions), function(i) {\n  region &lt;- bmr_regions[i]\n  density(accidents_ppps[[region]], \n          sigma = bw.diggle, \n          edge = TRUE, \n          kernel = \"gaussian\")\n})\nnames(densities) &lt;- bmr_regions\n\n\n\n\nShow the code\npar(mfrow = c(3, 2), mar = c(5, 5, 2, 1))\n\n# suppress lapply output\ninvisible(lapply(seq_along(densities), function(i) {\n  region &lt;- names(densities)[i]\n  plot(densities[[i]], main = region)\n}))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nAccidents appears to cluster along the major highways of each province.\nBangkok and Samut Prakan have the highest KDE values for accidents, with densities reaching up to 500 and 600, respectively, primarily along major highways; while Nakhon Pathom and Nonthaburi have lower KDE values among the 6 provinces.\n\n\n\n\n\n10.2.3 Nearest Neighbour Analysis: Clark-Evans Test\nAfter performing the first-order spatial point pattern analysis, we move on to Nearest Neighbour Analysis using the Clark-Evans test to quantitatively assess whether the traffic accident distribution follows a random, clustered, or dispersed pattern. This test complements the visual insights gained from the Kernel Density Estimation (KDE) by providing statistical evidence for spatial clustering.\n\nThe Clark-Evans aggregation index (R) compares the observed mean nearest neighbour distance to the expected distance under Complete Spatial Randomness (CSR).\nIf R = 1, the points are randomly distributed.\nIf R &lt; 1, the points exhibit clustering.\nIf R &gt; 1, the points are more regularly spaced, suggesting spatial dispersion.\n\nThe test hypotheses are:\n\n\\(H_0\\): The traffic accidents are randomly distributed.\n\\(H_1\\): The traffic accidents are not randomly distributed (i.e., they are clustered or ordered).\n\nWe use the 95% confidence interval for decision-making.\n\nclarkevans.test(accidents_ppp.km,\n                correction=\"none\",\n                clipregion=\"owin_bmr.km\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  accidents_ppp.km\nR = 0.16207, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe result of the Clark-Evans test shows:\n\nR = 0.16207, which is significantly less than 1, indicating that the traffic accidents exhibit strong spatial clustering.\nThe p-value &lt; 2.2e-16, which is much lower than the 0.05 significance level, thus we reject the null hypothesis (\\(H_0\\)).\n\nThe traffic accidents are not randomly distributed but are clustered, confirming that certain areas or road segments in the Bangkok Metropolitan Region (BMR) have significantly higher concentrations of accidents.\n\n\n\n\n10.2.4 Clark-Evans Test for Individual Provinces\nNext, we perform the Clark-Evans test for each province in the BMR to assess the spatial distribution of traffic accidents.\n\nfor (i in seq_along(accidents_ppps)) {\n  accidents_pr_ppp &lt;- accidents_ppps[[i]]\n  \n  cat(\"\\n##\", bmr_regions[i], \"\\n\")  # Print the region name for clarity\n  print(\n    clarkevans.test(accidents_pr_ppp,\n                    correction=\"none\",\n                    clipregion=NULL,\n                    alternative=c(\"two.sided\"),\n                    nsim=99)\n  )\n}\n\n\n## Bangkok \n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  accidents_pr_ppp\nR = 0.17623, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n## Nonthaburi \n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  accidents_pr_ppp\nR = 0.41798, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n## Nakhon Pathom \n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  accidents_pr_ppp\nR = 0.30852, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n## Pathum Thani \n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  accidents_pr_ppp\nR = 0.28094, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n## Samut Prakan \n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  accidents_pr_ppp\nR = 0.18842, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n## Samut Sakhon \n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  accidents_pr_ppp\nR = 0.27484, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nBangkok:\n\nR = 0.17306, p-value &lt; 2.2e-16\n\nThe R-value is significantly less than 1, indicating strong clustering of accidents in the province. The very low p-value confirms the clustering pattern is statistically significant.\n\nNonthaburi:\n\nR = 0.41915, p-value &lt; 2.2e-16\n\nThere is moderate clustering in Nonthaburi, though the clustering is less intense than in Bangkok. The p-value indicates this pattern is statistically significant.\n\nNakhon Pathom:\n\nR = 0.30873, p-value &lt; 2.2e-16\n\nThe results show moderate clustering of accidents in this province. The clustering is stronger than in Nonthaburi but still less pronounced than in Bangkok.\n\nPathum Thani:\n\nR = 0.27889, p-value &lt; 2.2e-16\n\nThere is moderate clustering of accidents in Pathum Thani, with an R-value similar to that of Nakhon Pathom, indicating a non-random pattern of accident distribution.\n\nSamut Prakan:\n\nR = 0.191, p-value &lt; 2.2e-16\n\nSamut Prakan exhibits strong clustering of accidents, with an R-value similar to Bangkok, suggesting accident hotspots in the province. This is confirmed by the extremely low p-value.\n\nSamut Sakhon:\n\nR = 0.27326, p-value &lt; 2.2e-16\n\nThe results indicate moderate clustering of accidents in this province, similar to Pathum Thani and Nakhon Pathom, suggesting multiple local accident clusters.\n\n\nIn summary, we reject the null hypothesis across all provinces in the BMR. The Clark-Evans test results show that traffic accidents are not randomly distributed but are strongly clustered. Bangkok and Samut Prakan exhibit the highest levels of clustering, while the other provinces show moderate clustering.\n\n\n\n\n\n10.3 Second Order Spatial Point Pattern Analysis\nIn this section, we will focus on the K-function to analyze the overall pattern of clustering or dispersion of road accidents across various distances. We opt for the K-function due to its ability to capture the disc-like accumulation of points, making it ideal for understanding broader clustering trends over various distances.\n\n10.3.1 Compute K-Function Estimate for BMR\nFirst, we will compute the K-function to estimate the spatial relationships between accidents across the BMR.\n\n\nShow the code\nK_BMR = Kest(accidents_ppp.km, correction = \"Ripley\")\nplot(K_BMR, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(km)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nThe K-function shows strong clustering of accidents across multiple distances, as the empirical curve is significantly above the Poisson process line.\nClustering exists at both local and broader spatial scales.\n\n\n\n\n\n10.3.2 Perform Complete Spatial Randomness Test\nTo further analyze whether the distribution of accidents deviates from Complete Spatial Randomness (CSR), we conduct a hypothesis test with the following hypotheses:\n\n\\(H_0\\): The distribution of accidents is randomly distributed across the BMR.\n\\(H_1\\): The distribution of accidents is not randomly distributed (i.e., clustered or dispersed).\n\nWe use a 95% confidence interval for this test.\n\n\nShow the code\nbmr_K.csr &lt;- envelope(accidents_ppp.km, Kest, nsim = 49, rank = 1,  glocal=TRUE)\n\n\nGenerating 49 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, \n49.\n\nDone.\n\n\nShow the code\nplot(bmr_K.csr, . - r ~ r, xlab=\"d (km)\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nThe empirical K-function lies above the theoretical K-function , indicating significant clustering of accidents across all distances.\nThe envelope (shaded area) confirms that the observed clustering is statistically significant, as the empirical K-function remains outside the bounds expected under complete spatial randomness.\nThus we will reject the null hypothesis.\n\n\n\n\n\n\n10.4 Network Constrained Spatial Point Pattern Analysis\nNetwork-Constrained Spatial Point Pattern Analysis (SPPA) is highly relevant for studying road accidents because these events are restricted to occurring along specific networks such as highways. Traditional spatial analysis techniques assume that events can occur anywhere in a continuous space, which is not realistic for accidents that are confined to road networks. By focusing on the structure and connectivity of roads, network-constrained methods provide more accurate insights into the spatial distribution of accidents, identifying high-risk areas such as intersections, highway segments, or urban streets.\nIn this section, we will use the spNetwork package to compute Network Kernel Density Estimation (NKDE). NKDE estimates the density of accidents while considering the network structure, offering a more realistic view of accident hotspots along the road network.\n\n10.4.1 Preparing the Lixels Objects\nBefore computing NKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance. This task can be performed by using with lixelize_lines() of spNetwork.\n\n\n\n\n\n\nNote\n\n\n\nChoice of lixel length Initially, We chosen lixel length of 100 and mindist of 50, based on recommended settings from related research: Visualizing Traffic Accident Hotspots Based on Spatial-Temporal Network Kernel Density Estimation.\nHowever, after visualizing the NKDE results, the shorter lixel length failed to reveal meaningful trends, likely due to an overly detailed segmentation of the network. To correct this, we increased the lixel length by an order of magnitude, allowing for a broader view and better identification of accident patterns at a larger scale.\n\n\n\n# filter for linestring only else error\nroads_bmr&lt;- roads_bmr %&gt;%\n  filter(st_geometry_type(.) == \"LINESTRING\")\n\nlixels &lt;- lixelize_lines(lines = roads_bmr,\n                         # increase by 1 magnitude\n                         lx_length = 5000,\n                         mindist = 2500)\n\nNext, we will use lines_center() of spNetwork to generate a SpatialPointsDataFrame (i.e. samples) with line centre points.\n\nsamples &lt;- lines_center(lixels)\n\n\n\n10.4.2 Computing NKDE\nTo compute the NKDE:\n\n\nShow the code\ndensities &lt;- nkde(\n  lines = roads_bmr, \n  events = accidents_bmr_ft,\n  w = rep(1, nrow(accidents_bmr_ft)),\n  samples = samples,\n  kernel_name = \"quartic\",\n  # increase by 1 magnitude\n  bw = 2250,\n  div = \"bw\",\n  method = \"simple\", \n  digits = 1, \n  tol = 1,\n  grid_shape = c(10,10), \n  max_depth = 8,\n  # agg = 5, \n  sparse = TRUE,\n  verbose = TRUE)\n\n\nWe will save the computation output as RDS data format for future analysis.\n\nwrite_rds(densities, \"data/rds/densities_2250.rds\")\n\n\ndensities &lt;- read_rds(\"data/rds/densities_2250.rds\")\n\n\n\n10.4.3 Visualizing NKDE\nTo visualise the NKDE values, we have to perform a few preparation steps.\n\nInsert the computed density values (i.e. densities) into samples and lixels objects as density field. Rescale the density values.\n\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\n\nUse tmap to visualize the NKDE output.\n\n\n\nShow the code\ncus_palette &lt;- colorRampPalette(c(\"lightyellow\", \"red\"))\n\ntm_shape(admin_boundary_bmr) +\n  tm_polygons(col = \"white\", border.col = \"black\") +\n  tm_shape(lixels) +\n  tm_lines(col = \"density\", palette = cus_palette(10), style = \"cont\", lwd = 2) + \n  tm_layout(\n    title = \"Network Kernel Density of Road Accidents in BMR\",\n    title.size = 1.5,\n    title.position = c(\"center\", \"top\"),\n    frame = FALSE, \n    legend.position = c(\"left\", \"bottom\"),\n    legend.title.size = 1.0,\n    legend.text.size = 0.8\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nThe density patterns tend to follow major highways and key intersections, particularly in the central and central-eastern areas of Bangkok Metropolitan Region (BMR), where the density of road accidents is higher."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-temporal-point-pattern-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-temporal-point-pattern-analysis",
    "title": "Take Home Exercise 1",
    "section": "11 Spatial Temporal Point Pattern Analysis",
    "text": "11 Spatial Temporal Point Pattern Analysis\nSpatio-temporal analysis combines both spatial and temporal aspects to reveal how events like road traffic accidents vary over time and location.\nIn this section, we use Spatio-temporal Kernel Density Estimation (STKDE) to visualize accident densities across space and time, capturing fluctuations in accident intensity throughout different periods.\n\nThe key questions in this section are:\n\nAre the locations of accidents in BMR spatial and spatio-temporally independent?\nIf not, where and when the observed accident locations tend to cluster?\n\n\nFor this analysis, we will focus on 2022 as it has the highest accident rate from our EDA results above.\n\n11.1 Computing STKDE by Month\nTo better understand how accident densities fluctuate over time, we compute Spatio-temporal Kernel Density Estimation (STKDE) by month. This allows us to identify temporal trends and pinpoint high-risk periods or clusters of accidents that may correspond to specific events or seasons, such as holidays, weather changes, or increased traffic flow.\nTo do so, we first filter the dataset to include only the road accidents that occurred in the year 2022.\n\naccidents_month_2022  &lt;- accidents_bmr_ft %&gt;%\n  filter(year == 2022) %&gt;%\n  select(month_number)\n\nNext, we convert the filtered accident data into a point pattern object (ppp) for spatial analysis. To ensure the plot scaling is more readable and appropriate for our analysis, we rescale the spatial units from meters to kilometers.\n\naccidents_month_2022_ppp &lt;- as.ppp(accidents_month_2022)\n# rescale from m to km\naccidents_month_2022_ppp.km &lt;- rescale(accidents_month_2022_ppp, 1000, \"km\")\n\nNext, we check for duplicated entries within the point pattern object.\n\nany(duplicated(accidents_month_2022_ppp.km))\n\n[1] TRUE\n\n\nSince there may be overlapping points due to accidents occurring at the same location, we apply a random jitter to the points. This reduces overlap by introducing slight random shifts, and we summarize the jittered point pattern to verify the changes.\n\naccidents_month_2022_ppp_jit.km &lt;- rjitter(accidents_month_2022_ppp.km, \n                                        retry=TRUE, \n                                        nsim=1, \n                                        drop=TRUE)\n\nsummary(accidents_month_2022_ppp_jit.km)\n\nMarked planar point pattern:  3593 points\nAverage intensity 0.3520227 points per square km\n\nCoordinates are given to 13 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00    4.00    7.00    6.99   10.00   12.00 \n\nWindow: rectangle = [595.5406, 709.36] x [1486.8457, 1576.5205] km\n                    (113.8 x 89.67 km)\nWindow area = 10206.7 square km\nUnit of length: 1 km\n\n\nNext we create the owin object which is the administrative boundary of the Bangkok Metropolitan Region (BMR). We also rescale the boundary to match the units used in the point pattern (kilometers).\n\nowin_bmr &lt;- as.owin(admin_boundary_bmr)\nowin_bmr.km &lt;- rescale(owin_bmr, 1000)\nowin_bmr.km\n\nwindow: polygonal boundary\nenclosing rectangle: [587.8935, 712.4405] x [1484.4137, 1579.0763] units\n\n\nAfter defining the observation window, we subset the jittered point pattern to include only the accident points that fall within the boundary of the BMR.\nWe then summarize the resulting point pattern to ensure that the filtering was successful.\n\naccidents_month_2022_owin.km &lt;- accidents_month_2022_ppp_jit.km[owin_bmr.km]\nsummary(accidents_month_2022_owin.km)\n\nMarked planar point pattern:  3592 points\nAverage intensity 0.4683796 points per square km\n\nCoordinates are given to 13 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   4.000   7.000   6.989  10.000  12.000 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587.8935, 712.4405] x [1484.4137, 1579.0763] km\n                     (124.5 x 94.66 km)\nWindow area = 7668.99 square km\nUnit of length: 1 km\nFraction of frame area: 0.65\n\n\nNext, we generate the plot of the spatial distribution of road accidents within the BMR boundary.\n\nplot(accidents_month_2022_owin.km)\n\n\n\n\n\n\n\n\nNext, we perform a Spatio-temporal Kernel Density Estimation (STKDE) on the accident data. This analysis estimates the density of road accidents in both spatial and temporal dimensions, allowing us to observe how accident densities vary over time and across locations. We then summarize the STKDE output.\n\nst_kde &lt;- spattemp.density(accidents_month_2022_owin.km)\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 4.8827 (spatial)\n  lambda = 0.0285 (temporal)\n\nNo. of observations\n  3592 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [587.8935, 712.4405] x [1484.414, 1579.076]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [5.335629e-16, 0.002847148]\n\n\nFinally, we plot the results of the spatio-temporal KDE for each month of the year 2022. These plots illustrate the monthly variation in road accident densities across the Bangkok Metropolitan Region.\n\npar(mfrow = c(4,3), mar = c(2, 2, 2, 2))\n\nfor(i in seq(1, 12)){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at month\", i))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nMonth 1: The accident hotspots are primarily concentrated in the central BMR, with moderate intensity and slight diffusion towards the outer areas.\nMonth 2-7: Generally, there is a lower intensity of hotspots during this periods\nMonth 8-11: Bangkok remains the area of highest accident density; the clusters are seen to increase in size.\nMonth 12: Accident density peaks towards the end of the year, with a notable increase in the central region, especially in December. Surrounding areas also show a rise in accident activity, likely due to higher traffic or adverse conditions during this holiday time. see Bangkok Post - Road deaths rise to 256 after 5 days of New Year holiday travel\n\n\n\n\n11.2 Observing the Impact of the “7 Deadly Days” of Songkran using STKDE\nIn this section, we apply Spatio-temporal Kernel Density Estimation (STKDE) to analyze accident patterns during the 7 Deadly Days of Songkran in April 2022. By focusing on the month of April, particularly the Songkran festival, STKDE allows us to capture and visualize how accident densities vary spatially and temporally (before, during and after the festival).\n\naccidents_april_2022  &lt;- accidents_bmr_ft %&gt;%\n  filter(year == 2022, month_number == 4) %&gt;%\n  select(day_of_month)\n\naccidents_april_2022_ppp.km &lt;- rescale(as.ppp(accidents_april_2022), 1000, \"km\")\n\nNext, we check for duplicated entries within the point pattern object.\n\nany(duplicated(accidents_april_2022_ppp.km, rule=\"unmark\"))\n\n[1] TRUE\n\n\nSince there may be overlapping points due to accidents occurring at the same location, we apply a random jitter to the points. This reduces overlap by introducing slight random shifts, and we summarize the jittered point pattern to verify the changes. Then, we subset the jittered point pattern to include only the accident points that fall within the boundary of the BMR.\n\naccidents_april_2022_ppp_jit.km &lt;- rjitter(accidents_april_2022_ppp.km, \n                                        retry=TRUE, \n                                        nsim=1, \n                                        drop=TRUE)\n\naccidents_april_2022_owin.km &lt;- accidents_april_2022_ppp_jit.km[owin_bmr.km]\nsummary(accidents_april_2022_owin.km)\n\nMarked planar point pattern:  331 points\nAverage intensity 0.04316082 points per square km\n\nCoordinates are given to 13 decimal places\n\nmarks are numeric, of type 'integer'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    1.0    10.5    14.0    15.3    21.0    30.0 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587.8935, 712.4405] x [1484.4137, 1579.0763] km\n                     (124.5 x 94.66 km)\nWindow area = 7668.99 square km\nUnit of length: 1 km\nFraction of frame area: 0.65\n\n\n\nplot(accidents_april_2022_owin.km, \n     main = \"Spatial Distribution of Road Accidents in April 2022 (BMR)\")\n\n\n\n\n\n\n\n\nNext, we perform a Spatio-temporal Kernel Density Estimation (STKDE) on the accident data for April 2022. This analysis estimates the density of road accidents in both spatial and temporal dimensions, allowing us to observe how accident densities vary across locations for the month of April.\n\nst_kde_april &lt;- spattemp.density(accidents_april_2022_owin.km)\nsummary(st_kde_april)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 7.7139 (spatial)\n  lambda = 1.513 (temporal)\n\nNo. of observations\n  331 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [587.8935, 712.4405] x [1484.414, 1579.076]\n\nTemporal bound\n  [1, 30]\n\nEvaluation\n  128 x 128 x 30 trivariate lattice\n  Density range: [4.084262e-14, 3.13749e-05]\n\n\nFinally, we plot the results of the spatio-temporal KDE for each day of April 2022. These plots illustrate the monthly variation in road accident densities across the Bangkok Metropolitan Region.\n\ndays_per_plot &lt;- 6\n\ntotal_days &lt;- 30\n\nfor (i in seq(1, total_days, by = days_per_plot)) {\n  # (2 rows, 3 columns)\n  par(mfrow = c(2, 3), mar = c(2, 2, 2, 2))\n  \n  for (day in i:(i + days_per_plot - 1)) {\n    if (day &gt; total_days) break\n    \n    # Highlight Songkran period (April 11-17)\n    if (day &gt;= 11 & day &lt;= 17) {\n      plot(st_kde_april, day, \n           override.par = FALSE, \n           fix.range = TRUE, \n           main = paste(\"April 2022 Day\", day, \"(Songkran)\"), \n           col.main = \"red\")\n    } else {\n      plot(st_kde_april, day, \n           override.par = FALSE, \n           fix.range = TRUE, \n           main = paste(\"April 2022 Day\", day))\n    }\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations for April 2022:\n\n1st to 10th April:\n\nThe highest density of accidents remains concentrated in the central region of the Bangkok Metropolitan Area (BMR), with some variation day-to-day.\nA pattern of increasing intensity is seen leading up to the Songkran festival.\n\nSongkran Festival (11th to 17th April):\n\n11th to 13th April: Significant increase in accident density during the Songkran holiday, particularly in central and southern areas.\n14th to 17th April: Accident hotspots during the Songkran period appear to expand further, possibly due to higher travel activities and road congestion.\nThe Songkran period highlights the most critical accident-prone days, showing a stark rise in traffic incidents.\n\n18th to 30th April:\n\nAccident density slightly decreases after the Songkran period but remains concentrated in similar central zones.\nPost-Songkran accident rates maintain a moderate level."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conclusion",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conclusion",
    "title": "Take Home Exercise 1",
    "section": "12 Conclusion",
    "text": "12 Conclusion\nThe analysis of road traffic accidents in the Bangkok Metropolitan Region (BMR) provided insights into both spatial and temporal patterns of these incidents. By the data processing steps, we added columns such as seasons, peak periods, and Songkran holidays, capturing key factors that may influence accident trends.\nSpatial analysis revealed significant clustering of accidents in the central urban areas of Bangkok and Samut Prakan. These provinces exhibited the highest Kernel Density Estimates (KDE), indicating they are major hotspots for road traffic accidents.The Clark-Evans test and second-order spatial point pattern analysis further confirmed that traffic accidents in the BMR are not randomly distributed but instead follow a clustered pattern. The consistently low R values and highly significant p-values across all six provinces underscored this spatial clustering, highlighting the concentration of accidents in certain areas. Using Network Kernel Density Estimation (NKDE), we observed that accidents are concentrated along specific road segments, particularly major highways and intersections.\nSpatio-temporal KDE provided insights into how accident patterns vary over time. The analysis captured monthly trends, revealing that accident density fluctuates throughout the year, with higher concentrations observed at the beginning and end of the year, particularly in December. This suggests seasonal influences, such as changes in traffic patterns or road conditions during the holiday season. The subsequent analysis highlighted a sharp increase in accident density during the Songkran festival (April 11-17), a time of heightened travel activity. From the STKDE plots, we can observe clear spikes in density during this period.\nIn summary, the findings of this study highlight the non-random, spatially clustered distribution of road accidents in the BMR. We hope this comprehensive spatial-temporal analysis will support policymakers in implementing data-driven strategies that effectively mitigate road accidents in the region."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#references",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#references",
    "title": "Take Home Exercise 1",
    "section": "13 References",
    "text": "13 References\n\nWikiProject Thailand - OpenStreetMap Wiki\nBangkok - Wikipedia\nHow Do You Beat Bangkok Traffic?\n25 deaths in 234 road accidents recorded on 1st of Songkran’s ‘7 dangerous days’\nSPATIAL STATISTICS\nChapter 6 Studying spatial point patterns | Crime Mapping in R\nVisualizing Traffic Accident Hotspots Based on Spatial-Temporal Network Kernel Density Estimation"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-Class Exercise 4",
    "section": "",
    "text": "ISSS626 Geospatial Analytics and Applications - In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#exercise-reference",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#exercise-reference",
    "title": "In-Class Exercise 4",
    "section": "",
    "text": "ISSS626 Geospatial Analytics and Applications - In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#overview",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#overview",
    "title": "In-Class Exercise 4",
    "section": "2 Overview",
    "text": "2 Overview\nIn this session, we will learn about Geographically-Weighted Models.\n\nGeographically weighted regression (GWR) is a spatial analysis technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these predictors and an outcome of interest.\nGWR is an outgrowth of ordinary least squares regression (OLS) see more: Geographically Weighted Regression | Columbia University Mailman School of Public Health\n\n\n\n\n\n\n\nNote\n\n\n\nGWModel is under active development. It supports many features such as GW discriminant analysis, GW PCA, regression models and so on.\nGWM is distance-based and does not support adjacency matrices."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#learning-outcome",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#learning-outcome",
    "title": "In-Class Exercise 4",
    "section": "3 Learning Outcome",
    "text": "3 Learning Outcome\n\nReview techniques to merge geospatial and aspatial datasets using dplyr functions like left_join(), covered in Hands-on Exercise.\nConvert spatial data from sf to sp format for compatibility with the GWmodel package.\nCompute geographically weighted summary statistics with adaptive and fixed bandwidth using GWmodel.\nVisualize geographically weighted summary statistics using tmap."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#import-the-r-packages",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#import-the-r-packages",
    "title": "In-Class Exercise 4",
    "section": "4 Import the R Packages",
    "text": "4 Import the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\n\nsf\nHandles spatial data; imports, manages, and processes vector-based geospatial data.\nImporting and managing geospatial data, such as Hunan’s county boundary shapefile.\n\n\nGWmodel\nProvides functions for geographically weighted regression and summary statistics.\nComputing geographically weighted summary statistics using adaptive and fixed bandwidth methods.\n\n\ntidyverse\nA collection of R packages for data science tasks like data manipulation, visualization, and modeling.\nWrangling aspatial data and joining with spatial datasets.\n\n\ntmap\nCreates static and interactive thematic maps using cartographic quality elements.\nVisualizing geographically weighted summary statistics and creating thematic maps.\n\n\nggstatsplot\nEnhances plots with statistical details and facilitates data visualization.\nStatistical graphics for analysis, comparison, and visualization of summary statistics.\n\n\nknitr\nEnables dynamic report generation and integration of R code with documents.\nFormatting output and generating reports for the exercise.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(sf, ggstatsplot, spdep, tmap, tidyverse, knitr, GWmodel)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#the-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#the-data",
    "title": "In-Class Exercise 4",
    "section": "5 The Data",
    "text": "5 The Data\nThe following datasets will be used in this exercise:\n\n\n\n\n\n\n\n\nData Set\nDescription\nFormat\n\n\n\n\nHunan County Boundary Layer\nA geospatial dataset containing Hunan’s county boundaries.\nESRI Shapefile\n\n\nHunan_2012.csv\nA CSV file containing selected local development indicators for Hunan in 2012.\nCSV\n\n\n\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex04/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor admin boundaries, we will typically encounter polygon or multipolygon data objects.\nA polygon represents a single contiguous area, while a multipolygon consists of multiple disjoint areas grouped together (e.g., islands that belong to the same admin region).\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\nglimpse(hunan2012)\n\nRows: 88\nColumns: 29\n$ County      &lt;chr&gt; \"Anhua\", \"Anren\", \"Anxiang\", \"Baojing\", \"Chaling\", \"Changn…\n$ City        &lt;chr&gt; \"Yiyang\", \"Chenzhou\", \"Changde\", \"Hunan West\", \"Zhuzhou\", …\n$ avg_wage    &lt;dbl&gt; 30544, 28058, 31935, 30843, 31251, 28518, 54540, 28597, 33…\n$ deposite    &lt;dbl&gt; 10967.0, 4598.9, 5517.2, 2250.0, 8241.4, 10860.0, 24332.0,…\n$ FAI         &lt;dbl&gt; 6831.7, 6386.1, 3541.0, 1005.4, 6508.4, 7920.0, 33624.0, 1…\n$ Gov_Rev     &lt;dbl&gt; 456.72, 220.57, 243.64, 192.59, 620.19, 769.86, 5350.00, 1…\n$ Gov_Exp     &lt;dbl&gt; 2703.0, 1454.7, 1779.5, 1379.1, 1947.0, 2631.6, 7885.5, 11…\n$ GDP         &lt;dbl&gt; 13225.0, 4941.2, 12482.0, 4087.9, 11585.0, 19886.0, 88009.…\n$ GDPPC       &lt;dbl&gt; 14567, 12761, 23667, 14563, 20078, 24418, 88656, 10132, 17…\n$ GIO         &lt;dbl&gt; 9276.90, 4189.20, 5108.90, 3623.50, 9157.70, 37392.00, 513…\n$ Loan        &lt;dbl&gt; 3954.90, 2555.30, 2806.90, 1253.70, 4287.40, 4242.80, 4053…\n$ NIPCR       &lt;dbl&gt; 3528.3, 3271.8, 7693.7, 4191.3, 3887.7, 9528.0, 17070.0, 3…\n$ Bed         &lt;dbl&gt; 2718, 970, 1931, 927, 1449, 3605, 3310, 582, 2170, 2179, 1…\n$ Emp         &lt;dbl&gt; 494.310, 290.820, 336.390, 195.170, 330.290, 548.610, 670.…\n$ EmpR        &lt;dbl&gt; 441.4, 255.4, 270.5, 145.6, 299.0, 415.1, 452.0, 127.6, 21…\n$ EmpRT       &lt;dbl&gt; 338.0, 99.4, 205.9, 116.4, 154.0, 273.7, 219.4, 94.4, 174.…\n$ Pri_Stu     &lt;dbl&gt; 54.175, 33.171, 19.584, 19.249, 33.906, 81.831, 59.151, 18…\n$ Sec_Stu     &lt;dbl&gt; 32.830, 17.505, 17.819, 11.831, 20.548, 44.485, 39.685, 7.…\n$ Household   &lt;dbl&gt; 290.4, 104.6, 148.1, 73.2, 148.7, 211.2, 300.3, 76.1, 139.…\n$ Household_R &lt;dbl&gt; 234.5, 121.9, 135.4, 69.9, 139.4, 211.7, 248.4, 59.6, 110.…\n$ NOIP        &lt;dbl&gt; 101, 34, 53, 18, 106, 115, 214, 17, 55, 70, 44, 84, 74, 17…\n$ Pop_R       &lt;dbl&gt; 670.3, 243.2, 346.0, 184.1, 301.6, 448.2, 475.1, 189.6, 31…\n$ RSCG        &lt;dbl&gt; 5760.60, 2386.40, 3957.90, 768.04, 4009.50, 5220.40, 22604…\n$ Pop_T       &lt;dbl&gt; 910.8, 388.7, 528.3, 281.3, 578.4, 816.3, 998.6, 256.7, 45…\n$ Agri        &lt;dbl&gt; 4942.253, 2357.764, 4524.410, 1118.561, 3793.550, 6430.782…\n$ Service     &lt;dbl&gt; 5414.5, 3814.1, 14100.0, 541.8, 5444.0, 13074.6, 17726.6, …\n$ Disp_Inc    &lt;dbl&gt; 12373, 16072, 16610, 13455, 20461, 20868, 183252, 12379, 1…\n$ RORP        &lt;dbl&gt; 0.7359464, 0.6256753, 0.6549309, 0.6544614, 0.5214385, 0.5…\n$ ROREmp      &lt;dbl&gt; 0.8929619, 0.8782065, 0.8041262, 0.7460163, 0.9052651, 0.7…\n\n\n\n\n\n\n\n\nNote\n\n\n\nRecall that to do left join, we need a common identifier between the 2 data objects. The content must be the same eg. same format and same case. In Hands-on Exercise 1B, we need to (PA, SZ) in the dataset to uppercase before we can join the data.\n\n\n\nhunan_sf &lt;- left_join(hunan_sf, hunan2012) %&gt;%\n  select(1:3, 7, 15, 16, 31, 32)\nhunan_sf\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     NAME_2  ID_3    NAME_3    County GDPPC      GIO      Agri Service\n1   Changde 21098   Anxiang   Anxiang 23667   5108.9  4524.410 14100.0\n2   Changde 21100   Hanshou   Hanshou 20981  13491.0  6545.350 17727.0\n3   Changde 21101    Jinshi    Jinshi 34592  10935.0  2562.460  7525.0\n4   Changde 21102        Li        Li 24473  18402.0  7562.340 53160.0\n5   Changde 21103     Linli     Linli 25554   8214.0  3583.910  7031.0\n6   Changde 21104    Shimen    Shimen 27137  17795.0  5266.510  6981.0\n7  Changsha 21109   Liuyang   Liuyang 63118  99254.0 10844.470 26617.8\n8  Changsha 21110 Ningxiang Ningxiang 62202 114145.0 12804.480 18447.7\n9  Changsha 21111 Wangcheng Wangcheng 70666 148976.0  5222.356  6648.6\n10 Chenzhou 21112     Anren     Anren 12761   4189.2  2357.764  3814.1\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#mapping-gdppc",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#mapping-gdppc",
    "title": "In-Class Exercise 4",
    "section": "6 Mapping GDPPC",
    "text": "6 Mapping GDPPC\nTo plot a chrolopleth map of geographic distribution of GDP per Capita (GDPPC) in Hunan:\n\nbasemap &lt;- tm_shape(hunan_sf) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan_sf, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#converting-to-spatialpolygondataframe",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#converting-to-spatialpolygondataframe",
    "title": "In-Class Exercise 4",
    "section": "7 Converting to SpatialPolygonDataFrame",
    "text": "7 Converting to SpatialPolygonDataFrame\n\n\n\n\n\n\nNote\n\n\n\nGWmodel presently is built around the older sp and not sf formats for handling spatial data in R.\n\n\n\nhunan_sp &lt;- hunan_sf %&gt;%\n  as_Spatial()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-adaptive-bandwidths",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-adaptive-bandwidths",
    "title": "In-Class Exercise 4",
    "section": "8 Geographically Weighted Summary Statistics with Adaptive Bandwidths",
    "text": "8 Geographically Weighted Summary Statistics with Adaptive Bandwidths\nIn this section, we aim to determine the optimal adaptive bandwidth for performing Geographically Weighted Regression (GWR). Specifically, we are interested in finding the best bandwidth to use for summarizing the spatial variation in GDP per capita (GDPPC) across the Hunan region.\n\n8.1 Determine Adaptive Bandwidth\nAn adaptive bandwidth allows the number of neighbors considered in the model to vary depending on the density of data points. This is particularly useful when data points are unevenly distributed across the study area.\nWe will use two different criteria—cross-validation (CV) and Akaike information criterion to determine the optimal bandwidth.\nThe bandwidth that minimizes these metrics will be selected.\n\n8.1.1 Cross Validation\n\nbw_CV&lt;- bw.gwr(GDPPC ~ 1,\n               data = hunan_sp,\n               approach= \"CV\",\n               adaptive = TRUE,\n               kernel = \"bisquare\",\n               longlat = T)  # great circle distance\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\n\n\nbw_CV\n\n[1] 22\n\n\n\n\n8.1.2 Akaike Information Criterion (AIC)\nNext, we use the AIC approach to determine the optimal bandwidth. AIC is a model selection criterion that balances model fit and complexity, with a lower AIC value indicating a better model.\nWe use the same GWR model setup, but the bandwidth is now optimized based on the AIC value instead of cross-validation.\n\nbw_AIC&lt;- bw.gwr(GDPPC ~ 1,\n               data = hunan_sp,\n               approach= \"AIC\",\n               adaptive = TRUE,\n               kernel = \"bisquare\",\n               longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\n\n\nbw_AIC\n\n[1] 22\n\n\n\n\n\n\n\n\nNote\n\n\n\nIntepretation\nThe output from these 2 methods indicate the number of nearest neighbour we should choose. In this case, both methods produce the same result: 22 nearest neighbours.\nSometimes the result may differ, and either methods is acceptable for further analysis."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth",
    "title": "In-Class Exercise 4",
    "section": "9 Geographically Weighted Summary Statistics with adaptive bandwidth",
    "text": "9 Geographically Weighted Summary Statistics with adaptive bandwidth\nTo compute Geographically Weighted Summary Statistics:\n\ngwstat &lt;- gwss (data = hunan_sp,\n                vars = \"GDPPC\",\n                bw = bw_AIC,\n                kernel = \"bisquare\",\n                adaptive = TRUE,\n                longlat = T)\n\n\n\n\n\n\n\nNote\n\n\n\nWe use bw_AIC as the bandwidth parameter, which was determined previously based on AIC optimization.\nAdditionally, we apply the same bisquare kernel for consistency with the CV and AIC computation above.\nThe output of the gwss() function is a gwss object, which is a list containing localized summary statistics for GDPPC across Hunan.\nNote that the abbreviation in the output refers to:\n\nLM : local mean\nLSD: local standard deviation\nLVar: local variance\nLSKe: standard estimations\nLCV: local correlation variance\n\n\n\n\n9.1 Preparing the output data\nLet’s observe the gwstat object before converting to a suitable format for analysis.\n\nclass(gwstat)\n\n[1] \"gwss\"\n\ngwstat\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n\n   ***********************Calibration information*************************\n\n   Local summary statistics calculated for variables:\n    GDPPC\n   Number of summary points: 88\n   Kernel function: bisquare \n   Summary points: the same locations as observations are used.\n   Adaptive bandwidth: 22 (number of nearest neighbours)\n   Distance metric: Great Circle distance metric is used.\n\n   ************************Local Summary Statistics:**********************\n   Summary information for Local means:\nGDPPC_LM \n    Min.  1st Qu.   Median  3rd Qu.     Max. \n13688.70 17995.43 23408.07 27865.12 49005.84 \n   Summary information for local standard deviation :\nGDPPC_LSD \n     Min.   1st Qu.    Median   3rd Qu.      Max. \n 4282.599  6297.788  8281.756 16315.028 22568.841 \n   Summary information for local variance :\nGDPPC_LVar \n     Min.   1st Qu.    Median   3rd Qu.      Max. \n 18340656  39662960  68633859 266187788 509352591 \n   Summary information for Local skewness:\nGDPPC_LSKe \n      Min.    1st Qu.     Median    3rd Qu.       Max. \n-0.2150599  0.9900027  1.3714638  1.8387524  3.7525953 \n   Summary information for localized coefficient of variation:\nGDPPC_LCV \n     Min.   1st Qu.    Median   3rd Qu.      Max. \n0.2000503 0.3107774 0.3829294 0.5129959 0.8018153 \n\n   ************************************************************************\n\n\n\ngwstat$SDF\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 88 \nextent      : 108.7831, 114.2544, 24.6342, 30.12812  (xmin, xmax, ymin, ymax)\ncrs         : +proj=longlat +datum=WGS84 +no_defs \nvariables   : 5\nnames       :         GDPPC_LM,        GDPPC_LSD,       GDPPC_LVar,         GDPPC_LSKe,         GDPPC_LCV \nmin values  : 13688.6986033259, 4282.59917616925, 18340655.7037255, -0.215059890053627, 0.200050258645349 \nmax values  : 49005.8382943034, 22568.8411539952, 509352591.034267,    3.7525953469342, 0.801815253056722 \n\n\nIn particular, we are interested to extract the SDF data table from gwstat. We can convert it into a data frame and append it onto hunan_sf.\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)\n\n\n\n9.2 Visualising geographically weighted summary statistics\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geographically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.50, \n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-fixed-bandwidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-fixed-bandwidth",
    "title": "In-Class Exercise 4",
    "section": "10 Geographically Weighted Summary Statistics with Fixed Bandwidth",
    "text": "10 Geographically Weighted Summary Statistics with Fixed Bandwidth\nSimilarly, we can use the same process to generate summary stats with fixed bandwidth.\n\n10.1 Determine Fixed Bandwidth\n\nCross-Validation\n\n\nbw_CV_fixed &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp,\n             approach = \"CV\",\n             adaptive = FALSE, \n             kernel = \"bisquare\", \n             longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\n\n\nbw_CV_fixed\n\n[1] 76.29126\n\n\n\nAIC\n\n\nbw_AIC_fixed &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp,\n             approach =\"AIC\",\n             adaptive = FALSE, \n             kernel = \"bisquare\", \n             longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\n\n\nbw_AIC_fixed\n\n[1] 160.5517\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote the results differs this time.\nWe will just use bw_AIC_fixed for this example.\n\n\n\ngwstat_fixed &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC_fixed,\n               kernel = \"bisquare\",\n               adaptive = FALSE,\n               longlat = T)\n\n\n\n10.2 Preparing the output data\n\ngwstat_df_fixed &lt;- as.data.frame(gwstat_fixed$SDF)\nhunan_gstat_fixed &lt;- cbind(hunan_sf, gwstat_df_fixed)\n\n\n\n10.3 Visualising geographically weighted summary statistics\n\ntm_shape(hunan_gstat_fixed) +\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geographically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 1.8,\n            legend.text.size = 1.2,\n            legend.height = 1.50,\n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualizing-correlation",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualizing-correlation",
    "title": "In-Class Exercise 4",
    "section": "11 Visualizing Correlation",
    "text": "11 Visualizing Correlation\nBusiness question: Is there any relationship between GDP per capita and Gross Industry Output?\n\nggscatterstats(\n  data = hunan2012, \n  x = Agri, \n  y = GDPPC,\n  xlab = \"Gross Agriculture Output\",\n  ylab = \"GDP per capita\", \n  label.var = County, \n  label.expression = Agri &gt; 10000 & GDPPC &gt; 50000, \n  point.label.args = list(alpha = 0.7, size = 4, color = \"grey50\"),\n  xfill = \"#CC79A7\", \n  yfill = \"#009E73\", \n  title = \"Relationship between GDP PC and Gross Agriculture Output\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that above shows a conventional statistical solution to the business question. We can also approach the same question with a geospatial approach."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-correlation-with-adaptive-bandwidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-correlation-with-adaptive-bandwidth",
    "title": "In-Class Exercise 4",
    "section": "12 Geographically Weighted Correlation with Adaptive Bandwidth",
    "text": "12 Geographically Weighted Correlation with Adaptive Bandwidth\nTo come up with the geospatial analytics solution, we can repeat what we have learnt above.\n\n# determine bandwidth\nbw &lt;- bw.gwr(GDPPC ~ GIO, \n             data = hunan_sp, \n             approach = \"AICc\", \n             adaptive = TRUE)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1870.235 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1870.852 \nAdaptive bandwidth (number of nearest neighbours): 72 AICc value: 1869.744 \nAdaptive bandwidth (number of nearest neighbours): 78 AICc value: 1869.713 \nAdaptive bandwidth (number of nearest neighbours): 82 AICc value: 1869.604 \nAdaptive bandwidth (number of nearest neighbours): 84 AICc value: 1869.537 \nAdaptive bandwidth (number of nearest neighbours): 86 AICc value: 1869.647 \nAdaptive bandwidth (number of nearest neighbours): 83 AICc value: 1869.567 \nAdaptive bandwidth (number of nearest neighbours): 84 AICc value: 1869.537 \n\n\n\n# compute gwCorrelation\ngwstats &lt;- gwss(hunan_sp, \n                vars = c(\"GDPPC\", \"GIO\"), \n                bw = bw,\n                kernel = \"bisquare\",\n                adaptive = TRUE, \n                longlat = T)\n\ngwstats$SDF\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 88 \nextent      : 108.7831, 114.2544, 24.6342, 30.12812  (xmin, xmax, ymin, ymax)\ncrs         : +proj=longlat +datum=WGS84 +no_defs \nvariables   : 13\nnames       :         GDPPC_LM,           GIO_LM,        GDPPC_LSD,          GIO_LSD,       GDPPC_LVar,         GIO_LVar,       GDPPC_LSKe,         GIO_LSKe,         GDPPC_LCV,          GIO_LCV,    Cov_GDPPC.GIO,    Corr_GDPPC.GIO, Spearman_rho_GDPPC.GIO \nmin values  : 19131.1142970311, 10893.8161299979, 10277.2097869105, 14522.4178379531,  105621041.00417, 210900619.860099, 1.48323193793682,  2.0736607949458, 0.536791980126491, 1.00164110576375, 103845165.127288,  0.68232363208861,       0.57886543894541 \nmax values  : 30957.9353099472, 31000.8255210838, 17996.8393335404, 31051.7011545276, 323886225.997265, 964208144.590089, 2.90892414233837, 5.17918131636017, 0.648888935893182, 1.46498918439505, 417614864.583691, 0.760623282755834,       0.73344304557923 \n\n\n\n# convert result to df\ngwstat_df &lt;- as.data.frame(gwstats$SDF) %&gt;%\n  # select(c(12,13)) %&gt;%\n  select(c(\"Corr_GDPPC.GIO\",\"Spearman_rho_GDPPC.GIO\")) %&gt;%\n  rename(gwCorr = Corr_GDPPC.GIO,\n         gwSpearman = Spearman_rho_GDPPC.GIO)\n\nhunan_Corr &lt;- cbind(hunan_sf, gwstat_df)\nhunan_Corr\n\nSimple feature collection with 88 features and 10 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     NAME_2  ID_3    NAME_3    County GDPPC      GIO      Agri Service\n1   Changde 21098   Anxiang   Anxiang 23667   5108.9  4524.410 14100.0\n2   Changde 21100   Hanshou   Hanshou 20981  13491.0  6545.350 17727.0\n3   Changde 21101    Jinshi    Jinshi 34592  10935.0  2562.460  7525.0\n4   Changde 21102        Li        Li 24473  18402.0  7562.340 53160.0\n5   Changde 21103     Linli     Linli 25554   8214.0  3583.910  7031.0\n6   Changde 21104    Shimen    Shimen 27137  17795.0  5266.510  6981.0\n7  Changsha 21109   Liuyang   Liuyang 63118  99254.0 10844.470 26617.8\n8  Changsha 21110 Ningxiang Ningxiang 62202 114145.0 12804.480 18447.7\n9  Changsha 21111 Wangcheng Wangcheng 70666 148976.0  5222.356  6648.6\n10 Chenzhou 21112     Anren     Anren 12761   4189.2  2357.764  3814.1\n      gwCorr gwSpearman                       geometry\n1  0.7486038  0.7052022 POLYGON ((112.0625 29.75523...\n2  0.7444358  0.6931584 POLYGON ((112.2288 29.11684...\n3  0.7506001  0.7106856 POLYGON ((111.8927 29.6013,...\n4  0.7529990  0.7175096 POLYGON ((111.3731 29.94649...\n5  0.7521408  0.7147542 POLYGON ((111.6324 29.76288...\n6  0.7546843  0.7224617 POLYGON ((110.8825 30.11675...\n7  0.7332991  0.6800127 POLYGON ((113.9905 28.5682,...\n8  0.7305758  0.6608931 POLYGON ((112.7181 28.38299...\n9  0.7341173  0.6716514 POLYGON ((112.7914 28.52688...\n10 0.7520181  0.7236245 POLYGON ((113.1757 26.82734...\n\n\n\n12.1 Visualizing Local Correlation\n\nLocal Correlation Coefficient\n\n\ntm_shape(hunan_Corr) +\n  tm_fill(\"gwCorr\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Local Correlation Coefficient\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.50, \n            legend.width = 1.50,\n            frame = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInterpretation\n\nThe strongest correlations are found in the eastern and northern parts of the province, indicated by the darker shades.\nThe weaker correlations are located in the central and western areas, where the lighter colors predominate.\n\n\n\n\nLocal Spearman Coefficient\n\nNote that we will observe similar trend using Local Spearman Coefficient. See notes below.\n\ntm_shape(hunan_Corr) +\n  tm_fill(\"gwSpearman\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Local Spearman Rho\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.50, \n            legend.width = 1.50,\n            frame = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nNotes on local correlation coefficient and the local Spearman coefficient:\n\nLocal Correlation Coefficient (Pearson)\n\n\nType: Parametric\n\nThe local correlation coefficient, often represented by Pearson’s correlation coefficient, assumes that the data follows a normal distribution.\n\nNature: Continuous\n\nIt measures the linear relationship between two continuous variables.\n\nType of Measure: Not Ranked\n\nThe Pearson correlation is sensitive to the actual values of the data points, not their ranks. It considers both the magnitude and direction of the linear relationship.\n\n\n\nLocal Spearman Coefficient\n\n\nType: Non-Parametric\n\nThe local Spearman coefficient is a rank-based measure and does not assume any specific distribution for the data. It is robust to non-normality.\n\nNature: Continuous (based on ranks)\n\nAlthough it works with ranks, the coefficient itself can take any continuous value between -1 and 1, like Pearson’s.\n\nType of Measure: Ranked\n\nThe Spearman correlation is based on the ranks of the data rather than their actual values. It measures the strength and direction of a monotonic relationship between two variables."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-Class Exercise 2",
    "section": "",
    "text": "ISSS626 Geospatial Analytics and Applications - In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#exercise-reference",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#exercise-reference",
    "title": "In-Class Exercise 2",
    "section": "",
    "text": "ISSS626 Geospatial Analytics and Applications - In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#learning-outcome",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#learning-outcome",
    "title": "In-Class Exercise 2",
    "section": "2 Learning Outcome",
    "text": "2 Learning Outcome\n\nUnderstand how to handle the retired R package such as maptools\nUnderstand the difference in usage of st_combine() and st_union() in the sf package.\nRecap on usage of the spatstat package for analyzing two-dimensional spatial point patterns.\nRecap on conversion steps of sf data frames to ppp and owin objects using as.ppp() and as.owin() functions for point pattern analysis.\nRecap on Kernel Density Estimation (KDE) on spatial point events and visualize results usingspatstat.geom methods.\nUnderstand importance of setting random seed for reproducible results when applying Monte Carlo simulations for spatial analysis.\nPractice importing and visualizing data from regional data sources in preparation for Take Home Assignment 1"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#how-to-handle-retired-r-packages",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#how-to-handle-retired-r-packages",
    "title": "In-Class Exercise 2",
    "section": "3 How to Handle Retired R Packages",
    "text": "3 How to Handle Retired R Packages\nIn our work, we might need to use retired R packages. In this section, we will see how we can use a retired package such as maptools.\nAlthough maptools is retired and removed from CRAN, we can still download from Posit Public Package Manager snapshots by using the code block below.\n\n\n\n\n\n\nTip\n\n\n\nInclude #| eval: false in the installation code block to avoid repetitively downloads of maptools whenever the Quarto document is rendered.\n\n\n\ninstall.packages(\"maptools\",\n                 repos = \"https://packagemanager.posit.co/cran/2023-10-13\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#understanding-the-salient-differences-between-st_combine-and-st_union",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#understanding-the-salient-differences-between-st_combine-and-st_union",
    "title": "In-Class Exercise 2",
    "section": "4 Understanding the Salient Differences Between st_combine() and st_union()",
    "text": "4 Understanding the Salient Differences Between st_combine() and st_union()\nIn sf package, there are two functions allow us to combine multiple simple features into one simple features. They are st_combine() and st_union().\n\n\n\n\n\n\nTip\n\n\n\n\nst_combine() returns a single, combined geometry, with no resolved boundaries; returned geometries may well be invalid.\nIf y is missing, st_union(x) returns a single geometry with resolved boundaries, else the geometries for all unioned pairs of x[i] and y[j].\n\nsee Combine or union feature geometries — geos_combine • sf"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#understanding-the-spatstat-package",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#understanding-the-spatstat-package",
    "title": "In-Class Exercise 2",
    "section": "5 Understanding the spatstat Package",
    "text": "5 Understanding the spatstat Package\nspatstat R package is a comprehensive open-source toolbox for analysing Spatial Point Patterns. Focused mainly on two-dimensional point patterns, including multitype or marked points, in any spatial region.\nIt comprises of many sub-packages for specific usage.\n\n\n\nPackage\nDescription\n\n\n\n\nspatstat\nContains documentation and introductory material, including beginner’s guides, vignettes, and demos.\n\n\nspatstat.data\nContains all datasets required for the spatstat package.\n\n\nspatstat.utils\nProvides basic utility functions for use within spatstat.\n\n\nspatstat.univar\nContains functions for estimating and manipulating probability distributions of 1-dimensional random variables.\n\n\nspatstat.sparse\nFunctions for handling sparse arrays and performing linear algebra operations.\n\n\nspatstat.geom\nDefines spatial objects (e.g., point patterns, windows, pixel images) and includes geometrical operations.\n\n\nspatstat.random\nFunctions for generating random spatial patterns and simulating models.\n\n\nspatstat.explore\nCode for exploratory data analysis and nonparametric spatial data analysis.\n\n\nspatstat.model\nCode for model-fitting, diagnostics, and formal inference within spatial data analysis.\n\n\nspatstat.linnet\nDefines spatial data on linear networks and performs geometrical operations and statistical analysis."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#creating-ppp-objects-from-sf-data.frame",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#creating-ppp-objects-from-sf-data.frame",
    "title": "In-Class Exercise 2",
    "section": "6 Creating ppp Objects from sf data.frame",
    "text": "6 Creating ppp Objects from sf data.frame\nWe can derive an ppp object layer directly from a sf tibble data.frame using as.ppp() from spatstat.geom.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nFrom the output above, we can observe the properties of the ppp objects."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#creating-owin-object-from-sf-data.frame",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#creating-owin-object-from-sf-data.frame",
    "title": "In-Class Exercise 2",
    "section": "7 Creating owin object from sf data.frame",
    "text": "7 Creating owin object from sf data.frame\nWe can create owin object from polygon sf tibble data.frame using as.owin() of spatstat.geom.\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n80 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            14650  6.97996e+08      8.93e-01\npolygon 2 (hole)         3 -2.21090e+00     -2.83e-09\npolygon 3              285  1.61128e+06      2.06e-03\npolygon 4 (hole)         3 -2.05920e-03     -2.63e-12\npolygon 5 (hole)         3 -8.83647e-03     -1.13e-11\npolygon 6              668  5.40368e+07      6.91e-02\npolygon 7               44  2.26577e+03      2.90e-06\npolygon 8               27  1.50315e+04      1.92e-05\npolygon 9              711  1.28815e+07      1.65e-02\npolygon 10 (hole)       36 -4.01660e+04     -5.14e-05\npolygon 11 (hole)      317 -5.11280e+04     -6.54e-05\npolygon 12 (hole)        3 -3.41405e-01     -4.37e-10\npolygon 13 (hole)        3 -2.89050e-05     -3.70e-14\npolygon 14              77  3.29939e+05      4.22e-04\npolygon 15              30  2.80002e+04      3.58e-05\npolygon 16 (hole)        3 -2.83151e-01     -3.62e-10\npolygon 17              71  8.18750e+03      1.05e-05\npolygon 18 (hole)        3 -1.68316e-04     -2.15e-13\npolygon 19 (hole)       36 -7.79904e+03     -9.97e-06\npolygon 20 (hole)        4 -2.05611e-02     -2.63e-11\npolygon 21 (hole)        3 -2.18000e-06     -2.79e-15\npolygon 22 (hole)        3 -3.65501e-03     -4.67e-12\npolygon 23 (hole)        3 -4.95057e-02     -6.33e-11\npolygon 24 (hole)        3 -3.99521e-02     -5.11e-11\npolygon 25 (hole)        3 -6.62377e-01     -8.47e-10\npolygon 26 (hole)        3 -2.09065e-03     -2.67e-12\npolygon 27              91  1.49663e+04      1.91e-05\npolygon 28 (hole)       26 -1.25665e+03     -1.61e-06\npolygon 29 (hole)      349 -1.21433e+03     -1.55e-06\npolygon 30 (hole)       20 -4.39069e+00     -5.62e-09\npolygon 31 (hole)       48 -1.38338e+02     -1.77e-07\npolygon 32 (hole)       28 -1.99862e+01     -2.56e-08\npolygon 33              40  1.38607e+04      1.77e-05\npolygon 34 (hole)       40 -6.00381e+03     -7.68e-06\npolygon 35 (hole)        7 -1.40545e-01     -1.80e-10\npolygon 36 (hole)       12 -8.36709e+01     -1.07e-07\npolygon 37              45  2.51218e+03      3.21e-06\npolygon 38             142  3.22293e+03      4.12e-06\npolygon 39             148  3.10395e+03      3.97e-06\npolygon 40              75  1.73526e+04      2.22e-05\npolygon 41              83  5.28920e+03      6.76e-06\npolygon 42             211  4.70521e+05      6.02e-04\npolygon 43             106  3.04104e+03      3.89e-06\npolygon 44             266  1.50631e+06      1.93e-03\npolygon 45              71  5.63061e+03      7.20e-06\npolygon 46              10  1.99717e+02      2.55e-07\npolygon 47             478  2.06120e+06      2.64e-03\npolygon 48             155  2.67502e+05      3.42e-04\npolygon 49            1027  1.27782e+06      1.63e-03\npolygon 50 (hole)        3 -1.16959e-03     -1.50e-12\npolygon 51              65  8.42861e+04      1.08e-04\npolygon 52              47  3.82087e+04      4.89e-05\npolygon 53               6  4.50259e+02      5.76e-07\npolygon 54             132  9.53357e+04      1.22e-04\npolygon 55 (hole)        3 -3.23310e-04     -4.13e-13\npolygon 56               4  2.69313e+02      3.44e-07\npolygon 57 (hole)        3 -1.46474e-03     -1.87e-12\npolygon 58            1045  4.44510e+06      5.68e-03\npolygon 59              22  6.74651e+03      8.63e-06\npolygon 60              64  3.43149e+04      4.39e-05\npolygon 61 (hole)        3 -1.98390e-03     -2.54e-12\npolygon 62 (hole)        4 -1.13774e-02     -1.46e-11\npolygon 63              14  5.86546e+03      7.50e-06\npolygon 64              95  5.96187e+04      7.62e-05\npolygon 65 (hole)        4 -1.86410e-02     -2.38e-11\npolygon 66 (hole)        3 -5.12482e-03     -6.55e-12\npolygon 67 (hole)        3 -1.96410e-03     -2.51e-12\npolygon 68 (hole)        3 -5.55856e-03     -7.11e-12\npolygon 69             234  2.08755e+06      2.67e-03\npolygon 70              10  4.90942e+02      6.28e-07\npolygon 71             234  4.72886e+05      6.05e-04\npolygon 72 (hole)       13 -3.91907e+02     -5.01e-07\npolygon 73              15  4.03300e+04      5.16e-05\npolygon 74             227  1.10308e+06      1.41e-03\npolygon 75              10  6.60195e+03      8.44e-06\npolygon 76              19  3.09221e+04      3.95e-05\npolygon 77             145  9.61782e+05      1.23e-03\npolygon 78              30  4.28933e+03      5.49e-06\npolygon 79              37  1.29481e+04      1.66e-05\npolygon 80               4  9.47108e+01      1.21e-07\nenclosing rectangle: [2667.54, 56396.44] x [15748.72, 50256.33] units\n                     (53730 x 34510 units)\nWindow area = 781945000 square units\nFraction of frame area: 0.422\n\n\nAs shown above, we can display the summary information of the owin object class."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#combining-point-events-object-and-owin-object",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#combining-point-events-object-and-owin-object",
    "title": "In-Class Exercise 2",
    "section": "8 Combining point events object and owin object",
    "text": "8 Combining point events object and owin object\nTo combine point events object and owin object:\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#kernel-density-estimation-of-spatial-point-event",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#kernel-density-estimation-of-spatial-point-event",
    "title": "In-Class Exercise 2",
    "section": "9 Kernel Density Estimation of Spatial Point Event",
    "text": "9 Kernel Density Estimation of Spatial Point Event\nIn this section, we will show why we should re-scale to appropriate unit of measurement before performing KDE.\n\nkde_childcareSG_adaptive_m &lt;- adaptive.density(\n  childcareSG_ppp,\n  method=\"kernel\")\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp,\n                                  1000,\n                                  \"km\")\n\nkde_childcareSG_adaptive_km &lt;- adaptive.density(\n  childcareSG_ppp.km,\n  method=\"kernel\")\n\n\npar(mfrow=c(1,2))\n\nplot(kde_childcareSG_adaptive_m)\nplot(kde_childcareSG_adaptive_km)\n\n\n\n\n\n\n\n\nFrom the output above, we can notice that the plot on the right has a more interpretable scale range from 0-40km range as compared to the left plot where rescaling was not performed."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#kernel-density-estimation",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#kernel-density-estimation",
    "title": "In-Class Exercise 2",
    "section": "10 Kernel Density Estimation",
    "text": "10 Kernel Density Estimation\nThere is 2 different ways to convert KDE output into grid object. spatstat.geom is preferred.\n\nspatstat.geom methodmaptools method\n\n\n\ngridded_kde_childcareSG_ad &lt;- as(\n  kde_childcareSG_adaptive_km,\n  \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\n\n\n\ngridded_kde_childcareSG_ad &lt;- maptools::as.SpatialGridDataFrame.im(\n  kde_childcareSG_adaptive_km)\nspplot(gridded_kde_childcareSG_ad)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#kernel-density-estimation-1",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#kernel-density-estimation-1",
    "title": "In-Class Exercise 2",
    "section": "11 Kernel Density Estimation",
    "text": "11 Kernel Density Estimation\n\n11.1 Visualising KDE using tmap\nTo visualize KDE in raster output using tmap:\n\ntm_shape(kde_childcareSG_ad_raster) +\n  tm_raster(palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#extracting-study-area-using-sf-objects",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#extracting-study-area-using-sf-objects",
    "title": "In-Class Exercise 2",
    "section": "12 Extracting Study Area Using sf Objects",
    "text": "12 Extracting Study Area Using sf Objects\nTo extract and create an ppp object showing child care services and within Punggol Planning Area:\n\n\n\n\n\n\nTip\n\n\n\nfilter() of dplyr package should be used to extract the target planning areas.\n\n\n\npg_owin &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\") %&gt;%\n  as.owin()\n\nchildcare_pg = childcare_ppp[pg_owin]\n\nplot(childcare_pg)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#monte-carlo-simulation",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#monte-carlo-simulation",
    "title": "In-Class Exercise 2",
    "section": "13 Monte Carlo Simulation",
    "text": "13 Monte Carlo Simulation\n\n\n\n\n\n\nTip\n\n\n\nIn order to ensure reproducibility, it is important to include the code block below before using spatstat functions involve Monte Carlo simulation\n\n\n\nset.seed(1234)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#edge-correction-methods-of-spatstat",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#edge-correction-methods-of-spatstat",
    "title": "In-Class Exercise 2",
    "section": "14 Edge Correction Methods of spatstat",
    "text": "14 Edge Correction Methods of spatstat\nIn spatstat, edge correction methods are used to handle biases that arise when estimating spatial statistics near the boundaries of a study region. These corrections are essential for ensuring accurate estimates in spatial point pattern analysis, especially for summary statistics like the K-function, L-function, pair correlation function, etc.\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\nnone\nNo edge correction is applied. Assumes no bias at the edges, which may lead to underestimation of statistics near the boundaries.\n\n\nisotropic\nCorrects for edge effects by assuming the point pattern is isotropic (uniform in all directions) and compensates for missing neighbors outside the boundary.\n\n\ntranslate\n(Translation Correction) Uses translation correction by translating the observation window so every point lies entirely within it, then averaging statistics over all translations.\n\n\nRipley\n(Ripley’s Correction) Similar to isotropic correction, but specifically tailored for Ripley’s K-function and related functions. Adjusts the expected number of neighbors near edges based on the window’s shape and size.\n\n\nborder\nBorder correction reduces bias by only considering points far enough from the boundary so that their neighborhood is fully contained within the window, minimizing edge effects."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#geospatial-analytics-for-social-good-thailand-road-accident-case-study",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#geospatial-analytics-for-social-good-thailand-road-accident-case-study",
    "title": "In-Class Exercise 2",
    "section": "15 Geospatial Analytics for Social Good: Thailand Road Accident Case Study",
    "text": "15 Geospatial Analytics for Social Good: Thailand Road Accident Case Study\nThis section is in preparation of Take-home Exercise 1: Geospatial Analytics for Public Good\n\n15.1 Background\nFor an overview of the road traffic accidents in Thailand, you may refer to:\n\nRoad traffic injuries, WHO.\nRoad traffic deaths and injuries in Thailand\n\n\n\n15.2 The Study Area\nThe study area is Bangkok Metropolitan Region.\n\n\n\n\n\n\n\nNote\n\n\n\nThe projected coordinate system of Thailand is WGS 84 / UTM zone 47N and the EPSG code is 32647.\n\n\n\n\n15.3 The Data\nFor the purpose of this exercise, three basic data sets are needed, they are:\n\nThailand Road Accident [2019-2022] on Kaggle\nThailand Roads (OpenStreetMap Export) on HDX.\nThailand - Subnational Administrative Boundaries on HDX.\n\n\n15.3.1 Traffic Accident Data\n\nrdacc_sf &lt;- read_csv(\"data/geospatial/thai_road_accident_2019_2022.csv\") %&gt;%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\") %&gt;%\n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %&gt;%\n  st_transform(crs = 32647)\n\n\nplot(rdacc_sf)\n\n\n\n\n\n\n\n\n\n\n15.3.2 Administrative Boundary\n\n# country\nadminboundary0 &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"tha_admbnda_adm0_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm0_rtsd_20220121' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 13 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n# # province\n# adminboundary1 &lt;- st_read(dsn = \"data/geospatial\",\n#                 layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\n# # district\n# adminboundary2 &lt;- st_read(dsn = \"data/geospatial\",\n#                 layer = \"tha_admbnda_adm2_rtsd_20220121\")\n\n# # sub-district\n# adminboundary3 &lt;- st_read(dsn = \"data/geospatial\",\n#                 layer = \"tha_admbnda_adm3_rtsd_20220121\")\n\n\nplot(adminboundary0, max.plot=1)\n\n\n\n\n\n\n\n# plot(adminboundary1)\n# plot(adminboundary2)\n# plot(adminboundary3)\n\n\n\n15.3.3 Thai Roads\n\nroads &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"hotosm_tha_roads_lines_shp\")\n\nReading layer `hotosm_tha_roads_lines_shp' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2792590 features and 14 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 97.34457 ymin: 5.643645 xmax: 105.6528 ymax: 20.47168\nCRS:           NA"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-Class Exercise 1",
    "section": "",
    "text": "ISSS626 Geospatial Analytics and Applications - In-class Exercise 1: Geospatial Data Science with R"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#exercise-reference",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#exercise-reference",
    "title": "In-Class Exercise 1",
    "section": "",
    "text": "ISSS626 Geospatial Analytics and Applications - In-class Exercise 1: Geospatial Data Science with R"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#learning-outcome",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#learning-outcome",
    "title": "In-Class Exercise 1",
    "section": "2 Learning Outcome",
    "text": "2 Learning Outcome\n\nImport and transform geospatial data using tidyverse and sf packages.\nAnalyze spatial datasets and extract meaningful insights.\nCreate and customize choropleth maps using the tmap package.\nDevelop analytical maps to visualize spatial patterns and distributions.\nPerform statistical analysis on spatial data using the ggstatsplot package.\nManage geospatial data workflows effectively in R."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#import-the-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#import-the-r-packages",
    "title": "In-Class Exercise 1",
    "section": "3 Import the R Packages",
    "text": "3 Import the R Packages\n\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\n\nsf\nImporting, managing, and processing geospatial data.\nHandling and processing geospatial data in R.\n\n\ntidyverse\nComprehensive set of tools for data science tasks.\nImporting, wrangling, and visualizing data.\n\n\ntmap\nCreating thematic maps for visualizing spatial data.\nDesigning and displaying thematic maps to represent spatial patterns.\n\n\nggstatsplot\nEnhancing ggplot2 plots with statistical analyses.\nAdding statistical summaries and tests to visualizations for better insights.\n\n\n\n\npacman::p_load(tidyverse, sf, tmap, ggstatsplot)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#the-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#the-data",
    "title": "In-Class Exercise 1",
    "section": "4 The Data",
    "text": "4 The Data\n\n\n\nDataset\nSource\nDescription\n\n\n\n\nMaster Plan 2014 Subzone Boundary (Web)\ndata.gov.sg\nGeospatial boundaries for Singapore’s planning subzones in 2014.\n\n\nMaster Plan 2019 Subzone Boundary (Web)\ndata.gov.sg\nUpdated geospatial boundaries for Singapore’s planning subzones in 2019.\n\n\nPre-Schools Location\ndata.gov.sg\nLocation data for pre-schools in Singapore.\n\n\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2023\nsingstat.gov.sg\nAspatial data on residents of Singapore by planning area, subzone, age, sex, and type of dwelling for June 2023."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-master-plan-planning-sub-zone-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-master-plan-planning-sub-zone-data",
    "title": "In-Class Exercise 1",
    "section": "5 Working with Master Plan Planning Sub-zone Data",
    "text": "5 Working with Master Plan Planning Sub-zone Data\nTo import the shapefile version of the Sub-zone data:\n\nmpsz14_shp &lt;- st_read(dsn = \"data\",\n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex01/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nNotice that mpsz14_shp is of class sf and inherits from data.frame. This means it combines spatial features with tabular data structure.\n\nclass(mpsz14_shp)\n\n[1] \"sf\"         \"data.frame\"\n\n\nTo import the kml version of the Sub-zone data:\n\nmpsz14_kml &lt;- st_read(\"data/MasterPlan2014SubzoneBoundaryWebKML.kml\")\n\n\nNote that this is a corrupted file. It is likely that the agency has unknowingly uploaded a corrupted kml file.\n\nTo render a workable kml, we can convert the shp object and save it as a kml file.\n\nst_write(mpsz14_shp,\n         \"data/MasterPlan2014SubzoneBoundaryWebKML.kml\",\n         delete_dsn=TRUE)\n\nNote that the delete_dsn=TRUE argument ensures that any existing file with the same name is deleted before saving the new KML file, preventing potential conflicts or errors from overwriting.\nTo import pre-school location data in kml format:\n\npreschool_kml &lt;- st_read(\"data/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex01/data/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nTo import Master Plan 2019 Subzone Boundary (No SEA) kml and MPSZ-2019 into sf simple feature data.frame:\n\nmpsz19_shp &lt;- st_read(dsn = \"data\",\n                  layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs=3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex01/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz19_kml &lt;- st_read(\"data/MasterPlan2019RegionBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_REGION_NO_SEA_PL' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex01/data/MasterPlan2019RegionBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 5 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#handling-coordinate-systems",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#handling-coordinate-systems",
    "title": "In-Class Exercise 1",
    "section": "6 Handling Coordinate Systems",
    "text": "6 Handling Coordinate Systems\nTo check the project of the imported sf objects:\n\nst_crs(mpsz19_shp)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNext, re-write the code chunk to import the Master Plan Sub-zone 2019 and Pre-schools Location with proper transformation.\n\nmpsz19_shp &lt;- st_read(dsn = \"data/\",\n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex01/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\npreschool &lt;- st_read(\"data/PreSchoolsLocation.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex01/data/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#geospatial-data-wrangling",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#geospatial-data-wrangling",
    "title": "In-Class Exercise 1",
    "section": "7 Geospatial Data Wrangling",
    "text": "7 Geospatial Data Wrangling\n\n7.1 Point-in-Polygon count\nThe code below counts the number of preschools within each planning subzone. It uses st_intersects to find intersections between the geometries of the subzones (mpsz19_shp) and the preschool locations, identifying where the two sets of geometries overlap or share common points.\nThe lengths() function is then applied to count the number of intersecting preschools for each subzone, effectively returning the total number of preschools within each subzone in the mpsz19_shp shapefile.\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(`PreSch Count` = lengths(\n    st_intersects(mpsz19_shp, preschool)))\n\n\n\n7.2 Computing Density\nThe code below performs the following tasks:\nDerive the area of each planning sub-zone.\nDrop the unit of measurement of the area (i.e. m^2)\nCalculate the density of pre-school at the planning sub-zone level.\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(Area = units::drop_units(\n    st_area(.)),\n    `PreSch Density` = `PreSch Count` / Area * 1000000\n  )"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#statistical-analysis",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#statistical-analysis",
    "title": "In-Class Exercise 1",
    "section": "8 Statistical Analysis",
    "text": "8 Statistical Analysis\nIn this section, we will use appropriate Exploratory Data Analysis (EDA) and Confirmatory Data Analysis (CDA) methods to explore and confirm the statistical relationship between Pre-school Density and Pre-school count.\n\n# Convert the 'PreSch Density' column in 'mpsz19_shp' to numeric format\nmpsz19_shp$`PreSch Density` &lt;- as.numeric(as.character(mpsz19_shp$`PreSch Density`))\n\n# Convert the 'PreSch Count' column in 'mpsz19_shp' to numeric format\nmpsz19_shp$`PreSch Count` &lt;- as.numeric(as.character(mpsz19_shp$`PreSch Count`))\n\n# Convert the spatial data frame 'mpsz19_shp' to a regular data frame for plotting\nmpsz19_df &lt;- as.data.frame(mpsz19_shp)\n\n# Create a scatter plot with statistical details using the 'ggscatterstats' function from the 'ggstatsplot' package\nggstatsplot::ggscatterstats(data = mpsz19_df,\n               x = `PreSch Density`, # Set 'PreSch Density' as the x-axis variable\n               y = `PreSch Count`, # Set 'PreSch Count' as the y-axis variable\n               type = \"parametric\", # Specify the type of statistical test to use (parametric)\n               label.var = SUBZONE_N, # Label points with the subzone names\n               label.expression = `PreSch Count` &gt; 40) # Label only those points where 'PreSch Count' is greater than 40\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nOutput Intepretation:\nThe plot shows a moderately strong positive correlation between preschool density and the number of preschools in each subzone. As the preschool density increases, the number of preschools tends to increase as well."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-population-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-population-data",
    "title": "In-Class Exercise 1",
    "section": "9 Working with Population data",
    "text": "9 Working with Population data\n\npopdata &lt;- read_csv(\"data/respopagesextod2023.csv\")\n\nTo prepare a data.frame showing population by Planning Area and Planning subzone:\n\npopdata2023 &lt;- popdata %&gt;%\n  # Group the data by Planning Area (PA), Subzone (SZ), and Age Group (AG)\n  group_by(PA, SZ, AG) %&gt;%\n  # Summarize the population (POP) by calculating the sum of 'Pop' within each group\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  # Remove the grouping structure to avoid issues in further operations\n  ungroup() %&gt;%\n  # Reshape the data to a wider format: create separate columns for each Age Group (AG)\n  # with their corresponding population values (POP)\n  pivot_wider(names_from = AG, values_from = POP)\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\nNow, we will perform data processing to derive a tibble data.framewith the following fields PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY where by:\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group.\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  # Calculate the 'YOUNG' population: sum of age groups 0-24, 10-24, and 5-9\n  mutate(YOUNG = rowSums(.[3:6]) + rowSums(.[14])) %&gt;%\n  # Calculate the 'ECONOMY ACTIVE' population: sum of age groups 25-59 and 60-64\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13]) + rowSums(.[15])) %&gt;%\n  # Calculate the 'AGED' population: sum of age groups 65 and above\n  mutate(`AGED` = rowSums(.[16:21])) %&gt;%\n  # Calculate the 'TOTAL' population: sum of all age groups\n  mutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\n  # Calculate the 'DEPENDENCY' ratio: (YOUNG + AGED) / ECONOMY ACTIVE\n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`) / `ECONOMY ACTIVE`) %&gt;%\n  # Select only the relevant columns to keep in the final data frame\n  select(`PA`, `SZ`, `YOUNG`, `ECONOMY ACTIVE`, `AGED`, `TOTAL`, `DEPENDENCY`)\n\nNext, we will joining aspatial and geospatial data. First, we use toupper() to convert elements of PA and SZ to upper case.\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ),\n          .funs = list(toupper))\n\nThe code below demonstrates how to use left_join() to merge the geospatial data mpsz19_shp with the population data popdata2023. By keeping mpsz19_shp as the left table in the first join, we ensure that the geometry details of the spatial data are preserved:\n\nmpsz_pop2023 &lt;- left_join(mpsz19_shp, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nIn contrast, the second join keeps popdata2023 as the left table, meaning the population data is retained, and geometry details from mpsz19_shp are added where they match:\n\npop2023_mpsz &lt;- left_join(popdata2023, mpsz19_shp,\n                          by = c(\"SZ\" = \"SUBZONE_N\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#choropleth-map-of-dependency-ratio-by-planning-subzone",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#choropleth-map-of-dependency-ratio-by-planning-subzone",
    "title": "In-Class Exercise 1",
    "section": "10 Choropleth Map of Dependency Ratio by Planning Subzone",
    "text": "10 Choropleth Map of Dependency Ratio by Planning Subzone\n\n# Set the base shape for the map using the merged geospatial and population data\ntm_shape(mpsz_pop2023) +\n\n  # Fill the map areas based on the \"DEPENDENCY\" variable, using a quantile classification and a blue color palette\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n\n  # Customize the layout of the map with a title and legend adjustments\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.title.size = 1,\n            legend.height = 0.45,\n            legend.width = 0.35) + # Corrected: add \"+\" to continue chaining elements\n\n  # Add semi-transparent borders around the subzones\n  tm_borders(alpha = 0.5) +\n\n  # Add compass with a star-shaped style\n  tm_compass(type = \"8star\", size = 1.5) +\n\n  # Add scale bar\n  tm_scale_bar() +\n\n  # Add grid to map\n  tm_grid(alpha = 0.2) +\n\n  # Cite the data source\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authority (URA)\\n and Population data from Department of Statistics (DOS)\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe output is a choropleth map showing the distribution of the dependency ratio by planning subzone in Singapore.\n\nThe map clearly shows which areas have higher or lower dependency ratios. For instance, darker areas like certain central regions have higher dependency ratios, suggesting a higher number of dependents (both young and aged) compared to the working-age population.\nLighter areas have lower ratios, indicating a balance or a larger working-age population compared to dependents."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-percentile-map",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-percentile-map",
    "title": "In-Class Exercise 1",
    "section": "11 Analytical Map: Percentile Map",
    "text": "11 Analytical Map: Percentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\nFirst, we have to process the data by dropping NA records.\n\nmpsz_pop2023 &lt;- mpsz_pop2023 %&gt;%\n  drop_na()\n\nNext, we defines a function to get the input data and field to be used for creating the percentile map.\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;%\n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\nThen, we creates a percentile mapping function for computing and plotting the percentile map.\n\n# Create a percentile map based on a variable\npercentmap &lt;- function(vnam, df, legtitle = NA, mtitle = \"Percentile Map\") {\n  # Define percentile breaks to be used for map legend\n  percent &lt;- c(0, .01, .1, .5, .9, .99, 1)\n\n  # Retrieve the variable from the data frame based on the variable name\n  var &lt;- get.var(vnam, df)\n\n  # Calculate the percentile values (break points) for the variable\n  bperc &lt;- quantile(var, percent)\n\n  # Create the base shape layer using the mpsz_pop2023 dataset\n  tm_shape(mpsz_pop2023) +\n  tm_polygons() + # Draw polygons for subzones\n\n  # Overlay the specified data frame 'df' on the map\n  tm_shape(df) +\n     tm_fill(vnam, # Fill polygons based on the variable 'vnam'\n             title = legtitle, # Set legend title\n             breaks = bperc, # Use calculated percentiles for breaks\n             palette = \"Blues\", # Apply a blue color palette\n             labels = c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() + # Add borders to the map polygons\n\n  # Customize the layout and appearance of the map\n  tm_layout(main.title = mtitle, # Set the main title of the map\n            title.position = c(\"right\", \"bottom\"))\n}\n\nFinally, we can plot the percentile map.\n\npercentmap(\"DEPENDENCY\", mpsz_pop2023)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-box-map",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-box-map",
    "title": "In-Class Exercise 1",
    "section": "12 Analytical Map: Box Map",
    "text": "12 Analytical Map: Box Map\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nCreate the boxbreaks function\n\nThe code block below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\n# int a function 'boxbreaks' to calculate break points based on boxplot statistics\nboxbreaks &lt;- function(v, mult = 1.5) {\n  # Calculate the quartiles of the input vector 'v' and remove names\n  qv &lt;- unname(quantile(v))\n\n  # Calculate the interquartile range (IQR)\n  iqr &lt;- qv[4] - qv[2]\n\n  # Calculate the upper and lower fences for outlier detection\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n\n  # Initialize a numeric vector 'bb' with 7 elements to store the break points\n  bb &lt;- vector(mode = \"numeric\", length = 7)\n\n  # Determine lower break points based on lower fence\n  if (lofence &lt; qv[1]) {  # No lower outliers\n    bb[1] &lt;- lofence      # Set lower fence as the first break point\n    bb[2] &lt;- floor(qv[1]) # Round down to the nearest integer for the next break point\n  } else {                # There are lower outliers\n    bb[2] &lt;- lofence      # Set lower fence as the second break point\n    bb[1] &lt;- qv[1]        # Set the minimum value as the first break point\n  }\n\n  # Determine upper break points based on upper fence\n  if (upfence &gt; qv[5]) {  # No upper outliers\n    bb[7] &lt;- upfence      # Set upper fence as the last break point\n    bb[6] &lt;- ceiling(qv[5]) # Round up to the nearest integer for the previous break point\n  } else {                # There are upper outliers\n    bb[6] &lt;- upfence      # Set upper fence as the sixth break point\n    bb[7] &lt;- qv[5]        # Set the maximum value as the last break point\n  }\n\n  # Set the inner quartile values (Q1, Median, Q3) as middle break points\n  bb[3:5] &lt;- qv[2:4]\n\n  return(bb)\n}\n\n\nCreate the get.var function\n\nThe R function below extracts a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\n# init  a function 'get.var' to extract a variable from a data frame without its spatial geometry\nget.var &lt;- function(vname, df) {\n  # Select the specified variable 'vname' from the data frame 'df' and remove the spatial geometry information\n  v &lt;- df[vname] %&gt;%\n    st_set_geometry(NULL) # Remove the geometry component from the sf object to get a plain data frame\n\n  # Remove the column name from the variable and convert it to a plain vector\n  v &lt;- unname(v[,1])\n\n  return(v)\n}\n\n\nCreate the Boxmap function\n\nThe code chunk below is an R function to create a box map.\n\narguments:\n\nvnam: variable name (as character, in quotes)\ndf: simple features polygon layer\nlegtitle: legend title\nmtitle: map title\nmult: multiplier for IQR\n\nreturns:\n\na tmap-element (plots a map)\n\n\n\n# Define a function 'boxmap' to create a box map based on a variable\nboxmap &lt;- function(vnam, df,\n                   legtitle = NA, # Set default value for legend title as NA\n                   mtitle = \"Box Map\", # Set default value for main title\n                   mult = 1.5) { # Set default multiplier for calculating fences in boxplot\n\n  # Extract the variable data from the data frame without geometry\n  var &lt;- get.var(vnam, df)\n\n  # Calculate the break points for the box map using the 'boxbreaks' function\n  bb &lt;- boxbreaks(var)\n\n  # Create the base shape layer using the specified data frame 'df'\n  tm_shape(df) +\n    tm_polygons() + # Draw polygons for spatial units\n\n  # Overlay the data frame again to apply fill color based on the variable\n  tm_shape(df) +\n     tm_fill(vnam, # Fill polygons based on the variable 'vnam'\n             title = legtitle, # Set legend title\n             breaks = bb, # Use calculated boxplot breaks for coloring\n             palette = \"Blues\", # Apply a blue color palette\n             labels = c(\"Lower outlier\",  # Label for lower outliers\n                        \"&lt; 25%\",          # Label for first quartile\n                        \"25% - 50%\",      # Label for second quartile (median)\n                        \"50% - 75%\",      # Label for third quartile\n                        \"&gt; 75%\",          # Label for upper quartile\n                        \"Upper outlier\")) + # Label for upper outliers\n  tm_borders() + # Add borders to the polygons on the map\n\n  # Customize the layout and appearance of the map\n  tm_layout(main.title = mtitle, # Set the main title of the map\n            title.position = c(\"left\", \"top\"), # Position the title at the top left\n            frame = F) # Remove the map frame\n}\n\n\nFinally, plot the Box Map\n\nStatic Box Map\n\nboxmap(\"DEPENDENCY\", mpsz_pop2023)\n\n\n\n\n\n\n\n\nInteractive Box Map\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\ntm_basemap(\"Esri.WorldGrayCanvas\") +\nboxmap(\"DEPENDENCY\", mpsz_pop2023)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-Class Exercise 5",
    "section": "",
    "text": "ISSS626 Geospatial Analytics and Applications - In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#exercise-reference",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#exercise-reference",
    "title": "In-Class Exercise 5",
    "section": "",
    "text": "ISSS626 Geospatial Analytics and Applications - In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#overview",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#overview",
    "title": "In-Class Exercise 5",
    "section": "\n2 Overview",
    "text": "2 Overview\nIn this exercise, we will use the sfdep package to perform global and local measures of spatial autocorrelation using Hunan’s spatial data. In Hands-on Exercise 5, we learnt to perform spatial autocorrelation using spdep package.\n\n\n\n\n\n\nNote\n\n\n\nThe sfdep and spdep packages in R are both designed for spatial data analysis, particularly focusing on spatial autocorrelation, but they differ in their approach and compatibility with modern R data structures.\n\nspdep: This is the older and more established package for spatial dependence analysis in R. It provides functions for creating spatial weights, spatial lag models, and global and local spatial autocorrelation statistics such as Moran’s I. However, spdep was originally built to work with the sp package, which uses the older Spatial* classes for handling spatial data.\nsfdep: This is a newer package designed to work seamlessly with the sf package, which has become the standard for handling spatial data in R using simple features. sfdep provides an interface for spatial dependence analysis that is compatible with sf’s sf objects (simple feature geometries) and makes extensive use of tidyverse conventions, such as list columns, which allow for more flexible and tidy manipulation of spatial data.\n\n\n2.1 Key Differences:\n\n\nData Structures:\n\n\nspdep works with Spatial* objects from the sp package.\n\nsfdep works with sf objects from the sf package, which are easier to integrate with modern R workflows and the tidyverse ecosystem.\n\n\n\nIntegration:\n\n\nsfdep is more compatible with modern workflows using the tidyverse, allowing for easier manipulation of data within data frames and list columns.\n\nspdep relies on the older base R style and is less intuitive when working with modern data pipelines.\n\n\n\nFunctionality:\n\nBoth packages provide similar functionalities for spatial autocorrelation, such as computing Moran’s I and local Moran’s I.\n\nsfdep introduces new functionalities that leverage list columns for easier spatial dependence operations.\n\n\n\nsfdep can essentially be considered a wrapper around the functionality provided by spdep, designed to work with the modern sf (simple features) framework for spatial data in R."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#learning-outcome",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#learning-outcome",
    "title": "In-Class Exercise 5",
    "section": "\n3 Learning Outcome",
    "text": "3 Learning Outcome\n\nPerform global Moran’s I test for spatial autocorrelation.\nCompute and visualize local Moran’s I and Gi* statistics for identifying clusters and outliers.\nCreate choropleth maps to display the results of spatial autocorrelation analysis."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#import-the-r-packages",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#import-the-r-packages",
    "title": "In-Class Exercise 5",
    "section": "\n4 Import the R Packages",
    "text": "4 Import the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\nsf\nHandles spatial data; imports, manages, and processes vector-based geospatial data.\nImporting and managing geospatial data, such as Hunan’s county boundary shapefile.\n\n\nsfdep\nProvides functions for spatial autocorrelation, including Moran’s I and local Moran’s I.\nPerforming spatial autocorrelation analysis with global and local measures.\n\n\ntidyverse\nA collection of R packages for data science tasks like data manipulation, visualization, and modeling.\nWrangling aspatial data and joining with spatial datasets.\n\n\ntmap\nCreates static and interactive thematic maps using cartographic quality elements.\nVisualizing spatial analysis results and creating thematic maps.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(sf, sfdep, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#the-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#the-data",
    "title": "In-Class Exercise 5",
    "section": "\n5 The Data",
    "text": "5 The Data\nThe following datasets will be used in this exercise:\n\n\n\n\n\n\n\nData Set\nDescription\nFormat\n\n\n\nHunan County Boundary Layer\nA geospatial dataset containing Hunan’s county boundaries.\nESRI Shapefile\n\n\nHunan_2012.csv\nA CSV file containing selected local development indicators for Hunan in 2012.\nCSV\n\n\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex05/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nglimpse(hunan)\n\nRows: 88\nColumns: 8\n$ NAME_2     &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Cha…\n$ ID_3       &lt;int&gt; 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 211…\n$ NAME_3     &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ ENGTYPE_3  &lt;chr&gt; \"County\", \"County\", \"County City\", \"County\", \"County\", \"Cou…\n$ Shape_Leng &lt;dbl&gt; 1.869074, 2.360691, 1.425620, 3.474325, 2.289506, 4.171918,…\n$ Shape_Area &lt;dbl&gt; 0.10056190, 0.19978745, 0.05302413, 0.18908121, 0.11450357,…\n$ County     &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"L…\n$ geometry   &lt;POLYGON [°]&gt; POLYGON ((112.0625 29.75523..., POLYGON ((112.2288 …\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor admin boundaries, we will typically encounter polygon or multipolygon data objects.\nA polygon represents a single contiguous area, while a multipolygon consists of multiple disjoint areas grouped together (e.g., islands that belong to the same admin region).\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\nglimpse(hunan2012)\n\nRows: 88\nColumns: 29\n$ County      &lt;chr&gt; \"Anhua\", \"Anren\", \"Anxiang\", \"Baojing\", \"Chaling\", \"Changn…\n$ City        &lt;chr&gt; \"Yiyang\", \"Chenzhou\", \"Changde\", \"Hunan West\", \"Zhuzhou\", …\n$ avg_wage    &lt;dbl&gt; 30544, 28058, 31935, 30843, 31251, 28518, 54540, 28597, 33…\n$ deposite    &lt;dbl&gt; 10967.0, 4598.9, 5517.2, 2250.0, 8241.4, 10860.0, 24332.0,…\n$ FAI         &lt;dbl&gt; 6831.7, 6386.1, 3541.0, 1005.4, 6508.4, 7920.0, 33624.0, 1…\n$ Gov_Rev     &lt;dbl&gt; 456.72, 220.57, 243.64, 192.59, 620.19, 769.86, 5350.00, 1…\n$ Gov_Exp     &lt;dbl&gt; 2703.0, 1454.7, 1779.5, 1379.1, 1947.0, 2631.6, 7885.5, 11…\n$ GDP         &lt;dbl&gt; 13225.0, 4941.2, 12482.0, 4087.9, 11585.0, 19886.0, 88009.…\n$ GDPPC       &lt;dbl&gt; 14567, 12761, 23667, 14563, 20078, 24418, 88656, 10132, 17…\n$ GIO         &lt;dbl&gt; 9276.90, 4189.20, 5108.90, 3623.50, 9157.70, 37392.00, 513…\n$ Loan        &lt;dbl&gt; 3954.90, 2555.30, 2806.90, 1253.70, 4287.40, 4242.80, 4053…\n$ NIPCR       &lt;dbl&gt; 3528.3, 3271.8, 7693.7, 4191.3, 3887.7, 9528.0, 17070.0, 3…\n$ Bed         &lt;dbl&gt; 2718, 970, 1931, 927, 1449, 3605, 3310, 582, 2170, 2179, 1…\n$ Emp         &lt;dbl&gt; 494.310, 290.820, 336.390, 195.170, 330.290, 548.610, 670.…\n$ EmpR        &lt;dbl&gt; 441.4, 255.4, 270.5, 145.6, 299.0, 415.1, 452.0, 127.6, 21…\n$ EmpRT       &lt;dbl&gt; 338.0, 99.4, 205.9, 116.4, 154.0, 273.7, 219.4, 94.4, 174.…\n$ Pri_Stu     &lt;dbl&gt; 54.175, 33.171, 19.584, 19.249, 33.906, 81.831, 59.151, 18…\n$ Sec_Stu     &lt;dbl&gt; 32.830, 17.505, 17.819, 11.831, 20.548, 44.485, 39.685, 7.…\n$ Household   &lt;dbl&gt; 290.4, 104.6, 148.1, 73.2, 148.7, 211.2, 300.3, 76.1, 139.…\n$ Household_R &lt;dbl&gt; 234.5, 121.9, 135.4, 69.9, 139.4, 211.7, 248.4, 59.6, 110.…\n$ NOIP        &lt;dbl&gt; 101, 34, 53, 18, 106, 115, 214, 17, 55, 70, 44, 84, 74, 17…\n$ Pop_R       &lt;dbl&gt; 670.3, 243.2, 346.0, 184.1, 301.6, 448.2, 475.1, 189.6, 31…\n$ RSCG        &lt;dbl&gt; 5760.60, 2386.40, 3957.90, 768.04, 4009.50, 5220.40, 22604…\n$ Pop_T       &lt;dbl&gt; 910.8, 388.7, 528.3, 281.3, 578.4, 816.3, 998.6, 256.7, 45…\n$ Agri        &lt;dbl&gt; 4942.253, 2357.764, 4524.410, 1118.561, 3793.550, 6430.782…\n$ Service     &lt;dbl&gt; 5414.5, 3814.1, 14100.0, 541.8, 5444.0, 13074.6, 17726.6, …\n$ Disp_Inc    &lt;dbl&gt; 12373, 16072, 16610, 13455, 20461, 20868, 183252, 12379, 1…\n$ RORP        &lt;dbl&gt; 0.7359464, 0.6256753, 0.6549309, 0.6544614, 0.5214385, 0.5…\n$ ROREmp      &lt;dbl&gt; 0.8929619, 0.8782065, 0.8041262, 0.7460163, 0.9052651, 0.7…\n\n\n\n\n\n\n\n\nNote\n\n\n\nRecall that to do left join, we need a common identifier between the 2 data objects. The content must be the same eg. same format and same case. In Hands-on Exercise 1B, we need to (PA, SZ) in the dataset to uppercase before we can join the data.\n\n\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\nglimpse(hunan)\n\nRows: 88\nColumns: 7\n$ NAME_2    &lt;chr&gt; \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Changde\", \"Chan…\n$ ID_3      &lt;int&gt; 21098, 21100, 21101, 21102, 21103, 21104, 21109, 21110, 2111…\n$ NAME_3    &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"Li…\n$ ENGTYPE_3 &lt;chr&gt; \"County\", \"County\", \"County City\", \"County\", \"County\", \"Coun…\n$ County    &lt;chr&gt; \"Anxiang\", \"Hanshou\", \"Jinshi\", \"Li\", \"Linli\", \"Shimen\", \"Li…\n$ GDPPC     &lt;dbl&gt; 23667, 20981, 34592, 24473, 25554, 27137, 63118, 62202, 7066…\n$ geometry  &lt;POLYGON [°]&gt; POLYGON ((112.0625 29.75523..., POLYGON ((112.2288 2…"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-choropleth-map-of-gdppc-of-hunan",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-choropleth-map-of-gdppc-of-hunan",
    "title": "In-Class Exercise 5",
    "section": "\n6 Visualising Choropleth Map of GDPPC of Hunan",
    "text": "6 Visualising Choropleth Map of GDPPC of Hunan\nTo plot a choropleth map showing the distribution of GDPPC of Hunan province:\n\ntmap_mode(\"plot\")\ntm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by county, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#global-measures-of-spatial-association",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#global-measures-of-spatial-association",
    "title": "In-Class Exercise 5",
    "section": "\n7 Global Measures of Spatial Association",
    "text": "7 Global Measures of Spatial Association\n\n7.1 Deriving Queen’s contiguity weights: sfdep methods\nTo derive the Queen’s contiguity weights:\n\nwm_q &lt;- hunan %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\n\n\n\n\n\n\nTip\n\n\n\nNotice that st_weights() provides tree arguments, they are:\n\n\nnb: A neighbor list object as created by st_neighbors().\n\nstyle: Default “W” for row standardized weights. This value can also be “B”, “C”, “U”, “minmax”, and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\n\nallow_zero: If TRUE, assigns zero as lagged value to zone without neighbors.\n\n\n\n\n7.2 Computing Global Moran’ I\nWe will use global_moran() function to compute the Moran’s I value.\n\nmoranI &lt;- global_moran(\n  wm_q$GDPPC, # Target variable: GDP per capita\n  wm_q$nb, # Neighborhood structure\n  wm_q$wt # Spatial weights\n)\n\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\n\n\n\n\n\n\nTip\n\n\n\nUnlike the spdep package, the output of the global_moran() function is a tibble data frame, making it easier to work with in the tidyverse environment."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#performing-global-morans-i-test",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#performing-global-morans-i-test",
    "title": "In-Class Exercise 5",
    "section": "\n8 Performing Global Moran’s I Test",
    "text": "8 Performing Global Moran’s I Test\n\n\n\n\n\n\nTip\n\n\n\nPreviously, we calculated the Moran’s I statistic using the global_moran() function. However, this approach does not allow for formal hypothesis testing, as it only returns the Moran’s I value, not the associated p-value or significance level. Therefore, we cannot determine whether spatial autocorrelation is statistically significant with this method.\n\n\nTo conduct a proper hypothesis test, we need to use the global_moran_test() function from the sfdep package, which computes the Moran’s I statistic and also performs a permutation-based significance test. This allows us to assess whether the observed spatial autocorrelation is significantly different from what would be expected under spatial randomness.\nThe following code demonstrates how to perform the Moran’s I test:\n\nglobal_moran_test(\n  wm_q$GDPPC, # Target variable: GDP per capita\n  wm_q$nb, # Neighborhood structure\n  wm_q$wt # Spatial weights\n)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nTip\n\n\n\n\nThe default for alternative argument is “two.sided”. Other supported arguments are “greater” or “less”. randomization, and\nBy default the randomization argument is TRUE. If FALSE, under the assumption of normality.\n\n\n\nThis method not only calculates the Moran’s I statistic but also provides a p-value for assessing the significance of the spatial autocorrelation.\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\n\nMoran’s I statistic: 0.301, indicating moderate positive spatial autocorrelation.\n\nP-value: 1.095e-06, highly significant, confirming strong evidence of positive spatial autocorrelation."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#perfoming-global-morans-i-permutation-test",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#perfoming-global-morans-i-permutation-test",
    "title": "In-Class Exercise 5",
    "section": "\n9 Perfoming Global Moran’s I Permutation Test",
    "text": "9 Perfoming Global Moran’s I Permutation Test\nIn practice, a Monte Carlo simulation should be used to perform the statistical test. In the sfdep package, this is supported by the global_moran_perm() function.\nTo ensure that the computation is reproducible, we will use set.seed() before performing simulation.\n\nset.seed(1234)\n\nNow we will perform Monte Carlo simulation using global_moran_perm().\n\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe statistical report on previous tab shows that the p-value is smaller than alpha value of 0.05. Hence, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of GPD per capita are resemble random distribution (i.e. independent from spatial). Because the Moran’s I statistics is greater than 0. We can infer that the spatial distribution shows sign of clustering."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html",
    "title": "8A: Geographically Weighted Predictive Models",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 14  Geographically Weighted Predictive Models"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#exercise-8a-reference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#exercise-8a-reference",
    "title": "8A: Geographically Weighted Predictive Models",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 14  Geographically Weighted Predictive Models"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#overview",
    "title": "8A: Geographically Weighted Predictive Models",
    "section": "\n2 Overview",
    "text": "2 Overview\nIn this exercise, we will learn how to build predictive models using the geographical random forest method to predict outcomes based on geospatial factors and historical geospatial locations.\nPredictive modeling uses statistical and machine learning techniques to forecast future outcomes. To build these models, we start with a dataset where the outcomes are already known, along with various input variables (predictors) that might influence those outcomes. The model learns from these known examples to make accurate predictions about future events.\nGeospatial predictive modelling is conceptually rooted in the principle that the occurrences of events being modeled are limited in distribution.\n\nWhen geographically referenced data are used, occurrences of events are neither uniform nor random in distribution over space. There are geospatial factors (infrastructure, sociocultural, topographic, etc.) that constrain and influence where the locations of events occur.\n\nGeospatial predictive modeling identifies and analyzes these factors by examining the relationship between past event locations and the environmental conditions that might have influenced those locations. This helps to better understand and predict where similar events are likely to happen in the future.\n\n\n\n\n\n\nTip\n\n\n\nSeveral sections in this exercise will take a while to compute… , we will save several intermediate rds file as checkpoints for future uses."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#learning-outcome",
    "title": "8A: Geographically Weighted Predictive Models",
    "section": "\n3 Learning Outcome",
    "text": "3 Learning Outcome\n\nPrepare training and test datasets using appropriate data sampling methods.\nCalibrate predictive models using both geospatial statistical learning and machine learning methods.\nCompare and select the best model for predicting future outcomes.\nPredict future outcomes using the best-calibrated model."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#the-data",
    "title": "8A: Geographically Weighted Predictive Models",
    "section": "\n4 The Data",
    "text": "4 The Data\nThe following datasets will be used in this study:\n\n\n\n\n\n\n\nData Type\nDescription\nFormat\n\n\n\nAspatial dataset\nHDB Resale data: a list of HDB resale transacted prices in Singapore from Jan 2017 onwards.\nCSV\n\n\nGeospatial dataset\n\nMP14_SUBZONE_WEB_PL: A polygon feature dataset providing information on URA 2014 Master Plan Planning Subzone boundary data.\nESRI Shapefile\n\n\nLocational factors with geographic coordinates\nVarious data sets including Eldercare, Hawker Centre, Parks, Supermarket, CHAS clinics, Childcare services, Kindergartens, MRT, and Bus stops.\nGeoJSON/Shapefile\n\n\nLocational factors without geographic coordinates\nPrimary school data, CBD coordinates, Shopping malls, Good primary schools (ranking by popularity).\nCSV/Other Sources"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#installing-and-launching-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#installing-and-launching-the-r-packages",
    "title": "8A: Geographically Weighted Predictive Models",
    "section": "\n5 Installing and Launching the R Packages",
    "text": "5 Installing and Launching the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\nsf\nHandles vector-based geospatial data.\nImporting and manipulating polygon and point feature data.\n\n\nspdep\nProvides functions for spatial dependence analysis, including spatial weights and spatial autocorrelation.\nPerforming spatially constrained cluster analysis using geographically weighted regression (GWR).\n\n\nGWmodel\nProvides geographically weighted modeling methods.\nCalibrating models to predict HDB resale prices using geographically weighted regression.\n\n\nSpatialML\nSupports geographical random forest models and spatial machine learning methods.\nCalibrating models using geographically weighted random forest (GW RF).\n\n\ntmap\nCreates static and interactive thematic maps.\nVisualizing geospatial data, model predictions, and other geographic patterns.\n\n\nrsample\nProvides tools for data resampling.\nSplitting datasets into training and testing subsets.\n\n\nMetrics\nProvides evaluation metrics for statistical and machine learning models.\nCalculating RMSE (Root Mean Square Error) to evaluate model accuracy.\n\n\ntidyverse\nA collection of packages for data science tasks such as data manipulation, visualization, and modeling.\nData wrangling, visualization, and performing statistical operations on datasets.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(sf, spdep, GWmodel, SpatialML, tmap, rsample, Metrics, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#import-data-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#import-data-and-preparation",
    "title": "8A: Geographically Weighted Predictive Models",
    "section": "\n6 Import Data and Preparation",
    "text": "6 Import Data and Preparation\n\n6.1 Reading Data File\nWe begin by loading the input data, which is stored as a simple feature data frame.\n\nmdata &lt;- read_rds(\"data/aspatial/mdata.rds\")\n\n\n6.2 Data Sampling\nThe data is split into 65% training and 35% test sets using the initial_split() function from the rsample package (part of tidymodels).\n\nset.seed(1234)\n\nresale_split &lt;- initial_split(mdata, \n                              prop = 6.5/10,)\n\ntrain_data &lt;- training(resale_split)\ntest_data &lt;- testing(resale_split)\n\nSave the split datasets:\n\nwrite_rds(train_data, \"data/model/train_data.rds\")\nwrite_rds(test_data, \"data/model/test_data.rds\")\n\n\n6.3 Computing Correlation Matrix\nIt is important to check for multicollinearity using a correlation matrix before building the predictive model.\n\nmdata_nogeo &lt;- mdata %&gt;% st_drop_geometry()\ncorrplot::corrplot(cor(mdata_nogeo[, 2:17]), \n                   diag = FALSE, \n                   order = \"AOE\", \n                   tl.pos = \"td\", \n                   tl.cex = 0.5, \n                   method = \"number\", \n                   type = \"upper\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations: All correlation values are below 0.8, indicating no sign of multicollinearity.\n\n\n\n6.4 Retrieving Stored Data\nFinally, load the previously saved training and test data:\n\ntrain_data &lt;- read_rds(\"data/model/train_data.rds\")\ntest_data &lt;- read_rds(\"data/model/test_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#building-a-non-spatial-multiple-linear-regression",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#building-a-non-spatial-multiple-linear-regression",
    "title": "8A: Geographically Weighted Predictive Models",
    "section": "\n7 Building a Non-Spatial Multiple Linear Regression",
    "text": "7 Building a Non-Spatial Multiple Linear Regression\nNext, we will build a multiple linear regression (MLR) model to predict resale_price using various predictors:\n\nprice_mlr &lt;- lm(resale_price ~ \n                  floor_area_sqm +\n                  storey_order + \n                  remaining_lease_mths +\n                  PROX_CBD + \n                  PROX_ELDERLYCARE + \n                  PROX_HAWKER +\n                  PROX_MRT + \n                  PROX_PARK + \n                  #PROX_GOOD_PRISCH + \n                  PROX_MALL +\n                  #PROX_CHAS + \n                  PROX_SUPERMARKET + \n                  WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + \n                  WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                data=train_data)\n\nsummary(price_mlr)\n\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + \n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + \n    PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\nfloor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\nstorey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\nremaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\nPROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\nPROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\nPROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\nPROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\nPROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\nPROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\nPROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\nWITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\nWITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\nWITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\nWITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61650 on 10320 degrees of freedom\nMultiple R-squared:  0.7373,    Adjusted R-squared:  0.737 \nF-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16\n\n\nSave the model for future use:\n\nwrite_rds(price_mlr, \"data/model/price_mlr.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#gwr-predictive-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#gwr-predictive-method",
    "title": "8A: Geographically Weighted Predictive Models",
    "section": "\n8 GWR Predictive Method",
    "text": "8 GWR Predictive Method\nIn this section, we use Geographically Weighted Regression (GWR) to predict HDB resale prices.\n\n8.1 Converting sf Data Frame to SpatialPointsDataFrame\nConvert the training data into a SpatialPointsDataFrame for use in GWR:\n\ntrain_data_sp &lt;- as_Spatial(train_data)\ntrain_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 10335 \nextent      : 11597.31, 42623.63, 28217.39, 48741.06  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,          PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       218000,             74,            1,                  555, 0.999393538715878, 1.98943787433087e-08, 0.0333358643817954, 0.0220407324774434, 0.0441643212802781, 0.0652540365486641,                0, 6.20621206270077e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1186888,            133,           17,                 1164,  19.6500691667807,     3.30163731686804,   2.86763031236184,   2.13060636038504,   2.41313695915468,   10.6223726149914, 2.27100643784442,    0.808332738794272,     1.57131703651196,                        7,                    20, ... \n\n\n\n8.2 Computing Adaptive Bandwidth\nNext, we use bw.gwr() to compute the optimal adaptive bandwidth using cross-validation:\n\nbw_adaptive &lt;- bw.gwr(resale_price ~ \n                        floor_area_sqm +\n                        storey_order + \n                        remaining_lease_mths +\n                        PROX_CBD + \n                        PROX_ELDERLYCARE + \n                        PROX_HAWKER +\n                        PROX_MRT + \n                        PROX_PARK + \n                        #PROX_GOOD_PRISCH +\n                        PROX_MALL +\n                        #PROX_CHAS +\n                        PROX_SUPERMARKET + \n                        WITHIN_350M_KINDERGARTEN +\n                        WITHIN_350M_CHILDCARE + \n                        WITHIN_350M_BUS +\n                        WITHIN_1KM_PRISCH,\n                      data=train_data_sp,\n                      approach=\"CV\",\n                      kernel=\"gaussian\",\n                      adaptive=TRUE,\n                      longlat=FALSE)\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nBased on the output from bw.gwr() function, the optimal bandwidth is determined to be 40 neighbor points. This means the model will consider the 40 nearest neighbors when estimating parameters for a specific location.\n\n\nSave the result:\n\nwrite_rds(bw_adaptive, \"data/model/bw_adaptive.rds\")\n\n\n8.3 Constructing the Adaptive Bandwidth GWR Model\nLoad the saved bandwidth and calibrate the GWR model:\n\nbw_adaptive &lt;- read_rds(\"data/model/bw_adaptive.rds\")\nbw_adaptive\n\n[1] 40\n\n\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and Gaussian kernel as shown in the code below.\n\ngwr_adaptive &lt;- gwr.basic(formula = resale_price ~\n                            floor_area_sqm + \n                            storey_order +\n                            remaining_lease_mths + \n                            PROX_CBD + \n                            PROX_ELDERLYCARE + \n                            PROX_HAWKER +\n                            PROX_MRT + \n                            PROX_PARK +\n                            #PROX_GOOD_PRISCH +\n                            PROX_MALL + \n                            #PROX_CHAS +\n                            PROX_SUPERMARKET + \n                            WITHIN_350M_KINDERGARTEN +\n                            WITHIN_350M_CHILDCARE + \n                            WITHIN_350M_BUS +\n                            WITHIN_1KM_PRISCH,\n                          data = train_data_sp,\n                          bw = bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive = TRUE,\n                          longlat = FALSE)\n\nSave the GWR model:\n\nwrite_rds(gwr_adaptive, \"data/model/gwr_adaptive.rds\")\n\n\n8.4 Retrieving the GWR Model\nTo retrieve and display the saved GWR model:\n\ngwr_adaptive &lt;- read_rds(\"data/model/gwr_adaptive.rds\")\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-09-29 03:07:48.292409 \n   Call:\n   gwr.basic(formula = resale_price ~ floor_area_sqm + storey_order + \n    remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + \n    PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data_sp, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  resale_price\n   Independent variables:  floor_area_sqm storey_order remaining_lease_mths PROX_CBD PROX_ELDERLYCARE PROX_HAWKER PROX_MRT PROX_PARK PROX_MALL PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN WITHIN_350M_CHILDCARE WITHIN_350M_BUS WITHIN_1KM_PRISCH\n   Number of data points: 10335\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\n   Coefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\n   floor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\n   storey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\n   remaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\n   PROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\n   PROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\n   PROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\n   PROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\n   PROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\n   PROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\n   PROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\n   WITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\n   WITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\n   WITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\n   WITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 61650 on 10320 degrees of freedom\n   Multiple R-squared: 0.7373\n   Adjusted R-squared: 0.737 \n   F-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 3.922202e+13\n   Sigma(hat): 61610.08\n   AIC:  257320.2\n   AICc:  257320.3\n   BIC:  247249\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 40 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                                   Min.     1st Qu.      Median     3rd Qu.\n   Intercept                -3.2594e+08 -4.7727e+05 -8.3004e+03  5.5025e+05\n   floor_area_sqm           -2.8714e+04  1.4475e+03  2.3011e+03  3.3900e+03\n   storey_order              3.3186e+03  8.5899e+03  1.0826e+04  1.3397e+04\n   remaining_lease_mths     -1.4431e+03  2.6063e+02  3.9048e+02  5.2865e+02\n   PROX_CBD                 -1.0837e+07 -5.7697e+04 -1.3787e+04  2.6552e+04\n   PROX_ELDERLYCARE         -3.2291e+07 -4.0643e+04  1.0562e+04  6.1054e+04\n   PROX_HAWKER              -2.3985e+08 -5.1365e+04  3.0026e+03  6.4287e+04\n   PROX_MRT                 -1.1660e+07 -1.0488e+05 -4.9373e+04  5.1037e+03\n   PROX_PARK                -6.5961e+06 -4.8671e+04 -8.8128e+02  5.3498e+04\n   PROX_MALL                -1.8112e+07 -7.4238e+04 -1.3982e+04  4.9779e+04\n   PROX_SUPERMARKET         -4.5761e+06 -6.3461e+04 -1.7429e+04  3.5616e+04\n   WITHIN_350M_KINDERGARTEN -4.1881e+05 -6.0040e+03  9.0209e+01  4.7127e+03\n   WITHIN_350M_CHILDCARE    -1.0273e+05 -2.2375e+03  2.6668e+02  2.6388e+03\n   WITHIN_350M_BUS          -1.1757e+05 -1.4719e+03  1.1626e+02  1.7584e+03\n   WITHIN_1KM_PRISCH        -6.6465e+05 -5.5959e+03  2.6916e+02  5.7500e+03\n                                  Max.\n   Intercept                1.6493e+08\n   floor_area_sqm           5.0907e+04\n   storey_order             2.9537e+04\n   remaining_lease_mths     1.8119e+03\n   PROX_CBD                 2.2489e+07\n   PROX_ELDERLYCARE         8.2444e+07\n   PROX_HAWKER              5.9654e+06\n   PROX_MRT                 2.0189e+08\n   PROX_PARK                1.5224e+07\n   PROX_MALL                1.0443e+07\n   PROX_SUPERMARKET         3.8330e+06\n   WITHIN_350M_KINDERGARTEN 6.6799e+05\n   WITHIN_350M_CHILDCARE    1.0802e+05\n   WITHIN_350M_BUS          3.7313e+04\n   WITHIN_1KM_PRISCH        5.0262e+05\n   ************************Diagnostic information*************************\n   Number of data points: 10335 \n   Effective number of parameters (2trace(S) - trace(S'S)): 1730.101 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 8604.899 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 238871.8 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 237036.9 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 238209 \n   Residual sum of squares: 4.829177e+12 \n   R-square value:  0.9676571 \n   Adjusted R-square value:  0.9611535 \n\n   ***********************************************************************\n   Program stops at: 2024-09-29 03:09:04.929015 \n\n\n\n8.5 Converting Test Data to SpatialPointsDataFrame\nConvert the test data:\n\ntest_data_sp &lt;- test_data %&gt;%\n  as_Spatial()\ntest_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 5566 \nextent      : 11597.31, 42623.63, 28287.8, 48669.59  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,         PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       230888,             74,            1,                  546, 1.00583660772922, 3.34897933104965e-07, 0.0474019664161957, 0.0414043955932523, 0.0502664084494264, 0.0907500295577619,                0, 4.55547870890763e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1050000,            138,           14,                 1151,  19.632402730488,     3.30163731686804,   2.83106651960209,   2.13060636038504,   2.41313695915468,   10.6169590126272, 2.26056404492346,     0.79249074802552,     1.53786629004208,                        7,                    16, ... \n\n\n\n8.6 Computing Adaptive Bandwidth for the Test Data\nSimilarly, we use the bw.gwr() function from the GWmodel package to determine the optimal bandwidth for our GWR model on the test data.\n\ngwr_bw_test_adaptive &lt;- bw.gwr(resale_price ~ \n                                 floor_area_sqm +\n                                 storey_order + \n                                 remaining_lease_mths +\n                                 PROX_CBD + \n                                 PROX_ELDERLYCARE + \n                                 PROX_HAWKER +\n                                 PROX_MRT + \n                                 PROX_PARK + \n                                 #PROX_GOOD_PRISCH +\n                                 PROX_MALL + \n                                 #PROX_CHAS +\n                                 PROX_SUPERMARKET + \n                                 WITHIN_350M_KINDERGARTEN +\n                                 WITHIN_350M_CHILDCARE + \n                                 WITHIN_350M_BUS +\n                                 WITHIN_1KM_PRISCH,\n                               data = test_data_sp,\n                               approach = \"CV\",\n                               kernel = \"gaussian\",\n                               adaptive = TRUE,\n                               longlat = FALSE)\n\n\nwrite_rds(gwr_bw_test_adaptive, \"data/model/gwr_bw_test_adaptive.rds\")\n\n\ngwr_bw_test_adaptive &lt;- read_rds(\"data/model/gwr_bw_test_adaptive.rds\")\n\n\n8.7 Computing Predicted Values of the Test Data\nFinally, we use the gwr.predict() function from the GWmodel package to compute the predicted values of the test data based on our GWR model. We specify our formula, training data, test data, bandwidth, kernel type, and set adaptive=TRUE and longlat=FALSE.\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                        data=train_data_sp, \n                        predictdata = test_data_sp, \n                        bw=40, \n                        kernel = 'gaussian', \n                        adaptive=TRUE, \n                        longlat = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#preparing-coordinates-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#preparing-coordinates-data",
    "title": "8A: Geographically Weighted Predictive Models",
    "section": "\n9 Preparing Coordinates Data",
    "text": "9 Preparing Coordinates Data\n\n9.1 Extracting Coordinates\nThe code below extracts the x, y coordinates for the full, training, and test datasets:\n\ncoords &lt;- st_coordinates(mdata)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\n\nSave the extracted coordinates for future use:\n\ncoords_train &lt;- write_rds(coords_train, \"data/model/coords_train.rds\")\ncoords_test &lt;- write_rds(coords_test, \"data/model/coords_test.rds\")\n\n\ncoords_train &lt;- read_rds(\"data/model/coords_train.rds\")\ncoords_test &lt;- read_rds(\"data/model/coords_test.rds\")\n\n\n9.2 Dropping Geometry Field\nWe remove the geometry column from the training data using st_drop_geometry():\n\ntrain_data &lt;- train_data %&gt;% \n  st_drop_geometry()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#calibrating-random-forest-model",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#calibrating-random-forest-model",
    "title": "8A: Geographically Weighted Predictive Models",
    "section": "\n10 Calibrating Random Forest Model",
    "text": "10 Calibrating Random Forest Model\nWe will now calibrate a random forest model using the ranger package to predict HDB resale prices:\n\nset.seed(1234)\n\nrf &lt;- ranger(resale_price ~ floor_area_sqm + storey_order + \n               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n               WITHIN_1KM_PRISCH,\n             data=train_data)\n\nSave the model:\n\nwrite_rds(rf, \"data/model/rf.rds\")\n\n\nrf &lt;- read_rds(\"data/model/rf.rds\")\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       731404460 \nR squared (OOB):                  0.9493789"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#calibrating-geographical-random-forest-model",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08a.html#calibrating-geographical-random-forest-model",
    "title": "8A: Geographically Weighted Predictive Models",
    "section": "\n11 Calibrating Geographical Random Forest Model",
    "text": "11 Calibrating Geographical Random Forest Model\nWe now calibrate a geographic random forest model using grf() from the SpatialML package.\n\n11.1 Calibrating with Training Data\nCalibrate the model with an adaptive bandwidth:\n\nset.seed(1234)\ngwRF_adaptive &lt;- grf(formula = resale_price ~ floor_area_sqm + storey_order +\n                       remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +\n                       PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +\n                       PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                       WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                       WITHIN_1KM_PRISCH,\n                     dframe=train_data, \n                     bw=55,\n                     kernel=\"adaptive\",\n                     coords=coords_train)\n\nSave the model:\n\nwrite_rds(gwRF_adaptive, \"data/model/gwRF_adaptive.rds\")\n\n\ngwRF_adaptive &lt;- read_rds(\"data/model/gwRF_adaptive.rds\")\n\n\n11.2 Predicting with Test Data\n\n11.2.1 Preparing the Test Data\nCombine the test data with its coordinates:\n\ntest_data &lt;- cbind(test_data, coords_test) %&gt;% \n  st_drop_geometry()\n\n\n11.2.2 Predicting Resale Prices\nUse the trained geographical random forest model to predict prices:\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive, \n                           test_data, \n                           x.var.name = \"X\",\n                           y.var.name = \"Y\", \n                           local.w = 1,\n                           global.w = 0)\n\nSave the predicted values:\n\nGRF_pred &lt;- write_rds(gwRF_pred, \"data/model/GRF_pred.rds\")\n\n\n11.2.3 Converting Predicted Output into a Data Frame\nThe output of the predict.grf() function is a vector of predicted values. For further visualization and analysis, it’s useful to convert it into a data frame. To convert the prediction output to a data frame for analysis:\n\nGRF_pred &lt;- read_rds(\"data/model/GRF_pred.rds\")\nGRF_pred_df &lt;- as.data.frame(GRF_pred)\n\n\n# append pred values into the test data\ntest_data_p &lt;- cbind(test_data, GRF_pred_df)\n\n\nwrite_rds(test_data_p, \"data/model/test_data_p.rds\")\n\n\n11.3 Calculating Root Mean Square Error (RMSE)\nCompute RMSE to evaluate the model’s predictive accuracy:\n\ntest_data_p &lt;- read_rds(\"data/model/test_data_p.rds\")\n\nrmse(test_data_p$resale_price, \n     test_data_p$GRF_pred)\n\n[1] 27302.9\n\n\nThe lower the RMSE value, the better the predictive model is.\n\n11.4 Visualizing the Predicted Values\nCreate a scatterplot to compare actual vs. predicted resale prices:\n\nggplot(data = test_data_p, aes(x = GRF_pred, y = resale_price)) +\n  geom_point()+\n    geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"solid\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nA good predictive model should have the scatter point close to the diagonal line. The scatter plot can be also used to detect if any outliers in the model."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html",
    "title": "10A: Processing and Visualising Flow Data",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 15  Processing and Visualising Flow Data"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#exercise-10a-reference",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#exercise-10a-reference",
    "title": "10A: Processing and Visualising Flow Data",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 15  Processing and Visualising Flow Data"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#overview",
    "title": "10A: Processing and Visualising Flow Data",
    "section": "\n2 Overview",
    "text": "2 Overview\nIn this exercise, we will explore the concept of spatial interaction, and learn how to build an OD (origin/destination) matrix.\nSpatial interaction represent the flow of people, material, or information between locations in geographical space. It encompasses everything from freight shipments, energy flows, and the global trade in rare antiquities, to flight schedules, rush hour woes, and pedestrian foot traffic.\n\nAn OD matrix, or spatial interaction matrix, represents each spatial interaction as a discrete origin/destination pair, where each pair corresponds to a cell in the matrix; the rows denote the locations (centroids) of origin, and the columns represent the locations (centroids) of destination."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#learning-outcome",
    "title": "10A: Processing and Visualising Flow Data",
    "section": "\n3 Learning Outcome",
    "text": "3 Learning Outcome\n\nImport and extract OD data for a selected time interval.\nImport and save geospatial data (bus stops and planning subzones) into sf tibble data frame objects.\nPopulate planning subzone codes into bus stops sf tibble data frames.\nConstruct desire lines geospatial data from the OD data.\nVisualize passenger volume by origin and destination bus stops using the desire lines data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#the-data",
    "title": "10A: Processing and Visualising Flow Data",
    "section": "\n4 The Data",
    "text": "4 The Data\nThe following datasets will be used in this exercise:\n\n\n\n\n\n\n\nData Set\nDescription\nFormat\n\n\n\nPassenger Volume by Origin Destination Bus Stops\nOD data set representing the volume of passengers traveling between bus stops.\nCSV\n\n\nBusStop\nGeospatial data providing the locations of bus stops as of the last quarter of 2022.\nESRI Shapefile\n\n\nMPSZ-2019\nGeospatial data providing the sub-zone boundary of the URA Master Plan 2019.\nESRI Shapefile"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#installing-and-launching-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#installing-and-launching-the-r-packages",
    "title": "10A: Processing and Visualising Flow Data",
    "section": "\n5 Installing and Launching the R Packages",
    "text": "5 Installing and Launching the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\nsf\nHandles vector-based geospatial data.\nImporting, processing, and transforming geospatial data, such as bus stop locations and sub-zone boundaries.\n\n\ntidyverse\nA collection of packages for data science tasks such as data manipulation, visualization, and modeling.\nImporting and wrangling OD and geospatial data, and visualizing analysis outputs.\n\n\ntmap\nCreates static and interactive thematic maps using cartographic quality elements.\nVisualizing passenger flows and geographic clusters in a cartographic format.\n\n\nstplanr\nProvides functions for transport planning and modeling.\nCreating geographic desire lines from OD data and solving transport-related problems.\n\n\nDT\nProvides an R interface to the JavaScript library DataTables for interactive table display.\nDisplaying data tables in an interactive format within the HTML output.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(tmap, sf, DT, stplanr, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#geospatial-data-wrangling",
    "title": "10A: Processing and Visualising Flow Data",
    "section": "\n8 Geospatial Data Wrangling",
    "text": "8 Geospatial Data Wrangling\n\n8.1 Combining BusStop and MPSZ\nThe code below joins the planning subzone codes from mpsz to the bus stops in busstop:\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\n\ndatatable(head(busstop_mpsz, 10))\n\n\n\n\n\n\nnrow(busstop)\n\n[1] 5166\n\nnrow(busstop_mpsz)\n\n[1] 5161\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nst_intersection() performs a point-and-polygon overlay.\n\nselect() keeps only BUS_STOP_N and SUBZONE_C fields.\nFive bus stops outside Singapore are excluded.\n\n\n\nSave the result as an RDS file:\n\nwrite_rds(busstop_mpsz, \"data/rds/busstop_mpsz.rds\")\n\nNext, append the subzone codes to the odbus6_9 dataset:\n\nod_data &lt;- left_join(odbus6_9, busstop_mpsz, by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE, ORIGIN_SZ = SUBZONE_C, DESTIN_BS = DESTINATION_PT_CODE)\n\nCheck for duplicate records:\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n() &gt; 1) %&gt;%\n  ungroup()\n\nduplicate\n\n# A tibble: 1,464 × 4\n   ORIGIN_BS DESTIN_BS TRIPS ORIGIN_SZ\n   &lt;chr&gt;     &lt;fct&gt;     &lt;dbl&gt; &lt;chr&gt;    \n 1 09047     02029         2 ORSZ02   \n 2 09047     02029         2 ORSZ02   \n 3 09047     02049        49 ORSZ02   \n 4 09047     02049        49 ORSZ02   \n 5 09047     02089        46 ORSZ02   \n 6 09047     02089        46 ORSZ02   \n 7 09047     02151        95 ORSZ02   \n 8 09047     02151        95 ORSZ02   \n 9 09047     02161        35 ORSZ02   \n10 09047     02161        35 ORSZ02   \n# ℹ 1,454 more rows\n\n\nSince duplicates exist, we will remove them:\n\nnrow(od_data)\n\n[1] 240554\n\nod_data &lt;- unique(od_data)\nnrow(od_data)\n\n[1] 239822\n\n\nNow, append the destination subzone codes:\n\nod_data &lt;- left_join(od_data, busstop_mpsz, by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) %&gt;%\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  drop_na() %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\nod_data_fii &lt;- od_data\n\nFinally, save the cleaned data:\n\nwrite_rds(od_data_fii, \"data/rds/od_data_fii.rds\")\nod_data_fii &lt;- read_rds(\"data/rds/od_data_fii.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#aspatial-data-handling-and-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#aspatial-data-handling-and-wrangling",
    "title": "10A: Modelling Geographical Accessibility",
    "section": "\n7 Aspatial Data Handling and Wrangling",
    "text": "7 Aspatial Data Handling and Wrangling\n\n7.1 Importing Distance Matrix\nWe import the OD_Matrix.csv file using read_csv() from the readr package, which creates a tibble data frame called ODMatrix.\n\nODMatrix &lt;- read_csv(\"data/aspatial/OD_Matrix.csv\", skip = 0)\n\n\n7.2 Tidying the Distance Matrix\nThe imported ODMatrix organizes the distance matrix column-wise.\n\nhead(ODMatrix)\n\n# A tibble: 6 × 6\n  origin_id destination_id entry_cost network_cost exit_cost total_cost\n      &lt;dbl&gt;          &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1         1              1       668.       19847.      47.6     20562.\n2         1              2       668.       45027.      31.9     45727.\n3         1              3       668.       17644.     173.      18486.\n4         1              4       668.       36010.      92.2     36770.\n5         1              5       668.       31068.      64.6     31801.\n6         1              6       668.       31195.     117.      31980.\n\n\nHowever, most R modeling packages expect the matrix in a format where rows represent origins (from) and columns represent destinations (to).\nWe use pivot_wider() from the tidyr package to reshape the data from a long format to a wide format.\n\ndistmat &lt;- ODMatrix %&gt;%\n  select(origin_id, destination_id, total_cost) %&gt;%\n  pivot_wider(names_from = destination_id, values_from = total_cost) %&gt;%\n  select(-origin_id)\n\n\n7.3 Converting Distance to Kilometers\nSince the distances are in meters (due to the SVY21 projected coordinate system), we convert them to kilometers using the code below.\n\ndistmat_km &lt;- as.matrix(distmat/1000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#modelling-and-visualising-accessibility-using-hansen-method",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#modelling-and-visualising-accessibility-using-hansen-method",
    "title": "10A: Modelling Geographical Accessibility",
    "section": "\n8 Modelling and Visualising Accessibility using Hansen Method",
    "text": "8 Modelling and Visualising Accessibility using Hansen Method\n\n\n\n\n\n\nNote\n\n\n\nHansen Accessibility Model (1959) is based upon concept that the more accessible an area is to various activities and the more vacant land area has greater growth potential. It is a spatial analysis method used to measure accessibility by considering both the distance to and the capacity of services or facilities (e.g., eldercare centers). It calculates accessibility as a function of the proximity of a location to these facilities, weighted by their capacity, and decays with distance.\nFor more info: Hansen Accessibility Model - Front Desk Architects\n\n\n\n8.1 Computing Hansen’s Accessibility\nWe compute Hansen’s accessibility using the ac() function from the SpatialAcc package. The code below calculates accessibility, and the output is saved in a data frame called acc_Hansen.\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            power = 2, \n                            family = \"Hansen\"))\n\nhead(acc_Hansen)\n\n  ac.hexagons.demand..eldercare.capacity..distmat_km..power...2..\n1                                                    1.648313e-14\n2                                                    1.096143e-16\n3                                                    3.865857e-17\n4                                                    1.482856e-17\n5                                                    1.051348e-17\n6                                                    5.076391e-18\n\n\n\n8.2 Renaming Columns and Formatting Data\nThe default field names are messy, so we rename the output column to accHansen and convert the data to a tibble format.\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\nacc_Hansen &lt;- tbl_df(acc_Hansen)\n\nhead(acc_Hansen)\n\n# A tibble: 6 × 1\n  accHansen\n      &lt;dbl&gt;\n1  1.65e-14\n2  1.10e-16\n3  3.87e-17\n4  1.48e-17\n5  1.05e-17\n6  5.08e-18\n\n\n\n8.3 Joining with Hexagons Data\nWe use bind_cols() from dplyr to join the accessibility data with the hexagons simple feature data frame. The output is saved as hexagon_Hansen.\n\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)\nclass(hexagon_Hansen)\n\n[1] \"sf\"         \"data.frame\"\n\n\nNote that hexagon_Hansen is a simple feature data frame and not a typical tibble data frame.\n\n8.4 Visualising Hansen’s Accessibility\n\n8.4.1 Extracting Map Extent\nFirst, we extract the extent of the hexagons data using st_bbox() from the sf package.\n\nmapex &lt;- st_bbox(hexagons)\n\n\n8.4.2 Creating the Map\nWe use tmap to visualize accessibility to eldercare centers with Hansen’s method. The map shows accessibility in Singapore with color-coded hexagons.\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_Hansen, bbox = mapex) + \n  tm_fill(col = \"accHansen\", n = 10, style = \"quantile\",\n          border.col = \"black\", border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: Hansen method\",\n            main.title.position = \"center\", main.title.size = 2,\n            legend.outside = FALSE, legend.height = 0.45, \n            legend.width = 3.0, legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"), frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n\n\n\n\n\n\n8.5 Statistical Graphic Visualization\nIn this section, we will compare the distribution of Hansen’s accessibility values by URA Planning Region.\n\n8.5.1 Comparing Hansen’s Accessibility by Region\nWe first add the planning region field to hexagon_Hansen by spatially joining it with the mpsz dataset.\n\nhexagon_Hansen &lt;- st_join(hexagon_Hansen, mpsz, join = st_intersects)\n\nThen, we use ggplot() to visualize the distribution of Hansen’s accessibility values by URA Planning Region, using a boxplot.\n\nggplot(data=hexagon_Hansen, \n       aes(y = log(accHansen), x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", fun.y=\"mean\", colour =\"red\", size=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations: The Central Region shows the highest and most consistent accessibility, while the West Region exhibits the most variation and lower overall accessibility. The East Region has many outliers, indicating some areas with very low accessibility compared to the rest. The North-East and North Regions show moderate variation, with the North Region exhibiting more negative extremes than the North-East."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#modelling-and-visualising-accessibility-using-kd2sfca-method",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#modelling-and-visualising-accessibility-using-kd2sfca-method",
    "title": "10A: Modelling Geographical Accessibility",
    "section": "\n9 Modelling and Visualising Accessibility using KD2SFCA Method",
    "text": "9 Modelling and Visualising Accessibility using KD2SFCA Method\n\n9.1 Computing Accessibility\nWe calculate accessibility using the KD2SFCA method with the ac() function from SpatialAcc. data.frame() is used to save the output in a data frame called acc_KD2SFCA.\nNote that KD2SFCA is used for family argument.\n\nacc_KD2SFCA &lt;- data.frame(ac(hexagons$demand, eldercare$capacity, distmat_km, d0 = 50, power = 2, family = \"KD2SFCA\"))\ncolnames(acc_KD2SFCA) &lt;- \"accKD2SFCA\"\nacc_KD2SFCA &lt;- tibble::as_tibble(acc_KD2SFCA)\nhexagon_KD2SFCA &lt;- bind_cols(hexagons, acc_KD2SFCA)\n\n\n9.2 Visualizing KD2SFCA Accessibility\nWe create a map showing accessibility using the KD2SFCA method.\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_KD2SFCA, bbox = mapex) + \n  tm_fill(col = \"accKD2SFCA\", n = 10, style = \"quantile\", border.col = \"black\", border.lwd = 1) +\n  tm_shape(eldercare) + tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to Eldercare: KD2SFCA Method\", main.title.position = \"center\", main.title.size = 2)\n\n\n\n\n\n\n\n\n9.3 Statistical Graphic Visualisation\nNow, we will compare the distribution of KD2CFA accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into hexagon_KD2SFCA simple feature data frame by using the code below.\n\nhexagon_KD2SFCA &lt;- st_join(hexagon_KD2SFCA, mpsz, \n                          join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method.\n\nggplot(data=hexagon_KD2SFCA, \n       aes(y = accKD2SFCA, \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nThe Central Region stands out with significantly higher accessibility to services compared to other regions.\nMost regions have lower accessibility, with minimal differences between the East, North-East, North, and West Regions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#modelling-and-visualising-accessibility-using-spatial-accessibility-measure-sam-method",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#modelling-and-visualising-accessibility-using-spatial-accessibility-measure-sam-method",
    "title": "10A: Modelling Geographical Accessibility",
    "section": "\n10 Modelling and Visualising Accessibility using Spatial Accessibility Measure (SAM) Method",
    "text": "10 Modelling and Visualising Accessibility using Spatial Accessibility Measure (SAM) Method\n\n10.1 Computing Accessibility\nWe repeat the steps for the SAM method, using ac().\n\nacc_SAM &lt;- data.frame(ac(hexagons$demand, eldercare$capacity, distmat_km, d0 = 50, power = 2, family = \"SAM\"))\ncolnames(acc_SAM) &lt;- \"accSAM\"\nacc_SAM &lt;- tbl_df(acc_SAM)\nhexagon_SAM &lt;- bind_cols(hexagons, acc_SAM)\n\n\n10.2 Visualizing SAM Accessibility\nWe create a map to visualize SAM accessibility.\n\ntm_shape(hexagon_SAM, bbox = mapex) + \n  tm_fill(col = \"accSAM\", n = 10, style = \"quantile\", border.col = \"black\", border.lwd = 1) +\n  tm_shape(eldercare) + tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to Eldercare: SAM Method\", main.title.position = \"center\", main.title.size = 2)\n\n\n\n\n\n\n\n\n10.3 Comparing SAM Accessibility by Region\nWe add the planning region field to hexagon_SAM and visualize accessibility values using boxplots.\n\nhexagon_SAM &lt;- st_join(hexagon_SAM, mpsz, join = st_intersects)\n\nggplot(data=hexagon_SAM, \n       aes(y = accSAM, x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", fun.y=\"mean\", colour =\"red\", size=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nA relatively large number of smaller outliers indicate some areas within the Central Region have much higher accessibility than most others.\n\n\n\n\n\n\n\n\nNote\n\n\n\nOverall Observations comparing the three methods:\n\nAcross all three methods—Hansen, KD2SFCA, and SAM—the Central Region consistently had the highest accessibility values.\nThe Hansen method revealed a broader range of accessibility across the Central Region, while KD2SFCA and SAM produced similar results with fewer outliers and a more concentrated range of values."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html",
    "title": "9A: Modelling Geographical Accessibility",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 17  Modelling Geographical Accessibility"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#exercise-9a-reference",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#exercise-9a-reference",
    "title": "9A: Processing and Visualising Flow Data",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 15  Processing and Visualising Flow Data"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#overview",
    "title": "9A: Modelling Geographical Accessibility",
    "section": "\n2 Overview",
    "text": "2 Overview\nIn this exercise, we will learn to model geographical accessibility using Hansen’s potential model, Spatial Accessibility Measure (SAM), and other methods in R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#learning-outcome",
    "title": "9A: Modelling Geographical Accessibility",
    "section": "\n3 Learning Outcome",
    "text": "3 Learning Outcome\n\nImport GIS polygon data into R and save them as a simple feature data frame using the sf package.\nImport aspatial data into R and save them as a simple feature data frame using the sf package.\nCompute accessibility measures using Hansen’s potential model and Spatial Accessibility Measure (SAM).\nVisualize the accessibility measures using tmap and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#the-data",
    "title": "9A: Modelling Geographical Accessibility",
    "section": "\n4 The Data",
    "text": "4 The Data\nThe following datasets will be used in this exercise:\n\n\n\n\n\n\n\nData Set\nDescription\nFormat\n\n\n\nMP14_SUBZONE_NO_SEA_PL\nURA Master Plan 2014 subzone boundary GIS data.\nESRI Shapefile\n\n\nhexagons\nA 250m radius hexagons GIS data created using the st_make_grid() function of the sf package.\nESRI Shapefile\n\n\nELDERCARE\nGIS data showing the location of eldercare services, available in both ESRI shapefile and Google KML format.\nESRI Shapefile\n\n\nOD_Matrix\nA distance matrix with origin-destination information, including entry, network, and exit costs.\nCSV\n\n\n\n\nAll the values of the cost related fields are in metres."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#installing-and-launching-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#installing-and-launching-the-r-packages",
    "title": "9A: Modelling Geographical Accessibility",
    "section": "\n5 Installing and Launching the R Packages",
    "text": "5 Installing and Launching the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\nsf\nHandles spatial data; imports, manages, and processes vector-based geospatial data.\nImporting and transforming geospatial datasets such as subzone boundaries, hexagons, and eldercare locations.\n\n\nSpatialAcc\nProvides functions for computing geographical accessibility measures.\nCalculating Hansen’s potential model, Spatial Accessibility Measure (SAM), and other accessibility metrics.\n\n\ntidyverse\nA collection of R packages for data science tasks like data manipulation, visualization, and modeling.\nWrangling and visualizing data, including importing CSV files and performing data transformations.\n\n\ntmap\nCreates static and interactive thematic maps using cartographic quality elements.\nVisualizing accessibility measures on thematic maps.\n\n\nggplot2\nCreates data visualizations using a layered grammar of graphics.\nVisualizing statistical graphics such as histograms and boxplots of accessibility measures.\n\n\nggstatsplot\nEnhances plots with statistical details and facilitates data visualization.\nCreating statistically enriched plots for exploratory data analysis and comparing distributions.\n\n\nreshape2\nProvides tools to reshape data between wide and long formats.\nTransforming data matrices into suitable formats for modeling.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(tmap, SpatialAcc, sf, ggstatsplot, reshape2, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#preparing-the-flow-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#preparing-the-flow-data",
    "title": "9A: Processing and Visualising Flow Data",
    "section": "\n6 Preparing the Flow Data",
    "text": "6 Preparing the Flow Data\n\n6.1 Importing the OD data\nFirst, we import the Passenger Volume by Origin Destination Bus Stops dataset using read_csv() from the readr package.\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202408.csv\")\nglimpse(odbus)\n\nRows: 5,760,081\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2024-08\", \"2024-08\", \"2024-08\", \"2024-08\", \"2024-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/…\n$ TIME_PER_HOUR       &lt;dbl&gt; 18, 7, 19, 9, 5, 12, 23, 15, 12, 13, 7, 9, 17, 15,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"76201\", \"10351\", \"76061\", \"14271\", \"54581\", \"1008…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"76079\", \"13201\", \"75371\", \"07021\", \"66471\", \"1007…\n$ TOTAL_TRIPS         &lt;dbl&gt; 6, 7, 1, 2, 1, 145, 2, 78, 2, 1, 3, 1, 2, 3, 5, 3,…\n\n\nodbus tibble data frame shows that the values in ORIGIN_PT_CODE and DESTINATON_PT_CODE are in character data type, we will convert themm into factor data type.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\nglimpse(odbus)\n\nRows: 5,760,081\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2024-08\", \"2024-08\", \"2024-08\", \"2024-08\", \"2024-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/…\n$ TIME_PER_HOUR       &lt;dbl&gt; 18, 7, 19, 9, 5, 12, 23, 15, 12, 13, 7, 9, 17, 15,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 76201, 10351, 76061, 14271, 54581, 10089, 67231, 5…\n$ DESTINATION_PT_CODE &lt;fct&gt; 76079, 13201, 75371, 07021, 66471, 10079, 67179, 5…\n$ TOTAL_TRIPS         &lt;dbl&gt; 6, 7, 1, 2, 1, 145, 2, 78, 2, 1, 3, 1, 2, 3, 5, 3,…\n\n\n\n6.2 Extracting the Study Data\nFor the purpose of this exercise, we extract commuting flows on weekdays between 6 and 9 a.m. and sum the trips.\n\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE, DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\nThe table below shows the head content of odbus6_9:\n\ndatatable(head(odbus6_9, 10))\n\n\n\n\n\n\n6.3 Saving and loading the data\nWe save the filtered data for future use in RDS format.\n\nwrite_rds(odbus6_9, \"data/rds/odbus6_9.rds\")\nodbus6_9 &lt;- read_rds(\"data/rds/odbus6_9.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#working-with-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#working-with-geospatial-data",
    "title": "9A: Processing and Visualising Flow Data",
    "section": "\n7 Working with Geospatial Data",
    "text": "7 Working with Geospatial Data\nFor this exercise, two geospatial datasets will be used:\n\n\nBusStop: Contains the locations of bus stops as of Q4 2022.\n\nMPSZ-2019: Provides the sub-zone boundaries from the URA Master Plan 2019.\n\nBoth datasets are in ESRI shapefile format.\n\n7.1 Importing Geospatial Data\nThe code below imports the geospatial data:\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\", layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex09/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5166 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48285.52 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex09/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz &lt;- write_rds(mpsz, \"data/rds/mpsz.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#geospatial-data-wrangling",
    "title": "9A: Modelling Geographical Accessibility",
    "section": "\n6 Geospatial Data Wrangling",
    "text": "6 Geospatial Data Wrangling\n\n6.1 Importing Geospatial Data\nThree geospatial datasets—MP14_SUBZONE_NO_SEA_PL, hexagons, and ELDERCARE—are imported from the data/geospatial folder using the st_read() function from the sf package.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_NO_SEA_PL\")\n\nReading layer `MP14_SUBZONE_NO_SEA_PL' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex09/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nhexagons &lt;- st_read(dsn = \"data/geospatial\", layer = \"hexagons\")\n\nReading layer `hexagons' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex09/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3125 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21506.33 xmax: 50010.26 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\n\neldercare &lt;- st_read(dsn = \"data/geospatial\", layer = \"ELDERCARE\")\n\nReading layer `ELDERCARE' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex09/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 120 features and 19 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21 / Singapore TM\n\n\n\n6.2 Updating CRS Information\nWe update the Coordinate Reference System (CRS) to EPSG:3414 for all datasets.\n\nmpsz &lt;- st_transform(mpsz, 3414)\neldercare &lt;- st_transform(eldercare, 3414)\nhexagons &lt;- st_transform(hexagons, 3414)\n\nYou can verify the CRS of mpsz using st_crs():\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n6.3 Cleaning and Updating Attribute Fields\nWe remove redundant fields and add new ones. For eldercare, we add a capacity field, and for hexagons, we add a demand field, both with a constant value of 100.\n\neldercare &lt;- eldercare %&gt;%\n  select(fid, ADDRESSPOS) %&gt;%\n  mutate(capacity = 100)\n\n\nhexagons &lt;- hexagons %&gt;%\n  select(fid) %&gt;%\n  mutate(demand = 100)\n\n\n\n\n\n\n\nTip\n\n\n\nFor this exercise, a constant value of 100 is used. In practice, actual demand and capacity values should be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#visualising-spatial-interaction",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#visualising-spatial-interaction",
    "title": "9A: Processing and Visualising Flow Data",
    "section": "\n9 Visualising Spatial Interaction",
    "text": "9 Visualising Spatial Interaction\nIn this section, we will prepare a desire line by using stplanr package.\n\n9.1 Removing Intra-Zonal Flows\nWe will exclude flows within the same zone to focus on inter-zonal flows. The code below removes these intra-zonal flows:\n\nod_data_fij &lt;- od_data[od_data$ORIGIN_SZ != od_data$DESTIN_SZ,]\n\n\n\n\n\n\n\nTip\n\n\n\nThe comma in the code od_data1 &lt;- od_data[od_data$ORIGIN_SZ != od_data$DESTIN_SZ,] is crucial because it specifies that you are subsetting the rows of the data frame based on a condition, while keeping all the columns.\n\n\nSave the result for future use:\n\nwrite_rds(od_data_fij, \"data/rds/od_data_fij.rds\")\n\n\nod_data_fij &lt;- read_rds(\"data/rds/od_data_fij.rds\")\n\n\n9.2 Creating Desire Lines\n\n\n\n\n\n\nNote\n\n\n\nDesire lines are used to illustrate on a map the flows of people or goods from point to point based on the values from a matrix.\n\n\nNext, we use od2line() from the stplanr package to generate desire lines:\n\nflowLine &lt;- od2line(flow = od_data_fij, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\nflowLine\n\nSimple feature collection with 20625 features and 3 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 5105.594 ymin: 25813.33 xmax: 46654.41 ymax: 49552.79\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   ORIGIN_SZ DESTIN_SZ MORNING_PEAK                       geometry\n1     AMSZ01    AMSZ02        10895 LINESTRING (29501.77 39419....\n2     AMSZ01    AMSZ03        15626 LINESTRING (29501.77 39419....\n3     AMSZ01    AMSZ04         2865 LINESTRING (29501.77 39419....\n4     AMSZ01    AMSZ05         8166 LINESTRING (29501.77 39419....\n5     AMSZ01    AMSZ06         2309 LINESTRING (29501.77 39419....\n6     AMSZ01    AMSZ07         1446 LINESTRING (29501.77 39419....\n7     AMSZ01    AMSZ08         2572 LINESTRING (29501.77 39419....\n8     AMSZ01    AMSZ09         2380 LINESTRING (29501.77 39419....\n9     AMSZ01    AMSZ10          287 LINESTRING (29501.77 39419....\n10    AMSZ01    AMSZ11          741 LINESTRING (29501.77 39419....\n\n\nSave the generated desire lines:\n\nwrite_rds(flowLine, \"data/rds/flowLine.rds\")\n\nflowLine &lt;- read_rds(\"data/rds/flowLine.rds\")\n\n\n9.3 Filtering High-Volume Flows\nTo simplify the visual output and focus on significant flows, we filter for high-volumes flows.\n\nsummary(flowLine$MORNING_PEAK)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n     1.0     16.0     84.0    993.9    429.0 218070.0 \n\n\nFor example, we can visualize flow greater than or equal to 2000 as shown below.\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \n  # filter for 2000\n  filter(MORNING_PEAK &gt;= 2000) %&gt;%  \ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6)\n\n\n\n\n\n\n#           alpha = 0.3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html",
    "title": "9B: Calibrating Spatial Interaction Models with R",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 16  Calibrating Spatial Interaction Models with R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#exercise-9b-reference",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#exercise-9b-reference",
    "title": "9B: Calibrating Spatial Interaction Models with R",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 16  Calibrating Spatial Interaction Models with R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#overview",
    "title": "9B: Calibrating Spatial Interaction Models with R",
    "section": "\n2 Overview",
    "text": "2 Overview\nIn this exercise, we will learn to calibrate Spatial Interaction Models (SIMs) using various regression methods to determine factors affecting public bus passenger flows during the morning peak in Singapore.\nSpatial Interaction Models (SIMs) are mathematical models for estimating flows between spatial entities developed by Alan Wilson in the late 1960s and early 1970, with considerable uptake and refinement for transport modelling since then Boyce and Williams (2015).\nThere are four main types of traditional SIMs (Wilson 1971):\n\nUnconstrained\nProduction-constrained\nAttraction-constrained\nDoubly-constrained\n\nOrdinary least square (OLS), log-normal, Poisson and negative binomial (NB) regression methods have been used extensively to calibrate OD flow models by processing flow data as different types of dependent variables. In this chapter, you will gain hands-on experiences on using appropriate R packages to calibrate SIM by using there four regression methods.\n\n\n\n\n\n\nNote\n\n\n\nCalibration is the process of adjusting parameters in the model to try and get the estimates to agree with the observed data as much as possible. Adjusting the parameters is the sort of iterative process that computers are particularly good at and the goodness-of-fit statistics can be used to indicate when the optimum solution is found. Historically this process required a researcher with the requisite programming skills to write a computer algorithm to iteratively adjust each parameter, check the goodness-of-fit, and then start all over again until the goodness-of-fit statistic was maximised/minimised. (Adam Dennett, 2018)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#learning-outcome",
    "title": "9B: Calibrating Spatial Interaction Models with R",
    "section": "\n3 Learning Outcome",
    "text": "3 Learning Outcome\n\nUnderstand and apply different types of Spatial Interaction Models (SIMs).\nCalibrate SIMs using Ordinary Least Squares (OLS), log-normal, Poisson, and Negative Binomial (NB) regression methods.\nImport and prepare geospatial data using R packages such as sf and tidyverse.\nCompute a distance matrix for spatial data using the sp package.\nVisualize and compare model performance using ggplot2 and performance packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#the-data",
    "title": "9B: Calibrating Spatial Interaction Models with R",
    "section": "\n4 The Data",
    "text": "4 The Data\nThis exercise is a continuation of Hands-on Exercise 9A and the following datasets will be used in this exercise:\n\n\n\n\n\n\n\nData Set\nDescription\nFormat\n\n\n\nod_data.rds\nWeekday morning peak passenger flows at the planning subzone level.\nRDS\n\n\nmpsz.rds\nURA Master Plan 2019 Planning Subzone boundary in simple feature tibble data frame format.\nRDS\n\n\npop.csv\nAdditional attribute data file providing population information.\nCSV\n\n\n\nThese datasets will be utilized to calibrate and visualize the Spatial Interaction Models.\n\nThis exercise is a continuation from Hands-on Exercise 9A."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#installing-and-launching-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#installing-and-launching-the-r-packages",
    "title": "9B: Calibrating Spatial Interaction Models with R",
    "section": "\n5 Installing and Launching the R Packages",
    "text": "5 Installing and Launching the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\nsf\nImports, integrates, processes, and transforms vector-based geospatial data.\nHandling vector geospatial data, such as the URA Master Plan 2019 Planning Subzone boundary.\n\n\ntidyverse\nA collection of packages for data science tasks such as data manipulation, visualization, and modeling.\nImporting CSV files, wrangling data, and performing relational joins.\n\n\ntmap\nCreates static and interactive thematic maps using cartographic quality elements.\nVisualizing regional development indicators and plotting maps showing spatial relationships and patterns.\n\n\nperformance\nProvides tools to assess and compare the performance of regression models.\nComparing model performance metrics, such as R-squared and RMSE, for different spatial interaction models.\n\n\nsp\nProvides functions for spatial dependence analysis, including spatial weights and spatial autocorrelation.\nComputing spatial weights and distance matrices for geospatial data.\n\n\nggplot2\nCreates data visualizations using a layered grammar of graphics.\nPlotting histograms, scatter plots, and visualizing model fits and residuals for calibrated Spatial Interaction Models.\n\n\nreshape2\nProvides functions to reshape data between wide and long formats.\nPivoting distance matrices into long format for model calibration and analysis.\n\n\nggpubr\nProvides tools for creating and customizing publication-ready plots in ggplot2.\nCombining multiple plots into a single visual for comparing different models.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(tmap, sf, sp, performance, reshape2, ggpubr, tidyverse)\n\n\n5.1 Computing Distance Matrix\nIn spatial interaction, a distance matrix displays the distance between pairs of locations. For example, the Euclidean distance between two locations like MESZ01 and RVSZ05 is 3926.0025, and between MESZ01 and SRSZ01 is 3939.1079. An entry of 0 on the diagonal indicates that the location is compared with itself.\nFirst, import mpsz.rds into R:\n\nmpsz &lt;- read_rds(\"data/rds/mpsz.rds\")\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\nNote that it is a sf tibble dataframe object class.\n\n5.2 Converting from sf data.table to SpatialPolygonsDataFrame\nThere are at least two ways to compute the required distance matrix. One is based on sf and the other is based on sp. Past experience shown that computing distance matrix by using sf function took relatively longer time that sp method especially the data set is large. In view of this, sp method is used in the code chunks below.\nFirst as.Spatial() will be used to convert mpsz from sf tibble data frame to SpatialPolygonsDataFrame of sp object as shown in the code chunk below.\n\nmpsz_sp &lt;- as(mpsz, \"Spatial\")\nmpsz_sp\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 332 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 6\nnames       : SUBZONE_N, SUBZONE_C, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C \nmin values  : ADMIRALTY,    AMSZ01, ANG MO KIO,         AM, CENTRAL REGION,       CR \nmax values  :    YUNNAN,    YSSZ09,     YISHUN,         YS,    WEST REGION,       WR \n\n\n\n5.3 Computing the Distance Matrix\nNow, we compute the Euclidean distance between centroids of planning subzones using spDists() from the sp package.\n\n\n\n\n\n\nQ&A\n\n\n\nDo you know why the distance is calculated between two centroids of a pair of spatial polygons?\nCentroids simplify distance calculations by representing each polygon with a single point, avoiding the complexity of measuring distances between all boundary points of irregular shapes\n\n\n\ndist &lt;- spDists(mpsz_sp, longlat = FALSE)\n\nhead(dist, n = c(10, 10))\n\n           [,1]       [,2]      [,3]      [,4]       [,5]      [,6]      [,7]\n [1,]     0.000  3926.0025  3939.108 20252.964  2989.9839  1431.330 19211.836\n [2,]  3926.003     0.0000   305.737 16513.865   951.8314  5254.066 16242.523\n [3,]  3939.108   305.7370     0.000 16412.062  1045.9088  5299.849 16026.146\n [4,] 20252.964 16513.8648 16412.062     0.000 17450.3044 21665.795  7229.017\n [5,]  2989.984   951.8314  1045.909 17450.304     0.0000  4303.232 17020.916\n [6,]  1431.330  5254.0664  5299.849 21665.795  4303.2323     0.000 20617.082\n [7,] 19211.836 16242.5230 16026.146  7229.017 17020.9161 20617.082     0.000\n [8,] 14960.942 12749.4101 12477.871 11284.279 13336.0421 16281.453  5606.082\n [9,]  7515.256  7934.8082  7649.776 18427.503  7801.6163  8403.896 14810.930\n[10,]  6391.342  4975.0021  4669.295 15469.566  5226.8731  7707.091 13111.391\n           [,8]      [,9]     [,10]\n [1,] 14960.942  7515.256  6391.342\n [2,] 12749.410  7934.808  4975.002\n [3,] 12477.871  7649.776  4669.295\n [4,] 11284.279 18427.503 15469.566\n [5,] 13336.042  7801.616  5226.873\n [6,] 16281.453  8403.896  7707.091\n [7,]  5606.082 14810.930 13111.391\n [8,]     0.000  9472.024  8575.490\n [9,]  9472.024     0.000  3780.800\n[10,]  8575.490  3780.800     0.000\n\n\nThe output dist is a matrix without labeled rows and columns for the planning subzone codes.\n\n5.4 Labeling the Distance Matrix\nWe will label the rows and columns of the distance matrix using the planning subzone codes.\n\nsz_names &lt;- mpsz$SUBZONE_C\ncolnames(dist) &lt;- sz_names\nrownames(dist) &lt;- sz_names\n\n\n5.5 Pivoting the Distance Matrix\nNext, we pivot the distance matrix into a long format, where rows represent the origin and destination pairs.\n\ndistPair &lt;- melt(dist) %&gt;%\n  rename(dist = value)\nhead(distPair, 10)\n\n     Var1   Var2      dist\n1  MESZ01 MESZ01     0.000\n2  RVSZ05 MESZ01  3926.003\n3  SRSZ01 MESZ01  3939.108\n4  WISZ01 MESZ01 20252.964\n5  MUSZ02 MESZ01  2989.984\n6  MPSZ05 MESZ01  1431.330\n7  WISZ03 MESZ01 19211.836\n8  WISZ02 MESZ01 14960.942\n9  SISZ02 MESZ01  7515.256\n10 SISZ01 MESZ01  6391.342\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe within zone distance is 0.\n\n\n\n5.6 Updating Intra-Zonal Distances\nIn this section, we are going to append a constant value to replace the intra-zonal distance of 0.\nWe will select and find out the minimum value of the distance by using summary().\n\ndistPair %&gt;%\n  filter(dist &gt; 0) %&gt;%\n  summary()\n\n      Var1             Var2             dist        \n MESZ01 :   331   MESZ01 :   331   Min.   :  173.8  \n RVSZ05 :   331   RVSZ05 :   331   1st Qu.: 7149.5  \n SRSZ01 :   331   SRSZ01 :   331   Median :11890.0  \n WISZ01 :   331   WISZ01 :   331   Mean   :12229.4  \n MUSZ02 :   331   MUSZ02 :   331   3rd Qu.:16401.7  \n MPSZ05 :   331   MPSZ05 :   331   Max.   :49894.4  \n (Other):107906   (Other):107906                    \n\n\nThen, we replace intra-zonal distances (which are 0) with a constant value of 50m.\n\ndistPair$dist &lt;- ifelse(distPair$dist == 0, 50, distPair$dist)\ndistPair %&gt;%\n  summary()\n\n      Var1             Var2             dist      \n MESZ01 :   332   MESZ01 :   332   Min.   :   50  \n RVSZ05 :   332   RVSZ05 :   332   1st Qu.: 7097  \n SRSZ01 :   332   SRSZ01 :   332   Median :11864  \n WISZ01 :   332   WISZ01 :   332   Mean   :12193  \n MUSZ02 :   332   MUSZ02 :   332   3rd Qu.:16388  \n MPSZ05 :   332   MPSZ05 :   332   Max.   :49894  \n (Other):108232   (Other):108232                  \n\n\n\n5.7 Renaming Fields and Saving\nNext, qe rename the origin and destination fields for clarity.\n\ndistPair &lt;- distPair %&gt;%\n  rename(orig = Var1, dest = Var2)\n\nFinally, save the updated distance pair dataframe for future use.\n\nwrite_rds(distPair, \"data/rds/distPair.rds\")\ndistPair &lt;- read_rds(\"data/rds/distPair.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#preparing-flow-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#preparing-flow-data",
    "title": "9B: Calibrating Spatial Interaction Models with R",
    "section": "\n6 Preparing Flow Data",
    "text": "6 Preparing Flow Data\nFirst, we import the od_data from Hands-on Exercise 9A.\n\nod_data_fii &lt;- read_rds(\"data/rds/od_data_fii.rds\")\n\n\n6.1 Computing Total Passenger Trips\nNext, compute the total passenger trips between and within planning subzones.\n\nflow_data &lt;- od_data_fii %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarize(TRIPS = sum(MORNING_PEAK))\n\nDisplay the first 10 rows of flow_data:\n\nhead(flow_data, 10)\n\n\n6.2 Separating Intra-Zonal Flows\nThe code below adds two fields to flow_data, separating intra-zonal trips.\n\nflow_data$FlowNoIntra &lt;- ifelse(flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 0, flow_data$TRIPS)\nflow_data$offset &lt;- ifelse(flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 0.000001, 1)\n\n\n6.3 Combining Passenger Volume and Distance Data\nBefore we can join flow_data and distPair, we need to convert data value type of ORIGIN_SZ and DESTIN_SZ fields of flow_data dataframe into factor data type.\n\nflow_data$ORIGIN_SZ &lt;- as.factor(flow_data$ORIGIN_SZ)\nflow_data$DESTIN_SZ &lt;- as.factor(flow_data$DESTIN_SZ)\n\nThen, we can perform left join on flow_data with distPair to combine passenger volumes with distances.\n\nflow_data1 &lt;- flow_data %&gt;%\n  left_join(distPair, by = c(\"ORIGIN_SZ\" = \"orig\", \"DESTIN_SZ\" = \"dest\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#preparing-origin-and-destination-attributes",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#preparing-origin-and-destination-attributes",
    "title": "9B: Calibrating Spatial Interaction Models with R",
    "section": "\n7 Preparing Origin and Destination Attributes",
    "text": "7 Preparing Origin and Destination Attributes\nIn this section, we will prepare the origin and destination attribute data.\n\n7.1 Importing Population Data\n\npop &lt;- read_csv(\"data/aspatial/pop.csv\")\n\n\n7.2 Geospatial Data Wrangling\nJoin the population data with mpsz.\n\npop &lt;- pop %&gt;%\n  left_join(mpsz, by = c(\"PA\" = \"PLN_AREA_N\", \"SZ\" = \"SUBZONE_N\")) %&gt;%\n  select(1:6) %&gt;%\n  rename(SZ_NAME = SZ, SZ = SUBZONE_C)\n\n\n7.3 Adding Origin Attributes\nJoin population data with flow_data1 for origin attributes.\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop, by = c(ORIGIN_SZ = \"SZ\")) %&gt;%\n  rename(ORIGIN_AGE7_12 = AGE7_12, ORIGIN_AGE13_24 = AGE13_24, ORIGIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))\n\n\n7.4 Adding Destination Attributes\nJoin population data with flow_data1 for destination attributes.\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop, by = c(DESTIN_SZ = \"SZ\")) %&gt;%\n  rename(DESTIN_AGE7_12 = AGE7_12, DESTIN_AGE13_24 = AGE13_24, DESTIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))\n\n\n7.5 Saving Processed Data\nThe final output will be saved as SIM_data in RDS format.\n\nwrite_rds(flow_data1, \"data/rds/flow_data_6-9.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#calibrating-spatial-interaction-models",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09b.html#calibrating-spatial-interaction-models",
    "title": "9B: Calibrating Spatial Interaction Models with R",
    "section": "\n8 Calibrating Spatial Interaction Models",
    "text": "8 Calibrating Spatial Interaction Models\nIn this section, you will learn how to calibrate Spatial Interaction Models by using Poisson Regression method.\n\n8.1 Importing the Modelling Data\nFirstly, we will import the saved modelling data.\n\nSIM_data &lt;- read_rds(\"data/rds/flow_data_6-9.rds\")\n\n\n8.2 Visualizing the Dependent Variable\nTo visualize the dependent variable, we will plot the distribution of TRIPS using a histogram.\n\nggplot(data = SIM_data, aes(x = TRIPS)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nNotice that the distribution is highly skewed and not resemble bell shape or also known as normal distribution.\n\n\nWe can also visualize the relationship between TRIPS and distance using a scatter plot.\n\nggplot(data = SIM_data, aes(x = dist, y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nthe relationship between TRIPS and distance hardly resemble a linear relationship.\n\n\nWe can perform log-transformation on both variables to make he relationship appears more linear.\n\nggplot(data = SIM_data, aes(x = log(dist), y = log(TRIPS))) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n\n\n8.3 Handling Zero Values in Variables\nSince Poisson Regression is based of log and log 0 is undefined, it is important for us to ensure that no 0 values in the explanatory variables.\nWe will compute the summary statistics of all variables in SIM_data data frame.\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS         FlowNoIntra      \n Length:20916       Length:20916       Min.   :     1   Min.   :     0.0  \n Class :character   Class :character   1st Qu.:    17   1st Qu.:    15.0  \n Mode  :character   Mode  :character   Median :    87   Median :    81.0  \n                                       Mean   :  1178   Mean   :   980.1  \n                                       3rd Qu.:   454   3rd Qu.:   417.0  \n                                       Max.   :344039   Max.   :218070.0  \n     offset              dist       ORIGIN_AGE7_12   ORIGIN_AGE13_24\n Min.   :0.000001   Min.   :   50   Min.   :   0.0   Min.   :    0  \n 1st Qu.:1.000000   1st Qu.: 3373   1st Qu.:  50.0   1st Qu.:  100  \n Median :1.000000   Median : 6172   Median : 510.0   Median : 1130  \n Mean   :0.986087   Mean   : 6992   Mean   : 888.6   Mean   : 1954  \n 3rd Qu.:1.000000   3rd Qu.: 9918   3rd Qu.:1360.0   3rd Qu.: 3010  \n Max.   :1.000000   Max.   :26136   Max.   :6340.0   Max.   :16380  \n ORIGIN_AGE25_64 DESTIN_AGE7_12   DESTIN_AGE13_24 DESTIN_AGE25_64\n Min.   :    0   Min.   :   0.0   Min.   :    0   Min.   :    0  \n 1st Qu.:  730   1st Qu.:  10.0   1st Qu.:   60   1st Qu.:  630  \n Median : 5730   Median : 510.0   Median : 1100   Median : 5710  \n Mean   : 9092   Mean   : 854.6   Mean   : 1896   Mean   : 8829  \n 3rd Qu.:14180   3rd Qu.:1350.0   3rd Qu.: 2920   3rd Qu.:13830  \n Max.   :74610   Max.   :6340.0   Max.   :16380   Max.   :74610  \n\n\nThe print report above reveals that variables ORIGIN_AGE7_12, ORIGIN_AGE13_24, ORIGIN_AGE25_64,DESTIN_AGE7_12, DESTIN_AGE13_24, DESTIN_AGE25_64 consist of 0 values.\n\nSIM_data$DESTIN_AGE7_12 &lt;- ifelse(SIM_data$DESTIN_AGE7_12 == 0, 0.99, SIM_data$DESTIN_AGE7_12)\nSIM_data$DESTIN_AGE13_24 &lt;- ifelse(SIM_data$DESTIN_AGE13_24 == 0, 0.99, SIM_data$DESTIN_AGE13_24)\nSIM_data$DESTIN_AGE25_64 &lt;- ifelse(SIM_data$DESTIN_AGE25_64 == 0, 0.99, SIM_data$DESTIN_AGE25_64)\nSIM_data$ORIGIN_AGE7_12 &lt;- ifelse(SIM_data$ORIGIN_AGE7_12 == 0, 0.99, SIM_data$ORIGIN_AGE7_12)\nSIM_data$ORIGIN_AGE13_24 &lt;- ifelse(SIM_data$ORIGIN_AGE13_24 == 0, 0.99, SIM_data$ORIGIN_AGE13_24)\nSIM_data$ORIGIN_AGE25_64 &lt;- ifelse(SIM_data$ORIGIN_AGE25_64 == 0, 0.99, SIM_data$ORIGIN_AGE25_64)\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS         FlowNoIntra      \n Length:20916       Length:20916       Min.   :     1   Min.   :     0.0  \n Class :character   Class :character   1st Qu.:    17   1st Qu.:    15.0  \n Mode  :character   Mode  :character   Median :    87   Median :    81.0  \n                                       Mean   :  1178   Mean   :   980.1  \n                                       3rd Qu.:   454   3rd Qu.:   417.0  \n                                       Max.   :344039   Max.   :218070.0  \n     offset              dist       ORIGIN_AGE7_12    ORIGIN_AGE13_24   \n Min.   :0.000001   Min.   :   50   Min.   :   0.99   Min.   :    0.99  \n 1st Qu.:1.000000   1st Qu.: 3373   1st Qu.:  50.00   1st Qu.:  100.00  \n Median :1.000000   Median : 6172   Median : 510.00   Median : 1130.00  \n Mean   :0.986087   Mean   : 6992   Mean   : 888.77   Mean   : 1954.26  \n 3rd Qu.:1.000000   3rd Qu.: 9918   3rd Qu.:1360.00   3rd Qu.: 3010.00  \n Max.   :1.000000   Max.   :26136   Max.   :6340.00   Max.   :16380.00  \n ORIGIN_AGE25_64    DESTIN_AGE7_12    DESTIN_AGE13_24    DESTIN_AGE25_64   \n Min.   :    0.99   Min.   :   0.99   Min.   :    0.99   Min.   :    0.99  \n 1st Qu.:  730.00   1st Qu.:  10.00   1st Qu.:   60.00   1st Qu.:  630.00  \n Median : 5730.00   Median : 510.00   Median : 1100.00   Median : 5710.00  \n Mean   : 9092.13   Mean   : 854.82   Mean   : 1896.17   Mean   : 8829.27  \n 3rd Qu.:14180.00   3rd Qu.:1350.00   3rd Qu.: 2920.00   3rd Qu.:13830.00  \n Max.   :74610.00   Max.   :6340.00   Max.   :16380.00   Max.   :74610.00  \n\n\nAll the 0 values have been replaced by 0.99.\n\n8.4 Unconstrained Spatial Interaction Model\nIn this section, we will calibrate an unconstrained spatial interaction model by using glm() of Base Stats.\n\n\n\n\n\n\nNote\n\n\n\nThe general formula of Unconstrained Spatial Interaction Model\n\\(\\lambda_{ij} = \\exp \\left( k + \\mu \\ln V_i + \\alpha \\ln W_j - \\beta \\ln d_{ij} \\right)\\)\n\n\nThe explanatory variables are origin population by different age cohort, destination population by different age cohort (i.e. ORIGIN_AGE25_64) and distance between origin and destination in km (i.e. dist). To fit an unconstrained Spatial Interaction Model using Poisson regression:\n\nuncSIM &lt;- glm(formula = TRIPS ~ log(ORIGIN_AGE25_64) + log(DESTIN_AGE25_64) + log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nuncSIM\n\n\nCall:  glm(formula = TRIPS ~ log(ORIGIN_AGE25_64) + log(DESTIN_AGE25_64) + \n    log(dist), family = poisson(link = \"log\"), data = SIM_data, \n    na.action = na.exclude)\n\nCoefficients:\n         (Intercept)  log(ORIGIN_AGE25_64)  log(DESTIN_AGE25_64)  \n            10.58389               0.26347               0.02567  \n           log(dist)  \n            -0.73018  \n\nDegrees of Freedom: 20915 Total (i.e. Null);  20912 Residual\nNull Deviance:      105500000 \nResidual Deviance: 62360000     AIC: 62490000\n\n\n\n8.5 Calculating R-squared for Unconstrained SIM\nIn order to measure how much variation of the trips can be accounted by the model, we will define a function to calculate R-squared and apply it to the model.\n\nCalcRSquared &lt;- function(observed, estimated){\n  r &lt;- cor(observed, estimated)\n  r^2\n}\n\nThen, we will calculate the R-squared of the unconstrained model.\n\nCalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)\n\n[1] 0.1938202\n\n\nAlternatively, we can calculate McFadden’s R-squared.\n\nr2_mcfadden(uncSIM)\n\n# R2 for Generalized Linear Regression\n       R2: 0.408\n  adj. R2: 0.408\n\n\n\n\n\n\n\n\nNote\n\n\n\nMcFadden’s R-squared\n\n\nInterpretation: McFadden’s R-squared is used for logistic regression models and measures the improvement of the fitted model over the null model. It is not directly comparable to the traditional R-squared.\n\nRange: McFadden’s R-squared values typically range from 0 to just under 1.\n\n\n0: The model is no better than the null model.\n\n1: The model perfectly predicts the outcome.\n\n\n\nGood Range:\n\n\n0.2 to 0.4: Considered good for logistic regression models.\n\nAbove 0.4: Indicates a very strong model.\n\n\n\n\n\n\n8.6 Origin (Production) Constrained SIM\nIn this section, we will fit an origin constrained SIM, where the trips are constrained by the origin.\n\n\n\n\n\n\nNote\n\n\n\nThe general formula of Origin Constrained Spatial Interaction Model\n\\(\\lambda_{ij} = \\exp\\left( k + \\mu_i + \\alpha \\ln W_j - \\beta \\ln d_{ij} \\right)\\)\nNotice that the difference between Unconstrained Spatial Interaction Model and this formula lies in the second term. In the Unconstrained Spatial Interaction Model formula, it is \\(\\mu \\ln V_i\\) as compared to \\(\\mu_i\\) in Origin Constrained Spatial Interaction Model.\n\n\n\norcSIM &lt;- glm(formula = TRIPS ~ ORIGIN_SZ + log(DESTIN_AGE25_64) + log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(orcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + log(DESTIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)           1.251e+01  3.144e-03  3977.962  &lt; 2e-16 ***\nORIGIN_SZAMSZ02       1.062e+00  3.687e-03   288.178  &lt; 2e-16 ***\nORIGIN_SZAMSZ03       6.217e-01  3.774e-03   164.747  &lt; 2e-16 ***\nORIGIN_SZAMSZ04      -2.100e-02  4.265e-03    -4.924 8.46e-07 ***\nORIGIN_SZAMSZ05      -1.778e-01  4.850e-03   -36.661  &lt; 2e-16 ***\nORIGIN_SZAMSZ06       3.340e-01  4.387e-03    76.126  &lt; 2e-16 ***\nORIGIN_SZAMSZ07      -1.141e+00  7.375e-03  -154.672  &lt; 2e-16 ***\nORIGIN_SZAMSZ08      -8.224e-01  6.804e-03  -120.871  &lt; 2e-16 ***\nORIGIN_SZAMSZ09       2.187e-01  4.538e-03    48.186  &lt; 2e-16 ***\nORIGIN_SZAMSZ10       5.139e-01  3.975e-03   129.304  &lt; 2e-16 ***\nORIGIN_SZAMSZ11      -1.476e+00  8.890e-03  -166.019  &lt; 2e-16 ***\nORIGIN_SZAMSZ12      -1.512e+00  8.974e-03  -168.491  &lt; 2e-16 ***\nORIGIN_SZBDSZ01       1.035e+00  3.647e-03   283.888  &lt; 2e-16 ***\nORIGIN_SZBDSZ02       5.114e-01  4.195e-03   121.896  &lt; 2e-16 ***\nORIGIN_SZBDSZ03       1.013e+00  3.733e-03   271.518  &lt; 2e-16 ***\nORIGIN_SZBDSZ04       1.738e+00  3.265e-03   532.437  &lt; 2e-16 ***\nORIGIN_SZBDSZ05       7.463e-01  3.713e-03   200.998  &lt; 2e-16 ***\nORIGIN_SZBDSZ06       9.612e-01  3.743e-03   256.801  &lt; 2e-16 ***\nORIGIN_SZBDSZ07      -9.204e-01  6.791e-03  -135.530  &lt; 2e-16 ***\nORIGIN_SZBDSZ08      -8.772e-01  6.694e-03  -131.044  &lt; 2e-16 ***\nORIGIN_SZBKSZ01      -2.932e-01  5.277e-03   -55.567  &lt; 2e-16 ***\nORIGIN_SZBKSZ02       4.668e-01  4.229e-03   110.382  &lt; 2e-16 ***\nORIGIN_SZBKSZ03       8.058e-01  3.924e-03   205.345  &lt; 2e-16 ***\nORIGIN_SZBKSZ04      -1.653e-03  4.828e-03    -0.342    0.732    \nORIGIN_SZBKSZ05       2.118e-02  4.537e-03     4.669 3.03e-06 ***\nORIGIN_SZBKSZ06       1.408e-01  4.826e-03    29.172  &lt; 2e-16 ***\nORIGIN_SZBKSZ07       8.012e-01  3.674e-03   218.081  &lt; 2e-16 ***\nORIGIN_SZBKSZ08       1.203e-01  4.328e-03    27.805  &lt; 2e-16 ***\nORIGIN_SZBKSZ09       8.939e-02  4.527e-03    19.745  &lt; 2e-16 ***\nORIGIN_SZBLSZ01      -1.359e+00  1.077e-02  -126.206  &lt; 2e-16 ***\nORIGIN_SZBLSZ02      -2.083e+00  1.559e-02  -133.643  &lt; 2e-16 ***\nORIGIN_SZBLSZ03      -3.206e+00  3.300e-02   -97.132  &lt; 2e-16 ***\nORIGIN_SZBLSZ04      -1.772e+00  1.577e-02  -112.360  &lt; 2e-16 ***\nORIGIN_SZBMSZ01       1.833e-01  3.973e-03    46.130  &lt; 2e-16 ***\nORIGIN_SZBMSZ02      -1.192e+00  5.701e-03  -209.042  &lt; 2e-16 ***\nORIGIN_SZBMSZ03      -3.159e-01  4.531e-03   -69.718  &lt; 2e-16 ***\nORIGIN_SZBMSZ04       2.399e-02  4.011e-03     5.980 2.23e-09 ***\nORIGIN_SZBMSZ05      -1.274e+00  6.120e-03  -208.104  &lt; 2e-16 ***\nORIGIN_SZBMSZ06      -1.756e+00  9.559e-03  -183.732  &lt; 2e-16 ***\nORIGIN_SZBMSZ07      -3.696e-01  4.489e-03   -82.352  &lt; 2e-16 ***\nORIGIN_SZBMSZ08      -4.495e-01  4.511e-03   -99.631  &lt; 2e-16 ***\nORIGIN_SZBMSZ09      -1.141e+00  5.807e-03  -196.571  &lt; 2e-16 ***\nORIGIN_SZBMSZ10      -1.193e+00  6.140e-03  -194.266  &lt; 2e-16 ***\nORIGIN_SZBMSZ11      -8.546e-01  5.373e-03  -159.060  &lt; 2e-16 ***\nORIGIN_SZBMSZ12      -1.026e+00  6.975e-03  -147.165  &lt; 2e-16 ***\nORIGIN_SZBMSZ13      -2.195e-02  4.435e-03    -4.948 7.50e-07 ***\nORIGIN_SZBMSZ14      -5.738e-01  5.292e-03  -108.430  &lt; 2e-16 ***\nORIGIN_SZBMSZ15      -3.203e-01  4.798e-03   -66.749  &lt; 2e-16 ***\nORIGIN_SZBMSZ16      -1.296e+00  6.081e-03  -213.135  &lt; 2e-16 ***\nORIGIN_SZBMSZ17      -1.756e+00  9.297e-03  -188.888  &lt; 2e-16 ***\nORIGIN_SZBPSZ01       2.254e-01  4.507e-03    50.006  &lt; 2e-16 ***\nORIGIN_SZBPSZ02       2.384e-01  4.944e-03    48.214  &lt; 2e-16 ***\nORIGIN_SZBPSZ03       5.272e-01  4.549e-03   115.887  &lt; 2e-16 ***\nORIGIN_SZBPSZ04       5.440e-01  4.077e-03   133.420  &lt; 2e-16 ***\nORIGIN_SZBPSZ05       6.051e-01  3.781e-03   160.027  &lt; 2e-16 ***\nORIGIN_SZBPSZ06      -9.856e-01  6.582e-03  -149.746  &lt; 2e-16 ***\nORIGIN_SZBPSZ07      -8.273e-01  6.535e-03  -126.592  &lt; 2e-16 ***\nORIGIN_SZBSSZ01       2.322e-03  4.357e-03     0.533    0.594    \nORIGIN_SZBSSZ02       4.265e-01  3.924e-03   108.702  &lt; 2e-16 ***\nORIGIN_SZBSSZ03       3.176e-01  3.876e-03    81.942  &lt; 2e-16 ***\nORIGIN_SZBTSZ01       9.283e-02  4.241e-03    21.890  &lt; 2e-16 ***\nORIGIN_SZBTSZ02      -9.336e-01  6.055e-03  -154.184  &lt; 2e-16 ***\nORIGIN_SZBTSZ03      -8.606e-02  4.554e-03   -18.899  &lt; 2e-16 ***\nORIGIN_SZBTSZ04      -6.871e-01  7.481e-03   -91.845  &lt; 2e-16 ***\nORIGIN_SZBTSZ05      -1.472e+00  8.267e-03  -178.077  &lt; 2e-16 ***\nORIGIN_SZBTSZ06      -6.835e-01  5.683e-03  -120.257  &lt; 2e-16 ***\nORIGIN_SZBTSZ07      -1.856e+00  8.657e-03  -214.406  &lt; 2e-16 ***\nORIGIN_SZBTSZ08      -1.019e+00  6.701e-03  -152.085  &lt; 2e-16 ***\nORIGIN_SZCCSZ01      -1.594e+00  1.065e-02  -149.672  &lt; 2e-16 ***\nORIGIN_SZCHSZ01      -1.120e+00  9.221e-03  -121.456  &lt; 2e-16 ***\nORIGIN_SZCHSZ02      -6.325e-01  6.780e-03   -93.284  &lt; 2e-16 ***\nORIGIN_SZCHSZ03       6.495e-01  4.608e-03   140.937  &lt; 2e-16 ***\nORIGIN_SZCKSZ01       4.387e-01  4.047e-03   108.404  &lt; 2e-16 ***\nORIGIN_SZCKSZ02       9.345e-01  4.067e-03   229.779  &lt; 2e-16 ***\nORIGIN_SZCKSZ03       9.446e-01  3.708e-03   254.769  &lt; 2e-16 ***\nORIGIN_SZCKSZ04       1.385e+00  3.782e-03   366.289  &lt; 2e-16 ***\nORIGIN_SZCKSZ05       1.101e+00  4.378e-03   251.560  &lt; 2e-16 ***\nORIGIN_SZCKSZ06       1.306e+00  4.171e-03   312.991  &lt; 2e-16 ***\nORIGIN_SZCLSZ01      -3.752e-01  5.690e-03   -65.937  &lt; 2e-16 ***\nORIGIN_SZCLSZ02      -1.661e+00  1.055e-02  -157.475  &lt; 2e-16 ***\nORIGIN_SZCLSZ03      -3.461e-01  5.238e-03   -66.071  &lt; 2e-16 ***\nORIGIN_SZCLSZ04       8.445e-01  3.627e-03   232.834  &lt; 2e-16 ***\nORIGIN_SZCLSZ05      -1.645e+00  1.013e-02  -162.395  &lt; 2e-16 ***\nORIGIN_SZCLSZ06       9.372e-01  3.478e-03   269.509  &lt; 2e-16 ***\nORIGIN_SZCLSZ07      -1.060e-01  4.398e-03   -24.110  &lt; 2e-16 ***\nORIGIN_SZCLSZ08       3.363e-01  4.833e-03    69.592  &lt; 2e-16 ***\nORIGIN_SZCLSZ09      -1.714e+00  1.353e-02  -126.689  &lt; 2e-16 ***\nORIGIN_SZDTSZ01      -1.720e+00  7.004e-03  -245.518  &lt; 2e-16 ***\nORIGIN_SZDTSZ02      -1.539e+00  6.422e-03  -239.640  &lt; 2e-16 ***\nORIGIN_SZDTSZ03      -2.810e+00  1.301e-02  -215.941  &lt; 2e-16 ***\nORIGIN_SZDTSZ04      -3.750e+00  9.290e-02   -40.363  &lt; 2e-16 ***\nORIGIN_SZDTSZ05      -3.057e+00  2.143e-02  -142.634  &lt; 2e-16 ***\nORIGIN_SZDTSZ06      -2.975e+00  1.737e-02  -171.216  &lt; 2e-16 ***\nORIGIN_SZDTSZ07      -1.877e+00  1.905e-02   -98.511  &lt; 2e-16 ***\nORIGIN_SZDTSZ08      -2.324e+00  9.698e-03  -239.632  &lt; 2e-16 ***\nORIGIN_SZDTSZ09      -3.034e+00  2.054e-02  -147.746  &lt; 2e-16 ***\nORIGIN_SZDTSZ10      -2.158e+00  1.036e-02  -208.287  &lt; 2e-16 ***\nORIGIN_SZDTSZ11      -2.329e+00  1.070e-02  -217.712  &lt; 2e-16 ***\nORIGIN_SZDTSZ12      -3.593e+00  2.551e-02  -140.861  &lt; 2e-16 ***\nORIGIN_SZDTSZ13      -2.397e+00  1.212e-02  -197.773  &lt; 2e-16 ***\nORIGIN_SZGLSZ01      -1.317e+00  7.123e-03  -184.848  &lt; 2e-16 ***\nORIGIN_SZGLSZ02       2.116e-01  4.067e-03    52.013  &lt; 2e-16 ***\nORIGIN_SZGLSZ03       2.050e-01  4.059e-03    50.498  &lt; 2e-16 ***\nORIGIN_SZGLSZ04       9.827e-01  3.416e-03   287.645  &lt; 2e-16 ***\nORIGIN_SZGLSZ05       6.442e-01  3.624e-03   177.781  &lt; 2e-16 ***\nORIGIN_SZHGSZ01       2.595e-01  3.998e-03    64.896  &lt; 2e-16 ***\nORIGIN_SZHGSZ02       6.162e-01  3.842e-03   160.374  &lt; 2e-16 ***\nORIGIN_SZHGSZ03       2.897e-01  4.204e-03    68.905  &lt; 2e-16 ***\nORIGIN_SZHGSZ04       9.444e-01  3.590e-03   263.071  &lt; 2e-16 ***\nORIGIN_SZHGSZ05       1.265e+00  3.527e-03   358.688  &lt; 2e-16 ***\nORIGIN_SZHGSZ06       1.062e-01  4.281e-03    24.815  &lt; 2e-16 ***\nORIGIN_SZHGSZ07       7.740e-01  3.700e-03   209.178  &lt; 2e-16 ***\nORIGIN_SZHGSZ08       2.462e-01  4.275e-03    57.586  &lt; 2e-16 ***\nORIGIN_SZHGSZ09      -5.094e-01  5.808e-03   -87.708  &lt; 2e-16 ***\nORIGIN_SZHGSZ10      -2.665e+00  3.983e-02   -66.910  &lt; 2e-16 ***\nORIGIN_SZJESZ01       3.998e-01  4.103e-03    97.427  &lt; 2e-16 ***\nORIGIN_SZJESZ02       2.755e-01  4.118e-03    66.890  &lt; 2e-16 ***\nORIGIN_SZJESZ03       2.744e-01  4.341e-03    63.207  &lt; 2e-16 ***\nORIGIN_SZJESZ04      -9.169e-01  7.072e-03  -129.657  &lt; 2e-16 ***\nORIGIN_SZJESZ05      -1.967e+00  1.188e-02  -165.550  &lt; 2e-16 ***\nORIGIN_SZJESZ06       3.359e-01  4.037e-03    83.202  &lt; 2e-16 ***\nORIGIN_SZJESZ07      -1.738e+00  9.337e-03  -186.144  &lt; 2e-16 ***\nORIGIN_SZJESZ08      -5.989e-01  8.299e-03   -72.169  &lt; 2e-16 ***\nORIGIN_SZJESZ09       4.456e-01  4.208e-03   105.910  &lt; 2e-16 ***\nORIGIN_SZJESZ10      -1.968e+00  1.632e-02  -120.552  &lt; 2e-16 ***\nORIGIN_SZJESZ11      -2.124e+00  1.681e-02  -126.318  &lt; 2e-16 ***\nORIGIN_SZJWSZ01       2.286e-01  5.369e-03    42.578  &lt; 2e-16 ***\nORIGIN_SZJWSZ02       8.915e-01  3.789e-03   235.292  &lt; 2e-16 ***\nORIGIN_SZJWSZ03       1.293e+00  3.515e-03   367.960  &lt; 2e-16 ***\nORIGIN_SZJWSZ04       1.351e+00  3.578e-03   377.520  &lt; 2e-16 ***\nORIGIN_SZJWSZ05      -1.267e+00  1.009e-02  -125.555  &lt; 2e-16 ***\nORIGIN_SZJWSZ06      -1.005e+00  8.836e-03  -113.734  &lt; 2e-16 ***\nORIGIN_SZJWSZ07      -2.587e+00  2.233e-02  -115.857  &lt; 2e-16 ***\nORIGIN_SZJWSZ08       1.978e+00  3.429e-03   576.877  &lt; 2e-16 ***\nORIGIN_SZJWSZ09       1.944e+00  3.247e-03   598.514  &lt; 2e-16 ***\nORIGIN_SZKLSZ01       1.947e-01  3.918e-03    49.689  &lt; 2e-16 ***\nORIGIN_SZKLSZ02      -4.677e-01  4.893e-03   -95.577  &lt; 2e-16 ***\nORIGIN_SZKLSZ03      -4.055e-01  4.886e-03   -82.983  &lt; 2e-16 ***\nORIGIN_SZKLSZ04      -1.639e+00  6.977e-03  -234.885  &lt; 2e-16 ***\nORIGIN_SZKLSZ05      -8.975e-01  6.538e-03  -137.284  &lt; 2e-16 ***\nORIGIN_SZKLSZ06      -5.593e-01  4.587e-03  -121.911  &lt; 2e-16 ***\nORIGIN_SZKLSZ07      -9.375e-01  6.042e-03  -155.160  &lt; 2e-16 ***\nORIGIN_SZKLSZ08      -8.039e-01  5.230e-03  -153.703  &lt; 2e-16 ***\nORIGIN_SZKLSZ09      -1.545e+00  6.681e-03  -231.271  &lt; 2e-16 ***\nORIGIN_SZLKSZ01      -2.964e+00  2.862e-02  -103.566  &lt; 2e-16 ***\nORIGIN_SZMDSZ01      -2.428e+00  2.166e-02  -112.061  &lt; 2e-16 ***\nORIGIN_SZMDSZ02      -1.119e+00  9.861e-03  -113.450  &lt; 2e-16 ***\nORIGIN_SZMDSZ03      -1.830e+00  1.316e-02  -138.979  &lt; 2e-16 ***\nORIGIN_SZMPSZ01      -9.639e-01  6.419e-03  -150.164  &lt; 2e-16 ***\nORIGIN_SZMPSZ02      -4.675e-01  5.349e-03   -87.390  &lt; 2e-16 ***\nORIGIN_SZMPSZ03       1.260e-01  4.248e-03    29.670  &lt; 2e-16 ***\nORIGIN_SZMSSZ01      -7.329e+00  2.673e-01   -27.422  &lt; 2e-16 ***\nORIGIN_SZMUSZ01      -1.240e+00  5.753e-03  -215.628  &lt; 2e-16 ***\nORIGIN_SZMUSZ02      -3.100e+00  1.434e-02  -216.222  &lt; 2e-16 ***\nORIGIN_SZMUSZ03      -1.786e+00  6.783e-03  -263.255  &lt; 2e-16 ***\nORIGIN_SZNTSZ01      -2.286e+00  2.415e-02   -94.639  &lt; 2e-16 ***\nORIGIN_SZNTSZ02      -2.401e+00  1.230e-02  -195.268  &lt; 2e-16 ***\nORIGIN_SZNTSZ03      -7.543e-01  5.755e-03  -131.074  &lt; 2e-16 ***\nORIGIN_SZNTSZ05      -3.114e+00  3.721e-02   -83.706  &lt; 2e-16 ***\nORIGIN_SZNTSZ06      -3.415e+00  4.002e-02   -85.338  &lt; 2e-16 ***\nORIGIN_SZNVSZ01       6.885e-01  3.551e-03   193.889  &lt; 2e-16 ***\nORIGIN_SZNVSZ02      -4.131e-01  4.796e-03   -86.147  &lt; 2e-16 ***\nORIGIN_SZNVSZ03      -1.054e+00  5.897e-03  -178.743  &lt; 2e-16 ***\nORIGIN_SZNVSZ04      -1.291e+00  7.055e-03  -182.959  &lt; 2e-16 ***\nORIGIN_SZNVSZ05      -2.522e+00  1.287e-02  -195.929  &lt; 2e-16 ***\nORIGIN_SZORSZ01      -2.858e+00  2.619e-02  -109.108  &lt; 2e-16 ***\nORIGIN_SZORSZ02      -1.160e+00  5.665e-03  -204.808  &lt; 2e-16 ***\nORIGIN_SZORSZ03      -1.632e+00  6.782e-03  -240.706  &lt; 2e-16 ***\nORIGIN_SZOTSZ01      -1.691e+00  7.205e-03  -234.655  &lt; 2e-16 ***\nORIGIN_SZOTSZ02      -1.755e+00  8.076e-03  -217.286  &lt; 2e-16 ***\nORIGIN_SZOTSZ03      -7.979e-01  5.279e-03  -151.147  &lt; 2e-16 ***\nORIGIN_SZOTSZ04      -7.263e-01  8.350e-03   -86.984  &lt; 2e-16 ***\nORIGIN_SZPGSZ01      -6.693e-01  9.124e-03   -73.359  &lt; 2e-16 ***\nORIGIN_SZPGSZ02      -3.145e-01  5.659e-03   -55.571  &lt; 2e-16 ***\nORIGIN_SZPGSZ03       1.146e+00  3.625e-03   315.999  &lt; 2e-16 ***\nORIGIN_SZPGSZ04       1.228e+00  3.627e-03   338.445  &lt; 2e-16 ***\nORIGIN_SZPGSZ05       4.787e-01  4.510e-03   106.145  &lt; 2e-16 ***\nORIGIN_SZPLSZ01      -4.797e-01  7.758e-03   -61.839  &lt; 2e-16 ***\nORIGIN_SZPLSZ02      -1.394e+00  1.121e-02  -124.392  &lt; 2e-16 ***\nORIGIN_SZPLSZ03      -2.963e+00  3.138e-02   -94.406  &lt; 2e-16 ***\nORIGIN_SZPLSZ04      -3.465e+00  3.524e-02   -98.323  &lt; 2e-16 ***\nORIGIN_SZPLSZ05      -2.266e+00  1.760e-02  -128.773  &lt; 2e-16 ***\nORIGIN_SZPNSZ01       1.532e+00  3.821e-03   400.912  &lt; 2e-16 ***\nORIGIN_SZPNSZ02      -5.587e-01  9.699e-03   -57.611  &lt; 2e-16 ***\nORIGIN_SZPNSZ03      -1.975e+00  1.746e-02  -113.152  &lt; 2e-16 ***\nORIGIN_SZPNSZ04      -2.601e+00  2.552e-02  -101.923  &lt; 2e-16 ***\nORIGIN_SZPNSZ05      -1.741e+00  1.729e-02  -100.694  &lt; 2e-16 ***\nORIGIN_SZPRSZ01      -6.841e-01  9.325e-03   -73.364  &lt; 2e-16 ***\nORIGIN_SZPRSZ02       1.110e+00  3.790e-03   292.835  &lt; 2e-16 ***\nORIGIN_SZPRSZ03       8.811e-01  3.786e-03   232.709  &lt; 2e-16 ***\nORIGIN_SZPRSZ04      -2.439e-01  6.099e-03   -39.986  &lt; 2e-16 ***\nORIGIN_SZPRSZ05       1.308e+00  3.625e-03   360.972  &lt; 2e-16 ***\nORIGIN_SZPRSZ06      -4.679e-01  6.803e-03   -68.781  &lt; 2e-16 ***\nORIGIN_SZPRSZ07      -2.530e+00  1.680e-02  -150.629  &lt; 2e-16 ***\nORIGIN_SZPRSZ08       1.336e-01  5.012e-03    26.655  &lt; 2e-16 ***\nORIGIN_SZQTSZ01      -3.690e-01  5.363e-03   -68.812  &lt; 2e-16 ***\nORIGIN_SZQTSZ02      -6.760e-01  5.029e-03  -134.429  &lt; 2e-16 ***\nORIGIN_SZQTSZ03      -2.233e-01  4.569e-03   -48.869  &lt; 2e-16 ***\nORIGIN_SZQTSZ04      -1.136e+00  6.204e-03  -183.037  &lt; 2e-16 ***\nORIGIN_SZQTSZ05      -1.992e-01  4.562e-03   -43.664  &lt; 2e-16 ***\nORIGIN_SZQTSZ06      -5.709e-01  5.252e-03  -108.705  &lt; 2e-16 ***\nORIGIN_SZQTSZ07      -1.532e+00  7.795e-03  -196.606  &lt; 2e-16 ***\nORIGIN_SZQTSZ08      -2.386e-01  4.733e-03   -50.403  &lt; 2e-16 ***\nORIGIN_SZQTSZ09      -5.253e-01  5.308e-03   -98.976  &lt; 2e-16 ***\nORIGIN_SZQTSZ10      -3.837e-01  5.196e-03   -73.846  &lt; 2e-16 ***\nORIGIN_SZQTSZ11      -1.313e+00  7.588e-03  -173.079  &lt; 2e-16 ***\nORIGIN_SZQTSZ12      -6.748e-01  6.337e-03  -106.488  &lt; 2e-16 ***\nORIGIN_SZQTSZ13      -8.076e-02  4.804e-03   -16.811  &lt; 2e-16 ***\nORIGIN_SZQTSZ14      -1.335e+00  7.113e-03  -187.705  &lt; 2e-16 ***\nORIGIN_SZQTSZ15      -7.194e-01  8.216e-03   -87.558  &lt; 2e-16 ***\nORIGIN_SZRCSZ01      -6.379e-01  5.283e-03  -120.740  &lt; 2e-16 ***\nORIGIN_SZRCSZ02      -2.358e+00  1.482e-02  -159.094  &lt; 2e-16 ***\nORIGIN_SZRCSZ03      -1.470e+00  7.322e-03  -200.791  &lt; 2e-16 ***\nORIGIN_SZRCSZ04      -2.219e+00  1.109e-02  -200.111  &lt; 2e-16 ***\nORIGIN_SZRCSZ05      -2.770e+00  1.341e-02  -206.629  &lt; 2e-16 ***\nORIGIN_SZRCSZ06      -4.466e-01  6.935e-03   -64.404  &lt; 2e-16 ***\nORIGIN_SZRCSZ08      -2.558e+00  1.610e-02  -158.880  &lt; 2e-16 ***\nORIGIN_SZRCSZ09      -1.978e+00  1.217e-02  -162.512  &lt; 2e-16 ***\nORIGIN_SZRCSZ10      -1.811e+00  6.993e-03  -259.015  &lt; 2e-16 ***\nORIGIN_SZRVSZ01      -2.814e+00  1.312e-02  -214.462  &lt; 2e-16 ***\nORIGIN_SZRVSZ02      -1.124e+00  6.715e-03  -167.428  &lt; 2e-16 ***\nORIGIN_SZRVSZ03      -1.888e+00  9.780e-03  -193.068  &lt; 2e-16 ***\nORIGIN_SZRVSZ04      -1.973e+00  1.378e-02  -143.142  &lt; 2e-16 ***\nORIGIN_SZRVSZ05      -2.176e+00  1.213e-02  -179.378  &lt; 2e-16 ***\nORIGIN_SZSBSZ01       7.906e-01  4.386e-03   180.258  &lt; 2e-16 ***\nORIGIN_SZSBSZ02      -5.268e-01  6.431e-03   -81.909  &lt; 2e-16 ***\nORIGIN_SZSBSZ03       1.010e+00  3.843e-03   262.897  &lt; 2e-16 ***\nORIGIN_SZSBSZ04       7.772e-01  4.361e-03   178.202  &lt; 2e-16 ***\nORIGIN_SZSBSZ05      -7.765e-02  5.496e-03   -14.128  &lt; 2e-16 ***\nORIGIN_SZSBSZ06      -1.650e+00  1.359e-02  -121.412  &lt; 2e-16 ***\nORIGIN_SZSBSZ07      -7.893e-01  9.127e-03   -86.478  &lt; 2e-16 ***\nORIGIN_SZSBSZ08      -9.503e-01  9.362e-03  -101.512  &lt; 2e-16 ***\nORIGIN_SZSBSZ09      -4.758e-01  7.016e-03   -67.806  &lt; 2e-16 ***\nORIGIN_SZSESZ02       1.165e+00  3.595e-03   323.972  &lt; 2e-16 ***\nORIGIN_SZSESZ03       1.289e+00  3.463e-03   372.373  &lt; 2e-16 ***\nORIGIN_SZSESZ04       1.019e+00  3.931e-03   259.250  &lt; 2e-16 ***\nORIGIN_SZSESZ05      -1.106e-01  4.827e-03   -22.907  &lt; 2e-16 ***\nORIGIN_SZSESZ06       9.972e-01  3.761e-03   265.133  &lt; 2e-16 ***\nORIGIN_SZSESZ07      -2.195e+00  1.404e-02  -156.357  &lt; 2e-16 ***\nORIGIN_SZSGSZ01      -8.301e-01  6.827e-03  -121.592  &lt; 2e-16 ***\nORIGIN_SZSGSZ02      -1.135e+00  8.180e-03  -138.755  &lt; 2e-16 ***\nORIGIN_SZSGSZ03       3.108e-01  4.304e-03    72.220  &lt; 2e-16 ***\nORIGIN_SZSGSZ04       3.315e-01  3.954e-03    83.844  &lt; 2e-16 ***\nORIGIN_SZSGSZ05      -1.574e+00  8.178e-03  -192.514  &lt; 2e-16 ***\nORIGIN_SZSGSZ06       4.707e-01  3.752e-03   125.452  &lt; 2e-16 ***\nORIGIN_SZSGSZ07      -5.168e-01  4.973e-03  -103.909  &lt; 2e-16 ***\nORIGIN_SZSKSZ01      -1.388e-01  6.497e-03   -21.359  &lt; 2e-16 ***\nORIGIN_SZSKSZ02       3.980e-01  4.751e-03    83.770  &lt; 2e-16 ***\nORIGIN_SZSKSZ03      -4.619e-01  6.153e-03   -75.064  &lt; 2e-16 ***\nORIGIN_SZSKSZ04      -2.355e+00  2.132e-02  -110.454  &lt; 2e-16 ***\nORIGIN_SZSKSZ05      -1.229e+00  1.245e-02   -98.702  &lt; 2e-16 ***\nORIGIN_SZSLSZ01      -3.172e+00  2.571e-02  -123.358  &lt; 2e-16 ***\nORIGIN_SZSLSZ04      -3.140e-01  5.780e-03   -54.333  &lt; 2e-16 ***\nORIGIN_SZSRSZ01      -1.508e+00  7.084e-03  -212.819  &lt; 2e-16 ***\nORIGIN_SZSRSZ02      -1.783e+00  7.222e-03  -246.939  &lt; 2e-16 ***\nORIGIN_SZSRSZ03      -2.801e+00  1.514e-02  -184.996  &lt; 2e-16 ***\nORIGIN_SZSVSZ01      -2.798e+00  2.815e-02   -99.409  &lt; 2e-16 ***\nORIGIN_SZTHSZ01      -2.986e+00  4.617e-02   -64.671  &lt; 2e-16 ***\nORIGIN_SZTHSZ03      -1.556e+00  1.269e-02  -122.621  &lt; 2e-16 ***\nORIGIN_SZTHSZ04      -3.011e+00  2.435e-02  -123.655  &lt; 2e-16 ***\nORIGIN_SZTHSZ06      -1.631e+00  1.084e-02  -150.482  &lt; 2e-16 ***\nORIGIN_SZTMSZ01       1.080e+00  4.087e-03   264.249  &lt; 2e-16 ***\nORIGIN_SZTMSZ02       2.226e+00  3.176e-03   700.906  &lt; 2e-16 ***\nORIGIN_SZTMSZ03       1.522e+00  3.389e-03   449.101  &lt; 2e-16 ***\nORIGIN_SZTMSZ04       9.516e-01  3.881e-03   245.213  &lt; 2e-16 ***\nORIGIN_SZTMSZ05      -2.458e-01  6.138e-03   -40.038  &lt; 2e-16 ***\nORIGIN_SZTNSZ01      -1.047e+00  5.897e-03  -177.587  &lt; 2e-16 ***\nORIGIN_SZTNSZ02      -1.015e+00  5.720e-03  -177.473  &lt; 2e-16 ***\nORIGIN_SZTNSZ03      -1.518e+00  7.506e-03  -202.275  &lt; 2e-16 ***\nORIGIN_SZTNSZ04      -6.469e-01  5.491e-03  -117.823  &lt; 2e-16 ***\nORIGIN_SZTPSZ01      -6.208e-01  5.132e-03  -120.979  &lt; 2e-16 ***\nORIGIN_SZTPSZ02       4.640e-01  3.614e-03   128.411  &lt; 2e-16 ***\nORIGIN_SZTPSZ03      -4.501e-01  5.102e-03   -88.218  &lt; 2e-16 ***\nORIGIN_SZTPSZ04      -2.797e-01  4.821e-03   -58.026  &lt; 2e-16 ***\nORIGIN_SZTPSZ05      -2.178e-01  4.987e-03   -43.675  &lt; 2e-16 ***\nORIGIN_SZTPSZ06       2.260e-01  5.019e-03    45.026  &lt; 2e-16 ***\nORIGIN_SZTPSZ07      -1.387e-01  5.015e-03   -27.651  &lt; 2e-16 ***\nORIGIN_SZTPSZ08      -6.925e-01  6.545e-03  -105.811  &lt; 2e-16 ***\nORIGIN_SZTPSZ09      -4.794e-01  5.358e-03   -89.465  &lt; 2e-16 ***\nORIGIN_SZTPSZ10      -3.714e-01  5.362e-03   -69.266  &lt; 2e-16 ***\nORIGIN_SZTPSZ11       2.625e-01  4.218e-03    62.229  &lt; 2e-16 ***\nORIGIN_SZTPSZ12      -4.955e-01  5.288e-03   -93.700  &lt; 2e-16 ***\nORIGIN_SZTSSZ01      -3.428e+00  3.961e-02   -86.524  &lt; 2e-16 ***\nORIGIN_SZTSSZ02       5.153e-01  5.790e-03    89.000  &lt; 2e-16 ***\nORIGIN_SZTSSZ03       5.407e-01  5.827e-03    92.803  &lt; 2e-16 ***\nORIGIN_SZTSSZ04       5.158e-01  6.000e-03    85.964  &lt; 2e-16 ***\nORIGIN_SZTSSZ05      -9.510e-01  1.122e-02   -84.796  &lt; 2e-16 ***\nORIGIN_SZTSSZ06      -1.155e+00  1.360e-02   -84.933  &lt; 2e-16 ***\nORIGIN_SZWCSZ01       3.529e-01  5.612e-03    62.877  &lt; 2e-16 ***\nORIGIN_SZWCSZ02      -2.680e+00  2.497e-02  -107.302  &lt; 2e-16 ***\nORIGIN_SZWCSZ03      -4.218e+00  1.325e-01   -31.839  &lt; 2e-16 ***\nORIGIN_SZWDSZ01       1.430e+00  3.467e-03   412.347  &lt; 2e-16 ***\nORIGIN_SZWDSZ02       1.111e+00  3.926e-03   283.079  &lt; 2e-16 ***\nORIGIN_SZWDSZ03       2.250e+00  3.358e-03   669.831  &lt; 2e-16 ***\nORIGIN_SZWDSZ04       1.192e+00  4.101e-03   290.750  &lt; 2e-16 ***\nORIGIN_SZWDSZ05       6.377e-01  4.136e-03   154.160  &lt; 2e-16 ***\nORIGIN_SZWDSZ06       1.295e+00  3.808e-03   340.102  &lt; 2e-16 ***\nORIGIN_SZWDSZ07       2.689e-01  5.407e-03    49.740  &lt; 2e-16 ***\nORIGIN_SZWDSZ08      -1.872e-01  6.132e-03   -30.533  &lt; 2e-16 ***\nORIGIN_SZWDSZ09       1.826e+00  3.498e-03   521.848  &lt; 2e-16 ***\nORIGIN_SZYSSZ01      -5.305e-02  4.658e-03   -11.389  &lt; 2e-16 ***\nORIGIN_SZYSSZ02       1.003e+00  4.134e-03   242.541  &lt; 2e-16 ***\nORIGIN_SZYSSZ03       1.997e+00  3.458e-03   577.479  &lt; 2e-16 ***\nORIGIN_SZYSSZ04       9.186e-01  3.725e-03   246.606  &lt; 2e-16 ***\nORIGIN_SZYSSZ05       1.984e-01  4.595e-03    43.178  &lt; 2e-16 ***\nORIGIN_SZYSSZ06      -8.206e-01  7.460e-03  -109.992  &lt; 2e-16 ***\nORIGIN_SZYSSZ07      -5.298e-01  7.220e-03   -73.381  &lt; 2e-16 ***\nORIGIN_SZYSSZ08      -1.277e-02  5.142e-03    -2.483    0.013 *  \nORIGIN_SZYSSZ09       1.405e+00  3.560e-03   394.739  &lt; 2e-16 ***\nlog(DESTIN_AGE25_64)  2.458e-02  6.646e-05   369.857  &lt; 2e-16 ***\nlog(dist)            -7.137e-01  1.016e-04 -7023.324  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 105499054  on 20915  degrees of freedom\nResidual deviance:  45982898  on 20605  degrees of freedom\nAIC: 46115907\n\nNumber of Fisher Scoring iterations: 7\n\n\nSimilarly, we can calculate R-squared for the origin-constrained model:\n\nCalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)\n\n[1] 0.3847416\n\n\n\n8.7 Destination Constrained\nIn this section, We will fit a destination-constrained Spatial Interaction Model (SIM).\n\n\n\n\n\n\nNote\n\n\n\nThe general formula of Destination Constrained Spatial Interaction Model\n\\(\\lambda_{ij} = \\exp \\left( k + \\mu \\ln V_i + \\alpha_i - \\beta \\ln d_{ij} \\right)\\)\nNotice that the difference between Unconstrained Spatial Interaction Model and this formula lies in the third term. In the Unconstrained Spatial Interaction Model formula, it is \\(\\alpha \\ln W_j\\) as compared to \\(\\alpha_i\\) in Destination Constrained Spatial Interaction Model.\n\n\n\ndecSIM &lt;- glm(formula = TRIPS ~\n                DESTIN_SZ +\n                log(ORIGIN_AGE25_64) +\n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(decSIM)\n\n\nCall:\nglm(formula = TRIPS ~ DESTIN_SZ + log(ORIGIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)          11.1886479  0.0027928  4006.284  &lt; 2e-16 ***\nDESTIN_SZAMSZ02       0.2047468  0.0035739    57.290  &lt; 2e-16 ***\nDESTIN_SZAMSZ03       0.2696890  0.0034700    77.720  &lt; 2e-16 ***\nDESTIN_SZAMSZ04      -0.9029147  0.0051608  -174.956  &lt; 2e-16 ***\nDESTIN_SZAMSZ05      -0.9208381  0.0048845  -188.522  &lt; 2e-16 ***\nDESTIN_SZAMSZ06      -0.7523009  0.0047388  -158.753  &lt; 2e-16 ***\nDESTIN_SZAMSZ07      -1.8644282  0.0085251  -218.699  &lt; 2e-16 ***\nDESTIN_SZAMSZ08      -0.9320542  0.0053993  -172.625  &lt; 2e-16 ***\nDESTIN_SZAMSZ09      -0.9606544  0.0051384  -186.955  &lt; 2e-16 ***\nDESTIN_SZAMSZ10       0.4367176  0.0035636   122.549  &lt; 2e-16 ***\nDESTIN_SZAMSZ11       0.1387581  0.0060108    23.085  &lt; 2e-16 ***\nDESTIN_SZAMSZ12      -0.0968912  0.0044113   -21.965  &lt; 2e-16 ***\nDESTIN_SZBDSZ01       0.5325773  0.0032062   166.106  &lt; 2e-16 ***\nDESTIN_SZBDSZ02      -0.1583330  0.0040652   -38.949  &lt; 2e-16 ***\nDESTIN_SZBDSZ03       0.0326536  0.0036002     9.070  &lt; 2e-16 ***\nDESTIN_SZBDSZ04       1.0265974  0.0029357   349.691  &lt; 2e-16 ***\nDESTIN_SZBDSZ05       0.4370921  0.0032622   133.986  &lt; 2e-16 ***\nDESTIN_SZBDSZ06       0.1411228  0.0036420    38.749  &lt; 2e-16 ***\nDESTIN_SZBDSZ07      -0.8768697  0.0072058  -121.689  &lt; 2e-16 ***\nDESTIN_SZBDSZ08      -1.4154555  0.0073628  -192.244  &lt; 2e-16 ***\nDESTIN_SZBKSZ01      -1.0792597  0.0053008  -203.605  &lt; 2e-16 ***\nDESTIN_SZBKSZ02      -0.1605882  0.0043097   -37.262  &lt; 2e-16 ***\nDESTIN_SZBKSZ03      -0.4113294  0.0044445   -92.548  &lt; 2e-16 ***\nDESTIN_SZBKSZ04       0.1040345  0.0039514    26.328  &lt; 2e-16 ***\nDESTIN_SZBKSZ05      -0.6361868  0.0045293  -140.461  &lt; 2e-16 ***\nDESTIN_SZBKSZ06      -0.8459238  0.0050627  -167.089  &lt; 2e-16 ***\nDESTIN_SZBKSZ07       0.2936470  0.0033772    86.949  &lt; 2e-16 ***\nDESTIN_SZBKSZ08      -1.0336173  0.0057054  -181.166  &lt; 2e-16 ***\nDESTIN_SZBKSZ09      -0.1990406  0.0040672   -48.938  &lt; 2e-16 ***\nDESTIN_SZBLSZ01      -0.3332097  0.0058008   -57.442  &lt; 2e-16 ***\nDESTIN_SZBLSZ02       0.6867036  0.0055489   123.755  &lt; 2e-16 ***\nDESTIN_SZBLSZ03       1.5117931  0.0059625   253.551  &lt; 2e-16 ***\nDESTIN_SZBLSZ04       0.0399457  0.0108522     3.681 0.000232 ***\nDESTIN_SZBMSZ01      -0.1382645  0.0037137   -37.231  &lt; 2e-16 ***\nDESTIN_SZBMSZ02      -0.4926028  0.0039199  -125.667  &lt; 2e-16 ***\nDESTIN_SZBMSZ03      -0.9056345  0.0047824  -189.366  &lt; 2e-16 ***\nDESTIN_SZBMSZ04      -0.5703442  0.0040984  -139.162  &lt; 2e-16 ***\nDESTIN_SZBMSZ05      -0.5916186  0.0049394  -119.775  &lt; 2e-16 ***\nDESTIN_SZBMSZ06      -1.6992029  0.0083045  -204.612  &lt; 2e-16 ***\nDESTIN_SZBMSZ07      -0.1189131  0.0036137   -32.906  &lt; 2e-16 ***\nDESTIN_SZBMSZ08      -1.0778761  0.0047721  -225.870  &lt; 2e-16 ***\nDESTIN_SZBMSZ09      -2.0275228  0.0075864  -267.257  &lt; 2e-16 ***\nDESTIN_SZBMSZ10      -1.5564968  0.0059936  -259.692  &lt; 2e-16 ***\nDESTIN_SZBMSZ11      -1.5778427  0.0059658  -264.483  &lt; 2e-16 ***\nDESTIN_SZBMSZ12      -1.0550880  0.0061596  -171.292  &lt; 2e-16 ***\nDESTIN_SZBMSZ13      -0.2495049  0.0038737   -64.410  &lt; 2e-16 ***\nDESTIN_SZBMSZ14      -1.0137466  0.0060702  -167.005  &lt; 2e-16 ***\nDESTIN_SZBMSZ15      -1.2476855  0.0056991  -218.927  &lt; 2e-16 ***\nDESTIN_SZBMSZ16      -1.6211588  0.0061126  -265.216  &lt; 2e-16 ***\nDESTIN_SZBMSZ17      -1.5085672  0.0071513  -210.951  &lt; 2e-16 ***\nDESTIN_SZBPSZ01      -0.4821870  0.0044490  -108.381  &lt; 2e-16 ***\nDESTIN_SZBPSZ02      -1.4688886  0.0071354  -205.860  &lt; 2e-16 ***\nDESTIN_SZBPSZ03      -1.1618519  0.0067027  -173.342  &lt; 2e-16 ***\nDESTIN_SZBPSZ04      -0.6445302  0.0049336  -130.641  &lt; 2e-16 ***\nDESTIN_SZBPSZ05       0.5220193  0.0032426   160.988  &lt; 2e-16 ***\nDESTIN_SZBPSZ06      -0.7705496  0.0060773  -126.790  &lt; 2e-16 ***\nDESTIN_SZBPSZ07      -0.5975374  0.0062143   -96.156  &lt; 2e-16 ***\nDESTIN_SZBSSZ01      -0.1159850  0.0036849   -31.476  &lt; 2e-16 ***\nDESTIN_SZBSSZ02      -0.7414329  0.0043019  -172.349  &lt; 2e-16 ***\nDESTIN_SZBSSZ03       0.3124431  0.0031917    97.893  &lt; 2e-16 ***\nDESTIN_SZBTSZ01       0.1570827  0.0034455    45.591  &lt; 2e-16 ***\nDESTIN_SZBTSZ02      -0.7950768  0.0055915  -142.194  &lt; 2e-16 ***\nDESTIN_SZBTSZ03      -0.1947127  0.0040495   -48.083  &lt; 2e-16 ***\nDESTIN_SZBTSZ04      -1.6039884  0.0079447  -201.895  &lt; 2e-16 ***\nDESTIN_SZBTSZ05      -0.7366517  0.0056153  -131.188  &lt; 2e-16 ***\nDESTIN_SZBTSZ06      -0.8638970  0.0050164  -172.216  &lt; 2e-16 ***\nDESTIN_SZBTSZ07      -1.9314011  0.0079429  -243.162  &lt; 2e-16 ***\nDESTIN_SZBTSZ08      -1.2455761  0.0066997  -185.914  &lt; 2e-16 ***\nDESTIN_SZCCSZ01      -0.4157153  0.0052731   -78.838  &lt; 2e-16 ***\nDESTIN_SZCHSZ01      -1.0527185  0.0073777  -142.689  &lt; 2e-16 ***\nDESTIN_SZCHSZ02      -0.0306697  0.0045975    -6.671 2.54e-11 ***\nDESTIN_SZCHSZ03       1.6952057  0.0032057   528.814  &lt; 2e-16 ***\nDESTIN_SZCKSZ01      -0.1484317  0.0040290   -36.840  &lt; 2e-16 ***\nDESTIN_SZCKSZ02      -0.4018663  0.0044007   -91.319  &lt; 2e-16 ***\nDESTIN_SZCKSZ03       0.7189825  0.0032425   221.737  &lt; 2e-16 ***\nDESTIN_SZCKSZ04      -0.6740941  0.0051090  -131.943  &lt; 2e-16 ***\nDESTIN_SZCKSZ05      -0.3100378  0.0053366   -58.096  &lt; 2e-16 ***\nDESTIN_SZCKSZ06       0.7865808  0.0037571   209.361  &lt; 2e-16 ***\nDESTIN_SZCLSZ01       0.4766029  0.0038956   122.345  &lt; 2e-16 ***\nDESTIN_SZCLSZ02      -2.2614707  0.0109131  -207.225  &lt; 2e-16 ***\nDESTIN_SZCLSZ03      -0.9662790  0.0060017  -161.000  &lt; 2e-16 ***\nDESTIN_SZCLSZ04       0.1515855  0.0035858    42.274  &lt; 2e-16 ***\nDESTIN_SZCLSZ05      -1.2509920  0.0070287  -177.983  &lt; 2e-16 ***\nDESTIN_SZCLSZ06       0.2066348  0.0033754    61.218  &lt; 2e-16 ***\nDESTIN_SZCLSZ07      -0.5707110  0.0043519  -131.139  &lt; 2e-16 ***\nDESTIN_SZCLSZ08      -0.4633052  0.0048981   -94.589  &lt; 2e-16 ***\nDESTIN_SZCLSZ09       0.3993821  0.0054058    73.880  &lt; 2e-16 ***\nDESTIN_SZDTSZ01      -0.8694081  0.0044649  -194.722  &lt; 2e-16 ***\nDESTIN_SZDTSZ02      -0.8521954  0.0043451  -196.127  &lt; 2e-16 ***\nDESTIN_SZDTSZ03      -1.0743465  0.0051507  -208.582  &lt; 2e-16 ***\nDESTIN_SZDTSZ04      -1.1505259  0.0110647  -103.981  &lt; 2e-16 ***\nDESTIN_SZDTSZ05      -1.0093612  0.0085677  -117.810  &lt; 2e-16 ***\nDESTIN_SZDTSZ06      -1.1371739  0.0058133  -195.615  &lt; 2e-16 ***\nDESTIN_SZDTSZ07      -1.9214590  0.0180651  -106.363  &lt; 2e-16 ***\nDESTIN_SZDTSZ08      -0.6971968  0.0042214  -165.156  &lt; 2e-16 ***\nDESTIN_SZDTSZ09      -1.5178484  0.0094552  -160.530  &lt; 2e-16 ***\nDESTIN_SZDTSZ10      -1.3018755  0.0075368  -172.737  &lt; 2e-16 ***\nDESTIN_SZDTSZ11      -0.8241052  0.0044947  -183.351  &lt; 2e-16 ***\nDESTIN_SZDTSZ12      -2.4402256  0.0146441  -166.636  &lt; 2e-16 ***\nDESTIN_SZDTSZ13      -1.9939705  0.0092374  -215.859  &lt; 2e-16 ***\nDESTIN_SZGLSZ01       0.0262850  0.0041498     6.334 2.39e-10 ***\nDESTIN_SZGLSZ02      -0.3074574  0.0038496   -79.867  &lt; 2e-16 ***\nDESTIN_SZGLSZ03       0.3982838  0.0032437   122.787  &lt; 2e-16 ***\nDESTIN_SZGLSZ04       0.3933413  0.0031685   124.141  &lt; 2e-16 ***\nDESTIN_SZGLSZ05       0.1442632  0.0033403    43.189  &lt; 2e-16 ***\nDESTIN_SZHGSZ01       0.4273977  0.0032226   132.624  &lt; 2e-16 ***\nDESTIN_SZHGSZ02      -0.5494812  0.0044023  -124.816  &lt; 2e-16 ***\nDESTIN_SZHGSZ03      -1.0856653  0.0052758  -205.781  &lt; 2e-16 ***\nDESTIN_SZHGSZ04      -0.2538606  0.0037451   -67.784  &lt; 2e-16 ***\nDESTIN_SZHGSZ05      -0.1395323  0.0037621   -37.089  &lt; 2e-16 ***\nDESTIN_SZHGSZ06      -0.6632432  0.0044051  -150.564  &lt; 2e-16 ***\nDESTIN_SZHGSZ07       0.2923291  0.0033875    86.296  &lt; 2e-16 ***\nDESTIN_SZHGSZ08      -0.2730755  0.0039832   -68.557  &lt; 2e-16 ***\nDESTIN_SZHGSZ09       0.2735423  0.0041633    65.704  &lt; 2e-16 ***\nDESTIN_SZHGSZ10      -3.1736449  0.0284659  -111.489  &lt; 2e-16 ***\nDESTIN_SZJESZ01      -0.1053234  0.0041515   -25.370  &lt; 2e-16 ***\nDESTIN_SZJESZ02      -0.4383285  0.0042949  -102.057  &lt; 2e-16 ***\nDESTIN_SZJESZ03      -0.5711346  0.0046960  -121.621  &lt; 2e-16 ***\nDESTIN_SZJESZ04      -0.0238346  0.0048249    -4.940 7.81e-07 ***\nDESTIN_SZJESZ05      -0.7798774  0.0074938  -104.070  &lt; 2e-16 ***\nDESTIN_SZJESZ06       0.3824640  0.0034475   110.939  &lt; 2e-16 ***\nDESTIN_SZJESZ07      -0.8847081  0.0061908  -142.907  &lt; 2e-16 ***\nDESTIN_SZJESZ08      -0.5789622  0.0064625   -89.589  &lt; 2e-16 ***\nDESTIN_SZJESZ09      -0.4456534  0.0046887   -95.049  &lt; 2e-16 ***\nDESTIN_SZJESZ10       0.7168959  0.0061692   116.205  &lt; 2e-16 ***\nDESTIN_SZJESZ11       1.0389409  0.0054888   189.285  &lt; 2e-16 ***\nDESTIN_SZJWSZ01      -0.3405028  0.0052968   -64.284  &lt; 2e-16 ***\nDESTIN_SZJWSZ02      -0.3557479  0.0045025   -79.011  &lt; 2e-16 ***\nDESTIN_SZJWSZ03       0.6822220  0.0033463   203.873  &lt; 2e-16 ***\nDESTIN_SZJWSZ04       1.0313249  0.0031431   328.118  &lt; 2e-16 ***\nDESTIN_SZJWSZ05      -0.1390898  0.0050165   -27.726  &lt; 2e-16 ***\nDESTIN_SZJWSZ06       0.4283248  0.0045931    93.255  &lt; 2e-16 ***\nDESTIN_SZJWSZ07      -0.8125529  0.0196066   -41.443  &lt; 2e-16 ***\nDESTIN_SZJWSZ08       0.4721844  0.0038233   123.502  &lt; 2e-16 ***\nDESTIN_SZJWSZ09       1.4834158  0.0028734   516.263  &lt; 2e-16 ***\nDESTIN_SZKLSZ01      -0.5939223  0.0040738  -145.792  &lt; 2e-16 ***\nDESTIN_SZKLSZ02      -0.7600734  0.0046596  -163.119  &lt; 2e-16 ***\nDESTIN_SZKLSZ03      -1.2543810  0.0051402  -244.031  &lt; 2e-16 ***\nDESTIN_SZKLSZ04      -1.7311984  0.0066049  -262.109  &lt; 2e-16 ***\nDESTIN_SZKLSZ05      -1.1216909  0.0066398  -168.935  &lt; 2e-16 ***\nDESTIN_SZKLSZ06      -0.9437123  0.0044840  -210.462  &lt; 2e-16 ***\nDESTIN_SZKLSZ07      -1.0592925  0.0050379  -210.265  &lt; 2e-16 ***\nDESTIN_SZKLSZ08      -0.1414796  0.0036529   -38.731  &lt; 2e-16 ***\nDESTIN_SZKLSZ09      -1.8622768  0.0066005  -282.142  &lt; 2e-16 ***\nDESTIN_SZLKSZ01      -1.6806379  0.0192395   -87.353  &lt; 2e-16 ***\nDESTIN_SZMDSZ01      -1.2927817  0.0158848   -81.385  &lt; 2e-16 ***\nDESTIN_SZMDSZ02      -1.1068976  0.0093181  -118.790  &lt; 2e-16 ***\nDESTIN_SZMDSZ03      -2.8169619  0.0208242  -135.274  &lt; 2e-16 ***\nDESTIN_SZMPSZ01      -1.2490736  0.0064894  -192.478  &lt; 2e-16 ***\nDESTIN_SZMPSZ02      -0.8411939  0.0048205  -174.505  &lt; 2e-16 ***\nDESTIN_SZMPSZ03      -0.1963932  0.0039391   -49.858  &lt; 2e-16 ***\nDESTIN_SZMSSZ01      -3.7028759  0.0680912   -54.381  &lt; 2e-16 ***\nDESTIN_SZMUSZ01      -1.1416953  0.0048741  -234.235  &lt; 2e-16 ***\nDESTIN_SZMUSZ02      -1.4043160  0.0069637  -201.663  &lt; 2e-16 ***\nDESTIN_SZMUSZ03      -1.1249185  0.0047737  -235.647  &lt; 2e-16 ***\nDESTIN_SZNTSZ01      -2.7232365  0.0219075  -124.306  &lt; 2e-16 ***\nDESTIN_SZNTSZ02      -2.0281258  0.0087672  -231.332  &lt; 2e-16 ***\nDESTIN_SZNTSZ03      -1.1948616  0.0060363  -197.945  &lt; 2e-16 ***\nDESTIN_SZNTSZ05      -1.7337767  0.0161951  -107.056  &lt; 2e-16 ***\nDESTIN_SZNTSZ06      -3.0002577  0.0278723  -107.643  &lt; 2e-16 ***\nDESTIN_SZNVSZ01      -0.2596984  0.0035898   -72.343  &lt; 2e-16 ***\nDESTIN_SZNVSZ02      -0.4670565  0.0040847  -114.343  &lt; 2e-16 ***\nDESTIN_SZNVSZ03      -0.5798852  0.0043601  -132.998  &lt; 2e-16 ***\nDESTIN_SZNVSZ04      -2.0652499  0.0084658  -243.951  &lt; 2e-16 ***\nDESTIN_SZNVSZ05      -1.8113949  0.0072668  -249.271  &lt; 2e-16 ***\nDESTIN_SZORSZ01      -2.0102988  0.0174760  -115.032  &lt; 2e-16 ***\nDESTIN_SZORSZ02       0.0988466  0.0034722    28.468  &lt; 2e-16 ***\nDESTIN_SZORSZ03      -0.8997969  0.0047365  -189.970  &lt; 2e-16 ***\nDESTIN_SZOTSZ01      -1.5647551  0.0060744  -257.599  &lt; 2e-16 ***\nDESTIN_SZOTSZ02      -0.8001690  0.0053202  -150.401  &lt; 2e-16 ***\nDESTIN_SZOTSZ03      -1.4925670  0.0057452  -259.793  &lt; 2e-16 ***\nDESTIN_SZOTSZ04      -1.5602417  0.0082363  -189.434  &lt; 2e-16 ***\nDESTIN_SZPGSZ01      -2.1137374  0.0140083  -150.892  &lt; 2e-16 ***\nDESTIN_SZPGSZ02      -0.7896523  0.0053545  -147.475  &lt; 2e-16 ***\nDESTIN_SZPGSZ03       0.5822347  0.0032692   178.098  &lt; 2e-16 ***\nDESTIN_SZPGSZ04       0.1448694  0.0036782    39.386  &lt; 2e-16 ***\nDESTIN_SZPGSZ05      -0.8881741  0.0060384  -147.087  &lt; 2e-16 ***\nDESTIN_SZPLSZ01      -0.0795041  0.0058033   -13.700  &lt; 2e-16 ***\nDESTIN_SZPLSZ02      -1.1900069  0.0102914  -115.631  &lt; 2e-16 ***\nDESTIN_SZPLSZ03      -0.1247849  0.0084378   -14.789  &lt; 2e-16 ***\nDESTIN_SZPLSZ04      -0.2719495  0.0081384   -33.416  &lt; 2e-16 ***\nDESTIN_SZPLSZ05      -0.6771576  0.0097439   -69.496  &lt; 2e-16 ***\nDESTIN_SZPNSZ01       1.1397906  0.0042414   268.733  &lt; 2e-16 ***\nDESTIN_SZPNSZ02       1.6933075  0.0055624   304.420  &lt; 2e-16 ***\nDESTIN_SZPNSZ03       0.9586915  0.0062893   152.432  &lt; 2e-16 ***\nDESTIN_SZPNSZ04       1.7374816  0.0063491   273.659  &lt; 2e-16 ***\nDESTIN_SZPNSZ05       0.8918270  0.0092596    96.314  &lt; 2e-16 ***\nDESTIN_SZPRSZ01      -0.6266318  0.0060975  -102.768  &lt; 2e-16 ***\nDESTIN_SZPRSZ02      -0.0691388  0.0040915   -16.898  &lt; 2e-16 ***\nDESTIN_SZPRSZ03       0.7957648  0.0031463   252.920  &lt; 2e-16 ***\nDESTIN_SZPRSZ04      -0.7720323  0.0069948  -110.373  &lt; 2e-16 ***\nDESTIN_SZPRSZ05      -0.0147428  0.0038961    -3.784 0.000154 ***\nDESTIN_SZPRSZ06       0.4832118  0.0041522   116.374  &lt; 2e-16 ***\nDESTIN_SZPRSZ07      -1.5779831  0.0103602  -152.313  &lt; 2e-16 ***\nDESTIN_SZPRSZ08      -0.8342815  0.0056390  -147.948  &lt; 2e-16 ***\nDESTIN_SZQTSZ01      -1.5074560  0.0081347  -185.311  &lt; 2e-16 ***\nDESTIN_SZQTSZ02      -1.4974563  0.0059956  -249.759  &lt; 2e-16 ***\nDESTIN_SZQTSZ03      -0.8830042  0.0053218  -165.922  &lt; 2e-16 ***\nDESTIN_SZQTSZ04      -1.1472088  0.0055287  -207.500  &lt; 2e-16 ***\nDESTIN_SZQTSZ05      -0.9139073  0.0048233  -189.476  &lt; 2e-16 ***\nDESTIN_SZQTSZ06      -1.1834757  0.0052284  -226.353  &lt; 2e-16 ***\nDESTIN_SZQTSZ07      -1.6922635  0.0088214  -191.837  &lt; 2e-16 ***\nDESTIN_SZQTSZ08       0.0925004  0.0037722    24.521  &lt; 2e-16 ***\nDESTIN_SZQTSZ09      -0.3797599  0.0045808   -82.903  &lt; 2e-16 ***\nDESTIN_SZQTSZ10      -0.4079167  0.0042387   -96.235  &lt; 2e-16 ***\nDESTIN_SZQTSZ11       0.2574301  0.0040515    63.539  &lt; 2e-16 ***\nDESTIN_SZQTSZ12      -0.3365383  0.0051991   -64.730  &lt; 2e-16 ***\nDESTIN_SZQTSZ13       0.1248056  0.0039363    31.706  &lt; 2e-16 ***\nDESTIN_SZQTSZ14      -0.1509191  0.0044507   -33.909  &lt; 2e-16 ***\nDESTIN_SZQTSZ15       0.0690162  0.0054153    12.745  &lt; 2e-16 ***\nDESTIN_SZRCSZ01      -1.0906712  0.0051802  -210.548  &lt; 2e-16 ***\nDESTIN_SZRCSZ02      -2.2359026  0.0135798  -164.649  &lt; 2e-16 ***\nDESTIN_SZRCSZ03      -1.1174100  0.0070391  -158.744  &lt; 2e-16 ***\nDESTIN_SZRCSZ04      -2.4568960  0.0102337  -240.080  &lt; 2e-16 ***\nDESTIN_SZRCSZ05      -2.3552607  0.0095366  -246.970  &lt; 2e-16 ***\nDESTIN_SZRCSZ06      -2.1550501  0.0124313  -173.356  &lt; 2e-16 ***\nDESTIN_SZRCSZ08      -2.0841001  0.0102626  -203.077  &lt; 2e-16 ***\nDESTIN_SZRCSZ09      -1.5747291  0.0094616  -166.434  &lt; 2e-16 ***\nDESTIN_SZRCSZ10      -1.1849003  0.0051385  -230.594  &lt; 2e-16 ***\nDESTIN_SZRVSZ01      -2.1529608  0.0085900  -250.637  &lt; 2e-16 ***\nDESTIN_SZRVSZ02      -2.4492143  0.0117753  -207.996  &lt; 2e-16 ***\nDESTIN_SZRVSZ03      -2.4222717  0.0100597  -240.790  &lt; 2e-16 ***\nDESTIN_SZRVSZ04      -1.7371692  0.0114377  -151.881  &lt; 2e-16 ***\nDESTIN_SZRVSZ05      -2.0839854  0.0111068  -187.632  &lt; 2e-16 ***\nDESTIN_SZSBSZ01      -0.0294186  0.0046753    -6.292 3.13e-10 ***\nDESTIN_SZSBSZ02      -0.9958381  0.0062222  -160.046  &lt; 2e-16 ***\nDESTIN_SZSBSZ03       0.7158194  0.0034449   207.793  &lt; 2e-16 ***\nDESTIN_SZSBSZ04       0.1191755  0.0043864    27.169  &lt; 2e-16 ***\nDESTIN_SZSBSZ05      -0.7522878  0.0057118  -131.708  &lt; 2e-16 ***\nDESTIN_SZSBSZ06      -2.7324967  0.0215545  -126.771  &lt; 2e-16 ***\nDESTIN_SZSBSZ07      -0.7273121  0.0152820   -47.593  &lt; 2e-16 ***\nDESTIN_SZSBSZ08       1.5312821  0.0041649   367.666  &lt; 2e-16 ***\nDESTIN_SZSBSZ09       0.8296969  0.0041401   200.405  &lt; 2e-16 ***\nDESTIN_SZSESZ02      -0.1094068  0.0038531   -28.395  &lt; 2e-16 ***\nDESTIN_SZSESZ03       0.7051751  0.0030797   228.975  &lt; 2e-16 ***\nDESTIN_SZSESZ04      -0.4959627  0.0043902  -112.970  &lt; 2e-16 ***\nDESTIN_SZSESZ05      -0.1095390  0.0037931   -28.879  &lt; 2e-16 ***\nDESTIN_SZSESZ06      -0.5019247  0.0047087  -106.594  &lt; 2e-16 ***\nDESTIN_SZSESZ07      -2.8784581  0.0198656  -144.897  &lt; 2e-16 ***\nDESTIN_SZSGSZ01      -0.4217244  0.0048327   -87.264  &lt; 2e-16 ***\nDESTIN_SZSGSZ02       0.0522081  0.0043245    12.073  &lt; 2e-16 ***\nDESTIN_SZSGSZ03      -0.3606981  0.0040326   -89.445  &lt; 2e-16 ***\nDESTIN_SZSGSZ04      -0.3212470  0.0039814   -80.687  &lt; 2e-16 ***\nDESTIN_SZSGSZ05      -1.9946206  0.0072648  -274.558  &lt; 2e-16 ***\nDESTIN_SZSGSZ06       0.4334467  0.0031411   137.991  &lt; 2e-16 ***\nDESTIN_SZSGSZ07      -0.3911286  0.0040499   -96.577  &lt; 2e-16 ***\nDESTIN_SZSISZ01      -0.9199242  0.0131178   -70.128  &lt; 2e-16 ***\nDESTIN_SZSKSZ01      -0.0948233  0.0058707   -16.152  &lt; 2e-16 ***\nDESTIN_SZSKSZ02       0.7988244  0.0041751   191.329  &lt; 2e-16 ***\nDESTIN_SZSKSZ03       0.0431353  0.0049234     8.761  &lt; 2e-16 ***\nDESTIN_SZSKSZ04      -0.6283844  0.0124899   -50.311  &lt; 2e-16 ***\nDESTIN_SZSKSZ05       0.0853350  0.0093562     9.121  &lt; 2e-16 ***\nDESTIN_SZSLSZ01      -0.3676636  0.0065766   -55.905  &lt; 2e-16 ***\nDESTIN_SZSLSZ04      -0.4556080  0.0052586   -86.641  &lt; 2e-16 ***\nDESTIN_SZSRSZ01      -1.6857168  0.0063800  -264.220  &lt; 2e-16 ***\nDESTIN_SZSRSZ02      -1.6369037  0.0074875  -218.618  &lt; 2e-16 ***\nDESTIN_SZSRSZ03      -1.5531939  0.0067905  -228.730  &lt; 2e-16 ***\nDESTIN_SZSVSZ01      -2.1265870  0.0278669   -76.312  &lt; 2e-16 ***\nDESTIN_SZTHSZ01      -2.5637337  0.0281096   -91.205  &lt; 2e-16 ***\nDESTIN_SZTHSZ03      -1.5761506  0.0171972   -91.652  &lt; 2e-16 ***\nDESTIN_SZTHSZ04      -2.2051773  0.0180679  -122.050  &lt; 2e-16 ***\nDESTIN_SZTHSZ06      -1.2196441  0.0115873  -105.257  &lt; 2e-16 ***\nDESTIN_SZTMSZ01       0.0307882  0.0042806     7.192 6.36e-13 ***\nDESTIN_SZTMSZ02       1.7151835  0.0027605   621.327  &lt; 2e-16 ***\nDESTIN_SZTMSZ03       0.7346828  0.0031466   233.481  &lt; 2e-16 ***\nDESTIN_SZTMSZ04       0.8505032  0.0032061   265.273  &lt; 2e-16 ***\nDESTIN_SZTMSZ05       0.6510306  0.0040091   162.390  &lt; 2e-16 ***\nDESTIN_SZTNSZ01      -0.7109821  0.0044663  -159.188  &lt; 2e-16 ***\nDESTIN_SZTNSZ02      -1.4620229  0.0058144  -251.447  &lt; 2e-16 ***\nDESTIN_SZTNSZ03      -1.4562412  0.0070409  -206.827  &lt; 2e-16 ***\nDESTIN_SZTNSZ04      -1.0851666  0.0054825  -197.934  &lt; 2e-16 ***\nDESTIN_SZTPSZ01      -0.5817555  0.0045298  -128.429  &lt; 2e-16 ***\nDESTIN_SZTPSZ02       0.1808566  0.0031446    57.513  &lt; 2e-16 ***\nDESTIN_SZTPSZ03      -0.4988927  0.0045255  -110.240  &lt; 2e-16 ***\nDESTIN_SZTPSZ04      -1.5628293  0.0061959  -252.235  &lt; 2e-16 ***\nDESTIN_SZTPSZ05      -0.8873261  0.0047840  -185.479  &lt; 2e-16 ***\nDESTIN_SZTPSZ06      -0.2876381  0.0053863   -53.402  &lt; 2e-16 ***\nDESTIN_SZTPSZ07      -1.7906770  0.0089538  -199.991  &lt; 2e-16 ***\nDESTIN_SZTPSZ08      -1.3194188  0.0064723  -203.855  &lt; 2e-16 ***\nDESTIN_SZTPSZ09      -0.6211985  0.0049347  -125.883  &lt; 2e-16 ***\nDESTIN_SZTPSZ10      -0.6393478  0.0059480  -107.489  &lt; 2e-16 ***\nDESTIN_SZTPSZ11      -0.3804245  0.0040839   -93.152  &lt; 2e-16 ***\nDESTIN_SZTPSZ12      -0.8566449  0.0050890  -168.331  &lt; 2e-16 ***\nDESTIN_SZTSSZ01      -0.6057724  0.0191686   -31.602  &lt; 2e-16 ***\nDESTIN_SZTSSZ02       1.0228252  0.0073989   138.240  &lt; 2e-16 ***\nDESTIN_SZTSSZ03       1.7210049  0.0054964   313.117  &lt; 2e-16 ***\nDESTIN_SZTSSZ04       1.6552387  0.0055719   297.069  &lt; 2e-16 ***\nDESTIN_SZTSSZ05       1.8953793  0.0058191   325.717  &lt; 2e-16 ***\nDESTIN_SZTSSZ06       0.9420685  0.0094085   100.130  &lt; 2e-16 ***\nDESTIN_SZWCSZ01       1.6641119  0.0036267   458.847  &lt; 2e-16 ***\nDESTIN_SZWCSZ02       0.1145004  0.0081389    14.068  &lt; 2e-16 ***\nDESTIN_SZWCSZ03      -1.2456001  0.0229509   -54.272  &lt; 2e-16 ***\nDESTIN_SZWDSZ01       1.6721786  0.0029145   573.752  &lt; 2e-16 ***\nDESTIN_SZWDSZ02      -0.2568974  0.0047005   -54.653  &lt; 2e-16 ***\nDESTIN_SZWDSZ03       1.2710250  0.0030587   415.540  &lt; 2e-16 ***\nDESTIN_SZWDSZ04       0.2153072  0.0044239    48.669  &lt; 2e-16 ***\nDESTIN_SZWDSZ05       0.2343907  0.0042605    55.015  &lt; 2e-16 ***\nDESTIN_SZWDSZ06       0.5955289  0.0033837   176.001  &lt; 2e-16 ***\nDESTIN_SZWDSZ07       1.2712699  0.0042065   302.217  &lt; 2e-16 ***\nDESTIN_SZWDSZ08       0.7528739  0.0050831   148.112  &lt; 2e-16 ***\nDESTIN_SZWDSZ09       0.7921131  0.0036639   216.196  &lt; 2e-16 ***\nDESTIN_SZYSSZ01       1.2635195  0.0031437   401.923  &lt; 2e-16 ***\nDESTIN_SZYSSZ02       0.2534000  0.0041190    61.519  &lt; 2e-16 ***\nDESTIN_SZYSSZ03      -0.0477465  0.0043261   -11.037  &lt; 2e-16 ***\nDESTIN_SZYSSZ04       0.0517178  0.0040947    12.631  &lt; 2e-16 ***\nDESTIN_SZYSSZ05      -1.5878543  0.0085780  -185.108  &lt; 2e-16 ***\nDESTIN_SZYSSZ06      -1.2417883  0.0064833  -191.535  &lt; 2e-16 ***\nDESTIN_SZYSSZ07      -0.8080207  0.0079004  -102.276  &lt; 2e-16 ***\nDESTIN_SZYSSZ08       0.7024251  0.0032453   216.443  &lt; 2e-16 ***\nDESTIN_SZYSSZ09       0.3893030  0.0033390   116.593  &lt; 2e-16 ***\nlog(ORIGIN_AGE25_64)  0.2272793  0.0001037  2191.851  &lt; 2e-16 ***\nlog(dist)            -0.7146129  0.0001018 -7020.061  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 105499054  on 20915  degrees of freedom\nResidual deviance:  44679882  on 20604  degrees of freedom\nAIC: 44812892\n\nNumber of Fisher Scoring iterations: 7\n\n\nNext, we can examine how the constraints hold for destinations this time.\n\nCalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)\n\n[1] 0.485937\n\n\n\n8.8 Doubly Constrained\nIn this section, We will fit a doubly constrained SIM.\n\n\n\n\n\n\nNote\n\n\n\nThe general formula of Doubly Constrained Spatial Interaction Model\n\\(\\lambda_{ij} = \\exp \\left( k + \\mu_i + \\alpha_i - \\beta \\ln d_{ij} \\right)\\)\nNotice that the difference between Unconstrained Spatial Interaction Model and this formula lies in the second and third term. Comparing Unconstrained Spatial Interaction Model formula and Doubly Constrained Spatial Interaction Model, it is \\(\\mu \\ln V_i\\) compared to \\(\\mu_i\\) and \\(\\alpha \\ln W_j\\) compared to \\(\\alpha_i\\) respectively.\n\n\n\ndbcSIM &lt;- glm(formula = TRIPS ~\n                ORIGIN_SZ +\n                DESTIN_SZ +\n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(dbcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + DESTIN_SZ + log(dist), family = poisson(link = \"log\"), \n    data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                  Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)     12.8209944  0.0037017  3463.498  &lt; 2e-16 ***\nORIGIN_SZAMSZ02  1.0211738  0.0037920   269.300  &lt; 2e-16 ***\nORIGIN_SZAMSZ03  0.5918913  0.0038618   153.267  &lt; 2e-16 ***\nORIGIN_SZAMSZ04  0.1495750  0.0043158    34.658  &lt; 2e-16 ***\nORIGIN_SZAMSZ05  0.0342910  0.0049206     6.969 3.20e-12 ***\nORIGIN_SZAMSZ06  0.4990749  0.0044867   111.235  &lt; 2e-16 ***\nORIGIN_SZAMSZ07 -0.7632253  0.0074431  -102.541  &lt; 2e-16 ***\nORIGIN_SZAMSZ08 -0.6370000  0.0069109   -92.174  &lt; 2e-16 ***\nORIGIN_SZAMSZ09  0.4389776  0.0046271    94.871  &lt; 2e-16 ***\nORIGIN_SZAMSZ10  0.4528313  0.0040674   111.331  &lt; 2e-16 ***\nORIGIN_SZAMSZ11 -1.5882086  0.0091196  -174.153  &lt; 2e-16 ***\nORIGIN_SZAMSZ12 -1.6680341  0.0090745  -183.815  &lt; 2e-16 ***\nORIGIN_SZBDSZ01  0.7900065  0.0037852   208.710  &lt; 2e-16 ***\nORIGIN_SZBDSZ02  0.4100908  0.0043348    94.604  &lt; 2e-16 ***\nORIGIN_SZBDSZ03  0.8165741  0.0038527   211.949  &lt; 2e-16 ***\nORIGIN_SZBDSZ04  1.4216001  0.0033859   419.856  &lt; 2e-16 ***\nORIGIN_SZBDSZ05  0.5426736  0.0038342   141.535  &lt; 2e-16 ***\nORIGIN_SZBDSZ06  0.8337532  0.0038916   214.246  &lt; 2e-16 ***\nORIGIN_SZBDSZ07 -0.8141464  0.0070275  -115.852  &lt; 2e-16 ***\nORIGIN_SZBDSZ08 -0.6895439  0.0067720  -101.822  &lt; 2e-16 ***\nORIGIN_SZBKSZ01 -0.1417253  0.0054077   -26.208  &lt; 2e-16 ***\nORIGIN_SZBKSZ02  0.5709571  0.0044624   127.949  &lt; 2e-16 ***\nORIGIN_SZBKSZ03  1.0136255  0.0041269   245.613  &lt; 2e-16 ***\nORIGIN_SZBKSZ04 -0.0550877  0.0050301   -10.952  &lt; 2e-16 ***\nORIGIN_SZBKSZ05  0.1809565  0.0046783    38.680  &lt; 2e-16 ***\nORIGIN_SZBKSZ06  0.3522991  0.0050200    70.179  &lt; 2e-16 ***\nORIGIN_SZBKSZ07  0.8090159  0.0038448   210.417  &lt; 2e-16 ***\nORIGIN_SZBKSZ08  0.3293552  0.0044605    73.839  &lt; 2e-16 ***\nORIGIN_SZBKSZ09  0.1029554  0.0047049    21.883  &lt; 2e-16 ***\nORIGIN_SZBLSZ01 -1.7475447  0.0109717  -159.277  &lt; 2e-16 ***\nORIGIN_SZBLSZ02 -2.8734452  0.0158781  -180.969  &lt; 2e-16 ***\nORIGIN_SZBLSZ03 -5.0152771  0.0334310  -150.019  &lt; 2e-16 ***\nORIGIN_SZBLSZ04 -2.2662350  0.0166319  -136.258  &lt; 2e-16 ***\nORIGIN_SZBMSZ01  0.2535848  0.0040863    62.058  &lt; 2e-16 ***\nORIGIN_SZBMSZ02 -1.0064943  0.0057776  -174.207  &lt; 2e-16 ***\nORIGIN_SZBMSZ03 -0.0690787  0.0046447   -14.872  &lt; 2e-16 ***\nORIGIN_SZBMSZ04  0.3074282  0.0041340    74.365  &lt; 2e-16 ***\nORIGIN_SZBMSZ05 -1.0255742  0.0062091  -165.172  &lt; 2e-16 ***\nORIGIN_SZBMSZ06 -1.2327549  0.0097168  -126.869  &lt; 2e-16 ***\nORIGIN_SZBMSZ07 -0.2831713  0.0046087   -61.443  &lt; 2e-16 ***\nORIGIN_SZBMSZ08 -0.1874351  0.0046013   -40.736  &lt; 2e-16 ***\nORIGIN_SZBMSZ09 -0.7228122  0.0058864  -122.793  &lt; 2e-16 ***\nORIGIN_SZBMSZ10 -0.8077952  0.0062270  -129.725  &lt; 2e-16 ***\nORIGIN_SZBMSZ11 -0.4924012  0.0054629   -90.136  &lt; 2e-16 ***\nORIGIN_SZBMSZ12 -0.6909135  0.0072100   -95.827  &lt; 2e-16 ***\nORIGIN_SZBMSZ13  0.0512890  0.0045905    11.173  &lt; 2e-16 ***\nORIGIN_SZBMSZ14 -0.2568311  0.0054867   -46.810  &lt; 2e-16 ***\nORIGIN_SZBMSZ15  0.0870108  0.0049432    17.602  &lt; 2e-16 ***\nORIGIN_SZBMSZ16 -0.9610030  0.0061491  -156.284  &lt; 2e-16 ***\nORIGIN_SZBMSZ17 -1.4357633  0.0093761  -153.131  &lt; 2e-16 ***\nORIGIN_SZBPSZ01  0.5477033  0.0046878   116.836  &lt; 2e-16 ***\nORIGIN_SZBPSZ02  0.8280377  0.0051841   159.727  &lt; 2e-16 ***\nORIGIN_SZBPSZ03  1.1025706  0.0048263   228.452  &lt; 2e-16 ***\nORIGIN_SZBPSZ04  0.7644581  0.0042529   179.748  &lt; 2e-16 ***\nORIGIN_SZBPSZ05  0.5761734  0.0039555   145.663  &lt; 2e-16 ***\nORIGIN_SZBPSZ06 -0.8038843  0.0067269  -119.503  &lt; 2e-16 ***\nORIGIN_SZBPSZ07 -0.7081274  0.0067298  -105.223  &lt; 2e-16 ***\nORIGIN_SZBSSZ01  0.0623814  0.0044582    13.993  &lt; 2e-16 ***\nORIGIN_SZBSSZ02  0.5536861  0.0039874   138.858  &lt; 2e-16 ***\nORIGIN_SZBSSZ03  0.2359262  0.0039552    59.649  &lt; 2e-16 ***\nORIGIN_SZBTSZ01  0.0704870  0.0043712    16.125  &lt; 2e-16 ***\nORIGIN_SZBTSZ02 -0.7549336  0.0061482  -122.789  &lt; 2e-16 ***\nORIGIN_SZBTSZ03 -0.0350744  0.0047023    -7.459 8.72e-14 ***\nORIGIN_SZBTSZ04 -0.2858571  0.0078090   -36.606  &lt; 2e-16 ***\nORIGIN_SZBTSZ05 -1.3311102  0.0083964  -158.534  &lt; 2e-16 ***\nORIGIN_SZBTSZ06 -0.5039784  0.0057973   -86.934  &lt; 2e-16 ***\nORIGIN_SZBTSZ07 -1.5400199  0.0087117  -176.777  &lt; 2e-16 ***\nORIGIN_SZBTSZ08 -0.7887679  0.0068453  -115.227  &lt; 2e-16 ***\nORIGIN_SZCCSZ01 -1.5745039  0.0108105  -145.646  &lt; 2e-16 ***\nORIGIN_SZCHSZ01 -1.1361530  0.0093612  -121.369  &lt; 2e-16 ***\nORIGIN_SZCHSZ02 -0.9128000  0.0069668  -131.022  &lt; 2e-16 ***\nORIGIN_SZCHSZ03 -0.4472993  0.0049038   -91.215  &lt; 2e-16 ***\nORIGIN_SZCKSZ01  0.5127473  0.0042287   121.254  &lt; 2e-16 ***\nORIGIN_SZCKSZ02  1.2022570  0.0043552   276.053  &lt; 2e-16 ***\nORIGIN_SZCKSZ03  0.8860008  0.0039444   224.624  &lt; 2e-16 ***\nORIGIN_SZCKSZ04  1.8272911  0.0041197   443.546  &lt; 2e-16 ***\nORIGIN_SZCKSZ05  1.5316688  0.0051392   298.034  &lt; 2e-16 ***\nORIGIN_SZCKSZ06  1.1564174  0.0054508   212.157  &lt; 2e-16 ***\nORIGIN_SZCLSZ01 -0.6010696  0.0058966  -101.936  &lt; 2e-16 ***\nORIGIN_SZCLSZ02 -1.3058599  0.0106228  -122.929  &lt; 2e-16 ***\nORIGIN_SZCLSZ03 -0.1976445  0.0053882   -36.681  &lt; 2e-16 ***\nORIGIN_SZCLSZ04  0.8670957  0.0037702   229.989  &lt; 2e-16 ***\nORIGIN_SZCLSZ05 -1.4675258  0.0102663  -142.946  &lt; 2e-16 ***\nORIGIN_SZCLSZ06  0.9061705  0.0036171   250.525  &lt; 2e-16 ***\nORIGIN_SZCLSZ07 -0.0547981  0.0045274   -12.104  &lt; 2e-16 ***\nORIGIN_SZCLSZ08  0.2882434  0.0051775    55.672  &lt; 2e-16 ***\nORIGIN_SZCLSZ09 -2.2592927  0.0139890  -161.505  &lt; 2e-16 ***\nORIGIN_SZDTSZ01 -1.3547208  0.0070619  -191.836  &lt; 2e-16 ***\nORIGIN_SZDTSZ02 -1.2364916  0.0064723  -191.043  &lt; 2e-16 ***\nORIGIN_SZDTSZ03 -2.5347494  0.0130438  -194.326  &lt; 2e-16 ***\nORIGIN_SZDTSZ04 -3.4173562  0.0929323   -36.773  &lt; 2e-16 ***\nORIGIN_SZDTSZ05 -2.8339289  0.0214468  -132.138  &lt; 2e-16 ***\nORIGIN_SZDTSZ06 -2.8287483  0.0173910  -162.656  &lt; 2e-16 ***\nORIGIN_SZDTSZ07 -1.4138308  0.0191288   -73.911  &lt; 2e-16 ***\nORIGIN_SZDTSZ08 -2.0630511  0.0097602  -211.373  &lt; 2e-16 ***\nORIGIN_SZDTSZ09 -2.6480874  0.0206165  -128.445  &lt; 2e-16 ***\nORIGIN_SZDTSZ10 -1.8351696  0.0104263  -176.013  &lt; 2e-16 ***\nORIGIN_SZDTSZ11 -1.9555077  0.0108002  -181.061  &lt; 2e-16 ***\nORIGIN_SZDTSZ12 -3.1193610  0.0255389  -122.141  &lt; 2e-16 ***\nORIGIN_SZDTSZ13 -2.0406987  0.0121657  -167.742  &lt; 2e-16 ***\nORIGIN_SZGLSZ01 -1.3805437  0.0072209  -191.187  &lt; 2e-16 ***\nORIGIN_SZGLSZ02  0.2358565  0.0041565    56.744  &lt; 2e-16 ***\nORIGIN_SZGLSZ03  0.0341089  0.0041526     8.214  &lt; 2e-16 ***\nORIGIN_SZGLSZ04  0.9786034  0.0035154   278.375  &lt; 2e-16 ***\nORIGIN_SZGLSZ05  0.5811863  0.0037114   156.594  &lt; 2e-16 ***\nORIGIN_SZHGSZ01  0.1686665  0.0040881    41.258  &lt; 2e-16 ***\nORIGIN_SZHGSZ02  0.6787539  0.0039351   172.488  &lt; 2e-16 ***\nORIGIN_SZHGSZ03  0.4547294  0.0042831   106.169  &lt; 2e-16 ***\nORIGIN_SZHGSZ04  0.9678527  0.0036761   263.282  &lt; 2e-16 ***\nORIGIN_SZHGSZ05  1.2917000  0.0036294   355.904  &lt; 2e-16 ***\nORIGIN_SZHGSZ06  0.2142855  0.0043515    49.244  &lt; 2e-16 ***\nORIGIN_SZHGSZ07  0.6701110  0.0037993   176.380  &lt; 2e-16 ***\nORIGIN_SZHGSZ08  0.1562024  0.0043722    35.726  &lt; 2e-16 ***\nORIGIN_SZHGSZ09 -0.7232166  0.0059862  -120.814  &lt; 2e-16 ***\nORIGIN_SZHGSZ10 -3.1262897  0.0398756   -78.401  &lt; 2e-16 ***\nORIGIN_SZJESZ01  0.4508052  0.0043040   104.741  &lt; 2e-16 ***\nORIGIN_SZJESZ02  0.3712710  0.0042775    86.796  &lt; 2e-16 ***\nORIGIN_SZJESZ03  0.3805622  0.0045067    84.443  &lt; 2e-16 ***\nORIGIN_SZJESZ04 -1.0165889  0.0072792  -139.656  &lt; 2e-16 ***\nORIGIN_SZJESZ05 -1.8580763  0.0120151  -154.645  &lt; 2e-16 ***\nORIGIN_SZJESZ06  0.2384917  0.0042026    56.749  &lt; 2e-16 ***\nORIGIN_SZJESZ07 -1.6783671  0.0094270  -178.039  &lt; 2e-16 ***\nORIGIN_SZJESZ08 -0.6513621  0.0086221   -75.545  &lt; 2e-16 ***\nORIGIN_SZJESZ09  0.4198064  0.0044417    94.515  &lt; 2e-16 ***\nORIGIN_SZJESZ10 -2.7745302  0.0169190  -163.989  &lt; 2e-16 ***\nORIGIN_SZJESZ11 -3.2086375  0.0173519  -184.916  &lt; 2e-16 ***\nORIGIN_SZJWSZ01  0.4595116  0.0057545    79.852  &lt; 2e-16 ***\nORIGIN_SZJWSZ02  0.9856003  0.0039792   247.690  &lt; 2e-16 ***\nORIGIN_SZJWSZ03  1.1845095  0.0037710   314.110  &lt; 2e-16 ***\nORIGIN_SZJWSZ04  0.9343282  0.0038871   240.367  &lt; 2e-16 ***\nORIGIN_SZJWSZ05 -1.5766208  0.0102768  -153.416  &lt; 2e-16 ***\nORIGIN_SZJWSZ06 -1.2683438  0.0090746  -139.769  &lt; 2e-16 ***\nORIGIN_SZJWSZ07 -2.2397234  0.0229427   -97.623  &lt; 2e-16 ***\nORIGIN_SZJWSZ08  1.9992609  0.0037950   526.820  &lt; 2e-16 ***\nORIGIN_SZJWSZ09  1.4974956  0.0035176   425.719  &lt; 2e-16 ***\nORIGIN_SZKLSZ01  0.3247754  0.0040006    81.181  &lt; 2e-16 ***\nORIGIN_SZKLSZ02 -0.3400447  0.0049775   -68.317  &lt; 2e-16 ***\nORIGIN_SZKLSZ03 -0.2580403  0.0049578   -52.048  &lt; 2e-16 ***\nORIGIN_SZKLSZ04 -1.2415420  0.0070255  -176.720  &lt; 2e-16 ***\nORIGIN_SZKLSZ05 -0.5469651  0.0066950   -81.698  &lt; 2e-16 ***\nORIGIN_SZKLSZ06 -0.2888779  0.0046575   -62.024  &lt; 2e-16 ***\nORIGIN_SZKLSZ07 -0.6642053  0.0061209  -108.514  &lt; 2e-16 ***\nORIGIN_SZKLSZ08 -0.7044480  0.0053085  -132.701  &lt; 2e-16 ***\nORIGIN_SZKLSZ09 -1.2073066  0.0067273  -179.465  &lt; 2e-16 ***\nORIGIN_SZLKSZ01 -2.3832693  0.0290465   -82.050  &lt; 2e-16 ***\nORIGIN_SZMDSZ01 -1.6623583  0.0228095   -72.880  &lt; 2e-16 ***\nORIGIN_SZMDSZ02 -1.0894780  0.0101251  -107.601  &lt; 2e-16 ***\nORIGIN_SZMDSZ03 -1.5576626  0.0133799  -116.418  &lt; 2e-16 ***\nORIGIN_SZMPSZ01 -0.8193562  0.0065154  -125.757  &lt; 2e-16 ***\nORIGIN_SZMPSZ02 -0.4499772  0.0054364   -82.771  &lt; 2e-16 ***\nORIGIN_SZMPSZ03  0.1072985  0.0043578    24.622  &lt; 2e-16 ***\nORIGIN_SZMSSZ01 -6.6161570  0.2716550   -24.355  &lt; 2e-16 ***\nORIGIN_SZMUSZ01 -0.9145758  0.0058126  -157.344  &lt; 2e-16 ***\nORIGIN_SZMUSZ02 -2.6469649  0.0143884  -183.965  &lt; 2e-16 ***\nORIGIN_SZMUSZ03 -1.4817336  0.0068290  -216.977  &lt; 2e-16 ***\nORIGIN_SZNTSZ01 -2.2277160  0.0241686   -92.174  &lt; 2e-16 ***\nORIGIN_SZNTSZ02 -2.0111227  0.0123512  -162.828  &lt; 2e-16 ***\nORIGIN_SZNTSZ03 -0.4524949  0.0058585   -77.238  &lt; 2e-16 ***\nORIGIN_SZNTSZ05 -2.7479537  0.0372348   -73.801  &lt; 2e-16 ***\nORIGIN_SZNTSZ06 -2.9645842  0.0400589   -74.006  &lt; 2e-16 ***\nORIGIN_SZNVSZ01  0.8704060  0.0036475   238.629  &lt; 2e-16 ***\nORIGIN_SZNVSZ02 -0.2594842  0.0048904   -53.060  &lt; 2e-16 ***\nORIGIN_SZNVSZ03 -0.9402480  0.0059727  -157.425  &lt; 2e-16 ***\nORIGIN_SZNVSZ04 -1.0520174  0.0071039  -148.090  &lt; 2e-16 ***\nORIGIN_SZNVSZ05 -2.2991493  0.0129008  -178.217  &lt; 2e-16 ***\nORIGIN_SZORSZ01 -2.5474177  0.0262225   -97.146  &lt; 2e-16 ***\nORIGIN_SZORSZ02 -1.0318529  0.0057495  -179.468  &lt; 2e-16 ***\nORIGIN_SZORSZ03 -1.3389968  0.0068438  -195.652  &lt; 2e-16 ***\nORIGIN_SZOTSZ01 -1.3085717  0.0072750  -179.873  &lt; 2e-16 ***\nORIGIN_SZOTSZ02 -1.5045539  0.0081728  -184.092  &lt; 2e-16 ***\nORIGIN_SZOTSZ03 -0.4288554  0.0053691   -79.875  &lt; 2e-16 ***\nORIGIN_SZOTSZ04 -0.5091409  0.0084280   -60.411  &lt; 2e-16 ***\nORIGIN_SZPGSZ01  0.6909111  0.0106331    64.978  &lt; 2e-16 ***\nORIGIN_SZPGSZ02 -0.2397081  0.0057837   -41.446  &lt; 2e-16 ***\nORIGIN_SZPGSZ03  0.9957099  0.0037730   263.907  &lt; 2e-16 ***\nORIGIN_SZPGSZ04  1.1597337  0.0037624   308.241  &lt; 2e-16 ***\nORIGIN_SZPGSZ05  0.6492546  0.0046923   138.366  &lt; 2e-16 ***\nORIGIN_SZPLSZ01 -0.5839333  0.0081061   -72.036  &lt; 2e-16 ***\nORIGIN_SZPLSZ02 -1.1064599  0.0114132   -96.946  &lt; 2e-16 ***\nORIGIN_SZPLSZ03 -3.2526684  0.0320369  -101.529  &lt; 2e-16 ***\nORIGIN_SZPLSZ04 -3.7343048  0.0355944  -104.913  &lt; 2e-16 ***\nORIGIN_SZPLSZ05 -2.2665620  0.0179181  -126.496  &lt; 2e-16 ***\nORIGIN_SZPNSZ01  1.0212905  0.0047143   216.637  &lt; 2e-16 ***\nORIGIN_SZPNSZ02 -1.7538504  0.0111979  -156.623  &lt; 2e-16 ***\nORIGIN_SZPNSZ03 -2.7059069  0.0179400  -150.831  &lt; 2e-16 ***\nORIGIN_SZPNSZ04 -4.6167880  0.0263377  -175.292  &lt; 2e-16 ***\nORIGIN_SZPNSZ05 -3.0427726  0.0196666  -154.718  &lt; 2e-16 ***\nORIGIN_SZPRSZ01 -0.6289953  0.0096046   -65.489  &lt; 2e-16 ***\nORIGIN_SZPRSZ02  1.0206156  0.0039549   258.062  &lt; 2e-16 ***\nORIGIN_SZPRSZ03  0.4912065  0.0039421   124.606  &lt; 2e-16 ***\nORIGIN_SZPRSZ04 -0.4025880  0.0064054   -62.852  &lt; 2e-16 ***\nORIGIN_SZPRSZ05  1.1225721  0.0037798   296.996  &lt; 2e-16 ***\nORIGIN_SZPRSZ06 -0.9516629  0.0070083  -135.791  &lt; 2e-16 ***\nORIGIN_SZPRSZ07 -2.5610511  0.0169070  -151.478  &lt; 2e-16 ***\nORIGIN_SZPRSZ08  0.0236310  0.0051603     4.579 4.66e-06 ***\nORIGIN_SZQTSZ01  0.1179359  0.0055302    21.326  &lt; 2e-16 ***\nORIGIN_SZQTSZ02 -0.4078722  0.0051104   -79.812  &lt; 2e-16 ***\nORIGIN_SZQTSZ03  0.1193841  0.0047115    25.339  &lt; 2e-16 ***\nORIGIN_SZQTSZ04 -0.9691910  0.0062944  -153.978  &lt; 2e-16 ***\nORIGIN_SZQTSZ05  0.0998289  0.0046955    21.260  &lt; 2e-16 ***\nORIGIN_SZQTSZ06 -0.2814267  0.0053649   -52.457  &lt; 2e-16 ***\nORIGIN_SZQTSZ07 -1.2548647  0.0078707  -159.436  &lt; 2e-16 ***\nORIGIN_SZQTSZ08 -0.2531659  0.0048952   -51.717  &lt; 2e-16 ***\nORIGIN_SZQTSZ09 -0.4447711  0.0054252   -81.983  &lt; 2e-16 ***\nORIGIN_SZQTSZ10 -0.3430013  0.0053350   -64.293  &lt; 2e-16 ***\nORIGIN_SZQTSZ11 -1.4903190  0.0077334  -192.711  &lt; 2e-16 ***\nORIGIN_SZQTSZ12 -0.6577501  0.0065839   -99.903  &lt; 2e-16 ***\nORIGIN_SZQTSZ13 -0.2096789  0.0050085   -41.864  &lt; 2e-16 ***\nORIGIN_SZQTSZ14 -1.3328463  0.0072466  -183.926  &lt; 2e-16 ***\nORIGIN_SZQTSZ15 -1.0923358  0.0087615  -124.675  &lt; 2e-16 ***\nORIGIN_SZRCSZ01 -0.3755902  0.0053737   -69.894  &lt; 2e-16 ***\nORIGIN_SZRCSZ02 -2.0022955  0.0148554  -134.786  &lt; 2e-16 ***\nORIGIN_SZRCSZ03 -0.9294765  0.0074480  -124.795  &lt; 2e-16 ***\nORIGIN_SZRCSZ04 -2.0113020  0.0111150  -180.953  &lt; 2e-16 ***\nORIGIN_SZRCSZ05 -2.2815677  0.0134388  -169.775  &lt; 2e-16 ***\nORIGIN_SZRCSZ06 -0.1380185  0.0069989   -19.720  &lt; 2e-16 ***\nORIGIN_SZRCSZ08 -2.2838985  0.0161757  -141.193  &lt; 2e-16 ***\nORIGIN_SZRCSZ09 -1.6700447  0.0122155  -136.715  &lt; 2e-16 ***\nORIGIN_SZRCSZ10 -1.4653375  0.0070450  -207.996  &lt; 2e-16 ***\nORIGIN_SZRVSZ01 -2.4788050  0.0131632  -188.313  &lt; 2e-16 ***\nORIGIN_SZRVSZ02 -0.5963401  0.0068203   -87.436  &lt; 2e-16 ***\nORIGIN_SZRVSZ03 -1.3147500  0.0098596  -133.347  &lt; 2e-16 ***\nORIGIN_SZRVSZ04 -1.5215037  0.0138329  -109.992  &lt; 2e-16 ***\nORIGIN_SZRVSZ05 -1.6049655  0.0123359  -130.105  &lt; 2e-16 ***\nORIGIN_SZSBSZ01  0.8915036  0.0049554   179.906  &lt; 2e-16 ***\nORIGIN_SZSBSZ02 -0.5941713  0.0065942   -90.106  &lt; 2e-16 ***\nORIGIN_SZSBSZ03  0.5697082  0.0041613   136.905  &lt; 2e-16 ***\nORIGIN_SZSBSZ04  0.3844219  0.0047855    80.331  &lt; 2e-16 ***\nORIGIN_SZSBSZ05 -0.0485925  0.0057352    -8.473  &lt; 2e-16 ***\nORIGIN_SZSBSZ06 -0.9922846  0.0139889   -70.934  &lt; 2e-16 ***\nORIGIN_SZSBSZ07 -0.1042518  0.0098005   -10.637  &lt; 2e-16 ***\nORIGIN_SZSBSZ08 -1.9893851  0.0098004  -202.991  &lt; 2e-16 ***\nORIGIN_SZSBSZ09 -1.1240957  0.0073195  -153.576  &lt; 2e-16 ***\nORIGIN_SZSESZ02  1.2134372  0.0036997   327.981  &lt; 2e-16 ***\nORIGIN_SZSESZ03  1.1004236  0.0035731   307.971  &lt; 2e-16 ***\nORIGIN_SZSESZ04  1.1489236  0.0040956   280.526  &lt; 2e-16 ***\nORIGIN_SZSESZ05 -0.1461118  0.0049210   -29.691  &lt; 2e-16 ***\nORIGIN_SZSESZ06  1.1678137  0.0038786   301.090  &lt; 2e-16 ***\nORIGIN_SZSESZ07 -1.9241440  0.0140591  -136.861  &lt; 2e-16 ***\nORIGIN_SZSGSZ01 -0.7959607  0.0069928  -113.826  &lt; 2e-16 ***\nORIGIN_SZSGSZ02 -1.2359549  0.0082778  -149.310  &lt; 2e-16 ***\nORIGIN_SZSGSZ03  0.3282470  0.0043939    74.705  &lt; 2e-16 ***\nORIGIN_SZSGSZ04  0.4006316  0.0040311    99.384  &lt; 2e-16 ***\nORIGIN_SZSGSZ05 -1.4296109  0.0082085  -174.163  &lt; 2e-16 ***\nORIGIN_SZSGSZ06  0.3863254  0.0038318   100.822  &lt; 2e-16 ***\nORIGIN_SZSGSZ07 -0.4469943  0.0050392   -88.703  &lt; 2e-16 ***\nORIGIN_SZSKSZ01 -0.1580149  0.0069175   -22.843  &lt; 2e-16 ***\nORIGIN_SZSKSZ02  0.1537997  0.0052382    29.361  &lt; 2e-16 ***\nORIGIN_SZSKSZ03 -0.4326739  0.0063779   -67.840  &lt; 2e-16 ***\nORIGIN_SZSKSZ04 -2.0322053  0.0227241   -89.430  &lt; 2e-16 ***\nORIGIN_SZSKSZ05 -1.1835613  0.0147778   -80.091  &lt; 2e-16 ***\nORIGIN_SZSLSZ01 -2.9837421  0.0258339  -115.497  &lt; 2e-16 ***\nORIGIN_SZSLSZ04 -0.2992181  0.0058854   -50.841  &lt; 2e-16 ***\nORIGIN_SZSRSZ01 -1.0561834  0.0071740  -147.223  &lt; 2e-16 ***\nORIGIN_SZSRSZ02 -1.4438175  0.0072835  -198.231  &lt; 2e-16 ***\nORIGIN_SZSRSZ03 -2.3619347  0.0152284  -155.101  &lt; 2e-16 ***\nORIGIN_SZSVSZ01 -2.2403092  0.0416577   -53.779  &lt; 2e-16 ***\nORIGIN_SZTHSZ01 -3.3500671  0.0462044   -72.505  &lt; 2e-16 ***\nORIGIN_SZTHSZ03 -0.8400127  0.0131456   -63.901  &lt; 2e-16 ***\nORIGIN_SZTHSZ04 -2.3078055  0.0244784   -94.279  &lt; 2e-16 ***\nORIGIN_SZTHSZ06 -1.2485071  0.0110208  -113.287  &lt; 2e-16 ***\nORIGIN_SZTMSZ01  0.8034289  0.0043154   186.178  &lt; 2e-16 ***\nORIGIN_SZTMSZ02  1.5977627  0.0033303   479.760  &lt; 2e-16 ***\nORIGIN_SZTMSZ03  1.2010374  0.0035316   340.081  &lt; 2e-16 ***\nORIGIN_SZTMSZ04  0.3986725  0.0041038    97.147  &lt; 2e-16 ***\nORIGIN_SZTMSZ05 -0.8775543  0.0064806  -135.412  &lt; 2e-16 ***\nORIGIN_SZTNSZ01 -0.7901703  0.0059867  -131.989  &lt; 2e-16 ***\nORIGIN_SZTNSZ02 -0.6947947  0.0058037  -119.716  &lt; 2e-16 ***\nORIGIN_SZTNSZ03 -1.1794385  0.0075996  -155.198  &lt; 2e-16 ***\nORIGIN_SZTNSZ04 -0.2906944  0.0056078   -51.837  &lt; 2e-16 ***\nORIGIN_SZTPSZ01 -0.4220000  0.0052288   -80.706  &lt; 2e-16 ***\nORIGIN_SZTPSZ02  0.5186540  0.0036928   140.449  &lt; 2e-16 ***\nORIGIN_SZTPSZ03 -0.4340206  0.0052061   -83.368  &lt; 2e-16 ***\nORIGIN_SZTPSZ04 -0.0658329  0.0049011   -13.432  &lt; 2e-16 ***\nORIGIN_SZTPSZ05  0.0876853  0.0051031    17.183  &lt; 2e-16 ***\nORIGIN_SZTPSZ06  0.5914622  0.0057688   102.528  &lt; 2e-16 ***\nORIGIN_SZTPSZ07  0.0863881  0.0051162    16.885  &lt; 2e-16 ***\nORIGIN_SZTPSZ08 -0.3835720  0.0066615   -57.580  &lt; 2e-16 ***\nORIGIN_SZTPSZ09 -0.4862839  0.0054787   -88.759  &lt; 2e-16 ***\nORIGIN_SZTPSZ10 -0.1484374  0.0054913   -27.031  &lt; 2e-16 ***\nORIGIN_SZTPSZ11  0.3115335  0.0043348    71.868  &lt; 2e-16 ***\nORIGIN_SZTPSZ12 -0.4386990  0.0053693   -81.705  &lt; 2e-16 ***\nORIGIN_SZTSSZ01 -3.4734418  0.0409852   -84.749  &lt; 2e-16 ***\nORIGIN_SZTSSZ02  0.1327694  0.0076669    17.317  &lt; 2e-16 ***\nORIGIN_SZTSSZ03 -0.1394126  0.0079630   -17.508  &lt; 2e-16 ***\nORIGIN_SZTSSZ04 -0.4834844  0.0081910   -59.026  &lt; 2e-16 ***\nORIGIN_SZTSSZ05 -2.6972890  0.0129593  -208.135  &lt; 2e-16 ***\nORIGIN_SZTSSZ06 -3.1376055  0.0185958  -168.727  &lt; 2e-16 ***\nORIGIN_SZWCSZ01 -0.8838079  0.0063970  -138.159  &lt; 2e-16 ***\nORIGIN_SZWCSZ02 -2.7133955  0.0253131  -107.194  &lt; 2e-16 ***\nORIGIN_SZWCSZ03 -4.6049194  0.1325023   -34.753  &lt; 2e-16 ***\nORIGIN_SZWDSZ01  0.8560664  0.0036494   234.575  &lt; 2e-16 ***\nORIGIN_SZWDSZ02  0.9855869  0.0041492   237.535  &lt; 2e-16 ***\nORIGIN_SZWDSZ03  1.7133802  0.0037306   459.281  &lt; 2e-16 ***\nORIGIN_SZWDSZ04  1.1377918  0.0045405   250.585  &lt; 2e-16 ***\nORIGIN_SZWDSZ05  0.4888027  0.0043787   111.633  &lt; 2e-16 ***\nORIGIN_SZWDSZ06  0.9765953  0.0040953   238.467  &lt; 2e-16 ***\nORIGIN_SZWDSZ07 -0.2293223  0.0058436   -39.243  &lt; 2e-16 ***\nORIGIN_SZWDSZ08 -0.6573590  0.0064698  -101.604  &lt; 2e-16 ***\nORIGIN_SZWDSZ09  1.6829017  0.0038504   437.071  &lt; 2e-16 ***\nORIGIN_SZYSSZ01 -0.4848312  0.0048344  -100.288  &lt; 2e-16 ***\nORIGIN_SZYSSZ02  0.9943936  0.0045034   220.811  &lt; 2e-16 ***\nORIGIN_SZYSSZ03  2.2977837  0.0037334   615.459  &lt; 2e-16 ***\nORIGIN_SZYSSZ04  0.8979911  0.0038661   232.276  &lt; 2e-16 ***\nORIGIN_SZYSSZ05  0.4287521  0.0046808    91.598  &lt; 2e-16 ***\nORIGIN_SZYSSZ06 -0.5936855  0.0075695   -78.432  &lt; 2e-16 ***\nORIGIN_SZYSSZ07 -0.4146970  0.0078162   -53.056  &lt; 2e-16 ***\nORIGIN_SZYSSZ08 -0.3883423  0.0053350   -72.792  &lt; 2e-16 ***\nORIGIN_SZYSSZ09  1.1966606  0.0037486   319.226  &lt; 2e-16 ***\nDESTIN_SZAMSZ02 -0.0636405  0.0036934   -17.231  &lt; 2e-16 ***\nDESTIN_SZAMSZ03  0.1352549  0.0035587    38.006  &lt; 2e-16 ***\nDESTIN_SZAMSZ04 -0.9163012  0.0052190  -175.571  &lt; 2e-16 ***\nDESTIN_SZAMSZ05 -0.8273596  0.0049522  -167.070  &lt; 2e-16 ***\nDESTIN_SZAMSZ06 -0.7114591  0.0048518  -146.637  &lt; 2e-16 ***\nDESTIN_SZAMSZ07 -1.6525934  0.0085950  -192.274  &lt; 2e-16 ***\nDESTIN_SZAMSZ08 -0.8286756  0.0054861  -151.051  &lt; 2e-16 ***\nDESTIN_SZAMSZ09 -1.0100389  0.0052362  -192.896  &lt; 2e-16 ***\nDESTIN_SZAMSZ10  0.0577538  0.0036539    15.806  &lt; 2e-16 ***\nDESTIN_SZAMSZ11  0.0264569  0.0062075     4.262 2.03e-05 ***\nDESTIN_SZAMSZ12  0.0699142  0.0044763    15.619  &lt; 2e-16 ***\nDESTIN_SZBDSZ01  0.4079216  0.0033431   122.020  &lt; 2e-16 ***\nDESTIN_SZBDSZ02 -0.2983737  0.0042145   -70.798  &lt; 2e-16 ***\nDESTIN_SZBDSZ03 -0.1081401  0.0037322   -28.975  &lt; 2e-16 ***\nDESTIN_SZBDSZ04  0.7139597  0.0030744   232.229  &lt; 2e-16 ***\nDESTIN_SZBDSZ05  0.4298721  0.0033834   127.052  &lt; 2e-16 ***\nDESTIN_SZBDSZ06 -0.0090534  0.0038123    -2.375 0.017558 *  \nDESTIN_SZBDSZ07 -0.5446859  0.0074833   -72.787  &lt; 2e-16 ***\nDESTIN_SZBDSZ08 -1.4299619  0.0074446  -192.080  &lt; 2e-16 ***\nDESTIN_SZBKSZ01 -1.2418700  0.0054274  -228.816  &lt; 2e-16 ***\nDESTIN_SZBKSZ02 -0.3747029  0.0045775   -81.858  &lt; 2e-16 ***\nDESTIN_SZBKSZ03 -0.8106383  0.0046912  -172.798  &lt; 2e-16 ***\nDESTIN_SZBKSZ04 -0.0447919  0.0041811   -10.713  &lt; 2e-16 ***\nDESTIN_SZBKSZ05 -0.6469806  0.0046863  -138.059  &lt; 2e-16 ***\nDESTIN_SZBKSZ06 -1.0379007  0.0052498  -197.703  &lt; 2e-16 ***\nDESTIN_SZBKSZ07  0.1008434  0.0035689    28.256  &lt; 2e-16 ***\nDESTIN_SZBKSZ08 -1.1235248  0.0058606  -191.708  &lt; 2e-16 ***\nDESTIN_SZBKSZ09 -0.1769490  0.0042448   -41.686  &lt; 2e-16 ***\nDESTIN_SZBLSZ01 -0.7202679  0.0059344  -121.371  &lt; 2e-16 ***\nDESTIN_SZBLSZ02  0.4289945  0.0057776    74.251  &lt; 2e-16 ***\nDESTIN_SZBLSZ03  1.6577344  0.0062905   263.530  &lt; 2e-16 ***\nDESTIN_SZBLSZ04 -0.4365000  0.0114393   -38.158  &lt; 2e-16 ***\nDESTIN_SZBMSZ01 -0.0437992  0.0038281   -11.442  &lt; 2e-16 ***\nDESTIN_SZBMSZ02 -0.2109099  0.0040034   -52.683  &lt; 2e-16 ***\nDESTIN_SZBMSZ03 -0.5831276  0.0048985  -119.042  &lt; 2e-16 ***\nDESTIN_SZBMSZ04 -0.3088132  0.0042301   -73.004  &lt; 2e-16 ***\nDESTIN_SZBMSZ05 -0.4009981  0.0050362   -79.623  &lt; 2e-16 ***\nDESTIN_SZBMSZ06 -1.1963226  0.0084448  -141.664  &lt; 2e-16 ***\nDESTIN_SZBMSZ07  0.1723604  0.0037269    46.248  &lt; 2e-16 ***\nDESTIN_SZBMSZ08 -0.7228516  0.0048637  -148.622  &lt; 2e-16 ***\nDESTIN_SZBMSZ09 -1.5648751  0.0076588  -204.324  &lt; 2e-16 ***\nDESTIN_SZBMSZ10 -1.0792725  0.0060780  -177.571  &lt; 2e-16 ***\nDESTIN_SZBMSZ11 -1.2337029  0.0060444  -204.105  &lt; 2e-16 ***\nDESTIN_SZBMSZ12 -0.6038761  0.0063848   -94.580  &lt; 2e-16 ***\nDESTIN_SZBMSZ13 -0.0069636  0.0040263    -1.730 0.083716 .  \nDESTIN_SZBMSZ14 -0.6078154  0.0063169   -96.220  &lt; 2e-16 ***\nDESTIN_SZBMSZ15 -0.9452800  0.0058509  -161.562  &lt; 2e-16 ***\nDESTIN_SZBMSZ16 -1.2893936  0.0061729  -208.880  &lt; 2e-16 ***\nDESTIN_SZBMSZ17 -1.3174691  0.0072184  -182.516  &lt; 2e-16 ***\nDESTIN_SZBPSZ01 -0.8121560  0.0046763  -173.675  &lt; 2e-16 ***\nDESTIN_SZBPSZ02 -1.7589943  0.0074436  -236.311  &lt; 2e-16 ***\nDESTIN_SZBPSZ03 -1.6224673  0.0071034  -228.408  &lt; 2e-16 ***\nDESTIN_SZBPSZ04 -0.9099544  0.0051560  -176.486  &lt; 2e-16 ***\nDESTIN_SZBPSZ05  0.2822083  0.0034510    81.776  &lt; 2e-16 ***\nDESTIN_SZBPSZ06 -0.7067413  0.0062576  -112.941  &lt; 2e-16 ***\nDESTIN_SZBPSZ07 -0.5700144  0.0064417   -88.488  &lt; 2e-16 ***\nDESTIN_SZBSSZ01  0.0907030  0.0037765    24.018  &lt; 2e-16 ***\nDESTIN_SZBSSZ02 -0.7477704  0.0043714  -171.058  &lt; 2e-16 ***\nDESTIN_SZBSSZ03  0.3866005  0.0032621   118.514  &lt; 2e-16 ***\nDESTIN_SZBTSZ01  0.1909204  0.0035812    53.312  &lt; 2e-16 ***\nDESTIN_SZBTSZ02 -0.7341012  0.0057096  -128.574  &lt; 2e-16 ***\nDESTIN_SZBTSZ03 -0.0353772  0.0041931    -8.437  &lt; 2e-16 ***\nDESTIN_SZBTSZ04 -1.2491209  0.0082702  -151.039  &lt; 2e-16 ***\nDESTIN_SZBTSZ05 -0.4058884  0.0057519   -70.565  &lt; 2e-16 ***\nDESTIN_SZBTSZ06 -0.6183505  0.0051158  -120.870  &lt; 2e-16 ***\nDESTIN_SZBTSZ07 -1.5213515  0.0080000  -190.170  &lt; 2e-16 ***\nDESTIN_SZBTSZ08 -0.7574454  0.0068701  -110.253  &lt; 2e-16 ***\nDESTIN_SZCCSZ01 -0.3364647  0.0053846   -62.487  &lt; 2e-16 ***\nDESTIN_SZCHSZ01 -1.1192854  0.0075000  -149.238  &lt; 2e-16 ***\nDESTIN_SZCHSZ02 -0.0606036  0.0047464   -12.768  &lt; 2e-16 ***\nDESTIN_SZCHSZ03  1.3032044  0.0033903   384.394  &lt; 2e-16 ***\nDESTIN_SZCKSZ01 -0.4095319  0.0042607   -96.118  &lt; 2e-16 ***\nDESTIN_SZCKSZ02 -0.9058865  0.0047164  -192.071  &lt; 2e-16 ***\nDESTIN_SZCKSZ03  0.2494727  0.0035349    70.575  &lt; 2e-16 ***\nDESTIN_SZCKSZ04 -1.5357890  0.0055042  -279.022  &lt; 2e-16 ***\nDESTIN_SZCKSZ05 -1.2168689  0.0062896  -193.474  &lt; 2e-16 ***\nDESTIN_SZCKSZ06  0.1354467  0.0050849    26.637  &lt; 2e-16 ***\nDESTIN_SZCLSZ01  0.2362502  0.0040934    57.714  &lt; 2e-16 ***\nDESTIN_SZCLSZ02 -2.1201551  0.0109974  -192.787  &lt; 2e-16 ***\nDESTIN_SZCLSZ03 -0.8930509  0.0061663  -144.829  &lt; 2e-16 ***\nDESTIN_SZCLSZ04 -0.0392053  0.0037661   -10.410  &lt; 2e-16 ***\nDESTIN_SZCLSZ05 -0.9701578  0.0071560  -135.572  &lt; 2e-16 ***\nDESTIN_SZCLSZ06  0.0809388  0.0035222    22.980  &lt; 2e-16 ***\nDESTIN_SZCLSZ07 -0.4671167  0.0044749  -104.386  &lt; 2e-16 ***\nDESTIN_SZCLSZ08 -0.4217114  0.0052202   -80.784  &lt; 2e-16 ***\nDESTIN_SZCLSZ09  0.4361858  0.0056700    76.929  &lt; 2e-16 ***\nDESTIN_SZDTSZ01 -0.5713120  0.0045261  -126.226  &lt; 2e-16 ***\nDESTIN_SZDTSZ02 -0.8007120  0.0043987  -182.033  &lt; 2e-16 ***\nDESTIN_SZDTSZ03 -1.0356648  0.0051957  -199.330  &lt; 2e-16 ***\nDESTIN_SZDTSZ04 -0.5609786  0.0111703   -50.221  &lt; 2e-16 ***\nDESTIN_SZDTSZ05 -0.6273075  0.0086387   -72.616  &lt; 2e-16 ***\nDESTIN_SZDTSZ06 -1.0970276  0.0058498  -187.531  &lt; 2e-16 ***\nDESTIN_SZDTSZ07 -1.9471138  0.0181117  -107.506  &lt; 2e-16 ***\nDESTIN_SZDTSZ08 -0.5726861  0.0042779  -133.871  &lt; 2e-16 ***\nDESTIN_SZDTSZ09 -1.6507230  0.0094872  -173.996  &lt; 2e-16 ***\nDESTIN_SZDTSZ10 -1.1437957  0.0076182  -150.140  &lt; 2e-16 ***\nDESTIN_SZDTSZ11 -0.7051074  0.0045503  -154.957  &lt; 2e-16 ***\nDESTIN_SZDTSZ12 -2.3853201  0.0146739  -162.555  &lt; 2e-16 ***\nDESTIN_SZDTSZ13 -1.7104226  0.0092829  -184.255  &lt; 2e-16 ***\nDESTIN_SZGLSZ01  0.1107368  0.0042492    26.061  &lt; 2e-16 ***\nDESTIN_SZGLSZ02 -0.2332991  0.0039456   -59.129  &lt; 2e-16 ***\nDESTIN_SZGLSZ03  0.3998628  0.0033286   120.131  &lt; 2e-16 ***\nDESTIN_SZGLSZ04  0.3437751  0.0032807   104.788  &lt; 2e-16 ***\nDESTIN_SZGLSZ05  0.1319578  0.0034312    38.458  &lt; 2e-16 ***\nDESTIN_SZHGSZ01  0.2919272  0.0033057    88.310  &lt; 2e-16 ***\nDESTIN_SZHGSZ02 -0.7143625  0.0045068  -158.507  &lt; 2e-16 ***\nDESTIN_SZHGSZ03 -1.2327433  0.0053627  -229.872  &lt; 2e-16 ***\nDESTIN_SZHGSZ04 -0.4872286  0.0038424  -126.804  &lt; 2e-16 ***\nDESTIN_SZHGSZ05 -0.5305026  0.0038947  -136.213  &lt; 2e-16 ***\nDESTIN_SZHGSZ06 -0.7221263  0.0044794  -161.212  &lt; 2e-16 ***\nDESTIN_SZHGSZ07  0.1396872  0.0034914    40.009  &lt; 2e-16 ***\nDESTIN_SZHGSZ08 -0.2910404  0.0040741   -71.437  &lt; 2e-16 ***\nDESTIN_SZHGSZ09 -0.0399258  0.0042623    -9.367  &lt; 2e-16 ***\nDESTIN_SZHGSZ10 -3.3525271  0.0284834  -117.701  &lt; 2e-16 ***\nDESTIN_SZJESZ01 -0.3179824  0.0043748   -72.685  &lt; 2e-16 ***\nDESTIN_SZJESZ02 -0.6166505  0.0044556  -138.398  &lt; 2e-16 ***\nDESTIN_SZJESZ03 -0.7409777  0.0048742  -152.021  &lt; 2e-16 ***\nDESTIN_SZJESZ04 -0.1314954  0.0050415   -26.083  &lt; 2e-16 ***\nDESTIN_SZJESZ05 -0.9093176  0.0076274  -119.217  &lt; 2e-16 ***\nDESTIN_SZJESZ06  0.1586402  0.0036120    43.921  &lt; 2e-16 ***\nDESTIN_SZJESZ07 -0.9858786  0.0062868  -156.818  &lt; 2e-16 ***\nDESTIN_SZJESZ08 -0.9337586  0.0066965  -139.440  &lt; 2e-16 ***\nDESTIN_SZJESZ09 -0.4910199  0.0049077  -100.052  &lt; 2e-16 ***\nDESTIN_SZJESZ10  0.6120048  0.0065254    93.788  &lt; 2e-16 ***\nDESTIN_SZJESZ11  1.0847026  0.0058522   185.349  &lt; 2e-16 ***\nDESTIN_SZJWSZ01 -0.8217727  0.0057128  -143.848  &lt; 2e-16 ***\nDESTIN_SZJWSZ02 -0.8115426  0.0047358  -171.364  &lt; 2e-16 ***\nDESTIN_SZJWSZ03  0.2537313  0.0036535    69.450  &lt; 2e-16 ***\nDESTIN_SZJWSZ04  0.7302341  0.0034528   211.489  &lt; 2e-16 ***\nDESTIN_SZJWSZ05 -0.4724558  0.0051651   -91.472  &lt; 2e-16 ***\nDESTIN_SZJWSZ06 -0.2407042  0.0048187   -49.953  &lt; 2e-16 ***\nDESTIN_SZJWSZ07 -1.6158410  0.0202993   -79.601  &lt; 2e-16 ***\nDESTIN_SZJWSZ08 -0.6230617  0.0043179  -144.298  &lt; 2e-16 ***\nDESTIN_SZJWSZ09  0.8898147  0.0031592   281.656  &lt; 2e-16 ***\nDESTIN_SZKLSZ01 -0.4396921  0.0041637  -105.602  &lt; 2e-16 ***\nDESTIN_SZKLSZ02 -0.6062908  0.0047420  -127.855  &lt; 2e-16 ***\nDESTIN_SZKLSZ03 -1.0819377  0.0052061  -207.823  &lt; 2e-16 ***\nDESTIN_SZKLSZ04 -1.5376025  0.0066483  -231.278  &lt; 2e-16 ***\nDESTIN_SZKLSZ05 -0.9160108  0.0067999  -134.710  &lt; 2e-16 ***\nDESTIN_SZKLSZ06 -0.6783138  0.0045567  -148.862  &lt; 2e-16 ***\nDESTIN_SZKLSZ07 -0.8053090  0.0051185  -157.332  &lt; 2e-16 ***\nDESTIN_SZKLSZ08 -0.0089414  0.0037295    -2.397 0.016509 *  \nDESTIN_SZKLSZ09 -1.5380396  0.0066445  -231.475  &lt; 2e-16 ***\nDESTIN_SZLKSZ01 -2.0292471  0.0195548  -103.772  &lt; 2e-16 ***\nDESTIN_SZMDSZ01 -1.6102095  0.0167391   -96.194  &lt; 2e-16 ***\nDESTIN_SZMDSZ02 -1.2155299  0.0095467  -127.325  &lt; 2e-16 ***\nDESTIN_SZMDSZ03 -2.1559429  0.0211092  -102.133  &lt; 2e-16 ***\nDESTIN_SZMPSZ01 -0.9113252  0.0065923  -138.242  &lt; 2e-16 ***\nDESTIN_SZMPSZ02 -0.6876636  0.0049043  -140.215  &lt; 2e-16 ***\nDESTIN_SZMPSZ03 -0.0982520  0.0040534   -24.240  &lt; 2e-16 ***\nDESTIN_SZMSSZ01 -1.2155215  0.0695228   -17.484  &lt; 2e-16 ***\nDESTIN_SZMUSZ01 -1.0087032  0.0049335  -204.461  &lt; 2e-16 ***\nDESTIN_SZMUSZ02 -0.9727755  0.0070311  -138.353  &lt; 2e-16 ***\nDESTIN_SZMUSZ03 -1.0017612  0.0048249  -207.621  &lt; 2e-16 ***\nDESTIN_SZNTSZ01 -2.3340377  0.0219411  -106.378  &lt; 2e-16 ***\nDESTIN_SZNTSZ02 -1.6675277  0.0088191  -189.082  &lt; 2e-16 ***\nDESTIN_SZNTSZ03 -1.0351545  0.0061401  -168.590  &lt; 2e-16 ***\nDESTIN_SZNTSZ05 -1.6317700  0.0162635  -100.334  &lt; 2e-16 ***\nDESTIN_SZNTSZ06 -3.0291034  0.0279066  -108.544  &lt; 2e-16 ***\nDESTIN_SZNVSZ01 -0.2360755  0.0036893   -63.990  &lt; 2e-16 ***\nDESTIN_SZNVSZ02 -0.2677703  0.0041811   -64.043  &lt; 2e-16 ***\nDESTIN_SZNVSZ03 -0.3232023  0.0044374   -72.837  &lt; 2e-16 ***\nDESTIN_SZNVSZ04 -1.7845955  0.0085152  -209.579  &lt; 2e-16 ***\nDESTIN_SZNVSZ05 -1.5100826  0.0073054  -206.707  &lt; 2e-16 ***\nDESTIN_SZORSZ01 -1.4567532  0.0175488   -83.011  &lt; 2e-16 ***\nDESTIN_SZORSZ02  0.2967492  0.0035666    83.202  &lt; 2e-16 ***\nDESTIN_SZORSZ03 -0.7064791  0.0048068  -146.974  &lt; 2e-16 ***\nDESTIN_SZOTSZ01 -1.0978002  0.0061453  -178.639  &lt; 2e-16 ***\nDESTIN_SZOTSZ02 -0.4045287  0.0054335   -74.451  &lt; 2e-16 ***\nDESTIN_SZOTSZ03 -1.2239180  0.0058241  -210.147  &lt; 2e-16 ***\nDESTIN_SZOTSZ04 -1.4445089  0.0082677  -174.717  &lt; 2e-16 ***\nDESTIN_SZPGSZ01 -2.4438950  0.0162749  -150.163  &lt; 2e-16 ***\nDESTIN_SZPGSZ02 -0.8451914  0.0055174  -153.186  &lt; 2e-16 ***\nDESTIN_SZPGSZ03  0.2529362  0.0034356    73.622  &lt; 2e-16 ***\nDESTIN_SZPGSZ04 -0.2478654  0.0038491   -64.395  &lt; 2e-16 ***\nDESTIN_SZPGSZ05 -1.0734785  0.0063344  -169.468  &lt; 2e-16 ***\nDESTIN_SZPLSZ01 -0.5495097  0.0060781   -90.408  &lt; 2e-16 ***\nDESTIN_SZPLSZ02 -1.5722351  0.0104885  -149.902  &lt; 2e-16 ***\nDESTIN_SZPLSZ03 -0.1782908  0.0086850   -20.529  &lt; 2e-16 ***\nDESTIN_SZPLSZ04 -0.1551944  0.0083786   -18.523  &lt; 2e-16 ***\nDESTIN_SZPLSZ05 -0.7996544  0.0099573   -80.308  &lt; 2e-16 ***\nDESTIN_SZPNSZ01 -0.2835835  0.0048952   -57.931  &lt; 2e-16 ***\nDESTIN_SZPNSZ02  0.9154659  0.0066065   138.570  &lt; 2e-16 ***\nDESTIN_SZPNSZ03  0.1077954  0.0066518    16.205  &lt; 2e-16 ***\nDESTIN_SZPNSZ04  1.7847445  0.0073641   242.356  &lt; 2e-16 ***\nDESTIN_SZPNSZ05  0.9532174  0.0108878    87.549  &lt; 2e-16 ***\nDESTIN_SZPRSZ01 -1.0013251  0.0062900  -159.194  &lt; 2e-16 ***\nDESTIN_SZPRSZ02 -0.4210558  0.0043114   -97.662  &lt; 2e-16 ***\nDESTIN_SZPRSZ03  0.6407861  0.0032924   194.624  &lt; 2e-16 ***\nDESTIN_SZPRSZ04 -0.6038200  0.0073749   -81.875  &lt; 2e-16 ***\nDESTIN_SZPRSZ05 -0.3237481  0.0041005   -78.954  &lt; 2e-16 ***\nDESTIN_SZPRSZ06  0.2039871  0.0043057    47.376  &lt; 2e-16 ***\nDESTIN_SZPRSZ07 -1.1457123  0.0104668  -109.461  &lt; 2e-16 ***\nDESTIN_SZPRSZ08 -0.8729830  0.0057992  -150.534  &lt; 2e-16 ***\nDESTIN_SZQTSZ01 -1.4677400  0.0083689  -175.380  &lt; 2e-16 ***\nDESTIN_SZQTSZ02 -1.2697556  0.0060732  -209.077  &lt; 2e-16 ***\nDESTIN_SZQTSZ03 -0.6967149  0.0054986  -126.708  &lt; 2e-16 ***\nDESTIN_SZQTSZ04 -0.7466019  0.0056216  -132.809  &lt; 2e-16 ***\nDESTIN_SZQTSZ05 -0.5993615  0.0049649  -120.719  &lt; 2e-16 ***\nDESTIN_SZQTSZ06 -0.8812866  0.0053353  -165.181  &lt; 2e-16 ***\nDESTIN_SZQTSZ07 -1.4915992  0.0089009  -167.578  &lt; 2e-16 ***\nDESTIN_SZQTSZ08  0.2165260  0.0039176    55.270  &lt; 2e-16 ***\nDESTIN_SZQTSZ09 -0.4146415  0.0046976   -88.266  &lt; 2e-16 ***\nDESTIN_SZQTSZ10 -0.2193841  0.0043617   -50.298  &lt; 2e-16 ***\nDESTIN_SZQTSZ11  0.3378311  0.0041782    80.855  &lt; 2e-16 ***\nDESTIN_SZQTSZ12 -0.2029944  0.0054158   -37.482  &lt; 2e-16 ***\nDESTIN_SZQTSZ13  0.2270464  0.0041252    55.038  &lt; 2e-16 ***\nDESTIN_SZQTSZ14  0.1102927  0.0045744    24.111  &lt; 2e-16 ***\nDESTIN_SZQTSZ15  0.1633004  0.0057721    28.291  &lt; 2e-16 ***\nDESTIN_SZRCSZ01 -0.8071584  0.0052748  -153.022  &lt; 2e-16 ***\nDESTIN_SZRCSZ02 -2.1569024  0.0136086  -158.495  &lt; 2e-16 ***\nDESTIN_SZRCSZ03 -1.0009513  0.0071508  -139.978  &lt; 2e-16 ***\nDESTIN_SZRCSZ04 -2.1570287  0.0102663  -210.107  &lt; 2e-16 ***\nDESTIN_SZRCSZ05 -2.1689708  0.0095674  -226.704  &lt; 2e-16 ***\nDESTIN_SZRCSZ06 -1.8254095  0.0124663  -146.428  &lt; 2e-16 ***\nDESTIN_SZRCSZ08 -1.5012102  0.0103539  -144.990  &lt; 2e-16 ***\nDESTIN_SZRCSZ09 -1.2443962  0.0095075  -130.885  &lt; 2e-16 ***\nDESTIN_SZRCSZ10 -0.8072282  0.0051969  -155.330  &lt; 2e-16 ***\nDESTIN_SZRVSZ01 -1.6546043  0.0086377  -191.555  &lt; 2e-16 ***\nDESTIN_SZRVSZ02 -2.2642314  0.0118550  -190.994  &lt; 2e-16 ***\nDESTIN_SZRVSZ03 -1.9241528  0.0101322  -189.905  &lt; 2e-16 ***\nDESTIN_SZRVSZ04 -1.3647507  0.0114905  -118.772  &lt; 2e-16 ***\nDESTIN_SZRVSZ05 -1.3337470  0.0113096  -117.931  &lt; 2e-16 ***\nDESTIN_SZSBSZ01 -0.3783598  0.0053692   -70.468  &lt; 2e-16 ***\nDESTIN_SZSBSZ02 -0.9714858  0.0063803  -152.263  &lt; 2e-16 ***\nDESTIN_SZSBSZ03  0.5849635  0.0037871   154.461  &lt; 2e-16 ***\nDESTIN_SZSBSZ04  0.0628994  0.0048666    12.925  &lt; 2e-16 ***\nDESTIN_SZSBSZ05 -0.7903141  0.0059734  -132.306  &lt; 2e-16 ***\nDESTIN_SZSBSZ06 -2.4749704  0.0221461  -111.757  &lt; 2e-16 ***\nDESTIN_SZSBSZ07 -2.0802889  0.0163700  -127.079  &lt; 2e-16 ***\nDESTIN_SZSBSZ08  1.0512838  0.0045018   233.528  &lt; 2e-16 ***\nDESTIN_SZSBSZ09  0.4794881  0.0044114   108.692  &lt; 2e-16 ***\nDESTIN_SZSESZ02 -0.5041790  0.0039964  -126.157  &lt; 2e-16 ***\nDESTIN_SZSESZ03  0.3999040  0.0031970   125.086  &lt; 2e-16 ***\nDESTIN_SZSESZ04 -0.8064748  0.0046027  -175.216  &lt; 2e-16 ***\nDESTIN_SZSESZ05 -0.2274573  0.0038846   -58.554  &lt; 2e-16 ***\nDESTIN_SZSESZ06 -0.8726109  0.0049007  -178.058  &lt; 2e-16 ***\nDESTIN_SZSESZ07 -3.2557191  0.0198930  -163.662  &lt; 2e-16 ***\nDESTIN_SZSGSZ01 -0.2147069  0.0049537   -43.343  &lt; 2e-16 ***\nDESTIN_SZSGSZ02 -0.2178068  0.0043929   -49.582  &lt; 2e-16 ***\nDESTIN_SZSGSZ03 -0.4519684  0.0041222  -109.641  &lt; 2e-16 ***\nDESTIN_SZSGSZ04 -0.3205081  0.0040661   -78.824  &lt; 2e-16 ***\nDESTIN_SZSGSZ05 -1.8375273  0.0072964  -251.842  &lt; 2e-16 ***\nDESTIN_SZSGSZ06  0.3861484  0.0032161   120.067  &lt; 2e-16 ***\nDESTIN_SZSGSZ07 -0.3839443  0.0041174   -93.249  &lt; 2e-16 ***\nDESTIN_SZSISZ01 -0.4807184  0.0132026   -36.411  &lt; 2e-16 ***\nDESTIN_SZSKSZ01 -0.6652944  0.0062595  -106.285  &lt; 2e-16 ***\nDESTIN_SZSKSZ02  0.2704252  0.0046528    58.121  &lt; 2e-16 ***\nDESTIN_SZSKSZ03 -0.4653217  0.0051732   -89.948  &lt; 2e-16 ***\nDESTIN_SZSKSZ04 -0.8906681  0.0133805   -66.564  &lt; 2e-16 ***\nDESTIN_SZSKSZ05 -0.4150470  0.0111530   -37.214  &lt; 2e-16 ***\nDESTIN_SZSLSZ01 -0.7565998  0.0066751  -113.347  &lt; 2e-16 ***\nDESTIN_SZSLSZ04 -0.8814465  0.0053640  -164.327  &lt; 2e-16 ***\nDESTIN_SZSRSZ01 -1.1903322  0.0064592  -184.284  &lt; 2e-16 ***\nDESTIN_SZSRSZ02 -1.3027415  0.0075504  -172.539  &lt; 2e-16 ***\nDESTIN_SZSRSZ03 -1.3475702  0.0068354  -197.144  &lt; 2e-16 ***\nDESTIN_SZSVSZ01 -1.0127677  0.0413591   -24.487  &lt; 2e-16 ***\nDESTIN_SZTHSZ01 -3.3280757  0.0281757  -118.119  &lt; 2e-16 ***\nDESTIN_SZTHSZ03 -2.1899228  0.0177909  -123.092  &lt; 2e-16 ***\nDESTIN_SZTHSZ04 -2.5247657  0.0181864  -138.827  &lt; 2e-16 ***\nDESTIN_SZTHSZ06 -1.6350566  0.0118054  -138.501  &lt; 2e-16 ***\nDESTIN_SZTMSZ01 -0.3684293  0.0045579   -80.833  &lt; 2e-16 ***\nDESTIN_SZTMSZ02  1.3042469  0.0029248   445.921  &lt; 2e-16 ***\nDESTIN_SZTMSZ03  0.4611332  0.0033186   138.952  &lt; 2e-16 ***\nDESTIN_SZTMSZ04  0.8108143  0.0034018   238.351  &lt; 2e-16 ***\nDESTIN_SZTMSZ05  0.6733671  0.0042473   158.540  &lt; 2e-16 ***\nDESTIN_SZTNSZ01 -0.4410888  0.0045518   -96.905  &lt; 2e-16 ***\nDESTIN_SZTNSZ02 -1.0328372  0.0058953  -175.197  &lt; 2e-16 ***\nDESTIN_SZTNSZ03 -1.0414947  0.0071340  -145.990  &lt; 2e-16 ***\nDESTIN_SZTNSZ04 -0.9341618  0.0055851  -167.258  &lt; 2e-16 ***\nDESTIN_SZTPSZ01 -0.3698813  0.0046189   -80.079  &lt; 2e-16 ***\nDESTIN_SZTPSZ02  0.2467295  0.0032238    76.534  &lt; 2e-16 ***\nDESTIN_SZTPSZ03 -0.2439122  0.0046552   -52.395  &lt; 2e-16 ***\nDESTIN_SZTPSZ04 -1.5337020  0.0062616  -244.936  &lt; 2e-16 ***\nDESTIN_SZTPSZ05 -0.9305243  0.0048843  -190.515  &lt; 2e-16 ***\nDESTIN_SZTPSZ06 -0.4458706  0.0063048   -70.720  &lt; 2e-16 ***\nDESTIN_SZTPSZ07 -1.8014933  0.0091025  -197.912  &lt; 2e-16 ***\nDESTIN_SZTPSZ08 -1.1930009  0.0065955  -180.881  &lt; 2e-16 ***\nDESTIN_SZTPSZ09 -0.3469701  0.0050671   -68.476  &lt; 2e-16 ***\nDESTIN_SZTPSZ10 -0.9026251  0.0060902  -148.210  &lt; 2e-16 ***\nDESTIN_SZTPSZ11 -0.3080454  0.0042040   -73.275  &lt; 2e-16 ***\nDESTIN_SZTPSZ12 -0.7156204  0.0051754  -138.273  &lt; 2e-16 ***\nDESTIN_SZTSSZ01 -0.8543639  0.0200859   -42.536  &lt; 2e-16 ***\nDESTIN_SZTSSZ02 -0.5825767  0.0092558   -62.942  &lt; 2e-16 ***\nDESTIN_SZTSSZ03  0.2500858  0.0075201    33.256  &lt; 2e-16 ***\nDESTIN_SZTSSZ04  0.4593958  0.0074856    61.370  &lt; 2e-16 ***\nDESTIN_SZTSSZ05  1.5286175  0.0074395   205.473  &lt; 2e-16 ***\nDESTIN_SZTSSZ06  1.6286875  0.0134475   121.114  &lt; 2e-16 ***\nDESTIN_SZWCSZ01  1.3710389  0.0041810   327.920  &lt; 2e-16 ***\nDESTIN_SZWCSZ02 -0.7273251  0.0084384   -86.192  &lt; 2e-16 ***\nDESTIN_SZWCSZ03 -1.9636127  0.0230329   -85.253  &lt; 2e-16 ***\nDESTIN_SZWDSZ01  0.9399623  0.0031066   302.572  &lt; 2e-16 ***\nDESTIN_SZWDSZ02 -0.7981392  0.0049869  -160.048  &lt; 2e-16 ***\nDESTIN_SZWDSZ03  0.5407450  0.0034954   154.700  &lt; 2e-16 ***\nDESTIN_SZWDSZ04 -0.4445645  0.0050274   -88.428  &lt; 2e-16 ***\nDESTIN_SZWDSZ05 -0.1434480  0.0045552   -31.491  &lt; 2e-16 ***\nDESTIN_SZWDSZ06  0.1461975  0.0036640    39.901  &lt; 2e-16 ***\nDESTIN_SZWDSZ07  0.2388041  0.0046521    51.332  &lt; 2e-16 ***\nDESTIN_SZWDSZ08 -0.0098378  0.0054437    -1.807 0.070733 .  \nDESTIN_SZWDSZ09 -0.2806644  0.0041193   -68.135  &lt; 2e-16 ***\nDESTIN_SZYSSZ01  0.9357382  0.0033642   278.144  &lt; 2e-16 ***\nDESTIN_SZYSSZ02 -0.3420741  0.0045422   -75.310  &lt; 2e-16 ***\nDESTIN_SZYSSZ03 -1.2656914  0.0047488  -266.528  &lt; 2e-16 ***\nDESTIN_SZYSSZ04 -0.3567482  0.0043080   -82.811  &lt; 2e-16 ***\nDESTIN_SZYSSZ05 -1.9189376  0.0087174  -220.126  &lt; 2e-16 ***\nDESTIN_SZYSSZ06 -1.3204784  0.0065783  -200.734  &lt; 2e-16 ***\nDESTIN_SZYSSZ07 -0.6894968  0.0085776   -80.383  &lt; 2e-16 ***\nDESTIN_SZYSSZ08  0.6192002  0.0033756   183.436  &lt; 2e-16 ***\nDESTIN_SZYSSZ09 -0.0120655  0.0035260    -3.422 0.000622 ***\nlog(dist)       -0.6933493  0.0001075 -6451.265  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 105499054  on 20915  degrees of freedom\nResidual deviance:  36022972  on 20297  degrees of freedom\nAIC: 36156596\n\nNumber of Fisher Scoring iterations: 7\n\n\nWe can examine how the constraints hold this time.\n\nCalcRSquared(dbcSIM$data$TRIPS, dbcSIM$fitted.values)\n\n[1] 0.5614171\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThere is a relatively greater improvement in the \\(R^2\\) value using the doubly constrained model.\n\n\n\n8.9 Model Comparison\nAnother useful model performance measure for continuous dependent variable is Root Mean Squared Error. We can use compare_performance() of performance package for this purpose.\nFirst, we will create a list of models:\n\nmodel_list &lt;- list(unconstrained=uncSIM,\n                   originConstrained=orcSIM,\n                   destinationConstrained=decSIM,\n                   doublyConstrained=dbcSIM)\n\nThen, compare their RMSE values:\n\ncompare_performance(model_list,\n                    metrics = \"RMSE\")\n\n# Comparison of Model Performance Indices\n\nName                   | Model |     RMSE\n-----------------------------------------\nunconstrained          |   glm | 5485.538\noriginConstrained      |   glm | 4849.984\ndestinationConstrained |   glm | 4409.233\ndoublyConstrained      |   glm | 4231.607\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe doubly constrained SIM has the lowest RMSE, making it the best model.\n\n\n\n8.10 Visualizing Fitted Values\nWe can extract and visualize the fitted values for each model. To do so, start by extracting the fitted values for each model and adding their fitted values to SIM_data:\n\ndf &lt;- as.data.frame(uncSIM$fitted.values) %&gt;%\n  round(digits = 0)\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(uncTRIPS = \"uncSIM$fitted.values\")\n\ndf &lt;- as.data.frame(orcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(orcTRIPS = \"orcSIM$fitted.values\")\n\ndf &lt;- as.data.frame(decSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(decTRIPS = \"decSIM$fitted.values\")\n\ndf &lt;- as.data.frame(dbcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(dbcTRIPS = \"dbcSIM$fitted.values\")\n\nCreate scatter plots for each model and present in single plot:\n\nunc_p &lt;- ggplot(data = SIM_data,\n                aes(x = uncTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\norc_p &lt;- ggplot(data = SIM_data,\n                aes(x = orcTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndec_p &lt;- ggplot(data = SIM_data,\n                aes(x = decTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndbc_p &lt;- ggplot(data = SIM_data,\n                aes(x = dbcTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\nggarrange(unc_p, orc_p, dec_p, dbc_p,\n          ncol = 2,\n          nrow = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nThe doubly constrained model provides the best fit to the data, as seen by the closer clustering around the diagonal line.\nBoth the origin and destination-constrained models improve over the unconstrained model but still show some deviations.\nThe unconstrained model performs the worst, with a weak relationship between predicted and actual values."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-Class Exercise 6",
    "section": "",
    "text": "ISSS626 Geospatial Analytics and Applications – In-class Exercise 6: Emerging Hot Spot Analysis"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#exercise-reference",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#exercise-reference",
    "title": "In-Class Exercise 6",
    "section": "",
    "text": "ISSS626 Geospatial Analytics and Applications – In-class Exercise 6: Emerging Hot Spot Analysis"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#overview",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#overview",
    "title": "In-Class Exercise 6",
    "section": "\n2 Overview",
    "text": "2 Overview\nIn this exercise, we will explore Emerging Hot Spot Analysis (EHSA), a spatio-temporal analysis method for identifying and categorizing hot and cold spot trends over time in a spatial dataset."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#learning-outcome",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#learning-outcome",
    "title": "In-Class Exercise 6",
    "section": "\n3 Learning Outcome",
    "text": "3 Learning Outcome\n\nLoad and install R packages for spatio-temporal analysis.\nCreate a space-time cube using geospatial and temporal data.\nCalculate Gi* statistics and use the Mann-Kendall test to detect monotonic trends.\nPerform Emerging Hot Spot Analysis using spatio-temporal data.\nVisualize the results of EHSA with spatial and temporal trends."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#import-the-r-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#import-the-r-packages",
    "title": "In-Class Exercise 6",
    "section": "\n4 Import the R Packages",
    "text": "4 Import the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\nsf\nHandles spatial data; imports, manages, and processes vector-based geospatial data.\nImporting and managing geospatial data, such as Hunan’s county boundary shapefile.\n\n\nsfdep\nProvides functions for spatial autocorrelation and temporal analysis, including Emerging Hot Spot Analysis (EHSA).\nPerforming spatio-temporal analysis using Gi* statistics and Mann-Kendall test.\n\n\nplotly\nCreates interactive plots in R.\nVisualizing spatio-temporal trends with interactive plots.\n\n\ntidyverse\nA collection of R packages for data science tasks like data manipulation, visualization, and modeling.\nWrangling aspatial data and joining it with geospatial datasets.\n\n\nKendall\nProvides functions for performing the Mann-Kendall test for detecting trends in time series data.\nPerforming the Mann-Kendall test to assess the trends in Gi* statistics over time.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(sf, sfdep, tmap, plotly, tidyverse, Kendall)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#the-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#the-data",
    "title": "In-Class Exercise 6",
    "section": "\n5 The Data",
    "text": "5 The Data\nThe following datasets will be used in this exercise:\n\n\n\n\n\n\n\nData Set\nDescription\nFormat\n\n\n\nHunan\nA geospatial dataset containing Hunan’s county boundaries.\nESRI Shapefile\n\n\nHunan_GDPPC\nA CSV file containing GDP per capita data of Hunan from 2000 to 2012.\nCSV\n\n\n\nSimilar to hands-on exercises, import the datasets accordingly:\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex06/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nGDPPC &lt;- read_csv(\"data/aspatial/Hunan_GDPPC.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#creating-a-time-series-cube",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#creating-a-time-series-cube",
    "title": "In-Class Exercise 6",
    "section": "\n6 Creating a Time Series Cube",
    "text": "6 Creating a Time Series Cube\n\n\n\n\n\n\nNote\n\n\n\nRelevant Reading Material: spacetime and spacetime cubes • sfdep\nA space-time cube represents spatio-temporal data, combining location and time to study trends, often used for identifying patterns like hot spots. It is popular for its ability to handle large datasets, and it is available in ArcGIS.\nIn R, it can be implemented for free using libraries like sfdep. The implementation in R follows tidyverse principles.\nConstraints: - Spatial locations (geometry) must be static. - Time and data values can be dynamic.\nGood for:\n\nTracking consistent locations over time (e.g., temperature changes in cities where admin boundaries are static).\n\nNot ideal for:\n\nEvents where boundaries shift, like forest fires, where the area or size of the fire evolves.\n\n\n\nTo create a spatio-temporal cube:\n\nGDPPC_st &lt;- spacetime(GDPPC, hunan,\n                      .loc_col = \"County\",\n                      .time_col = \"Year\")\n\nAnd it is always good to verify that we created a valid spacetime_cube object.\n\nis_spacetime_cube(GDPPC_st)\n\n[1] TRUE"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-gi",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-gi",
    "title": "In-Class Exercise 6",
    "section": "\n7 Computing Gi*",
    "text": "7 Computing Gi*\nNext, we will compute the local Gi* statistics.\n\n7.1 Deriving the spatial weights\nTo identify neighbors and to derive an inverse distance weights:\n\n\n\n\n\n\nTip\n\n\n\n\n\nactivate(\"geometry\"): Activates the geometry context for spatial operations.\n\nmutate(): Adds two columns:\n\n\nnb: Neighbors, including the observation itself (include_self), using spatial contiguity (st_contiguity).\n\nwt: Weights, calculated with inverse distance (st_inverse_distance).\n\n\n\nset_nbs() and set_wts(): Copies neighbors and weights to all time-slices. Ensure row order consistency after using these functions.\n\n\n\n\nGDPPC_nb &lt;- GDPPC_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wt = st_inverse_distance(nb, \n                             geometry, \n                             scale = 1,\n                             alpha = 1),\n    .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\nNote that this dataset now has neighbors and weights for each time-slice.\nTo calculate the local Gi* statistic for each location:\n\n\nGroup by Year: This ensures we calculate Gi* separately for each year in the dataset.\n\nUse local_gstar_perm(): This function computes the local Gi* statistic using the GDPPC values, neighbors (nb), and weights (wt).\n\nUnnest the Gi* results: The gi_star column is nested, so we use unnest() to extract the results into a clean format.\n\n\ngi_stars &lt;- GDPPC_nb %&gt;% \n  group_by(Year) %&gt;% \n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %&gt;% \n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#mann-kendall-test",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#mann-kendall-test",
    "title": "In-Class Exercise 6",
    "section": "\n8 Mann-Kendall Test",
    "text": "8 Mann-Kendall Test\n\n\n\n\n\n\nImportant\n\n\n\nA monotonic series or function is one that only increases (or decreases) and never changes direction. So long as the function either stays flat or continues to increase, it is monotonic.\n\\(H_0\\): No monotonic trend\n\\(H_1\\): Monotonic trend is present\nInterpretation\n\nReject the null-hypothesis null if the p-value is smaller than the alpha value (i.e. 1-confident level)\nTau ranges between -1 and 1 where:\n\n-1 is a perfectly decreasing series, and\n1 is a perfectly increasing series.\n\n\n\nRefer to Mann-Kendall Test For Monotonic Trend\n\n\n\n8.1 Mann-Kendall Test on Gi\nTo evaluate trends in Gi* measures over time using the Mann-Kendall test for a specific location, like Changsha county:\nFilter data for Changsha:\n\ncbg &lt;- gi_stars %&gt;% \n ungroup() %&gt;% \n filter(County == \"Changsha\") %&gt;% \n select(County, Year, gi_star)\n\nPlot the Gi* values over time using ggplot2:\n\np &lt;- ggplot(data = cbg, \n       aes(x = Year, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n\n\n\n\n\nTo print Mann-Kendall test report:\n\ncbg %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n    tau      sl     S     D  varS\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.485 0.00742    66  136.  589.\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nIn the above result, sl is the p-value. With reference to the results, we will reject the null hypothesis and infer that a slight upward trend.\n\n\n\n8.2 Mann-Kendall test data.frame\nTo replicate this for each location by using group_by() of dplyr package:\n\nehsa &lt;- gi_stars %&gt;%\n  group_by(County) %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;%\n  tidyr::unnest_wider(mk)\nhead(ehsa)\n\n# A tibble: 6 × 6\n  County        tau        sl     S     D  varS\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Anhua      0.191  0.303        26  136.  589.\n2 Anren     -0.294  0.108       -40  136.  589.\n3 Anxiang    0      1             0  136.  589.\n4 Baojing   -0.691  0.000128    -94  136.  589.\n5 Chaling   -0.0882 0.650       -12  136.  589.\n6 Changning -0.750  0.0000318  -102  136.  589.\n\n\nAnd sort to show significant emerging hot/cold spots:\n\nemerging &lt;- ehsa %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:10)\nhead(emerging)\n\n# A tibble: 6 × 6\n  County        tau         sl     S     D  varS\n  &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Shuangfeng  0.868 0.00000143   118  136.  589.\n2 Xiangtan    0.868 0.00000143   118  136.  589.\n3 Xiangxiang  0.868 0.00000143   118  136.  589.\n4 Chengbu    -0.824 0.00000482  -112  136.  589.\n5 Dongan     -0.824 0.00000482  -112  136.  589.\n6 Wugang     -0.809 0.00000712  -110  136.  589."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#performing-emerging-hotspot-analysis",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#performing-emerging-hotspot-analysis",
    "title": "In-Class Exercise 6",
    "section": "\n9 Performing Emerging Hotspot Analysis",
    "text": "9 Performing Emerging Hotspot Analysis\nTo perform Emerging Hotspot Analysis (EHSA), we can use the emerging_hotspot_analysis() function from the sfdep package. This function analyzes spatio-temporal trends by detecting areas that are hotspots over time. It takes the following parameters: - x: The spacetime object (e.g., GDPPC_st). - .var: The variable of interest (e.g., \"GDPPC\"). - k: Number of time lags (default is 1). - nsim: Number of simulations to run (e.g., 99).\n\nset.seed(1234)\nehsa &lt;- emerging_hotspot_analysis(\n  x = GDPPC_st, \n  .var = \"GDPPC\", \n  k = 1, \n  nsim = 99\n)\n\n\nehsa\n\n# A tibble: 88 × 4\n   location     tau    p_value classification     \n   &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;              \n 1 Anxiang    0.221 0.232      sporadic coldspot  \n 2 Hanshou    0.147 0.434      sporadic hotspot   \n 3 Jinshi     0.441 0.0151     oscilating hotspot \n 4 Li        -0.824 0.00000482 sporadic coldspot  \n 5 Linli      0.118 0.537      oscilating hotspot \n 6 Shimen    -0.471 0.00946    oscilating coldspot\n 7 Liuyang    0.868 0.00000143 sporadic hotspot   \n 8 Ningxiang -0.559 0.00201    sporadic coldspot  \n 9 Wangcheng -0.162 0.387      sporadic coldspot  \n10 Anren      0.456 0.0120     sporadic coldspot  \n# ℹ 78 more rows\n\n\n\n9.1 Visualising the Distribution of EHSA classes\nTo visualize the EHSA classification distribution using a bar chart with ggplot2:\n\nggplot(data = ehsa, aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\nThe bar char shows that sporadic cold spots class has the high numbers of county.\n\n\n\n\n\n\nImportant\n\n\n\nNote that in the above plot, we did not filter for statistically significant EHSA results, which may be misleading for our analysis\n\n\nTo filter for statistically significant EHSA results, we should focus on locations where the p_value is below a threshold (&lt; 0.05).\n\nehsa_significant &lt;- ehsa %&gt;%\n  filter(p_value &lt; 0.05)\n\nggplot(data = ehsa_significant, aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\nThis will display a bar chart showing the distribution of EHSA classes for locations with statistically significant results. Note that the distribution is similar, but the magnitude is smaller after filtering.\n\n9.2 Visualising EHSA\nTo visualise the geographic distribution EHSA classes, we need to join both hunan and ehsa together before creating the plot. Note that in this case, we have filtered for statistically significant results.\n\nhunan_ehsa &lt;- hunan %&gt;%\n  left_join(ehsa,\n            by = join_by(County == location))\n\nehsa_sig &lt;- hunan_ehsa  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(hunan_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\n9.3 Interpretation of EHSA classes\nAdditional Notes\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFinal Notes:\nEHSA and the Mann-Kendall test complement each other by analyzing spatio-temporal data in different ways.\n\nThe Mann-Kendall test checks for monotonic trends without randomization or permutation, calculating a tau value that indicates trend strength.\nOn the other hand, EHSA includes simulations, providing more robust spatial analysis with its own tau and p-values, which may differ from those in the Mann-Kendall test. And we will have use the EHSA results to do our final hotspot classification.\n\nBy performing both, we gain deeper insights into spatio-temporal trends, accounting for both trend significance and spatial randomness."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take Home Exercise 2",
    "section": "",
    "text": "Refer to: Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics – ISSS626 Geospatial Analytics and Applications"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#assignment-task",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#assignment-task",
    "title": "Take Home Exercise 2",
    "section": "",
    "text": "Refer to: Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics – ISSS626 Geospatial Analytics and Applications"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#overview",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#overview",
    "title": "Take Home Exercise 2",
    "section": "\n2 Overview",
    "text": "2 Overview\nTourism is a major industry in Thailand, accounting for about 20% of the GDP. In 2019, the sector generated 90 billion USD, but this dropped sharply to 24 billion USD in 2020 due to the COVID-19 pandemic. Notably,tourism revenue is also unevenly distributed, with provinces like Bangkok, Phuket, and Chiang Mai dominating the sector, while others see less impact.\nIn this exercise, we will explore how COVID-19 affected Thailand’s tourism economy using spatial and spatio-temporal analysis, focusing on how the impacts varied across different provinces and examining recovery patterns."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#objectives",
    "title": "Take Home Exercise 2",
    "section": "\n3 Objectives",
    "text": "3 Objectives\nThe main objectives of this exercise are:\n\nDetermine if the key indicators of tourism economy of Thailand are independent from space and space and time.\nIf the tourism economy shows spatial and spatio-temporal dependence, identify clusters, outliers, and emerging hotspot/cold spot areas."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#methodology",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#methodology",
    "title": "Take Home Exercise 2",
    "section": "\n4 Methodology",
    "text": "4 Methodology\nIn this exercise, we will follow these steps:\n\n\nGeospatial Data Preparation: Using sf and tidyverse packages to create spatial and spatio-temporal datasets, specifically:\n\n\na province level study area layer of Bangkok in sf polygon features\na tourism economy indicators layer within the study area in sf polygon features.\na derived tourism economy indicator layer in spacetime s3 class of sfdep. The time series will be at month and year levels.\n\n\nGlobal Spatial Autocorrelation Analysis: Using sfdep methods to identify spatial patterns in the tourism economy.\nLocal Spatial Autocorrelation Analysis: Detecting clusters and outliers at the provincial level.\nEmerging Hotspot Analysis: Applying spatio-temporal analysis to identify trends in tourism revenue recovery or decline."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-data",
    "title": "Take Home Exercise 2",
    "section": "\n5 The Data",
    "text": "5 The Data\nWe will use two primary datasets for this analysis:\n\n\nDataset Name\nDescription\nFormat\nSource\n\n\n\nThailand Domestic Tourism Statistics\nMonthly tourism statistics, including revenue and visitor numbers at the province level.\nCSV\nKaggle\n\n\nThailand - Subnational Administrative Boundaries\nGeospatial data of provincial boundaries in Thailand.\nESRI Shapefile\nHDX"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#installing-and-launching-the-r-packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#installing-and-launching-the-r-packages",
    "title": "Take Home Exercise 2",
    "section": "\n6 Installing and Launching the R Packages",
    "text": "6 Installing and Launching the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\nsf\nHandles spatial data; imports, manages, and processes vector-based geospatial data.\nImporting and managing geospatial data, such as Hunan’s county boundary shapefile.\n\n\nsfdep\nProvides functions for spatial autocorrelation and temporal analysis, including Emerging Hot Spot Analysis (EHSA).\nPerforming spatio-temporal analysis using Gi* statistics and Mann-Kendall test.\n\n\nplotly\nCreates interactive plots in R.\nVisualizing spatio-temporal trends with interactive plots.\n\n\ntidyverse\nA collection of R packages for data science tasks like data manipulation, visualization, and modeling.\nWrangling aspatial data and joining it with geospatial datasets.\n\n\nKendall\nProvides functions for performing the Mann-Kendall test for detecting trends in time series data.\nPerforming the Mann-Kendall test to assess the trends in Gi* statistics over time.\n\n\nspdep\nSpatial dependence modeling and analysis tools for areal data.\nConducting spatial autocorrelation analysis for cluster detection using Moran’s I and other statistics.\n\n\ntmap\nThematic map visualization for spatial data.\nCreating visually appealing maps to highlight spatial patterns.\n\n\nRColorBrewer\nProvides color palettes for enhancing visualizations.\nApplying color schemes to maps for better data interpretation.\n\n\nDT\nCreates interactive tables.\nDisplaying summary statistics in an interactive format for easy data exploration.\n\n\nggplot2\nA versatile package for static data visualization.\nPlotting spatial and aspatial data relationships, such as scatter plots and density maps.\n\n\ncorrplot\nVisualizes correlation matrices.\nDisplaying the relationships between different spatial features and their correlations.\n\n\n\n\npacman::p_load(tidyverse, sf, spdep, sfdep, tmap, knitr, DT, ggplot2, plotly, RColorBrewer, corrplot)\n\n\n6.1 Reproducibility\nFor reproducible results of this exercise, we will use seed value, 1234.\n\nset.seed(1234)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#import-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#import-data",
    "title": "Take Home Exercise 2",
    "section": "\n7 Import Data",
    "text": "7 Import Data\nIn this section, we will perform sanity checks on the raw data obtained from official sources.\n\n7.1 Import Geospatial Data\n\nFirstly, we import the spatial dataset of administrative level 1 boundaries for province-level analysis in Thailand. This forms the study area layer in sf polygon features and uses the UTM Zone 47N (EPSG:32647) CRS.\n\nWe will rename ADM1_EN column to be consistent with the aspatial dataset later on.\n\nadmin_boundary &lt;- st_read(dsn = \"data/raw_data/\", \n                      layer = \"tha_admbnda_adm1_rtsd_20220121\",\n                      crs=32647)\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Take-home_Ex/Take-home_Ex02/data/raw_data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nProjected CRS: WGS 84 / UTM zone 47N\n\nadmin_boundary &lt;- admin_boundary %&gt;%\n  rename(province_eng = ADM1_EN)\n\nglimpse(admin_boundary)\n\nRows: 77\nColumns: 17\n$ Shape_Leng   &lt;dbl&gt; 2.417227, 1.695100, 1.251111, 1.884945, 3.041716, 1.73990…\n$ Shape_Area   &lt;dbl&gt; 0.13133873, 0.07926199, 0.05323766, 0.12698345, 0.2139379…\n$ province_eng &lt;chr&gt; \"Bangkok\", \"Samut Prakan\", \"Nonthaburi\", \"Pathum Thani\", …\n$ ADM1_TH      &lt;chr&gt; \"กรุงเทพมหานคร\", \"สมุทรปราการ\", \"นนทบุรี\", \"ปทุมธานี\", \"พระนครศ…\n$ ADM1_PCODE   &lt;chr&gt; \"TH10\", \"TH11\", \"TH12\", \"TH13\", \"TH14\", \"TH15\", \"TH16\", \"…\n$ ADM1_REF     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ADM1ALT1EN   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ADM1ALT2EN   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ADM1ALT1TH   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ADM1ALT2TH   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ADM0_EN      &lt;chr&gt; \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand\", \"Thailand…\n$ ADM0_TH      &lt;chr&gt; \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเทศไทย\", \"ประเ…\n$ ADM0_PCODE   &lt;chr&gt; \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH\", \"TH…\n$ date         &lt;date&gt; 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-18, 2019-02-…\n$ validOn      &lt;date&gt; 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-22, 2022-01-…\n$ validTo      &lt;date&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ geometry     &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((100.6139 13..., MULTIPOLYGON…\n\n\n\n7.2 Import Aspatial Data\nWe import and examine the aspatial tourism dataset:\n\ntourism_df &lt;- read_csv(\"data/raw_data/thailand_domestic_tourism_2019_2023_ver2.csv\")\n\ntourism_df\n\n# A tibble: 30,800 × 7\n   date       province_thai province_eng   region_thai region_eng variable value\n   &lt;date&gt;     &lt;chr&gt;         &lt;chr&gt;          &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;    &lt;dbl&gt;\n 1 2019-01-01 กรุงเทพมหานคร  Bangkok        ภาคกลาง     central    ratio_t…  93.4\n 2 2019-01-01 ลพบุรี          Lopburi        ภาคกลาง     central    ratio_t…  61.3\n 3 2019-01-01 พระนครศรีอยุธยา Phra Nakhon S… ภาคกลาง     central    ratio_t…  73.4\n 4 2019-01-01 สระบุรี         Saraburi       ภาคกลาง     central    ratio_t…  67.3\n 5 2019-01-01 ชัยนาท         Chainat        ภาคกลาง     central    ratio_t…  79.3\n 6 2019-01-01 นครปฐม        Nakhon Pathom  ภาคกลาง     central    ratio_t…  71.7\n 7 2019-01-01 สิงห์บุรี         Sing Buri      ภาคกลาง     central    ratio_t…  64.6\n 8 2019-01-01 อ่างทอง        Ang Thong      ภาคกลาง     central    ratio_t…  71.2\n 9 2019-01-01 นนทบุรี         Nonthaburi     ภาคกลาง     central    ratio_t…  75.1\n10 2019-01-01 ปทุมธานี        Pathum Thani   ภาคกลาง     central    ratio_t…  60.8\n# ℹ 30,790 more rows\n\n\nFrom the output above, we can observe that there are 7 columns in this dataset and there are 30,800 records in this dataset.\nNext, we check for missing data in the dataset:\n\nnull_counts &lt;- sapply(tourism_df, function(x) sum(is.na(x)))\nnull_counts\n\n         date province_thai  province_eng   region_thai    region_eng \n            0             0             0             0             0 \n     variable         value \n            0             0 \n\ndata.frame(Column = names(null_counts), Null_Count = null_counts)\n\n                     Column Null_Count\ndate                   date          0\nprovince_thai province_thai          0\nprovince_eng   province_eng          0\nregion_thai     region_thai          0\nregion_eng       region_eng          0\nvariable           variable          0\nvalue                 value          0\n\n\nFrom the output above, there are no missing values in the dataset.\nNext, we check for duplicate values.\n\nduplicate_count &lt;- sum(duplicated(tourism_df))\nduplicate_count\n\n[1] 0\n\n\nThere are no exact duplicates in this dataset.\n\nglimpse(tourism_df)\n\nRows: 30,800\nColumns: 7\n$ date          &lt;date&gt; 2019-01-01, 2019-01-01, 2019-01-01, 2019-01-01, 2019-01…\n$ province_thai &lt;chr&gt; \"กรุงเทพมหานคร\", \"ลพบุรี\", \"พระนครศรีอยุธยา\", \"สระบุรี\", \"ชัยนาท…\n$ province_eng  &lt;chr&gt; \"Bangkok\", \"Lopburi\", \"Phra Nakhon Si Ayutthaya\", \"Sarab…\n$ region_thai   &lt;chr&gt; \"ภาคกลาง\", \"ภาคกลาง\", \"ภาคกลาง\", \"ภาคกลาง\", \"ภาคกลาง\", \"…\n$ region_eng    &lt;chr&gt; \"central\", \"central\", \"central\", \"central\", \"central\", \"…\n$ variable      &lt;chr&gt; \"ratio_tourist_stay\", \"ratio_tourist_stay\", \"ratio_touri…\n$ value         &lt;dbl&gt; 93.37, 61.32, 73.37, 67.33, 79.31, 71.70, 64.65, 71.21, …"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling",
    "title": "Take Home Exercise 2",
    "section": "\n8 Data Wrangling",
    "text": "8 Data Wrangling\nIn this section, we will perform some data cleaning, feature engineering and finally combine the two data sets for spatial and spatial-temporal analysis later on.\n\n8.1 Data Cleaning\nBased on the discussions in the Kaggle forum, there may be some mislabeled data and the provided data dictionary may not match this version (ver. 2) of the dataset.\nIn essence, we will address these issues in this section step by step:\n\nDrop unused columns in Thai.\nSimplify the region name \"east_northeast\" to \"northeast\".\nCorrect the region name for Sisaket.\nCreate a “bmr” region to further differentiate the Bangkok Metropolitan Region for more fine-grained analysis later on.\nCreate a time_period to indicate pre-covid, covid, post-covid periods.\nFactorize date into months and years\nCreate a date_int to facilitate space-time cube creation\nPivot the dataset to a wider format for analysis.\nCheck for discrepancies in region names as we will join both dataset with this field.\n\n\n\n\n\n\n\nRecap on the Covid-19 Pandemic Timeline for Thailand\n\n\n\nTo better understand the impact of the pandemic on Thailand’s tourism industry, it’s essential to distinguish the key phases of the pandemic: pre-covid, covid and post-covid phases.\n\n\nEvent\nDate(s)\n\n\n\nFirst COVID-19 Case in Thailand\nJanuary 13, 2020\n\n\nStart of Foreign Travel Ban\nApril 06, 2020\n\n\nNationwide Lockdown Begins\nMarch 26, 2020\n\n\nEmergency Decree Enforced\nMarch 26, 2020\n\n\nLockdown Lifted\nAugust 31, 2021\n\n\nFinal Foreign Travel Ban Lifted\nNovember 1, 2021\n\n\nEnd of Emergency Decree\nSeptember 30, 2022\n\n\n\nFrom this, we can define pandemic period as Jan 2020 to September 2022.\nSources:\n\nTimeline of the COVID-19 pandemic in Thailand - Wikipedia\nThailand - Full Restrictions, Travel regulations, Coronavirus regulations, travel bans - Travelbans\nThailand ends COVID-19 Emergency Decree on 30 September 2022 - TAT Newsroom\n\n\n\n\n# remove th columns\ntourism_df &lt;- tourism_df %&gt;%\n  select(-province_thai, -region_thai)\n\n# examine unique values\nlapply(tourism_df %&gt;% select(-value), unique)\n\n$date\n [1] \"2019-01-01\" \"2020-01-01\" \"2021-01-01\" \"2022-01-01\" \"2023-01-01\"\n [6] \"2019-02-01\" \"2020-02-01\" \"2021-02-01\" \"2022-02-01\" \"2023-02-01\"\n[11] \"2019-03-01\" \"2020-03-01\" \"2021-03-01\" \"2022-03-01\" \"2019-04-01\"\n[16] \"2020-04-01\" \"2021-04-01\" \"2022-04-01\" \"2019-05-01\" \"2020-05-01\"\n[21] \"2021-05-01\" \"2022-05-01\" \"2019-06-01\" \"2020-06-01\" \"2021-06-01\"\n[26] \"2022-06-01\" \"2019-07-01\" \"2020-07-01\" \"2021-07-01\" \"2022-07-01\"\n[31] \"2019-08-01\" \"2020-08-01\" \"2021-08-01\" \"2022-08-01\" \"2019-09-01\"\n[36] \"2020-09-01\" \"2021-09-01\" \"2022-09-01\" \"2019-10-01\" \"2020-10-01\"\n[41] \"2021-10-01\" \"2022-10-01\" \"2019-11-01\" \"2020-11-01\" \"2021-11-01\"\n[46] \"2022-11-01\" \"2019-12-01\" \"2020-12-01\" \"2021-12-01\" \"2022-12-01\"\n\n$province_eng\n [1] \"Bangkok\"                  \"Lopburi\"                 \n [3] \"Phra Nakhon Si Ayutthaya\" \"Saraburi\"                \n [5] \"Chainat\"                  \"Nakhon Pathom\"           \n [7] \"Sing Buri\"                \"Ang Thong\"               \n [9] \"Nonthaburi\"               \"Pathum Thani\"            \n[11] \"Samut Prakan\"             \"Samut Sakhon\"            \n[13] \"Chachoengsao\"             \"Ratchaburi\"              \n[15] \"Kanchanaburi\"             \"Samut Songkhram\"         \n[17] \"Suphan Buri\"              \"Phetchaburi\"             \n[19] \"Prachuap Khiri Khan\"      \"Chonburi\"                \n[21] \"Chanthaburi\"              \"Trat\"                    \n[23] \"Nakhon Nayok\"             \"Prachinburi\"             \n[25] \"Rayong\"                   \"Sa Kaeo\"                 \n[27] \"Phuket\"                   \"Phatthalung\"             \n[29] \"Trang\"                    \"Ranong\"                  \n[31] \"Chumphon\"                 \"Pattani\"                 \n[33] \"Yala\"                     \"Nakhon Si Thammarat\"     \n[35] \"Narathiwat\"               \"Krabi\"                   \n[37] \"Songkhla\"                 \"Phang Nga\"               \n[39] \"Surat Thani\"              \"Satun\"                   \n[41] \"Kamphaeng Phet\"           \"Chiang Rai\"              \n[43] \"Chiang Mai\"               \"Phichit\"                 \n[45] \"Nakhon Sawan\"             \"Tak\"                     \n[47] \"Phitsanulok\"              \"Phayao\"                  \n[49] \"Phetchabun\"               \"Phrae\"                   \n[51] \"Lampang\"                  \"Lamphun\"                 \n[53] \"Mae Hong Son\"             \"Uttaradit\"               \n[55] \"Uthai Thani\"              \"Sukhothai\"               \n[57] \"Nan\"                      \"Kalasin\"                 \n[59] \"Khon Kaen\"                \"Chaiyaphum\"              \n[61] \"Nakhon Phanom\"            \"Nakhon Ratchasima\"       \n[63] \"Buriram\"                  \"Maha Sarakham\"           \n[65] \"Mukdahan\"                 \"Roi Et\"                  \n[67] \"Loei\"                     \"Sisaket\"                 \n[69] \"Surin\"                    \"Nong Khai\"               \n[71] \"Bueng Kan\"                \"Udon Thani\"              \n[73] \"Ubon Ratchathani\"         \"Sakon Nakhon\"            \n[75] \"Yasothon\"                 \"Amnat Charoen\"           \n[77] \"Nong Bua Lamphu\"         \n\n$region_eng\n[1] \"central\"        \"east\"           \"south\"          \"north\"         \n[5] \"east_northeast\"\n\n$variable\n[1] \"ratio_tourist_stay\" \"no_tourist_stay\"    \"no_tourist_all\"    \n[4] \"no_tourist_thai\"    \"no_tourist_foreign\" \"revenue_all\"       \n[7] \"revenue_thai\"       \"revenue_foreign\"   \n\n\n\n# examine sisaket's region\ncheck_sisaket &lt;- tourism_df %&gt;%\n  filter(province_eng == \"Sisaket\") %&gt;%\n  select(province_eng, region_eng) %&gt;%\n  head(5)\n\ncheck_sisaket\n\n# A tibble: 5 × 2\n  province_eng region_eng\n  &lt;chr&gt;        &lt;chr&gt;     \n1 Sisaket      south     \n2 Sisaket      south     \n3 Sisaket      south     \n4 Sisaket      south     \n5 Sisaket      south     \n\n\nFrom the check, we notice Sisaket is indeed incorrectly labeled.\nWe then correct region names and assign provinces in the Bangkok Metropolitan Region to \"bmr\":\n\nbmr_list&lt;- c(\"Bangkok\", \"Nonthaburi\", \"Nakhon Pathom\", \"Pathum Thani\", \n           \"Samut Prakan\", \"Samut Sakhon\")\n\ntourism_df_cleaned &lt;- tourism_df %&gt;%\n  mutate(\n    # Rename the \"east_northeast\" region to \"northeast\"\n    region_eng = ifelse(region_eng == \"east_northeast\", \"northeast\", region_eng),\n    # Correct the region for Sisaket\n    region_eng = ifelse(province_eng == \"Sisaket\", \"northeast\", region_eng),\n    # Set the region to \"bmr\" for provinces in the metro list\n    region_eng = ifelse(province_eng %in% bmr_list, \"bmr\", region_eng),\n    # Create covid period column\n    time_period = case_when(\n      date &lt; as.Date(\"2020-01-01\") ~ \"pre-covid\",\n      date &gt;= as.Date(\"2020-01-01\") & date &lt;= as.Date(\"2022-10-01\") ~ \"covid\",\n      date &gt;= as.Date(\"2022-10-01\") ~ \"post-covid\"\n    ),\n    # Extract month number (1 = January, 12 = December)\n    month_number = month(date),\n    # Extract month as factor (\"Jan\", \"Feb\")\n    month_factor = month(date, label = TRUE, abbr = TRUE),\n    # Extract year\n    year = year(date),\n    # Make single date column for spacetimecube\n    date_int = as.numeric(format(date, \"%Y%m\"))\n  ) %&gt;%\n  # Drop date column\n  select(-date)\n\nWe check for unmatched region names between the spatial and aspatial datasets:\n\n# Find and see all unmatched values between admin_boundary and tourism_df\nunmatched_region_names &lt;- union(\n  anti_join(admin_boundary, tourism_df_cleaned, by = c(\"province_eng\")) %&gt;% pull(province_eng),\n  anti_join(tourism_df_cleaned, admin_boundary, by = c(\"province_eng\")) %&gt;% pull(province_eng)\n) %&gt;% sort()\n\nunmatched_region_names\n\n [1] \"Buri Ram\"         \"Buriram\"          \"Chai Nat\"         \"Chainat\"         \n [5] \"Chon Buri\"        \"Chonburi\"         \"Lop Buri\"         \"Lopburi\"         \n [9] \"Nong Bua Lam Phu\" \"Nong Bua Lamphu\"  \"Phang Nga\"        \"Phangnga\"        \n[13] \"Prachin Buri\"     \"Prachinburi\"      \"Si Sa Ket\"        \"Sisaket\"         \n\n\nWe notice some discrepancies, such as inconsistent spacing in names (e.g., \"Buri Ram\" vs. \"Buriram\").\nWe also pivot the dataset and correct the inconsistent province names:\n\ntourism_df_pivot &lt;- tourism_df_cleaned %&gt;%\n  pivot_wider(names_from = \"variable\", values_from = \"value\") %&gt;%\n  mutate(province_eng = recode(trimws(province_eng),\n                               \"Buriram\" = \"Buri Ram\",\n                               \"Chainat\" = \"Chai Nat\",\n                               \"Chonburi\" = \"Chon Buri\",\n                               \"Lopburi\" = \"Lop Buri\",\n                               \"Nong Bua Lamphu\" = \"Nong Bua Lam Phu\",\n                               \"Phang Nga\" = \"Phangnga\",\n                               \"Prachinburi\" = \"Prachin Buri\",\n                               \"Sisaket\" = \"Si Sa Ket\"))\n\nsummary(tourism_df_pivot)\n\n province_eng        region_eng        time_period         month_number \n Length:3850        Length:3850        Length:3850        Min.   : 1.0  \n Class :character   Class :character   Class :character   1st Qu.: 3.0  \n Mode  :character   Mode  :character   Mode  :character   Median : 6.0  \n                                                          Mean   : 6.3  \n                                                          3rd Qu.: 9.0  \n                                                          Max.   :12.0  \n                                                                        \n  month_factor       year         date_int      ratio_tourist_stay\n Jan    : 385   Min.   :2019   Min.   :201901   Min.   : 0.00     \n Feb    : 385   1st Qu.:2020   1st Qu.:202001   1st Qu.:20.18     \n Mar    : 308   Median :2021   Median :202102   Median :41.81     \n Apr    : 308   Mean   :2021   Mean   :202066   Mean   :38.93     \n May    : 308   3rd Qu.:2022   3rd Qu.:202202   3rd Qu.:56.20     \n Jun    : 308   Max.   :2023   Max.   :202302   Max.   :95.86     \n (Other):1848                                                     \n no_tourist_stay   no_tourist_all    no_tourist_thai   no_tourist_foreign \n Min.   :      0   Min.   :      0   Min.   :      0   Min.   :      0.0  \n 1st Qu.:  16271   1st Qu.:  39092   1st Qu.:  37169   1st Qu.:     49.2  \n Median :  44579   Median :  92122   Median :  88782   Median :    553.0  \n Mean   : 105161   Mean   : 206328   Mean   : 173962   Mean   :  32366.1  \n 3rd Qu.:  90902   3rd Qu.: 203646   3rd Qu.: 184256   3rd Qu.:   5189.5  \n Max.   :3335728   Max.   :6131044   Max.   :4087756   Max.   :2473725.0  \n                                                                          \n  revenue_all         revenue_thai       revenue_foreign     \n Min.   :0.000e+00   Min.   :0.000e+00   Min.   :-4.250e+03  \n 1st Qu.:6.332e+07   1st Qu.:5.925e+07   1st Qu.: 1.100e+05  \n Median :1.955e+08   Median :1.773e+08   Median : 1.540e+06  \n Mean   :1.344e+09   Mean   :6.636e+08   Mean   : 6.802e+08  \n 3rd Qu.:5.060e+08   3rd Qu.:4.600e+08   3rd Qu.: 1.742e+07  \n Max.   :1.103e+11   Max.   :4.506e+10   Max.   : 8.503e+10  \n                                                             \n\n\n\n\n\n\n\n\nNote\n\n\n\nFrom the outdated data dictionary in Kaggle and Piazza discussions, we can infer that this should be the intended data dictionary for dataset v2.\n\n\n\n\n\n\nVariable\nDefinition\n\n\n\nno_tourist_all\nTotal number of tourists who visited the province\n\n\nno_tourist_foreign\nNumber of Foreign tourists who visited the province\n\n\nno_tourist_thai\nNumber of Thai tourists who visited the province\n\n\nno_tourist_stay\nNumber of Tourists who stayed overnight in the province**\n\n\nratio_tourist_stay\nRatio of Tourists who stayed overnight**\n\n\nrevenue_all\nRevenue generated by all tourists in the province (Thai Baht)\n\n\nrevenue_foreign\nRevenue generated by Foreign tourists in the province (Thai Baht)\n\n\nrevenue_thai\nRevenue generated by Thai tourists in the province (Thai Baht)\n\n\n\nFrom this, we can notice that are several imposible values such as foreign revenue from the summary output above.\n\n\n\nnegative_revenue &lt;- tourism_df_pivot %&gt;%\n  filter(revenue_foreign &lt; 0)\n\ndatatable(negative_revenue)\n\n\n\n\n# check_revenue_computation&lt;- tourism_df_pivot %&gt;%\n#  filter(revenue_all != (revenue_foreign+ revenue_thai))\n\n# datatable(check_revenue_computation)\n\nWe noticed that revenue_all is indeed sum of revenue_thai and revenue_foreign. However, when revenue_thai is higher than revenue_all, the data records negative values for revenue_foreign to balance the equation. This is likely due to data entry error. Thus, we will take the conservative approach and cap revenue_thai at revenue_all if it exceeds the total, and set revenue_foreign to 0 if negative:\n\ntourism_df_pivot &lt;- tourism_df_pivot %&gt;%\n  mutate(\n    # Cap revenue_thai to revenue_all if revenue_thai is greater\n    revenue_thai = ifelse(revenue_thai &gt; revenue_all, revenue_all, revenue_thai),\n    \n    # Set revenue_foreign to 0 if it's negative\n    revenue_foreign = ifelse(revenue_foreign &lt; 0, 0, revenue_foreign)\n  )\n\nSimilarly, we also ensure that no_tourist_stay does not exceed no_tourist_all:\n\n#check_tourist_stay &lt;- tourism_df_pivot %&gt;%\n#  filter(no_tourist_stay != no_tourist_all)\n#check_tourist_stay &lt;- tourism_df_pivot %&gt;%\n#  filter(no_tourist_stay &lt;= no_tourist_all)\n\ncheck_tourist_stay &lt;- tourism_df_pivot %&gt;%\n  filter(no_tourist_stay &gt; no_tourist_all)\n\ndatatable(check_tourist_stay)\n\n\n\n\n\nFinally, we executed the remaining steps mentioned earlier in this section.\n\ntourism_df_pivot &lt;- tourism_df_pivot %&gt;%\n  mutate(\n    # Cap revenue_thai to revenue_all if revenue_thai is greater\n    revenue_thai = ifelse(revenue_thai &gt; revenue_all, revenue_all, revenue_thai),\n    # Set revenue_foreign to 0 if it's negative\n    revenue_foreign = ifelse(revenue_foreign &lt; 0, 0, revenue_foreign),\n    # Cap no_tourist_stay to no_tourist_all if no_tourist_stay is greater\n    no_tourist_stay = ifelse(no_tourist_stay &gt; no_tourist_all, no_tourist_all, no_tourist_stay)\n  )\n\nsummary(tourism_df_pivot)\n\n province_eng        region_eng        time_period         month_number \n Length:3850        Length:3850        Length:3850        Min.   : 1.0  \n Class :character   Class :character   Class :character   1st Qu.: 3.0  \n Mode  :character   Mode  :character   Mode  :character   Median : 6.0  \n                                                          Mean   : 6.3  \n                                                          3rd Qu.: 9.0  \n                                                          Max.   :12.0  \n                                                                        \n  month_factor       year         date_int      ratio_tourist_stay\n Jan    : 385   Min.   :2019   Min.   :201901   Min.   : 0.00     \n Feb    : 385   1st Qu.:2020   1st Qu.:202001   1st Qu.:20.18     \n Mar    : 308   Median :2021   Median :202102   Median :41.81     \n Apr    : 308   Mean   :2021   Mean   :202066   Mean   :38.93     \n May    : 308   3rd Qu.:2022   3rd Qu.:202202   3rd Qu.:56.20     \n Jun    : 308   Max.   :2023   Max.   :202302   Max.   :95.86     \n (Other):1848                                                     \n no_tourist_stay   no_tourist_all    no_tourist_thai   no_tourist_foreign \n Min.   :      0   Min.   :      0   Min.   :      0   Min.   :      0.0  \n 1st Qu.:  16259   1st Qu.:  39092   1st Qu.:  37169   1st Qu.:     49.2  \n Median :  44579   Median :  92122   Median :  88782   Median :    553.0  \n Mean   : 105134   Mean   : 206328   Mean   : 173962   Mean   :  32366.1  \n 3rd Qu.:  90902   3rd Qu.: 203646   3rd Qu.: 184256   3rd Qu.:   5189.5  \n Max.   :3335728   Max.   :6131044   Max.   :4087756   Max.   :2473725.0  \n                                                                          \n  revenue_all         revenue_thai       revenue_foreign    \n Min.   :0.000e+00   Min.   :0.000e+00   Min.   :0.000e+00  \n 1st Qu.:6.332e+07   1st Qu.:5.925e+07   1st Qu.:1.100e+05  \n Median :1.955e+08   Median :1.773e+08   Median :1.540e+06  \n Mean   :1.344e+09   Mean   :6.636e+08   Mean   :6.802e+08  \n 3rd Qu.:5.060e+08   3rd Qu.:4.600e+08   3rd Qu.:1.742e+07  \n Max.   :1.103e+11   Max.   :4.506e+10   Max.   :8.503e+10  \n                                                            \n\n\n\n8.2 Feature Engineering\nFrom the data dictionary above, we observe that some are related. For example, revenue_all is the sum of revenue_foreign and revenue_thai.\nLet’s create some additional features to aid our analysis:\n\n\n\n\n\n\n\nVariable\nFormula\nDefinition\n\n\n\nratio_tourist_foreign\nno_tourist_foreign / no_tourist_all\nRatio of foreign tourists to total tourists\n\n\nratio_tourist_thai\nno_tourist_thai / no_tourist_all\nRatio of Thai tourists to total tourists\n\n\nratio_revenue_foreign\nrevenue_foreign / revenue_all\nRatio of revenue generated by foreign tourists to total revenue\n\n\nratio_revenue_thai\nrevenue_thai / revenue_all\nRatio of revenue generated by Thai tourists to total revenue\n\n\navg_revenue_all\nrevenue_all / no_tourist_all\nAverage revenue generated per tourist (both Thai and foreign)\n\n\navg_revenue_foreign\nrevenue_foreign / no_tourist_foreign\nAverage revenue generated per foreign tourist\n\n\navg_revenue_thai\nrevenue_thai / no_tourist_thai\nAverage revenue generated per Thai tourist\n\n\n\n\ntourism_df_ft &lt;- tourism_df_pivot %&gt;%\n  mutate(\n    # ratio tourist\n    ratio_tourist_foreign = ifelse(no_tourist_all == 0, 0, no_tourist_foreign / no_tourist_all),    \n    ratio_tourist_thai = ifelse(no_tourist_all == 0, 0, no_tourist_thai / no_tourist_all),\n\n    # ratio revenue\n    ratio_revenue_thai = ifelse(revenue_all == 0, 0, revenue_thai / revenue_all),\n    ratio_revenue_foreign = ifelse(revenue_all == 0, 0, revenue_foreign / revenue_all),\n    \n    # average revenue per tourist\n    avg_revenue_all = ifelse(no_tourist_all == 0, 0, revenue_all / no_tourist_all),\n    avg_revenue_thai = ifelse(no_tourist_thai == 0, 0, revenue_thai / no_tourist_thai),\n    avg_revenue_foreign = ifelse(no_tourist_foreign == 0, 0, revenue_foreign / no_tourist_foreign),\n  )\n\nsummary(tourism_df_ft)\n\n province_eng        region_eng        time_period         month_number \n Length:3850        Length:3850        Length:3850        Min.   : 1.0  \n Class :character   Class :character   Class :character   1st Qu.: 3.0  \n Mode  :character   Mode  :character   Mode  :character   Median : 6.0  \n                                                          Mean   : 6.3  \n                                                          3rd Qu.: 9.0  \n                                                          Max.   :12.0  \n                                                                        \n  month_factor       year         date_int      ratio_tourist_stay\n Jan    : 385   Min.   :2019   Min.   :201901   Min.   : 0.00     \n Feb    : 385   1st Qu.:2020   1st Qu.:202001   1st Qu.:20.18     \n Mar    : 308   Median :2021   Median :202102   Median :41.81     \n Apr    : 308   Mean   :2021   Mean   :202066   Mean   :38.93     \n May    : 308   3rd Qu.:2022   3rd Qu.:202202   3rd Qu.:56.20     \n Jun    : 308   Max.   :2023   Max.   :202302   Max.   :95.86     \n (Other):1848                                                     \n no_tourist_stay   no_tourist_all    no_tourist_thai   no_tourist_foreign \n Min.   :      0   Min.   :      0   Min.   :      0   Min.   :      0.0  \n 1st Qu.:  16259   1st Qu.:  39092   1st Qu.:  37169   1st Qu.:     49.2  \n Median :  44579   Median :  92122   Median :  88782   Median :    553.0  \n Mean   : 105134   Mean   : 206328   Mean   : 173962   Mean   :  32366.1  \n 3rd Qu.:  90902   3rd Qu.: 203646   3rd Qu.: 184256   3rd Qu.:   5189.5  \n Max.   :3335728   Max.   :6131044   Max.   :4087756   Max.   :2473725.0  \n                                                                          \n  revenue_all         revenue_thai       revenue_foreign    \n Min.   :0.000e+00   Min.   :0.000e+00   Min.   :0.000e+00  \n 1st Qu.:6.332e+07   1st Qu.:5.925e+07   1st Qu.:1.100e+05  \n Median :1.955e+08   Median :1.773e+08   Median :1.540e+06  \n Mean   :1.344e+09   Mean   :6.636e+08   Mean   :6.802e+08  \n 3rd Qu.:5.060e+08   3rd Qu.:4.600e+08   3rd Qu.:1.742e+07  \n Max.   :1.103e+11   Max.   :4.506e+10   Max.   :8.503e+10  \n                                                            \n ratio_tourist_foreign ratio_tourist_thai ratio_revenue_thai\n Min.   :0.0000000     Min.   :0.0000     Min.   :0.0000    \n 1st Qu.:0.0008535     1st Qu.:0.9627     1st Qu.:0.9511    \n Median :0.0066240     Median :0.9932     Median :0.9911    \n Mean   :0.0637772     Mean   :0.9297     Mean   :0.9090    \n 3rd Qu.:0.0346323     3rd Qu.:0.9990     3rd Qu.:0.9988    \n Max.   :1.0000000     Max.   :1.0000     Max.   :1.0000    \n                                                            \n ratio_revenue_foreign avg_revenue_all  avg_revenue_thai avg_revenue_foreign\n Min.   :0.000000      Min.   :     0   Min.   :    0    Min.   :    0      \n 1st Qu.:0.001126      1st Qu.:  1366   1st Qu.: 1345    1st Qu.: 1294      \n Median :0.008700      Median :  1932   Median : 1880    Median : 2372      \n Mean   :0.084802      Mean   :  3513   Mean   : 2614    Mean   : 4504      \n 3rd Qu.:0.045997      3rd Qu.:  3199   3rd Qu.: 3082    3rd Qu.: 4137      \n Max.   :1.000000      Max.   :300000   Max.   :17325    Max.   :65000      \n                                                                            \n\n\n\n8.3 Combining Datasets\nAfter all the data cleaning and feature engineering steps, we can merge the aspatial dataset with the geospatial dataset.\nWe will select the relevant columns from the admin boundary and combine the two dataset with the common column which is province_eng for their respective datasets.\n\nadmin_boundary &lt;- admin_boundary%&gt;%\n  select(1:3, 17)\n\ntourism &lt;- left_join(admin_boundary, tourism_df_ft, by = c(\"province_eng\"))\n\nThe combined dataset is saved for future analysis.\n\nwrite_rds(tourism, \"data/rds/tourism.rds\")\n\n\nThis tourism object forms the tourism economy indicators layer within the study area in sf polygon features.\n\n\ntourism &lt;- read_rds(\"data/rds/tourism.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#conclusion",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#conclusion",
    "title": "Take Home Exercise 2",
    "section": "\n13 Conclusion",
    "text": "13 Conclusion\nThis report explored how COVID-19 impacted Thailand’s tourism economy through spatial and spatio-temporal analysis to identify whether key tourism indicators were spatially independent and, if dependent, to locate clusters, outliers, and emerging hotspot/coldspot areas. Our findings revealed the following:\n\n\nSpatial Independence:\n\nFor most indicators like total tourists, foreign and Thai revenues, the results indicated no significant spatial dependence across the country. This suggests that these economic factors were relatively independent in space.\nHowever, engineered features such as average revenue per tourist has showed persistent spatial clustering, with higher average spending per tourist clustering in the southern regions, particularly in provinces like Phuket.\n\n\n\nLocal Spatial Clusters:\n\nThe LISA analysis revealed consistent low-low clusters in the northeastern provinces for indicators like tourist numbers and revenues, suggesting these regions consistently performed below the national average.\nOn the other hand, Phuket and nearby southern regions were frequently identified as high-high clusters for average revenue per tourist, further reinforcing the economic significance of tourism in these areas.\n\n\n\nSpatio-Temporal Patterns Across Time Periods:\n\nThe spatial dependence in average revenue per tourist persisted across pre-COVID, COVID, and post-COVID periods, although the strength of clustering weakened in the post-pandemic phase, indicating some disruption caused by the pandemic.\n\n\n\nEmerging Hotspots:\n\nThe EHSA identified several regions with evolving patterns over time. Notably, central and southern regions displayed sporadic hotspot patterns for both **Thai revenue and average revenue per tourist indictators.\n\n\n\nIn summary, while the pandemic significantly disrupted Thailand’s tourism economy, spatial analysis revealed persistent geographic trends, particularly in average tourist spending. We hope these insights can guide policymakers and tourism stakeholders in better decision making and strategy making to revitalize the tourism industry in Thailand with consideration to the different characteristics of each region."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#references",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#references",
    "title": "Take Home Exercise 2",
    "section": "\n14 References",
    "text": "14 References\n\nThailand Tourism EDA\nTimeline of the COVID-19 pandemic in Thailand - Wikipedia\nThailand - Full Restrictions, Travel regulations, Coronavirus regulations, travel bans - Travelbans\nThailand ends COVID-19 Emergency Decree on 30 September 2022 - TAT Newsroom\nHot spots, cluster detection and spatial outlier analysis of teen birth rates in the U.S., 2003–2012 - PMC\nKNN Hyperparameters: A Friendly Guide to Optimization - ProgrammingR"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#determining-key-economic-indicators",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#determining-key-economic-indicators",
    "title": "Take Home Exercise 2",
    "section": "\n9 Determining Key-Economic Indicators",
    "text": "9 Determining Key-Economic Indicators\nIn this section, we select three key economic indicators for further geospatial analysis.\nThe selection is based on the following criteria:\n\nEconomic significance\n\nLow to moderate correlation: To avoid redundancy and ensure each indicator captures distinct information.\n\n\ncorrelation_matrix &lt;- tourism_df_ft %&gt;%\n  select(7:21) %&gt;%\n  cor(use = \"complete.obs\")  # Use \"complete.obs\" to handle NA values\ncorrplot(correlation_matrix, method = \"circle\", type = \"lower\", \n         tl.col = \"black\", tl.srt = 45, \n         addCoef.col = \"black\")  # Add correlation coefficients\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe will select the following economic indictators:\n-Total number of tourists (no_tourist_all): This captures the overall tourism demand across provinces, providing a broad view of how tourism is distributed. Since it is highly correlated with both foreign and domestic tourist numbers, we don’t have to analyse no_tourist_thai and no_tourist_foreign separately.\n\nRevenue from foreign tourists (revenue_foreign): This indicator is crucial for understanding the economic impact of international tourists, and it can indictate foreign revenue inflow to the Thai economy.\n\n\nAverage revenue per tourist (avg_revenue_all): This indicator reflects the quality of tourism by measuring spending per tourist. It also has a low correlation with other indicator, making it a distinct measure."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#local-measures-of-spatial-association",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#local-measures-of-spatial-association",
    "title": "In-Class Exercise 5",
    "section": "\n10 Local Measures of Spatial Association",
    "text": "10 Local Measures of Spatial Association"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#lisa-map",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#lisa-map",
    "title": "In-Class Exercise 5",
    "section": "\n11 LISA Map",
    "text": "11 LISA Map\nLISA map is a categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two type of clusters namely: High-High and Low-Low cluaters. In fact, LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p-values."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-local-morans-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-local-morans-i",
    "title": "In-Class Exercise 5",
    "section": "\n12 Computing Local Moran’s I",
    "text": "12 Computing Local Moran’s I\nIn this section, we will compute Local Moran’s I of GDPPC at county level by using local_moran() of sfdep package.\n\nlisa &lt;- wm_q %&gt;%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\n\n\n\n\n\nTip\n\n\n\n\nWe use unnest() in this context to convert the nested list column created by local_moran() into multiple rows, one for each simulation result per observation.\nThe local_moran() function from the sfdep package returns a nested list, with each element containing the results of local Moran’s I statistic for each spatial unit.\nUnnesting helps in expanding this list into individual rows, making each result (e.g., local Moran’s I values, p-values) accessible in a tidy, flat data frame format.\nThis step is crucial for easier manipulation, filtering, and visualization of the spatial autocorrelation results, allowing us to work with the data in a more intuitive and flexible way.\n\nThus, unnest() is applied to handle and process the simulation results efficiently.\n\nThe output of local_moran() is a sf data.frame containing the columns ii, eii, var_ii, z_ii, p_ii, p_ii_sim, and p_folded_sim.\n\nii: local moran statistic\neii: expectation of local moran statistic; for localmoran_permthe permutation sample means\nvar_ii: variance of local moran statistic; for localmoran_permthe permutation sample standard deviations\nz_ii: standard deviate of local moran statistic; for localmoran_perm based on permutation sample means and standard deviations p_ii: p-value of local moran statistic using pnorm(); for localmoran_perm using standard deviatse based on permutation sample means and standard deviations p_ii_sim: For localmoran_perm(), rank() and punif() of observed statistic rank for [0, 1] p-values using alternative= -p_folded_sim: the simulation folded [0, 0.5] range ranked p-value (based on https://github.com/pysal/esda/blob/4a63e0b5df1e754b17b5f1205b cadcbecc5e061/esda/crand.py#L211-L213)\nskewness: For localmoran_perm, the output of e1071::skewness() for the permutation samples underlying the standard deviates\nkurtosis: For localmoran_perm, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-local-morans-i-and-p-value",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-local-morans-i-and-p-value",
    "title": "In-Class Exercise 5",
    "section": "\n13 Visualising Local Moran’s I and p-value",
    "text": "13 Visualising Local Moran’s I and p-value\nWhen interpreting / visualizing local Moran’s I, we should plot the Moran’s I and p-value side by side.\n\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"Local Moran's I of GDPPC\",\n    main.title.size = 0.8\n  )\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"p-value of Local Moran's I\",\n    main.title.size = 0.8\n  )\n\ntmap_arrange(map1, map2, ncol = 2)\n\n\n\n\n\n\n\n\n13.1 Plotting LISA Map\nIn lisa sf data.frame, we can find three fields contain the LISA categories. They are mean, median and pysal. In general, classification in mean will be used as shown in the code below.\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#hot-spot-and-cold-spot-area-analysis",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#hot-spot-and-cold-spot-area-analysis",
    "title": "In-Class Exercise 5",
    "section": "\n14 Hot Spot and Cold Spot Area Analysis",
    "text": "14 Hot Spot and Cold Spot Area Analysis\nHot Spot and Cold Spot Analysis (HCSA) uses spatial weights to identify locations of statistically significant hot spots and cold spots within a spatially weighted attribute. These spots are identified based on a calculated distance that groups features when similar high (hot) or low (cold) values are found in proximity to one another. The polygon features typically represent administrative boundaries or a custom grid structure.\n\n14.1 Computing local Gi* statistics\nAs usual, we will need to derive a spatial weight matrix before we can compute local Gi* statistics. Code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.\n\nwm_idw &lt;- hunan %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wts = st_inverse_distance(nb,\n                              geometry,\n                              scale = 1,\n                              alpha = 1),\n         .before = 1)\n\n\n\n\n\n\n\nTip\n\n\n\n\nGi* and local Gi* are distance-based spatial statistics. Hence, distance methods instead of contiguity methods should be used to derive the spatial weight matrix.\nSince we are going to compute Gi* statistics, include_self()is used.\n\n\n\n\n14.2 Computing Local Gi* statistics\nNow, we will compute the local Gi* by using the code below.\n\nHCSA &lt;- wm_idw %&gt;%\n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n    gi_star cluster     e_gi  var_gi std_dev p_value p_sim p_folded_sim skewness\n      &lt;dbl&gt; &lt;fct&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.261   Low     0.00126  1.07e-7  0.283  7.78e-1  0.66         0.33    0.783\n 2 -0.276   Low     0.000969 4.76e-8 -0.123  9.02e-1  0.98         0.49    0.713\n 3  0.00573 High    0.00156  2.53e-7 -0.0571 9.54e-1  0.78         0.39    0.972\n 4  0.528   High    0.00155  2.97e-7  0.321  7.48e-1  0.56         0.28    0.942\n 5  0.466   High    0.00137  2.76e-7  0.386  7.00e-1  0.52         0.26    1.32 \n 6 -0.445   High    0.000992 7.08e-8 -0.588  5.57e-1  0.68         0.34    0.692\n 7  2.99    High    0.000700 4.05e-8  3.13   1.74e-3  0.04         0.02    0.975\n 8  2.04    High    0.00152  1.58e-7  1.77   7.59e-2  0.16         0.08    1.26 \n 9  4.42    High    0.00130  1.18e-7  4.22   2.39e-5  0.02         0.01    1.20 \n10  1.21    Low     0.00175  1.25e-7  1.49   1.36e-1  0.18         0.09    0.408\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;\n\n\n\n14.3 Visualising Local Hot Spot and Cold Spot Areas (HCSA)\nSimilarly, for effective comparison, we should plot the local Gi* values with its p-value.\n\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\n\n\n\n\n\n\nTo visualize HCSA, we will plot the significant (i.e. p-values less than 0.05) hot spot and cold spot areas by using appropriate tmap functions as shown below.\n\nHCSA_sig &lt;- HCSA  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations: The plot reveals that there is one hot spot area and two cold spot areas. Interestingly, the hot spot areas coincide with the High-high cluster identifies by using local Moran’s I method in the earlier sub-section."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#spatial-independence-of-thailands-tourism-economy-indictators",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#spatial-independence-of-thailands-tourism-economy-indictators",
    "title": "Take Home Exercise 2",
    "section": "\n10 Spatial Independence of Thailand’s Tourism Economy Indictators",
    "text": "10 Spatial Independence of Thailand’s Tourism Economy Indictators\nIn this section, we explore whether key tourism economy indicators in Thailand exhibit spatial dependence or independence. This involves creating spatial weight matrices, computing global and local Moran’s I statistics, and analyzing patterns of spatial autocorrelation.\n\n10.1 Creating Spatial Weight Matrix\nTo analyze spatial autocorrelation, we need to define how provinces in Thailand are related to each other spatially. The spatial relationships are captured using spatial weight matrices, which define the “neighborhood” structure for each province.\n\n10.1.1 Choice of Neighbors\n\n\nst_contiguity: This method defines neighbors based on shared boundaries (either Rook or Queen contiguity). Provinces are considered neighbors if they touch along a boundary or corner.\n\nst_dist_band: Defines neighbors based on a fixed distance band. Provinces within a certain distance are considered neighbors.\n\nst_knn: Defines neighbors based on the k-nearest neighbors approach, where each province has a fixed number of nearest neighbors. The distance band is adaptive.\n\nFor this study, we will use the st_knn method for these reasons:\n\nFrom general knowledge, we understand that Thailand has several islands such as Phuket; This makes st_contiguity the least ideal choice.\nUsing st_knn, it allows us to define a fixed number of neighbors for each province, ensuring that each province has the same number of neighbors, making the analysis more balanced and suitable for regions with varying geographic sizes and shapes.\n\n10.1.2 Choice of K\nWe choose the number of neighbors k as the square root of the total number of provinces (77), which is approximately 9 (since \\(\\sqrt{77} \\approx 8.77\\)). This is a common rule of thumb in spatial analysis, providing a reasonable number of neighbors to capture both local and slightly broader spatial interactions.\nIt is also important to choose an odd value for k (e.g., 9) to avoid ties when calculating spatial statistics.\nk should also be reasonably small to ensure that the spatial relationships remain localized. If k is too large, spatial patterns may become diluted. For this reason, we will also try k=5.\n\n10.1.3 Choice of Weights\n\n\nst_weights (binary): Neighbors either exist or don’t, with a binary weight of 1 for neighbors and 0 for non-neighbors.\n\nst_kernel_weights: Assigns weights based on a kernel function (such as Gaussian), where closer neighbors have higher weights, and the influence decays with distance.\n\nst_inverse_distance: Assigns weights based on the inverse of distance between provinces. Closer provinces have higher weights, and farther provinces have smaller weights.\n\nAccording to Tobler’s First Law of Geography, “everything is related to everything else, but near things are more related than distant things.” Using st_inverse_distance allows us to capture this principle, with closer provinces being assigned greater weights.\nIn the step below, We use sum for the variables like no_tourist_all, revenue_foreign, and revenue_thai because these are cumulative metrics and we use take the mean for avg_revenue_all.\n\ntourism_agg &lt;- tourism %&gt;%\n  group_by(province_eng) %&gt;%\n  summarize(\n    no_tourist_all = sum(no_tourist_all, na.rm = TRUE), \n    revenue_foreign = sum(revenue_foreign, na.rm = TRUE), \n    revenue_thai = sum(revenue_thai, na.rm = TRUE),\n    avg_revenue_all = mean(avg_revenue_all, na.rm = TRUE),\n    geometry = st_union(geometry)\n  )\n\nNext, we compute centroids for each province, which will be used for plotting and spatial weighting.\n\n# compute centroid using st_centroid\nlongitude &lt;- map_dbl(tourism_agg$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(tourism_agg$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)\n\nWe compute K-nearest neighbors using k = 9 and k = 5, and visually compare the results to determine the most appropriate value.\n\nnb_knn_9 &lt;- st_knn(tourism_agg$geometry, k = 9)\n\nnb_knn_5 &lt;- st_knn(tourism_agg$geometry, k = 5)\n\n\npar(mfrow=c(1,2))\n\nplot(tourism_agg$geometry,\n     main=\"K = 5\")\nplot(nb_knn_5,\n     coords,\n     pch = 19,\n     cex = 0.6,\n     add = TRUE,\n     col= \"red\")\n\nplot(tourism_agg$geometry,\n     main=\"K = 9\")\nplot(nb_knn_9,\n     coords,\n     pch = 19,\n     cex = 0.6,\n     add = TRUE,\n     col= \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFrom the plot above, K = 9 results in a more congested view, whereas K = 5 offers a clearer spatial relationship, making it a more appropriate choice.\n\n\n\nknn5_weights &lt;- st_weights(nb_knn_5, style = \"W\")\n\nUsing st_weights, each neighbour has the same weight of 0.2 (1/5), regardless of distance.\n\nknn5_weights_inv &lt;- st_inverse_distance(nb_knn_5,\n                                    tourism_agg$geometry,\n                                    # default=100; lower more agressive\n                                    scale= 1,\n                                    # default\n                                    alpha = 1)\n\nFinally, we selected st_inverse_distance to assign weights based on distance, ensuring closer provinces are weighted more heavily. After experimenting with various parameters, setting scale = 1 and alpha = 1 produces a reasonable range of weights, with values typically between 0 and 6, reflecting distance-based proximity effects.\n\n10.2 Global Spatial Autocorrelation Analysis\nIn this section, we compute Global Moran’s I to determine whether Thailand’s tourism economy indicators exhibit overall spatial autocorrelation. Global Moran’s I is a statistical measure used to evaluate the degree to which similar values in a dataset are clustered together or dispersed across a geographic space.\nIn simpler terms, it measures whether similar values occur near each other (positive autocorrelation) or if dissimilar values are found near each other (negative autocorrelation).\n\n\nNull Hypothesis (\\(H_0\\)): The tourism economy indicators are spatially independent, meaning they are randomly distributed across space.\n\nAlternative Hypothesis (\\(H_1\\)): The tourism economy indicators show spatial dependence, meaning similar values are either clustered together or systematically dispersed across space.\n\nWe will use an alpha value (α) of 0.05 (95% confidence level) to determine the statistical significance.\nWe will also focus on global_moran_perm as it performs permutation testing which ensures a more robust and accurate p-value estimation as compared to global_moran. global_moran does not allow for formal hypothesis testing, as it only returns the Moran’s I value, not the associated p-value or significance level.\nThe code below shows a list of function that applies global_moran_perm on multiple tourism KPIs iteratively, formats the results with p-values, and interprets whether spatial dependence exists based on a 95% confidence level.\n\nShow the codeset.seed(1234)\nkpis &lt;- c(\"no_tourist_all\", \"revenue_foreign\", \"revenue_thai\", \"avg_revenue_all\")\n\n# Function to compute Global Moran's I for each KPI\ncompute_global_moran_perm &lt;- function(tourism_data, kpi_column) {\n  global_moran_perm(tourism_data[[kpi_column]], \n                    nb_knn_5, \n                    knn5_weights_inv,\n                    nsim = 99)\n}\n\nextract_moran_info &lt;- function(moran_result) {\n  list(\n    moran_I = format(moran_result$statistic,  scientific = TRUE),\n    p_value = format(moran_result$p.value, scientific = TRUE),\n    interpretation = ifelse(moran_result$p.value &lt; 0.05,\n                            \"Spatial dependence detected\",\n                            \"No spatial dependence\")\n  )\n}\n\n# Apply the function to each KPI and store results\ngmp_results &lt;- map(kpis, ~compute_global_moran_perm(tourism_agg, .x))\n\n# Naming the results for easier interpretation\nnames(gmp_results) &lt;- kpis\n\n# Apply the extraction function to each KPI result\nmoran_summary &lt;- map_df(gmp_results, extract_moran_info, .id = \"kpi\")\n\ngmp_results\n\n$no_tourist_all\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = -0.020104, observed rank = 53, p-value = 0.94\nalternative hypothesis: two.sided\n\n\n$revenue_foreign\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = -0.021885, observed rank = 52, p-value = 0.96\nalternative hypothesis: two.sided\n\n\n$revenue_thai\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = -0.072233, observed rank = 11, p-value = 0.22\nalternative hypothesis: two.sided\n\n\n$avg_revenue_all\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.32153, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\ndatatable(moran_summary)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nno_tourist_all, revenue_foreign, and revenue_thai has high p-values (&gt; 0.05). This means we fail to reject the null hypothesis indicating these indictators are spatially independent.\nFor avg_revenue_all, the p-value of 2.2e-16 means that we can reject the null hypothesis. From the conclude that positive Moran’s I value, we can conclude that there is significant spatial dependence. Provinces with similar values for average revenue per tourist tend to cluster together.\n\n\n\n\n10.3 Local Spatial Autocorrelation Analysis\nWhile global indicators such asGlobal Moran’s I provides an overall measure of spatial autocorrelation for the entire study area, Local Indicators of Spatial Association (LISA) such as Local Moran’s I helps identify specific clusters or outliers.\nIn this section, we will compute the Local Moran’s I for the selected KPIs and visualize these clusters using LISA map.\nIn the code block below, we will use a custom function to compute the Local Moran’s I iteratively for the KPIs and save the results into lmp_summary.rds.\n\nShow the codeset.seed(1234)\nkpis &lt;- c(\"no_tourist_all\", \"revenue_foreign\", \"revenue_thai\", \"avg_revenue_all\")\n\n# Function to compute Local Moran's I for each KPI and add it to the data frame\ncompute_local_moran_df &lt;- function(data, kpi_column, nb, wt) {\n  data %&gt;%\n    mutate(local_moran = local_moran(!!sym(kpi_column), nb, wt, nsim = 99),\n           kpi = kpi_column,  \n           .before = 1) %&gt;%\n    unnest(local_moran) \n}\n\n# Apply the function to each KPI and combine into a single data frame\nlmp_summary &lt;- map_df(kpis, ~compute_local_moran_df(tourism_agg, \n                                                    .x, \n                                                    nb_knn_5, \n                                                    knn5_weights_inv))\n\nwrite_rds(lmp_summary, file = \"data/rds/lmp_summary.rds\")\n\n\nHere, we load and inspect the summary data for Local Moran’s I results:\n\nlmp_summary &lt;- read_rds(\"data/rds/lmp_summary.rds\")\n\nhead(lmp_summary)\n\nSimple feature collection with 6 features and 18 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 100.1913 ymin: 13.17847 xmax: 105.0603 ymax: 18.44898\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 6 × 19\n       ii      eii  var_ii   z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1   1.19    0.0338   3.35   0.631 0.528     0.2          0.1    -3.69    15.4  \n2  -0.351   0.490    4.83  -0.383 0.702     0.34         0.17   -3.19    12.1  \n3 -21.7   -12.0    534.    -0.419 0.675     0.76         0.38    0.769    0.131\n4   0.584  -0.0891   1.56   0.539 0.590     0.52         0.26   -2.73     8.19 \n5   0.117  -0.0486   0.206  0.364 0.716     0.72         0.36   -4.02    21.2  \n6   0.253  -0.0208   0.141  0.730 0.465     0.18         0.09    3.55    14.1  \n# ℹ 10 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, kpi &lt;chr&gt;,\n#   province_eng &lt;chr&gt;, no_tourist_all &lt;dbl&gt;, revenue_foreign &lt;dbl&gt;,\n#   revenue_thai &lt;dbl&gt;, avg_revenue_all &lt;dbl&gt;, geometry &lt;MULTIPOLYGON [m]&gt;\n\n\n\n10.3.1 Visualization of Local Moran’s I Maps\nIn this subsection, we will visualize the Local Moran’s I values on choropleth maps.\nSimilarly, we will implement a list of custom functions to process there KPIs iteratively.\n\nShow the codekpis &lt;- c(\"no_tourist_all\", \"revenue_foreign\", \"revenue_thai\", \"avg_revenue_all\")\n# kpis &lt;- c(\"no_tourist_all\")\n\np_value_palette &lt;- c(\"red\", \"orange\", \"yellow\")\n\n# Function to create maps for a given KPI\nplot_local_moran_kpi &lt;- function(kpi_name, data) {\n  # Filter the data for the current KPI\n  kpi_data &lt;- data %&gt;% filter(kpi == kpi_name)\n  \n  tmap_mode(\"plot\")\n\n  # Map 1: Moran's I\n  map1 &lt;- tm_shape(kpi_data) +\n    tm_fill(\"ii\") + \n    tm_borders(alpha = 0.5) +\n    tm_view(set.zoom.limits = c(6,8)) +\n    tm_layout(\n      main.title = paste(\"Local Moran's I of\", kpi_name),\n      main.title.size = 0.8\n    )\n\n  # Map 2: p-value\n  map2 &lt;- tm_shape(kpi_data) +\n    tm_fill(\n      \"p_ii_sim\", \n      breaks = c(0, 0.001, 0.01, 0.05, 1),\n      labels = c(\"&lt;0.001\", \"0.001-0.01\", \"0.01-0.05\", \"Not sig\"), \n      palette = p_value_palette\n    ) +\n    tm_borders(alpha = 0.5) +\n    tm_view(set.zoom.limits = c(6,8)) +\n    tm_layout(\n      main.title = paste(\"p-value of Local Moran's I for\", kpi_name),\n      main.title.size = 0.8\n    )\n\n  # Return the arranged maps\n  tmap_arrange(map1, map2, ncol = 2)\n}\n\n# Function to plot LISA map for a given KPI\nplot_lisa_kpi &lt;- function(kpi_name, data) {\n  # Filter the data for the selected KPI\n  kpi_data &lt;- data %&gt;% filter(kpi == kpi_name)\n  \n  # Filter significant LISA results (p_ii_sim &lt; 0.05)\n  lisa_sig &lt;- kpi_data %&gt;% filter(p_ii_sim &lt; 0.05)\n  \n  tmap_mode(\"plot\")\n\n  tm_shape(kpi_data) +\n    tm_polygons() + \n    tm_borders(alpha = 0.5) +\n    tm_layout(\n      main.title = paste(\"LISA Map for\", kpi_name),\n      main.title.size = 0.8\n    ) + \n    tm_shape(lisa_sig) +\n    tm_fill(\"mean\")\n}\n\n# Function to plot LISA maps for multiple KPIs side by side\nplot_lisa_multiple_kpis &lt;- function(kpi_list, data) {\n  tmap_mode(\"plot\")\n  \n  map_list &lt;- list()\n  \n  # Loop through each KPI and create a LISA map\n  for (kpi_name in kpi_list) {\n    # Filter the data for the selected KPI\n    kpi_data &lt;- data %&gt;% filter(kpi == kpi_name)\n    \n    # Filter significant LISA results (p_ii_sim &lt; 0.05)\n    lisa_sig &lt;- kpi_data %&gt;% filter(p_ii_sim &lt; 0.05)\n    \n    map &lt;- tm_shape(kpi_data) +\n      tm_polygons() + \n      tm_borders(alpha = 0.5) +\n      tm_layout(\n        main.title = paste(\"LISA Map for\", kpi_name),\n        main.title.size = 0.8\n      ) + \n      tm_shape(lisa_sig) +\n      tm_fill(\"mean\")\n    \n    map_list[[kpi_name]] &lt;- map\n  }\n  \n  tmap_arrange(map_list, ncol = length(kpi_list))\n}\n\n\nFor each KPI, the visualization has two maps:\n\n\nLocal Moran’s I Map: Shows the Moran’s I values for each region to identify spatial clusters and outliers.\n\nP-value Map: Displays the statistical significance of the Local Moran’s I results specifically regions with p &lt; 0.05 indicating significant spatial patterns.\n\n\n\nTotal no. of tourists\nRevenue\nAvg Revenue / Tourist\n\n\n\n\nplot_local_moran_kpi(\"no_tourist_all\",lmp_summary)\n\n\n\n\n\n\n\n\nplot_lisa_kpi(\"no_tourist_all\", lmp_summary)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThis LISA map shows the local spatial autocorrelation for the total number of tourists across Thailand.\n\nLight Green (Low-Low): These areas, mostly in the northwest and northeast regions of Thailand, are clusters of provinces with low numbers of tourists, surrounded by other provinces with similarly low tourist numbers.\nLight Purple (Low-High): Samut Prakan is shown as a Low-High outlier, meaning it has a low number of tourists compared to its neighboring provinces, which have higher tourist numbers.\nOther areas shown in grey indicate no statistically significant local spatial autocorrelation.\n\n\n\n\n\n\nplot_local_moran_kpi(\"revenue_foreign\",lmp_summary)\n\n\n\n\n\n\n\n\nplot_local_moran_kpi(\"revenue_thai\",lmp_summary)\n\n\n\n\n\n\n\n\nplot_lisa_multiple_kpis(c(\"revenue_foreign\", \"revenue_thai\"), lmp_summary)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThis LISA map shows the local spatial autocorrelation for revenue from local and foreign tourists across Thailand.\nInterestingly, the map reveals only Low-Low and Low-High clusters. The Northwest and Northeast regions, particularly areas like Nakhon Sawan and Kalasin, consistently exhibit Low-Low clusters for both local and foreign tourism revenue.\n\n\n\n\n\nplot_local_moran_kpi(\"avg_revenue_all\",lmp_summary)\n\n\n\n\n\n\n\n\nplot_lisa_kpi(\"avg_revenue_all\", lmp_summary)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThis LISA map shows the local spatial autocorrelation for average revenue per tourist across Thailand.\n\nLight Green (Low-Low): Northwestern regions such as Kanchanaburi and Northeastern regions such as Ubon-Ratchathani are Low-Low clusters, where provinces with low average revenue are surrounded by other provinces with similarly low average revenue per tourist.\nLight Purple (Low-High): Southern regions such as Nakhon Si Thammarat shows a Low-High outlier, indicating it has low average revenue but is surrounded by provinces with high average revenue.\nRed (High-High): Right beside the Low-High cluster, in provinces such as Surat Thani and Phuket are High-High clusters. This means they have high average revenue per tourist and are surrounded by other provinces with similarly high revenues. This suggests the region around Phuket, is a hotspot for tourism revenue."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#spatio-temporal-independence-of-thailands-tourism-economy-indictators",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#spatio-temporal-independence-of-thailands-tourism-economy-indictators",
    "title": "Take Home Exercise 2",
    "section": "\n11 Spatio-Temporal Independence of Thailand’s Tourism Economy Indictators",
    "text": "11 Spatio-Temporal Independence of Thailand’s Tourism Economy Indictators\nIn this section, we will form spatio-temporal analysis to understand the spatio-temporal patterns of Thailand’s tourism economy across different time periods—pre-COVID, during COVID, and post-COVID to uncover how the pandemic has impacted the tourism indicators.\nBy analyzing Global Moran’s I across these periods, we aim to assess whether these indicators exhibited spatial dependence (clustering or dispersion) during each phase.\n\n11.1 Global Spatial Autocorrelation Analysis Across Time Periods\nTo recap, the three distinct periods for this analysis:\n\nPre-COVID (before January 2020)\nCOVID (January 2020 to September 2022)\nPost-COVID (after September 2022)\n\nTo conduct the spatio-temporal analysis, we first aggregate the tourism data at the provincial level and for each time period (pre-COVID, COVID, post-COVID).\n\ntourism_agg_tp &lt;- tourism %&gt;%\n  group_by(province_eng, time_period) %&gt;%\n  summarize(\n    no_tourist_all = sum(no_tourist_all, na.rm = TRUE), \n    revenue_foreign = sum(revenue_foreign, na.rm = TRUE), \n    revenue_thai = sum(revenue_thai, na.rm = TRUE),\n    avg_revenue_all = mean(avg_revenue_all, na.rm = TRUE),\n    geometry = st_union(geometry)\n  )\n\nNext, we create subsets for each time period by filtering the aggregated data:\n\npre_covid_agg &lt;- filter(tourism_agg_tp, time_period ==\"pre-covid\")\ncovid_agg &lt;- filter(tourism_agg_tp, time_period ==\"covid\")\npost_covid_agg &lt;- filter(tourism_agg_tp, time_period ==\"post-covid\")\n\nWe will reuse the Global Moran’s I functions from the previous section and apply them to each time period (pre-COVID, COVID, post-COVID).\n\nShow the codeset.seed(1234)\ntime_periods &lt;- c(\"pre_covid\", \"covid\", \"post_covid\")\nagg_datasets &lt;- list(pre_covid_agg, covid_agg, post_covid_agg)\n\n# Define a function to calculate Moran's I for a dataset and append the time period\ncompute_moran_summary &lt;- function(tourism_data, time_period) {\n  gmp_results &lt;- map(kpis, ~compute_global_moran_perm(tourism_data, .x))\n\n  names(gmp_results) &lt;- kpis\n  \n  # Extract Moran's I info and add a time_period column\n  moran_summary &lt;- map_df(gmp_results, extract_moran_info, .id = \"kpi\") %&gt;%\n    mutate(time_period = time_period)\n  \n  return(moran_summary)\n}\n\n# Apply the function to each dataset (pre_covid_agg, covid_agg, post_covid_agg)\nall_gmp_summaries &lt;- map2_df(agg_datasets, time_periods, compute_moran_summary)\n\n\nAfter running the analysis, we combine all Moran’s I results into a single dataframe for easy interpretation.\n\ndatatable(all_gmp_summaries)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nFor most KPIs, total tourists, revenues from foreign or Thai tourists, across all time periods, we do not reject the null hypothesis, as the p-values are significantly higher than the threshold of 0.05. This means there is no evidence of spatial dependence for these indicators.\nHowever, for average revenue per tourist, the p-values are below the alpha value (&lt;0.05) for pre-covid and covid periods. Therefore, we reject the null hypothesis for this indicator. This suggests that average revenue per tourist tends to cluster spatially for these time periods.\nBoth of these observations is consistent with observations from previous sections. Notably, the spatial clustering for average revenue per tourist indicator weakens in the post-covid period, observed from the drop in Moran’s I value post-covid, suggesting that the pandemic may have disrupted tourism patterns but residual clustering persists.\n\n\n\n\n11.2 Local Spatial Autocorrelation Analysis Across Time Periods\nIn this subsection, we will perform local spatial autocorrelation analysis across time periods using Local Moran’s I.\nSimilar to previous sections, we will reuse existing local spatial custom functions to iterate through the three time periods to produce the results. The results for each time period are saved locally and read from the files for further analysis.\n\nShow the codeset.seed(1234)\ntime_periods &lt;- c(\"pre_covid\", \"covid\", \"post_covid\")\nagg_datasets &lt;- list(pre_covid_agg, covid_agg, post_covid_agg)\nkpis &lt;- c(\"no_tourist_all\", \"revenue_foreign\", \"revenue_thai\", \"avg_revenue_all\")\n\nfor (i in seq_along(agg_datasets)) {\n  # ungroup to avoid error in local moran computation\n  current_dataset &lt;- agg_datasets[[i]] %&gt;% ungroup()\n  # Compute local Moran's I for each KPI in the current dataset\n  lmp_summary_tp &lt;- map_df(kpis, ~compute_local_moran_df(current_dataset, \n                                                      .x, \n                                                      nb_knn_5, \n                                                      knn5_weights_inv))\n  \n  # Save the result with the corresponding time period in the filename\n  write_rds(lmp_summary_tp, file = paste0(\"data/rds/lmp_summary_\", time_periods[i], \".rds\"))\n}\n\n\nWe save the results and read them one by one:\n\nlmp_summary_pre_covid &lt;- read_rds(\"data/rds/lmp_summary_pre_covid.rds\")\nlmp_summary_covid &lt;- read_rds(\"data/rds/lmp_summary_covid.rds\")\nlmp_summary_post_covid &lt;- read_rds(\"data/rds/lmp_summary_post_covid.rds\")\n\n\n11.2.1 Total no. of tourists\nThis subsection presents the local spatial autocorrelation analysis (Local Moran’s I and LISA maps) for the total number of tourists across three different time periods: Pre-Covid, Covid, and Post-Covid.\n\n\nPre-Covid\nCovid\nPost-Covid\n\n\n\n\nplot_local_moran_kpi(\"no_tourist_all\",lmp_summary_pre_covid)\n\n\n\n\n\n\n\n\nplot_lisa_kpi(\"no_tourist_all\", lmp_summary_pre_covid)\n\n\n\n\n\n\n\n\n\n\nplot_local_moran_kpi(\"no_tourist_all\",lmp_summary_covid)\n\n\n\n\n\n\n\n\nplot_lisa_kpi(\"no_tourist_all\", lmp_summary_covid)\n\n\n\n\n\n\n\n\n\n\nplot_local_moran_kpi(\"no_tourist_all\",lmp_summary_post_covid)\n\n\n\n\n\n\n\n\nplot_lisa_kpi(\"no_tourist_all\", lmp_summary_post_covid)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nAcross the three time periods, we can notice that there are persistent Low-Low clusters in the northeast provinces.\n\nInterestingly, a High-Low cluster emerges in the southern part of Thailand (Songkhla area) during the Covid period.\n\n\n\n\n11.2.2 Revenue\nThis subsection presents the local spatial autocorrelation analysis (Local Moran’s I and LISA maps) for the revenue across three different time periods: Pre-Covid, Covid, and Post-Covid.\n\n\nPre-Covid\nCovid\nPost-Covid\n\n\n\n\nplot_local_moran_kpi(\"revenue_foreign\",lmp_summary_pre_covid)\n\n\n\n\n\n\n\n\nplot_local_moran_kpi(\"revenue_thai\",lmp_summary_pre_covid)\n\n\n\n\n\n\n\n\nplot_lisa_multiple_kpis(c(\"revenue_foreign\", \"revenue_thai\"), lmp_summary_pre_covid)\n\n\n\n\n\n\n\n\n\n\nplot_local_moran_kpi(\"revenue_foreign\",lmp_summary_covid)\n\n\n\n\n\n\n\n\nplot_local_moran_kpi(\"revenue_thai\",lmp_summary_covid)\n\n\n\n\n\n\n\n\nplot_lisa_multiple_kpis(c(\"revenue_foreign\", \"revenue_thai\"), lmp_summary_covid)\n\n\n\n\n\n\n\n\n\n\nplot_local_moran_kpi(\"revenue_foreign\",lmp_summary_post_covid)\n\n\n\n\n\n\n\n\nplot_local_moran_kpi(\"revenue_thai\",lmp_summary_post_covid)\n\n\n\n\n\n\n\n\nplot_lisa_multiple_kpis(c(\"revenue_foreign\", \"revenue_thai\"), lmp_summary_post_covid)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nFor Thai Revenue, we can notice that there are persistent Low-Low clusters in the northeast provinces such as Ubon-Ratchathani across all time periods.\nFor Foreign Revenue, we can notice that there are persistent Low-Low clusters in the northwest provinces such as Suphanburi across all time periods.\nKhanaburi province form as Low-Low cluster for foreign revenue during Covid and post-Covid. This suggests potential challenges in attracting foreign tourists to the area even after the pandemic.\n\n\n\n\n11.2.3 Avg Revenue/Tourist\nThis subsection presents the local spatial autocorrelation analysis (Local Moran’s I and LISA maps) for the average revenue per tourist across three different time periods: Pre-Covid, Covid, and Post-Covid.\n\n\nPre-Covid\nCovid\nPost-Covid\n\n\n\n\nplot_local_moran_kpi(\"avg_revenue_all\",lmp_summary_pre_covid)\n\n\n\n\n\n\n\n\nplot_lisa_kpi(\"avg_revenue_all\", lmp_summary_pre_covid)\n\n\n\n\n\n\n\n\n\n\nplot_local_moran_kpi(\"avg_revenue_all\",lmp_summary_covid)\n\n\n\n\n\n\n\n\nplot_lisa_kpi(\"avg_revenue_all\", lmp_summary_covid)\n\n\n\n\n\n\n\n\n\n\nplot_local_moran_kpi(\"avg_revenue_all\",lmp_summary_post_covid)\n\n\n\n\n\n\n\n\nplot_lisa_kpi(\"avg_revenue_all\", lmp_summary_post_covid)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nDuring Pre-Covid, Phuket and surrounding southern provinces formed a High-High cluster for average revenue per tourist indicator, indicating a strong concentration of high average revenues from tourists in this region.\nDuring Covid, the High-High cluster around Phuket remains strong in the Phuket region but seems to extend less into nearby provinces, suggesting a hit on the tourist industry in the region.\nDuring Post-Covid, the High-High cluster in Phuket remains but appears to be less pronounced compared to pre-Covid levels, possibly reflecting a slow recovery.\n\nIn other areas, there is a persistence of Low-Low clustters in the northeastern provinces throughout the different phases of the pandemic."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hotspot-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hotspot-analysis",
    "title": "Take Home Exercise 2",
    "section": "\n12 Emerging Hotspot Analysis",
    "text": "12 Emerging Hotspot Analysis\nThe goal of Emerging Hotspot Analysis (EHSA) is to assess how hotspots (areas of high activity) and coldspots (areas of low activity) evolve over time. EHSA helps answer key questions such as: Are hotspots becoming increasingly pronounced? Are coldspots cooling down further? Or are these areas maintaining the same pattern over time? In the context of tourism, emerging hotspot analysis can reveal regions that are consistently experiencing high or low levels of tourist activity or revenue, helping policymakers and business owners make data-driven decisions.\nTo achieve this, we will first construct a space-time cube to capture the spatial and temporal dimensions of the data. Then, we will compute the Getis-Ord Gi* statistic, which identifies clusters of high or low values spatially. Following this, we will evaluate the trends of these hotspots and coldspots over time using the Mann-Kendall Test, which assesses the significance of these trends. After that, we can utilizing the emerging_hotspot_analysis() function from the sfdep to detect and visualize emerging patterns over time.\n\n12.1 Computing Gi*\nIn this subsection, we will compute the Gi* statistics. We will use the tourism_st object from earlier section to identify neigbours and derive an inverse distance weights.\n\ntourism_nb &lt;- tourism_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(st_knn(geometry, k = 5)),\n         wt = st_inverse_distance(nb, \n                                       geometry,\n                                       scale = 1, \n                                       alpha = 1),\n         .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nactivate(\"geometry\"): Activates the geometry context for spatial operations.\n\nmutate(): Adds two columns:\n\n\nnb: Neighbors, including the observation itself (include_self), using spatial contiguity (st_contiguity).\n\nwt: Weights, calculated with inverse distance (st_inverse_distance).\n\n\n\nset_nbs() and set_wts(): Copies neighbors and weights to all time-slices. Ensure row order consistency after using these functions.\n\n\n\nTo calculate the local Gi* statistic for each location:\n\n\nGroup by date_int: This ensures we calculate Gi* separately for each month, year in the dataset.\n\nUse local_gstar_perm(): This function computes the local Gi* statistic using the GDPPC values, neighbors (nb), and weights (wt).\n\nUnnest the Gi* results: The gi_star column is nested, so we use unnest() to extract the results into a clean format.\n\nWe will do this iteratively for each KPI using a custom function that saves the computed result locally.\n\nShow the codekpis &lt;- c(\"no_tourist_all\", \"revenue_foreign\", \"revenue_thai\", \"avg_revenue_all\")\n\n# Function to compute Gi* and save the results\ncompute_and_save_gi_star &lt;- function(kpi) {\n  gi_stars &lt;- tourism_nb %&gt;%\n    group_by(date_int) %&gt;%\n    mutate(gi_star = local_gstar_perm(!!sym(kpi), nb, wt)) %&gt;%\n    tidyr::unnest(gi_star)\n\n  write_rds(gi_stars, file = paste0(\"data/rds/gi_stars_\", kpi, \".rds\"))\n}\n\npurrr::walk(kpis, compute_and_save_gi_star)\n\n\nWe read the results for further analysis:\n\ngi_stars_tourist &lt;- read_rds(\"data/rds/gi_stars_no_tourist_all.rds\")\ngi_stars_rev_fore &lt;- read_rds(\"data/rds/gi_stars_revenue_foreign.rds\")\ngi_stars_rev_thai &lt;- read_rds(\"data/rds/gi_stars_revenue_thai.rds\")\ngi_stars_avg_rev_all &lt;- read_rds(\"data/rds/gi_stars_avg_revenue_all.rds\")\n\n\n12.2 Mann-Kendall Test\nThe Mann-Kendall Test is used to determine whether a time series has a monotonic upward or downward trend.\nWe would like to test the following hypothesis for each KPI:\n\\(H_0\\): No monotonic trend\n\\(H_1\\): Monotonic trend is present (either positive, or negative)\nRefer to Mann-Kendall Test For Monotonic Trend\nSimilarly, we will do this iteratively for each KPI using a custom function that saves the computed result locally. In essence, this function performs the Mann-Kendall test for each province to assess trends in Gi* statistics, then filters by significance level and extracts the top k emerging hotspots by absolute tau values.\n\nShow the codecompute_emerging_hotspots &lt;- function(gi_stars, top_k, sig_level) {\n  # Perform Mann-Kendall trend test\n  ehsa &lt;- gi_stars %&gt;%\n    group_by(province_eng) %&gt;%\n    summarise(mk = list(unclass(Kendall::MannKendall(gi_star)))) %&gt;%\n    tidyr::unnest_wider(mk)\n  \n  # Filter by significance level (sl) and extract top k emerging hotspots\n  emerging &lt;- ehsa %&gt;%\n    filter(sl &lt; sig_level) %&gt;%\n    arrange(sl, abs(tau)) %&gt;%\n    slice(1:top_k) \n  \n  return(emerging)\n}\n\n\n\n\nTotal no. of tourists\nRevenue\nAvg Revenue / Tourist\n\n\n\n\neh_tourist &lt;- compute_emerging_hotspots(gi_stars_tourist, 10, 0.05)\ndatatable(eh_tourist)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe 10 provinces, including Phatthalung, Trang, Suphan Buri, Nakhon Si Thammarat, Phra Nakhon Si Ayutthaya, Ang Thong, Songkhla, Sing Buri, Uthai Thani, and Lop Buri, show significant trends with very small p-values (below alpha &lt;0.05), indicating strong statistical significance.\nNegative tau values (e.g., Phatthalung, Trang, Nakhon Si Thammarat) suggest a decreasing trend, potentially indicating coldspots, while positive tau values (e.g., Suphan Buri, Phra Nakhon Si Ayutthaya, Sing Buri) reflect an increasing trend, implying emerging hotspots in terms of tourist inflow in these areas.\n\n\n\n\n\neh_rev_fore &lt;- compute_emerging_hotspots(gi_stars_rev_fore, 10, 0.05)\ndatatable(eh_rev_fore)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations (Foreign Revenue):\nThe 10 provinces, including Phatthalung, Trang, Nakhon Si Thammarat, Ranong, Chumphon, Chon Buri, Trat, Chanthaburi, Rayong, and Sa Kaeo, show significant trends in foreign revenue with very small p-values (all below alpha &lt;0.05), indicating strong statistical significance.\nNegative tau values across all provinces (e.g., Phatthalung, Trang, Nakhon Si Thammarat) suggest a decreasing trend in foreign revenue, potentially indicating coldspots where foreign revenue are declining.\n\n\n\neh_rev_thai &lt;- compute_emerging_hotspots(gi_stars_rev_thai, 10, 0.05)\ndatatable(eh_rev_thai)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations (Thai Revenue):\nThe 10 provinces, including Trat, Chanthaburi, Prachuap Khiri Khan, Phayao, Nan, Pattani, Narathiwat, Satun, Songkhla, and Si Sa Ket, show significant trends in Thai revenue with very small p-values (all below alpha &lt;0.05), indicating strong statistical significance.\nPositive tau values (e.g., Nan, Phayao, Trat) suggest an increasing trend in Thai revenue, potentially highlighting emerging hotspots, while negative tau values (e.g., Pattani, Narathiwat, Songkhla) indicate a decreasing trend, suggesting coldspots where Thai revenue may be declining.\n\n\n\n\n\neh_avg_rev_all &lt;- compute_emerging_hotspots(gi_stars_avg_rev_all, 10, 0.05)\ndatatable(eh_avg_rev_all)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations (Average Revenue per Tourist):\nThe 10 provinces, including Tak, Sukhothai, Kamphaeng Phet, Prachin Buri, Phichit, Uttaradit, Phitsanulok, Phrae, Phetchabun, and Chumphon, show significant trends in average revenue per tourist with very small p-values (all below alpha &lt;0.05), indicating strong statistical significance.\nPositive tau values (e.g., Phrae, Phitsanulok, Phichit) suggest an increasing trend in average revenue per tourist, potentially indicating growing tourist spending in these areas. Chumphon, with a negative tau value, shows a decreasing trend, suggesting a potential decline in average revenue per tourist.\n\n\n\n\n\n\n12.3 Performing Emerging Hotspot Analysis\nTo perform Emerging Hotspot Analysis (EHSA), we can use the emerging_hotspot_analysis() function from the sfdep package. This function analyzes spatio-temporal trends by detecting areas that are hotspots over time. It takes the following parameters: - x: The spacetime object (e.g., GDPPC_st). - .var: The variable of interest (e.g., \"GDPPC\"). - k: Number of time lags (default is 1). - nsim: Number of simulations to run (e.g., 99).\nWe will use a for loop to iteratively compute for the selected KPIs.\n\nShow the codeset.seed(1234)\nkpis &lt;- c(\"no_tourist_all\", \"revenue_foreign\", \"revenue_thai\", \"avg_revenue_all\")\n\n# Loop through the KPIs\nfor (kpi in kpis) {\n  \n  # Perform the Emerging Hotspot Analysis for the current KPI\n  ehsa_result &lt;- emerging_hotspot_analysis(\n    x = tourism_st, \n    .var = kpi, \n    k = 1, \n    nsim = 99\n  )\n  \n  # Save the result with a file name based on the current KPI\n  save_file &lt;- paste0(\"data/rds/ehsa_\", kpi, \".rds\")\n  write_rds(ehsa_result, file = save_file)\n  \n}\n\n\n\nehsa_tourist &lt;- read_rds(\"data/rds/ehsa_no_tourist_all.rds\")\nehsa_rev_fore &lt;- read_rds(\"data/rds/ehsa_revenue_foreign.rds\")\nehsa_rev_thai &lt;- read_rds(\"data/rds/ehsa_revenue_thai.rds\")\nehsa_avg_rev_all &lt;- read_rds(\"data/rds/ehsa_avg_revenue_all.rds\")\n\n\n12.4 Visualizing Distribution of EHSA Classes and Maps\nTo visualize the distribution of EHSA classifications, we will create an interactive bar chart using ggplotly based on the EHSA results.\nFor visualizing the geographic distribution of EHSA classes, we need to join the admin_boundary data with the corresponding ehsa object (e.g., ehsa_tourist) before plotting. Note that in this case, we have filtered the data to include only statistically significant results.\n\n\nTotal no. of tourists\nRevenue\nAvg Revenue / Tourist\n\n\n\n\nehsa_tourist_sig &lt;- ehsa_tourist %&gt;%\n  filter(p_value &lt; 0.05)\n\nggplotly(ggplot(ehsa_tourist_sig, aes(x = classification)) + geom_bar())\n\n\n\n\n\n\nShow the codetourist_ehsa &lt;- admin_boundary %&gt;%\n  left_join(ehsa_tourist,\n            by = join_by(province_eng == location))\n\nsig_tourist_ehsa &lt;- tourist_ehsa  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(tourist_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(sig_tourist_ehsa ) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(title = \"EHSA Classification of Tourist Nums.\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nBoth the bar chart and the choropleth map display the classification of statistically significant hotspots or coldspots for the total number of tourists (alpha &lt; 0.05).\nFrom the bar chart we can notice most regions (over 40) are classified as “no pattern detected,” meaning no significant trends were found, while a few regions are classified as “oscillating coldspot,” indicating fluctuating coldspot patterns over time.\nThis is reflected on the choropleth map which provides a geographic representation of these classifications. Regions in green are marked as “no pattern detected,” spread across much of Thailand, while only a small region (in yellow) is classified as an “oscillating coldspot.” The remaining grey regions represent regions with no statistically significant patterns.\n\n\n\n\nForeign Revenue\n\nehsa_rev_fore_sig &lt;- ehsa_rev_fore %&gt;%\n  filter(p_value &lt; 0.05)\n\nggplotly(ggplot(ehsa_rev_fore_sig, aes(x = classification)) + geom_bar())\n\n\n\n\n\nThai Revenue\n\nehsa_rev_thai_sig &lt;- ehsa_rev_thai %&gt;%\n  filter(p_value &lt; 0.05)\n\nggplotly(ggplot(ehsa_rev_thai_sig, aes(x = classification)) + geom_bar())\n\n\n\n\n\nCombined Choropleth Map\nNote that as Foreign Revenue has 3 categories, while Thai Revenue has 4 categories, we have pegged the classification with fixed colors for comparison.\n\nShow the code# Define the color palette\nclassification_colors &lt;- c(\"no pattern detected\" = \"turquoise3\", \n                           \"oscillating coldspot\" = \"yellow2\", \n                           \"sporadic coldspot\" = \"mediumpurple1\", \n                           \"sporadic hotspot\" = \"tomato\")\n\n# Create first map (Foreign Revenue)\nrev_fore_ehsa &lt;- admin_boundary %&gt;%\n  left_join(ehsa_rev_fore, by = join_by(province_eng == location))\n\nsig_rev_fore_ehsa &lt;- rev_fore_ehsa %&gt;%\n  filter(p_value &lt; 0.05)\n\nmap_fore &lt;- tm_shape(rev_fore_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  tm_shape(sig_rev_fore_ehsa) +\n  tm_fill(\"classification\", palette = classification_colors) + \n  tm_borders(alpha = 0.4) +\n  tm_layout(title = \"EHSA Classification of Foreign Revenue\")\n\n# Create second map (Thai Revenue)\nrev_thai_ehsa &lt;- admin_boundary %&gt;%\n  left_join(ehsa_rev_thai, by = join_by(province_eng == location))\n\nsig_rev_thai_ehsa &lt;- rev_thai_ehsa %&gt;%\n  filter(p_value &lt; 0.05)\n\nmap_thai &lt;- tm_shape(rev_thai_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  tm_shape(sig_rev_thai_ehsa) +\n  tm_fill(\"classification\", palette = classification_colors) + \n  tm_borders(alpha = 0.4) +\n  tm_layout(title = \"EHSA Classification of Thai Revenue\")\n\ntmap_arrange(map_fore, map_thai, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations (Foreign & Thai Revenue):\nBoth the bar chart and the choropleth map show the classification of statistically significant (alpha &lt; 0.05). hotspots or coldspots for foreign and thai revenue respectively.\nFor foreign revenue, most regions are classified as “sporadic coldspot,” indicating inconsistent periods of lower foreign revenue. Some regions are marked as “no pattern detected,” meaning no significant trends were observed, while only a few regions are classified as “sporadic hotspot,” suggesting inconsistent periods of higher foreign revenue.\nFor thai revenue, the majority of regions are classified as “no pattern detected,” indicating no clear trends in Thai revenue. Some regions are marked as “sporadic coldspot,” meaning these areas experience inconsistent periods of lower Thai revenue, while a smaller number of regions are classified as “sporadic hotspot,” showing intermittent periods of higher Thai revenue.\nFrom the choropleth map for these two categories, we can notice some salient differences in the geographic distribution of these revenue sources. Notably, the Thai revenue map has a more diverse classification, with a significant number of “sporadic hotspots” (red), particularly in northern Thailand, which are not present on the foreign revenue map. From the maps, we can also notice that both revenue sources share the same sporadic coldspots cluster if not, they appear side by side if we overlap the maps.\n\n\n\n\n\nehsa_avg_rev_all_sig &lt;- ehsa_avg_rev_all %&gt;%\n  filter(p_value &lt; 0.05)\n\nggplotly(ggplot(ehsa_avg_rev_all_sig, aes(x = classification)) + geom_bar())\n\n\n\n\n\n\nShow the codeavg_rev_all_ehsa &lt;- admin_boundary %&gt;%\n  left_join(ehsa_avg_rev_all,\n            by = join_by(province_eng == location))\n\nsig_avg_rev_all_ehsa &lt;- avg_rev_all_ehsa  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(avg_rev_all_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(sig_avg_rev_all_ehsa ) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4) +\n  tm_layout(title = \"EHSA Classification of Avg Revenue/Tourist\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nBoth the bar chart and the choropleth map show the classification of statistically significant hotspots or coldspots for average revenue per tourist (alpha &lt; 0.05).\nFrom the bar chart, we can observe that most regions are classified as “sporadic coldspot,” indicating inconsistent periods of lower revenue, while a significant number of regions are marked as “sporadic hotspot,” showing intermittent periods of higher average revenue. Only a small number of regions show “oscilating coldspot”\nThe choropleth map provides a geographic representation of these classifications. Red regions indicate “sporadic hotspots,” while purple regions represent “sporadic coldspots.” Green areas show “no pattern detected,” and the few yellow areas represent “oscillating coldspot.” The remaining gray regions indicate areas with no statistically significant patterns. These regions with different are intermixed throughout Thailand."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#exploratory-data-analysis-eda",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#exploratory-data-analysis-eda",
    "title": "Take Home Exercise 2",
    "section": "\n9 Exploratory Data Analysis (EDA)",
    "text": "9 Exploratory Data Analysis (EDA)\nIn this section, we will perform Exploratory Data Analysis to understand data better and derive the important indictators of tourism economy of Thailand for further geospatial analysis.\n\nShow the code# Create a mapping of the number of months per year\nmonths_per_year &lt;- tourism_df_ft %&gt;%\n  group_by(year) %&gt;%\n  summarize(months_count = n_distinct(month_number)) %&gt;%\n  ungroup()\n\n# Normalize tourist data by dividing by months_count for each year\ntourists_by_year_type &lt;- tourism_df_ft %&gt;%\n  group_by(year) %&gt;%\n  summarize(\n    total_thai = sum(no_tourist_thai, na.rm = TRUE),\n    total_foreign = sum(no_tourist_foreign, na.rm = TRUE),\n    total_all = sum(no_tourist_all, na.rm = TRUE)\n  ) %&gt;%\n  ungroup() %&gt;%\n  left_join(months_per_year, by = \"year\") %&gt;%\n  mutate(\n    total_thai = total_thai / months_count,\n    total_foreign = total_foreign / months_count,\n    total_all = total_all / months_count\n  ) %&gt;%\n  select(-months_count)\n\ntourists_by_year_long &lt;- tourists_by_year_type %&gt;%\n  pivot_longer(cols = c(total_thai, total_foreign), names_to = \"tourist_type\", values_to = \"total_tourists\")\n\n# create stacked bar chart with trendline\nfig_tourists_by_year &lt;- plot_ly() %&gt;%\n  add_trace(\n    data = tourists_by_year_long %&gt;% filter(tourist_type == \"total_thai\"),\n    x = ~year,\n    y = ~total_tourists,\n    name = \"Thai Tourists\",\n    type = 'bar',\n    hoverinfo = 'text',\n    marker = list(color = 'dodgerblue2')\n  ) %&gt;%\n  add_trace(\n    data = tourists_by_year_long %&gt;% filter(tourist_type == \"total_foreign\"),\n    x = ~year,\n    y = ~total_tourists,\n    name = \"Foreign Tourists\",\n    type = 'bar',\n    hoverinfo = 'text',\n    marker = list(color = 'sienna3')\n  ) %&gt;%\n  # Add trendline for total tourists\n  add_trace(\n    data = tourists_by_year_type,\n    x = ~year,\n    y = ~total_all,\n    type = 'scatter',\n    mode = 'lines+markers',\n    line = list(color = 'black', dash = 'dash'),\n    marker = list(color = 'black', size = 6),\n    name = 'Total Tourists Trend'\n  ) %&gt;%\n  layout(\n    barmode = 'stack',\n    title = \"Normalized Distribution of Local and Foreign Tourists Over Time\",\n    xaxis = list(title = \"Year\"),\n    yaxis = list(title = \"Number of Tourists (Monthly Average)\"),\n    legend = list(title = list(text = \"Tourist Type\"))\n  )\n\nfig_tourists_by_year\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nThe plot above shows the distribution of local and foreign tourists over time, normalized by month. Normalization is done to ensure that the plot is still representative as there is partial yearly data for 2023.\nTourism peaked in 2023 (normalized by months), indicating that tourist numbers have rebounded strongly, even surpassing pre-pandemic levels from 2019.\nThe sharp decline from 2020 to 2021 due to the global impact of the COVID-19 pandemic and related restrictions is clearly visible.\nThe ratio of foreign tourists remains relatively low in comparison to local tourists, consistent across all the years, suggesting that local tourism has been a key driver in the recovery.\n\n\n\n\nShow the codemonths_per_year &lt;- tourism_df_ft %&gt;%\n  group_by(year) %&gt;%\n  summarize(months_count = n_distinct(month_number)) %&gt;%\n  ungroup()\n\n# Group data by year and summarize revenue for Thai, foreign, and all tourists, normalized by months\nrevenue_by_year_type &lt;- tourism_df_ft %&gt;%\n  st_drop_geometry() %&gt;%\n  group_by(year) %&gt;%\n  summarize(\n    total_revenue_thai = sum(revenue_thai, na.rm = TRUE),\n    total_revenue_foreign = sum(revenue_foreign, na.rm = TRUE),\n    total_revenue_all = sum(revenue_all, na.rm = TRUE)\n  ) %&gt;%\n  ungroup() %&gt;%\n  # Join with the months per year to normalize\n  left_join(months_per_year, by = \"year\") %&gt;%\n  mutate(\n    monthly_avg_revenue_thai = total_revenue_thai / months_count,\n    monthly_avg_revenue_foreign = total_revenue_foreign / months_count,\n    monthly_avg_revenue_all = total_revenue_all / months_count\n  )\n\n# Reshape data for stacked bar chart\nrevenue_by_year_long &lt;- revenue_by_year_type %&gt;%\n  pivot_longer(cols = c(monthly_avg_revenue_thai, monthly_avg_revenue_foreign), \n               names_to = \"revenue_type\", \n               values_to = \"monthly_avg_revenue\")\n\n# Create stacked bar chart with trendline for total revenue (monthly average)\nfig_revenue_by_year &lt;- plot_ly() %&gt;%\n  # Add trace for Thai tourist revenue (blue)\n  add_trace(\n    data = revenue_by_year_long %&gt;% filter(revenue_type == \"monthly_avg_revenue_thai\"),\n    x = ~year,\n    y = ~monthly_avg_revenue,\n    name = \"Thai Tourist Revenue\",\n    type = 'bar',\n    hoverinfo = 'text',\n    marker = list(color = 'dodgerblue2')\n  ) %&gt;%\n  # Add trace for Foreign tourist revenue (orange)\n  add_trace(\n    data = revenue_by_year_long %&gt;% filter(revenue_type == \"monthly_avg_revenue_foreign\"),\n    x = ~year,\n    y = ~monthly_avg_revenue,\n    name = \"Foreign Tourist Revenue\",\n    type = 'bar',\n    hoverinfo = 'text',\n    marker = list(color = 'sienna3')\n  ) %&gt;%\n  # Add trendline for total revenue (monthly average)\n  add_trace(\n    data = revenue_by_year_type,\n    x = ~year,\n    y = ~monthly_avg_revenue_all,\n    type = 'scatter',\n    mode = 'lines+markers',\n    line = list(color = 'black', dash = 'dash'),\n    marker = list(color = 'black', size = 6),\n    name = 'Total Revenue Trend'\n  ) %&gt;%\n  layout(\n    barmode = 'stack',\n    title = \"Normalized Distribution of Revenue by Tourist Type Over Time\",\n    xaxis = list(title = \"Year\"),\n    yaxis = list(title = \"Revenue (Monthly Average, Thai Baht)\"),\n    legend = list(title = list(text = \"Revenue Type\"))\n  )\n\nfig_revenue_by_year\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations (Comparing with revenue distribution with earlier tourist count plot):\n\nThe plot shows the normalized distribution of revenue from local and foreign tourists over time, adjusting for partial data in 2023 by normalizing the values per month.\nWhen comparing the revenue plot with the tourist count plot, it becomes clear that foreign tourists, though fewer in number, contribute significantly more to revenue than local tourists. This suggests that foreign tourists spend more per visit than local tourists, highlighting their economic importance on the tourism industry.\nTotal revenue peaked in 2019, but while tourist numbers have rebounded strongly in 2023, the revenue is still recovering and has not yet surpassed 2019 levels. This indicates that although tourism has picked up in terms of volume, the overall spending per tourist might be lower than pre-pandemic levels, or the higher-spending foreign tourists have not fully returned in their pre-2019 numbers.\n\n\n\n\nShow the code# Summarize total revenue by year and province\nrevenue_by_year_province &lt;- tourism_df_ft %&gt;%\n  group_by(year, province_eng) %&gt;%\n  summarize(\n    total_revenue_all = sum(revenue_all, na.rm = TRUE)\n  ) %&gt;%\n  ungroup()\n\n# Calculate the proportion (percent) of revenue by province for each year and reorder provinces by contribution\nrevenue_by_year_province &lt;- revenue_by_year_province %&gt;%\n  group_by(year) %&gt;%\n  mutate(\n    total_revenue_year = sum(total_revenue_all, na.rm = TRUE),\n    percent_revenue = (total_revenue_all / total_revenue_year) * 100,\n    # Reorder provinces based on their revenue contribution for each year\n    province_eng = fct_reorder(province_eng, percent_revenue, .desc = TRUE)\n  ) %&gt;%\n  ungroup()\n\n# Create stacked bar chart with percentages\nfig_revenue_by_year_province &lt;- plot_ly() %&gt;%\n  add_trace(\n    data = revenue_by_year_province,\n    x = ~year,\n    y = ~percent_revenue,\n    color = ~province_eng,\n    colors = brewer.pal(n = 12, \"Set3\"),\n    type = 'bar',\n    text = ~paste(province_eng, \": \", round(percent_revenue, 2), \"%\"),\n    hoverinfo = 'text',\n    name = ~province_eng,\n    marker = list(line = list(color = 'grey', width = 0.5))\n  ) %&gt;%\n  layout(\n    barmode = 'stack',\n    title = \"Percentage Distribution of Revenue Over Time by Province\",\n    xaxis = list(title = \"Year\"),\n    yaxis = list(title = \"Revenue (%)\"),\n    legend = list(title = list(text = \"Province\"))\n  )\n\n# Show the plot\nfig_revenue_by_year_province\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nThe revenue distribution across provinces is highly skewed, with a few provinces such as Bangkok, Phucket consistently contributing a significant portion of the total revenue.\nThis pattern remains even during the COVID period, although the skewness slightly decreases.\n\n\n\n\n9.1 Determining Key Economic Indicators\nIn this section, we select four key economic indicators or Key Performance Indicators (KPI) for further geospatial analysis.\nThe selection is based on the following criteria:\n\nEconomic significance\n\nLow to moderate correlation: To avoid redundancy and ensure each indicator captures distinct information.\n\n\ncorrelation_matrix &lt;- tourism_df_ft %&gt;%\n  select(7:21) %&gt;%\n  cor(use = \"complete.obs\")  # Use \"complete.obs\" to handle NA values\ncorrplot(correlation_matrix, method = \"circle\", type = \"lower\", \n         tl.col = \"black\", tl.srt = 45, \n         addCoef.col = \"black\")  # Add correlation coefficients\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe will select the following economic indictators:\n\nTotal number of tourists (no_tourist_all): This captures the overall tourism demand across provinces, providing a broad view of how tourism is distributed. Since it is highly correlated with both foreign and domestic tourist numbers, we don’t have to analyse no_tourist_thai and no_tourist_foreign separately.\nRevenue from foreign tourists (revenue_foreign): This indicator is crucial for understanding the economic impact of international tourists, and it can indictate foreign revenue inflow to the Thai economy.\nRevenue from thai tourists (revenue_thai): We will also analyse the revenue from Thai tourist to compare against revenue_foreign\nAverage revenue per tourist (avg_revenue_all): This indicator reflects the quality of tourism by measuring spending per tourist. It also has a low correlation with other indicator, making it a distinct measure.\n\n\n\n\n9.2 Creating the Derived Tourism Economy Indicators Layer in spacetime\nIn this subsection, we will create a derived tourism economy indictator layer in spacetime s3 class of sfdep. This is in preparation of the creation of space time cubes for emerging hot spot analysis in later sections.\nThe code below create the spacetime object using tourism_df_ft and admin_boundary. Then we use is_spacetime() to verify that tourism_st is a valid spacetime cube object.\n\ntourism_st &lt;- spacetime(\n  .data = tourism_df_ft, \n  .geometry = admin_boundary, \n  .loc_col = \"province_eng\", \n  .time_col = \"date_int\"\n  )\n\nis_spacetime_cube(tourism_st)\n\nThen we save tourism_st for future analysis.\n\nwrite_rds(tourism_st, file = \"data/rds/tourism_st.rds\")\n\n\ntourism_st &lt;- read_rds(\"data/rds/tourism_st.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html",
    "title": "7A: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 13  Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#exercise-7a-reference",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#exercise-7a-reference",
    "title": "7A: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 13  Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#overview",
    "title": "7A: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "\n2 Overview",
    "text": "2 Overview\nIn this exercise, we will learn to build hedonic pricing models for private high-rise property using Geographically Weighted Regression (GWR) methods to account for non-stationary variables.\nGeographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable).\n\nIn this exercise, The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational.\n\nWe will be using the GWmodel package. It provides a collection of localised spatial statistical methods, namely: GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms. Commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#learning-outcome",
    "title": "7A: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "\n3 Learning Outcome",
    "text": "3 Learning Outcome\n\nUnderstand the basics of geographically weighted regression (GWR).\nBuild and evaluate hedonic pricing models using GWR.\nConvert geospatial and aspatial data into appropriate formats for analysis.\nPerform exploratory data analysis (EDA) using statistical graphics.\nVisualize the model outputs and spatial patterns using various R packages.\nAssess spatial autocorrelation and other statistical properties of model residuals.\nCompare and interpret fixed and adaptive bandwidth GWR models."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#the-data",
    "title": "7A: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "\n4 The Data",
    "text": "4 The Data\nThe following 2 datasets will be used in this study:\n\n\n\n\n\n\n\nData Set\nDescription\nFormat\n\n\n\nMP14_SUBZONE_WEB_PL\nURA Master Plan 2014’s planning subzone boundaries represented as polygon features.\nESRI Shapefile\n\n\ncondo_resale_2015.csv\nData on condominium resale prices in 2015, including structural and locational attributes.\nCSV"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#installing-and-launching-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#installing-and-launching-the-r-packages",
    "title": "7A: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "\n5 Installing and Launching the R Packages",
    "text": "5 Installing and Launching the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\nsf\nManages, processes, and manipulates vector-based geospatial data.\nHandling and converting geospatial data such as the URA Master Plan boundaries.\n\n\nGWmodel\nCalibrates geographically weighted models for local spatial analysis.\nBuilding hedonic pricing models using fixed and adaptive bandwidth GWR methods.\n\n\nolsrr\nPerforms diagnostics and builds better multiple linear regression models.\nTesting for multicollinearity, normality, and linearity of the regression model.\n\n\ncorrplot\nProvides visual tools to explore data correlation matrices.\nVisualizing relationships between independent variables in the dataset.\n\n\ntmap\nCreates static and interactive thematic maps using cartographic quality elements.\nVisualizing the geospatial distribution of condominium resale prices and other model outputs.\n\n\ntidyverse\nA collection of packages for data science tasks such as data manipulation, visualization, and modeling.\nImporting CSV files, wrangling data, and performing data transformations and visualizations.\n\n\nggpubr\nEnhances ‘ggplot2’ for easier ‘publication-ready’ plots.\nCreating small multiple histograms and scatterplots for exploratory data analysis.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#geospatial-data-wrangling",
    "title": "7A: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "\n6 Geospatial Data Wrangling",
    "text": "6 Geospatial Data Wrangling\n\n6.1 Importing Geospatial Data\nTo import MP_SUBZONE_WEB_PL shapefile:\n\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex07/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe output above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz and it is a simple feature object. The geometry type is multipolygon. It is also important to note that mpsz simple feature object does not have EPSG information.\n\n6.2 Updating CRS Information\nThe code below updates the newly imported mpsz with the correct ESPG code (i.e. 3414)\n\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG: is indicated as 3414 now.\n\n6.3 Revealing the Extent of mpsz_svy21\nTo reveal the extent of mpsz_svy21:\n\nst_bbox(mpsz_svy21) #view extent\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#aspatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#aspatial-data-wrangling",
    "title": "7A: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "\n7 Aspatial Data Wrangling",
    "text": "7 Aspatial Data Wrangling\n\n7.1 Importing Aspatial Data\nThe condo_resale_2015 is in csv file format. The codes chunk below uses read_csv() function of readr package to import condo_resale_2015 into R as a tibble data frame called condo_resale.\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nTo display summary statistics of condo_resale:\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n7.2 Converting an Aspatial Data Frame to an sf Object\nIn this step, we will:\n\nUse the st_as_sf() function from the sf package to convert the aspatial data frame into a spatial (sf) object.\nApply st_transform() to reproject the coordinates from the WGS 84 coordinate system (CRS: 4326) to SVY21 (CRS: 3414), commonly used in Singapore.\n\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\n\nThe resulting output is a point-based feature data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#exploratory-data-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#exploratory-data-analysis",
    "title": "7A: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "\n8 Exploratory Data Analysis",
    "text": "8 Exploratory Data Analysis\nIn the section, we will use statistical graphics functions of ggplot2 package to perform EDA.\n\n8.1 EDA using Statistical Graphics\n\n8.2 6.1.1 Plot Distribution\nTo plot the distribution of SELLING_PRICE by using histograms:\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nA right skewed distribution.\nThis means that more condominium units were transacted at relative lower prices.\nStatistically, the skewed distribution can be normalised by using log transformation.\n\n\n\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\nNotice that the distribution is relatively less skewed after the transformation.\n\n8.3 Multiple Histogram Plots for Variable Distribution\nIn this section, we will create multiple histograms (also known as a trellis plot or small multiples) to visualize the distribution of several variables. We will use the ggarrange() function from the ggpubr package to organize these histograms into a 3-column by 4-row grid layout.\n\nShow the code# List of variables to plot\nvariables &lt;- c(\"AREA_SQM\", \"AGE\", \"PROX_CBD\", \"PROX_CHILDCARE\", \n               \"PROX_ELDERLYCARE\", \"PROX_URA_GROWTH_AREA\", \n               \"PROX_HAWKER_MARKET\", \"PROX_KINDERGARTEN\", \n               \"PROX_MRT\", \"PROX_PARK\", \"PROX_PRIMARY_SCH\", \n               \"PROX_TOP_PRIMARY_SCH\")\n\nhistograms &lt;- lapply(variables, function(var) {\n  ggplot(condo_resale.sf, aes_string(x = var)) + \n    geom_histogram(bins = 20, color = \"black\", fill = \"lightblue\")\n})\n\nggarrange(plotlist = histograms, ncol = 3, nrow = 4)\n\n\n\n\n\n\n\n\n8.4 Drawing a Statistical Point Map\nIn this section, we will visualize the geospatial distribution of condominium resale prices in Singapore.\n\nThe map will be prepared by using tmap package.\n\n\ntmap_mode(\"view\") to use the interactive mode of tmap\n\n\nThen, create an interactive point symbol map\n\n\ntm_dots() is used instead of tm_bubbles()\n\n\nset.zoom.limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively.\n\n\nLastly, tmap_mode(\"plot\") to display plot mode\n\n\nShow the codetmap_mode(\"view\")\ntmap_options(check.and.fix = TRUE)\n\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\nShow the codetmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#hedonic-pricing-model-in-r",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#hedonic-pricing-model-in-r",
    "title": "7A: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "\n9 Hedonic Pricing Model in R",
    "text": "9 Hedonic Pricing Model in R\nIn this section, we will build a hedonic pricing model for condominium resale units using the lm() function from base R.\n\n9.1 Simple Linear Regression\nWe start by modeling SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\n\ncondo.slr &lt;- lm(SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nThe model equation is:SELLING_PRICE = -258121.1 + 14719 * AREA_SQM\n\n\nR-squared: 0.4518, indicating the model explains 45% of the variation in resale prices.\n\nP-value: The very small p-value (&lt; 0.0001) indicates strong evidence to reject the null hypothesis, suggesting the model is a good fit.\n\nCoefficients: Both the intercept and slope have p-values &lt; 0.001, confirming that the parameters are significant predictors.\n\n\n\nTo visualize the fit, we can plot the data and the regression line:\n\nggplot(data = condo_resale.sf, aes(x = AREA_SQM, y = SELLING_PRICE)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n\nThis scatterplot with a fitted regression line highlights some high-price outliers in the dataset.\n\n9.2 Multiple Linear Regression\n\n9.2.1 Checking for Multicollinearity\nBefore building a multiple regression model, it is essential to ensure that the independent variables are not highly correlated, as this can lead to multicollinearity, which compromises the model’s quality.\nA correlation matrix is useful for visualizing relationships between variables. In this case, we use the corrplot package to plot a correlation matrix for the independent variables.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nFrom the matrix, we observe that Freehold and LEASE_99YEAR are highly correlated, so only Freehold will be included in the model.\n\n\n\n\n9.3 Building the Multiple Linear Regression Model\nWe now build a hedonic pricing model using multiple linear regression. The model predicts SELLING_PRICE based on several property characteristics.\n\ncondo.mlr &lt;- lm(SELLING_PRICE ~ AREA_SQM + AGE + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n                  PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + \n                  PROX_PRIMARY_SCH + PROX_TOP_PRIMARY_SCH + \n                  PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data = condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\n\nSignificant predictors:\n\n\nAREA_SQM (positive): Larger units have higher selling prices.\n\nAGE (negative): Older units tend to sell for less.\n\nPROX_CBD (negative): Proximity to the central business district reduces selling prices.\n\nPROX_PARK (positive): Proximity to parks increases resale prices.\n\nFREEHOLD (positive): Freehold properties sell for more than leasehold properties.\n\n\n\nNon-significant predictors (p &gt; 0.05):\n\n\nPROX_HAWKER_MARKET, PROX_TOP_PRIMARY_SCH, PROX_SUPERMARKET show weak or no significant relationship with SELLING_PRICE.\n\n\n\n\n\n\n9.4 Revising the Hedonic Pricing Model\nAfter reviewing the initial model, we will now remove non-significant variables to improve the model. The revised multiple linear regression model is calibrated as follows:\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                 data = condo_resale.sf)\nols_regress(condo.mlr1)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.592 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.592                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n9.5 Publication-Ready Table with gtsummary\n\nThe gtsummary package provides an elegant way to create publication-ready regression tables. The following code generates a formatted regression report:\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n\n95% CI\n1\n\np-value\n\n\n\n(Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n\n\nAREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n\n\nAGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n\n\nPROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n\n\nPROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n\n\nPROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n\n\nPROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n\n\nPROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n\n\nPROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n\n\nPROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n\n\nPROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n\n\nPROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n\n\nNO_Of_UNITS\n-245\n-418, -73\n0.005\n\n\nFAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n\n\nFREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n\n\n\n\n1\nCI = Confidence Interval\n\n\n\n\n\n\nYou can further enhance the report by adding model statistics using add_glance_table() or add_glance_source_note():\n\ntbl_regression(condo.mlr1, intercept = TRUE) %&gt;%\n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, AIC, statistic, p.value, sigma))\n\n\n9.5.1 Checking for Multicollinearity\nWe can check for multicollinearity using the olsrr package’s ols_vif_tol() function:\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nSince the VIF values are all below 10, there is no indication of multicollinearity among the independent variables.\n\n\n\n9.5.2 Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nTo test the linearity assumption, we use the ols_plot_resid_fit() function.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nMost points are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n\n9.5.3 Test for Normality Assumption\nWe can assess the normality of residuals with a histogram:\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\n\n\nThe residuals appear normally distributed. For a formal test, we can use ols_test_normality():\n\nols_test_normality(condo.mlr1)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\n\n9.5.4 Testing for Spatial Autocorrelation\nSince the hedonic model involves geographically referenced data, it is important to visualize the residuals and test for spatial autocorrelation.\nFirst, we export the residuals from the hedonic pricing model into a data frame.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\nNext, we join the residuals with the condo_resale.sf spatial data frame:\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, condo.mlr1$residuals) %&gt;%\n  rename(MLR_RES = condo.mlr1.residuals)\n\nWe convert the condo_resale.res.sf from an sf object to a SpatialPointsDataFrame for use with the spdep package:\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nUsing tmap, we visualize the spatial distribution of the residuals:\n\ntmap_mode(\"view\")\n\ntm_shape(mpsz_svy21) +\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\", alpha = 0.6, style = \"quantile\") +\n  tm_view(set.zoom.limits = c(11, 14))\n\n\n\n\ntmap_mode(\"plot\")\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe figure above reveal that there is sign of spatial autocorrelation.\n\n\nTo formally test for spatial autocorrelation using Moran’s I Test, we first compute a distance-based weight matrix:\n\nnb &lt;- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nConvert the neighbor list into spatial weights:\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nFinally, perform Moran’s I test on the model residuals:\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\n\nP-value: The p-value is extremely small (&lt; 0.05), leading us to reject the null hypothesis that residuals are randomly distributed.\n\nObserved Moran’s I: The value of 0.1424418 (greater than 0) indicates that residuals show a clustered pattern, confirming the presence of spatial autocorrelation."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#building-hedonic-pricing-models-using-gwmodel",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07a.html#building-hedonic-pricing-models-using-gwmodel",
    "title": "7A: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "\n10 Building Hedonic Pricing Models using GWmodel",
    "text": "10 Building Hedonic Pricing Models using GWmodel\nIn this section, we will model hedonic pricing using both fixed and adaptive bandwidth schemes.\n\n10.1 Building Fixed Bandwidth GWR Model\n\n10.1.1 Computing Fixed Bandwidth\nWe use the bw.gwr() function from the GWModel package to determine the optimal fixed bandwidth for the model.\nSetting adaptive = FALSE ensures that we are calculating a fixed bandwidth. There are two possible approaches for determining the stopping rule: CV cross-validation and AICc. In this case, we use the cross-validation approach (approach = \"CV\").\n\nbw.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n                     PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data = condo_resale.sp, \n                   approach = \"CV\", \n                   kernel = \"gaussian\", \n                   adaptive = FALSE, \n                   longlat = FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.379526e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3396 CV score: 4.721292e+14 \nFixed bandwidth: 971.3402 CV score: 4.721292e+14 \nFixed bandwidth: 971.3398 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3399 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \n\n\nThe recommended bandwidth is 971.34 meters.\n\n\n\n\n\n\nNote\n\n\n\nQuiz Answer:\nThe bandwidth is in meters because the model is using projected coordinates, SVY21, where distances are measured in meters.\n\n\n\n10.1.2 GWModel Method - Fixed Bandwidth\nWe can now calibrate the GWR model using a fixed bandwidth and a Gaussian kernel with the following code:\n\ngwr.fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n                         PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data = condo_resale.sp, \n                       bw = bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-14 19:55:45.822271 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.34 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3599e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7426e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5001e+06 -1.5970e+05  3.1970e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8074e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112794435\n   AREA_SQM                 21575\n   AGE                     434203\n   PROX_CBD               2704604\n   PROX_CHILDCARE         1654086\n   PROX_ELDERLYCARE      38867861\n   PROX_URA_GROWTH_AREA  78515805\n   PROX_MRT               3124325\n   PROX_PARK             18122439\n   PROX_PRIMARY_SCH       4637517\n   PROX_SHOPPING_MALL     1529953\n   PROX_BUS_STOP         11342209\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720745\n   FREEHOLD               6073642\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3807 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6193 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.534069e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430418 \n\n   ***********************************************************************\n   Program stops at: 2024-10-14 19:55:47.015626 \n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe AICc for this fixed bandwidth GWR model is 42263.61, which is lower than the global multiple linear regression model (AICc = 42967.1), indicating a better fit.\n\n\n\n10.2 Building Adaptive Bandwidth GWR Model\n\n10.2.1 Computing the Adaptive Bandwidth\nTo compute the adaptive bandwidth, we set adaptive = TRUE in the bw.gwr() function:\n\nbw.adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data = condo_resale.sp, \n                      approach = \"CV\", \n                      kernel = \"gaussian\", \n                      adaptive = TRUE, \n                      longlat = FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe result suggests using 30 data points for the adaptive bandwidth.\n\n\n\n10.2.2 Constructing the Adaptive Bandwidth GWR Model\nWe can now calibrate the GWR model with the adaptive bandwidth:\n\ngwr.adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data = condo_resale.sp, \n                          bw = bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive = TRUE, \n                          longlat = FALSE)\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-14 19:55:56.103874 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-10-14 19:55:57.424832 \n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe AICc for the adaptive bandwidth GWR model is 41982.22, which is even lower than the fixed bandwidth GWR model (AICc = 42263.61), indicating an improved model fit.\n\n\n\n10.3 Visualizing GWR Output\nThe output from GWR includes fields for observed and predicted values, residuals, local R², condition numbers, and explanatory variable coefficients:\n\n\nCondition Number: Identifies areas with strong local collinearity. Values over 30 may indicate unreliable results.\n\nLocal R²: Indicates how well the local model fits the observed values (ranges between 0.0 and 1.0). Mapping this can reveal where the model predicts well or poorly.\n\nPredicted Values: The estimated y values (fitted) by GWR.\n\nResiduals: Difference between observed and predicted values. Standardized residuals should have a mean of zero and a standard deviation of 1.\n\nCoefficient Standard Error: Measures the reliability of coefficient estimates. Smaller standard errors relative to coefficients indicate greater confidence in estimates.\n\nThese fields are stored in the SDF object from the GWR output, which is a SpatialPointsDataFrame or SpatialPolygonsDataFrame.\n\n10.4 Converting SDF to sf Data Frame\nWe first convert the SDF into an sf data frame for visualization:\n\ncondo_resale.sf.adaptive &lt;- st_as_sf(gwr.adaptive$SDF) %&gt;%\n  st_transform(crs = 3414)\n\ncondo_resale.sf.adaptive.svy21 &lt;- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.95        0   -0.72065801   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\ngwr.adaptive.output &lt;- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive &lt;- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\nWe can check the contents using glimpse and summary:\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       &lt;dbl&gt; 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              &lt;dbl&gt; 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   &lt;dbl&gt; -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              &lt;dbl&gt; -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        &lt;dbl&gt; 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      &lt;dbl&gt; -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  &lt;dbl&gt; -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              &lt;dbl&gt; -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             &lt;dbl&gt; -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      &lt;dbl&gt; 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    &lt;dbl&gt; 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         &lt;dbl&gt; 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           &lt;dbl&gt; 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       &lt;dbl&gt; -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              &lt;dbl&gt; 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               &lt;dbl&gt; 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               &lt;dbl&gt; 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\nsummary(gwr.adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901 \n\n\n\n10.5 Visualizing Local R2\nThe following code creates an interactive map showing local R2 values:\n\ntmap_mode(\"view\")\n\ntm_shape(mpsz_svy21) +\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\", border.col = \"gray60\", border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11, 14))\n\n\n\n\ntmap_mode(\"plot\")\n\n\n10.6 Visualizing Coefficient Estimates\nWe can visualize the standard errors and t-values of the AREA_SQM coefficient using the code below:\n\ntmap_mode(\"view\")\n\nAREA_SQM_SE &lt;- tm_shape(mpsz_svy21) +\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\", border.col = \"gray60\", border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11, 14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz_svy21) +\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\", border.col = \"gray60\", border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11, 14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, asp = 1, ncol = 2, sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\n10.6.1 By URA Planning Region\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N == \"CENTRAL REGION\", ]) +\n  tm_polygons() +\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\", size = 0.15, border.col = \"gray60\", border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/data/geospatial/hexagons.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/data/geospatial/hexagons.html",
    "title": "Walter Teng's Coursework for SMU ISSS626: Geospatial Analytics and Applications",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n                 0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#exercise-09a-reference",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#exercise-09a-reference",
    "title": "9A: Modelling Geographical Accessibility",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 17  Modelling Geographical Accessibility"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#aspatial-data-handling-and-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#aspatial-data-handling-and-wrangling",
    "title": "9A: Modelling Geographical Accessibility",
    "section": "\n7 Aspatial Data Handling and Wrangling",
    "text": "7 Aspatial Data Handling and Wrangling\n\n7.1 Importing Distance Matrix\nWe import the OD_Matrix.csv file using read_csv() from the readr package, which creates a tibble data frame called ODMatrix.\n\nODMatrix &lt;- read_csv(\"data/aspatial/OD_Matrix.csv\", skip = 0)\n\n\n7.2 Tidying the Distance Matrix\nThe imported ODMatrix organizes the distance matrix column-wise.\n\nhead(ODMatrix)\n\n# A tibble: 6 × 6\n  origin_id destination_id entry_cost network_cost exit_cost total_cost\n      &lt;dbl&gt;          &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1         1              1       668.       19847.      47.6     20562.\n2         1              2       668.       45027.      31.9     45727.\n3         1              3       668.       17644.     173.      18486.\n4         1              4       668.       36010.      92.2     36770.\n5         1              5       668.       31068.      64.6     31801.\n6         1              6       668.       31195.     117.      31980.\n\n\nHowever, most R modeling packages expect the matrix in a format where rows represent origins (from) and columns represent destinations (to).\nWe use pivot_wider() from the tidyr package to reshape the data from a long format to a wide format.\n\ndistmat &lt;- ODMatrix %&gt;%\n  select(origin_id, destination_id, total_cost) %&gt;%\n  pivot_wider(names_from = destination_id, values_from = total_cost) %&gt;%\n  select(-origin_id)\n\n\n7.3 Converting Distance to Kilometers\nSince the distances are in meters (due to the SVY21 projected coordinate system), we convert them to kilometers using the code below.\n\ndistmat_km &lt;- as.matrix(distmat/1000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#modelling-and-visualising-accessibility-using-hansen-method",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#modelling-and-visualising-accessibility-using-hansen-method",
    "title": "9A: Modelling Geographical Accessibility",
    "section": "\n8 Modelling and Visualising Accessibility using Hansen Method",
    "text": "8 Modelling and Visualising Accessibility using Hansen Method\n\n\n\n\n\n\nNote\n\n\n\nHansen Accessibility Model (1959) is based upon concept that the more accessible an area is to various activities and the more vacant land area has greater growth potential. It is a spatial analysis method used to measure accessibility by considering both the distance to and the capacity of services or facilities (e.g., eldercare centers). It calculates accessibility as a function of the proximity of a location to these facilities, weighted by their capacity, and decays with distance.\nFor more info: Hansen Accessibility Model - Front Desk Architects\n\n\n\n8.1 Computing Hansen’s Accessibility\nWe compute Hansen’s accessibility using the ac() function from the SpatialAcc package. The code below calculates accessibility, and the output is saved in a data frame called acc_Hansen.\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            power = 2, \n                            family = \"Hansen\"))\n\nhead(acc_Hansen)\n\n  ac.hexagons.demand..eldercare.capacity..distmat_km..power...2..\n1                                                    1.648313e-14\n2                                                    1.096143e-16\n3                                                    3.865857e-17\n4                                                    1.482856e-17\n5                                                    1.051348e-17\n6                                                    5.076391e-18\n\n\n\n8.2 Renaming Columns and Formatting Data\nThe default field names are messy, so we rename the output column to accHansen and convert the data to a tibble format.\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\nacc_Hansen &lt;- tbl_df(acc_Hansen)\n\nhead(acc_Hansen)\n\n# A tibble: 6 × 1\n  accHansen\n      &lt;dbl&gt;\n1  1.65e-14\n2  1.10e-16\n3  3.87e-17\n4  1.48e-17\n5  1.05e-17\n6  5.08e-18\n\n\n\n8.3 Joining with Hexagons Data\nWe use bind_cols() from dplyr to join the accessibility data with the hexagons simple feature data frame. The output is saved as hexagon_Hansen.\n\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)\nclass(hexagon_Hansen)\n\n[1] \"sf\"         \"data.frame\"\n\n\nNote that hexagon_Hansen is a simple feature data frame and not a typical tibble data frame.\n\n8.4 Visualising Hansen’s Accessibility\n\n8.4.1 Extracting Map Extent\nFirst, we extract the extent of the hexagons data using st_bbox() from the sf package.\n\nmapex &lt;- st_bbox(hexagons)\n\n\n8.4.2 Creating the Map\nWe use tmap to visualize accessibility to eldercare centers with Hansen’s method. The map shows accessibility in Singapore with color-coded hexagons.\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_Hansen, bbox = mapex) + \n  tm_fill(col = \"accHansen\", n = 10, style = \"quantile\",\n          border.col = \"black\", border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: Hansen method\",\n            main.title.position = \"center\", main.title.size = 2,\n            legend.outside = FALSE, legend.height = 0.45, \n            legend.width = 3.0, legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"), frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n\n\n\n\n\n\n8.5 Statistical Graphic Visualization\nIn this section, we will compare the distribution of Hansen’s accessibility values by URA Planning Region.\n\n8.5.1 Comparing Hansen’s Accessibility by Region\nWe first add the planning region field to hexagon_Hansen by spatially joining it with the mpsz dataset.\n\nhexagon_Hansen &lt;- st_join(hexagon_Hansen, mpsz, join = st_intersects)\n\nThen, we use ggplot() to visualize the distribution of Hansen’s accessibility values by URA Planning Region, using a boxplot.\n\nggplot(data=hexagon_Hansen, \n       aes(y = log(accHansen), x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", fun.y=\"mean\", colour =\"red\", size=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations: The Central Region shows the highest and most consistent accessibility, while the West Region exhibits the most variation and lower overall accessibility. The East Region has many outliers, indicating some areas with very low accessibility compared to the rest. The North-East and North Regions show moderate variation, with the North Region exhibiting more negative extremes than the North-East."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#modelling-and-visualising-accessibility-using-kd2sfca-method",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#modelling-and-visualising-accessibility-using-kd2sfca-method",
    "title": "9A: Modelling Geographical Accessibility",
    "section": "\n9 Modelling and Visualising Accessibility using KD2SFCA Method",
    "text": "9 Modelling and Visualising Accessibility using KD2SFCA Method\n\n9.1 Computing Accessibility\nWe calculate accessibility using the KD2SFCA method with the ac() function from SpatialAcc. data.frame() is used to save the output in a data frame called acc_KD2SFCA.\nNote that KD2SFCA is used for family argument.\n\nacc_KD2SFCA &lt;- data.frame(ac(hexagons$demand, eldercare$capacity, distmat_km, d0 = 50, power = 2, family = \"KD2SFCA\"))\ncolnames(acc_KD2SFCA) &lt;- \"accKD2SFCA\"\nacc_KD2SFCA &lt;- tibble::as_tibble(acc_KD2SFCA)\nhexagon_KD2SFCA &lt;- bind_cols(hexagons, acc_KD2SFCA)\n\n\n9.2 Visualizing KD2SFCA Accessibility\nWe create a map showing accessibility using the KD2SFCA method.\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_KD2SFCA, bbox = mapex) + \n  tm_fill(col = \"accKD2SFCA\", n = 10, style = \"quantile\", border.col = \"black\", border.lwd = 1) +\n  tm_shape(eldercare) + tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to Eldercare: KD2SFCA Method\", main.title.position = \"center\", main.title.size = 2)\n\n\n\n\n\n\n\n\n9.3 Statistical Graphic Visualisation\nNow, we will compare the distribution of KD2CFA accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into hexagon_KD2SFCA simple feature data frame by using the code below.\n\nhexagon_KD2SFCA &lt;- st_join(hexagon_KD2SFCA, mpsz, \n                          join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method.\n\nggplot(data=hexagon_KD2SFCA, \n       aes(y = accKD2SFCA, \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nThe Central Region stands out with significantly higher accessibility to services compared to other regions.\nMost regions have lower accessibility, with minimal differences between the East, North-East, North, and West Regions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#modelling-and-visualising-accessibility-using-spatial-accessibility-measure-sam-method",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09a.html#modelling-and-visualising-accessibility-using-spatial-accessibility-measure-sam-method",
    "title": "9A: Modelling Geographical Accessibility",
    "section": "\n10 Modelling and Visualising Accessibility using Spatial Accessibility Measure (SAM) Method",
    "text": "10 Modelling and Visualising Accessibility using Spatial Accessibility Measure (SAM) Method\n\n10.1 Computing Accessibility\nWe repeat the steps for the SAM method, using ac().\n\nacc_SAM &lt;- data.frame(ac(hexagons$demand, eldercare$capacity, distmat_km, d0 = 50, power = 2, family = \"SAM\"))\ncolnames(acc_SAM) &lt;- \"accSAM\"\nacc_SAM &lt;- tbl_df(acc_SAM)\nhexagon_SAM &lt;- bind_cols(hexagons, acc_SAM)\n\n\n10.2 Visualizing SAM Accessibility\nWe create a map to visualize SAM accessibility.\n\ntm_shape(hexagon_SAM, bbox = mapex) + \n  tm_fill(col = \"accSAM\", n = 10, style = \"quantile\", border.col = \"black\", border.lwd = 1) +\n  tm_shape(eldercare) + tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to Eldercare: SAM Method\", main.title.position = \"center\", main.title.size = 2)\n\n\n\n\n\n\n\n\n10.3 Comparing SAM Accessibility by Region\nWe add the planning region field to hexagon_SAM and visualize accessibility values using boxplots.\n\nhexagon_SAM &lt;- st_join(hexagon_SAM, mpsz, join = st_intersects)\n\nggplot(data=hexagon_SAM, \n       aes(y = accSAM, x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", fun.y=\"mean\", colour =\"red\", size=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nA relatively large number of smaller outliers indicate some areas within the Central Region have much higher accessibility than most others.\n\n\n\n\n\n\n\n\nNote\n\n\n\nOverall Observations comparing the three methods:\n\nAcross all three methods—Hansen, KD2SFCA, and SAM—the Central Region consistently had the highest accessibility values.\nThe Hansen method revealed a broader range of accessibility across the Central Region, while KD2SFCA and SAM produced similar results with fewer outliers and a more concentrated range of values."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/data/geospatial/ELDERCARE.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/data/geospatial/ELDERCARE.html",
    "title": "Walter Teng's Coursework for SMU ISSS626: Geospatial Analytics and Applications",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;  ELDERCARE  ENG dataset\n\nELDERCARE\n\n                 0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/data/geospatial/MPSZ-2019.html",
    "title": "Walter Teng's Coursework for SMU ISSS626: Geospatial Analytics and Applications",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html",
    "title": "10B: Calibrating Spatial Interaction Models with R",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 16  Calibrating Spatial Interaction Models with R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#exercise-10b-reference",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#exercise-10b-reference",
    "title": "10B: Calibrating Spatial Interaction Models with R",
    "section": "",
    "text": "R for Geospatial Data Science and Analytics - 16  Calibrating Spatial Interaction Models with R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#overview",
    "title": "10B: Calibrating Spatial Interaction Models with R",
    "section": "\n2 Overview",
    "text": "2 Overview\nIn this exercise, we will learn to calibrate Spatial Interaction Models (SIMs) using various regression methods to determine factors affecting public bus passenger flows during the morning peak in Singapore.\nSpatial Interaction Models (SIMs) are mathematical models for estimating flows between spatial entities developed by Alan Wilson in the late 1960s and early 1970, with considerable uptake and refinement for transport modelling since then Boyce and Williams (2015).\nThere are four main types of traditional SIMs (Wilson 1971):\n\nUnconstrained\nProduction-constrained\nAttraction-constrained\nDoubly-constrained\n\nOrdinary least square (OLS), log-normal, Poisson and negative binomial (NB) regression methods have been used extensively to calibrate OD flow models by processing flow data as different types of dependent variables. In this chapter, you will gain hands-on experiences on using appropriate R packages to calibrate SIM by using there four regression methods.\n\n\n\n\n\n\nNote\n\n\n\nCalibration is the process of adjusting parameters in the model to try and get the estimates to agree with the observed data as much as possible. Adjusting the parameters is the sort of iterative process that computers are particularly good at and the goodness-of-fit statistics can be used to indicate when the optimum solution is found. Historically this process required a researcher with the requisite programming skills to write a computer algorithm to iteratively adjust each parameter, check the goodness-of-fit, and then start all over again until the goodness-of-fit statistic was maximised/minimised. (Adam Dennett, 2018)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#learning-outcome",
    "title": "10B: Calibrating Spatial Interaction Models with R",
    "section": "\n3 Learning Outcome",
    "text": "3 Learning Outcome\n\nUnderstand and apply different types of Spatial Interaction Models (SIMs).\nCalibrate SIMs using Ordinary Least Squares (OLS), log-normal, Poisson, and Negative Binomial (NB) regression methods.\nImport and prepare geospatial data using R packages such as sf and tidyverse.\nCompute a distance matrix for spatial data using the sp package.\nVisualize and compare model performance using ggplot2 and performance packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#the-data",
    "title": "10B: Calibrating Spatial Interaction Models with R",
    "section": "\n4 The Data",
    "text": "4 The Data\nThis exercise is a continuation of Hands-on Exercise 10A and the following datasets will be used in this exercise:\n\n\n\n\n\n\n\nData Set\nDescription\nFormat\n\n\n\nod_data.rds\nWeekday morning peak passenger flows at the planning subzone level.\nRDS\n\n\nmpsz.rds\nURA Master Plan 2019 Planning Subzone boundary in simple feature tibble data frame format.\nRDS\n\n\npop.csv\nAdditional attribute data file providing population information.\nCSV\n\n\n\nThese datasets will be utilized to calibrate and visualize the Spatial Interaction Models.\n\nThis exercise is a continuation from Hands-on Exercise 9A."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#installing-and-launching-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#installing-and-launching-the-r-packages",
    "title": "10B: Calibrating Spatial Interaction Models with R",
    "section": "\n5 Installing and Launching the R Packages",
    "text": "5 Installing and Launching the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\nsf\nImports, integrates, processes, and transforms vector-based geospatial data.\nHandling vector geospatial data, such as the URA Master Plan 2019 Planning Subzone boundary.\n\n\ntidyverse\nA collection of packages for data science tasks such as data manipulation, visualization, and modeling.\nImporting CSV files, wrangling data, and performing relational joins.\n\n\ntmap\nCreates static and interactive thematic maps using cartographic quality elements.\nVisualizing regional development indicators and plotting maps showing spatial relationships and patterns.\n\n\nperformance\nProvides tools to assess and compare the performance of regression models.\nComparing model performance metrics, such as R-squared and RMSE, for different spatial interaction models.\n\n\nsp\nProvides functions for spatial dependence analysis, including spatial weights and spatial autocorrelation.\nComputing spatial weights and distance matrices for geospatial data.\n\n\nggplot2\nCreates data visualizations using a layered grammar of graphics.\nPlotting histograms, scatter plots, and visualizing model fits and residuals for calibrated Spatial Interaction Models.\n\n\nreshape2\nProvides functions to reshape data between wide and long formats.\nPivoting distance matrices into long format for model calibration and analysis.\n\n\nggpubr\nProvides tools for creating and customizing publication-ready plots in ggplot2.\nCombining multiple plots into a single visual for comparing different models.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(tmap, sf, sp, performance, reshape2, ggpubr, tidyverse)\n\n\n5.1 Computing Distance Matrix\nIn spatial interaction, a distance matrix displays the distance between pairs of locations. For example, the Euclidean distance between two locations like MESZ01 and RVSZ05 is 3926.0025, and between MESZ01 and SRSZ01 is 3939.1079. An entry of 0 on the diagonal indicates that the location is compared with itself.\nFirst, import mpsz.rds into R:\n\nmpsz &lt;- read_rds(\"data/rds/mpsz.rds\")\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\nNote that it is a sf tibble dataframe object class.\n\n5.2 Converting from sf data.table to SpatialPolygonsDataFrame\nThere are at least two ways to compute the required distance matrix. One is based on sf and the other is based on sp. Past experience shown that computing distance matrix by using sf function took relatively longer time that sp method especially the data set is large. In view of this, sp method is used in the code chunks below.\nFirst as.Spatial() will be used to convert mpsz from sf tibble data frame to SpatialPolygonsDataFrame of sp object as shown in the code chunk below.\n\nmpsz_sp &lt;- as(mpsz, \"Spatial\")\nmpsz_sp\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 332 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 6\nnames       : SUBZONE_N, SUBZONE_C, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C \nmin values  : ADMIRALTY,    AMSZ01, ANG MO KIO,         AM, CENTRAL REGION,       CR \nmax values  :    YUNNAN,    YSSZ09,     YISHUN,         YS,    WEST REGION,       WR \n\n\n\n5.3 Computing the Distance Matrix\nNow, we compute the Euclidean distance between centroids of planning subzones using spDists() from the sp package.\n\n\n\n\n\n\nQ&A\n\n\n\nDo you know why the distance is calculated between two centroids of a pair of spatial polygons?\nCentroids simplify distance calculations by representing each polygon with a single point, avoiding the complexity of measuring distances between all boundary points of irregular shapes\n\n\n\ndist &lt;- spDists(mpsz_sp, longlat = FALSE)\n\nhead(dist, n = c(10, 10))\n\n           [,1]       [,2]      [,3]      [,4]       [,5]      [,6]      [,7]\n [1,]     0.000  3926.0025  3939.108 20252.964  2989.9839  1431.330 19211.836\n [2,]  3926.003     0.0000   305.737 16513.865   951.8314  5254.066 16242.523\n [3,]  3939.108   305.7370     0.000 16412.062  1045.9088  5299.849 16026.146\n [4,] 20252.964 16513.8648 16412.062     0.000 17450.3044 21665.795  7229.017\n [5,]  2989.984   951.8314  1045.909 17450.304     0.0000  4303.232 17020.916\n [6,]  1431.330  5254.0664  5299.849 21665.795  4303.2323     0.000 20617.082\n [7,] 19211.836 16242.5230 16026.146  7229.017 17020.9161 20617.082     0.000\n [8,] 14960.942 12749.4101 12477.871 11284.279 13336.0421 16281.453  5606.082\n [9,]  7515.256  7934.8082  7649.776 18427.503  7801.6163  8403.896 14810.930\n[10,]  6391.342  4975.0021  4669.295 15469.566  5226.8731  7707.091 13111.391\n           [,8]      [,9]     [,10]\n [1,] 14960.942  7515.256  6391.342\n [2,] 12749.410  7934.808  4975.002\n [3,] 12477.871  7649.776  4669.295\n [4,] 11284.279 18427.503 15469.566\n [5,] 13336.042  7801.616  5226.873\n [6,] 16281.453  8403.896  7707.091\n [7,]  5606.082 14810.930 13111.391\n [8,]     0.000  9472.024  8575.490\n [9,]  9472.024     0.000  3780.800\n[10,]  8575.490  3780.800     0.000\n\n\nThe output dist is a matrix without labeled rows and columns for the planning subzone codes.\n\n5.4 Labeling the Distance Matrix\nWe will label the rows and columns of the distance matrix using the planning subzone codes.\n\nsz_names &lt;- mpsz$SUBZONE_C\ncolnames(dist) &lt;- sz_names\nrownames(dist) &lt;- sz_names\n\n\n5.5 Pivoting the Distance Matrix\nNext, we pivot the distance matrix into a long format, where rows represent the origin and destination pairs.\n\ndistPair &lt;- melt(dist) %&gt;%\n  rename(dist = value)\nhead(distPair, 10)\n\n     Var1   Var2      dist\n1  MESZ01 MESZ01     0.000\n2  RVSZ05 MESZ01  3926.003\n3  SRSZ01 MESZ01  3939.108\n4  WISZ01 MESZ01 20252.964\n5  MUSZ02 MESZ01  2989.984\n6  MPSZ05 MESZ01  1431.330\n7  WISZ03 MESZ01 19211.836\n8  WISZ02 MESZ01 14960.942\n9  SISZ02 MESZ01  7515.256\n10 SISZ01 MESZ01  6391.342\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe within zone distance is 0.\n\n\n\n5.6 Updating Intra-Zonal Distances\nIn this section, we are going to append a constant value to replace the intra-zonal distance of 0.\nWe will select and find out the minimum value of the distance by using summary().\n\ndistPair %&gt;%\n  filter(dist &gt; 0) %&gt;%\n  summary()\n\n      Var1             Var2             dist        \n MESZ01 :   331   MESZ01 :   331   Min.   :  173.8  \n RVSZ05 :   331   RVSZ05 :   331   1st Qu.: 7149.5  \n SRSZ01 :   331   SRSZ01 :   331   Median :11890.0  \n WISZ01 :   331   WISZ01 :   331   Mean   :12229.4  \n MUSZ02 :   331   MUSZ02 :   331   3rd Qu.:16401.7  \n MPSZ05 :   331   MPSZ05 :   331   Max.   :49894.4  \n (Other):107906   (Other):107906                    \n\n\nThen, we replace intra-zonal distances (which are 0) with a constant value of 50m.\n\ndistPair$dist &lt;- ifelse(distPair$dist == 0, 50, distPair$dist)\ndistPair %&gt;%\n  summary()\n\n      Var1             Var2             dist      \n MESZ01 :   332   MESZ01 :   332   Min.   :   50  \n RVSZ05 :   332   RVSZ05 :   332   1st Qu.: 7097  \n SRSZ01 :   332   SRSZ01 :   332   Median :11864  \n WISZ01 :   332   WISZ01 :   332   Mean   :12193  \n MUSZ02 :   332   MUSZ02 :   332   3rd Qu.:16388  \n MPSZ05 :   332   MPSZ05 :   332   Max.   :49894  \n (Other):108232   (Other):108232                  \n\n\n\n5.7 Renaming Fields and Saving\nNext, qe rename the origin and destination fields for clarity.\n\ndistPair &lt;- distPair %&gt;%\n  rename(orig = Var1, dest = Var2)\n\nFinally, save the updated distance pair dataframe for future use.\n\nwrite_rds(distPair, \"data/rds/distPair.rds\")\ndistPair &lt;- read_rds(\"data/rds/distPair.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#preparing-flow-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#preparing-flow-data",
    "title": "10B: Calibrating Spatial Interaction Models with R",
    "section": "\n6 Preparing Flow Data",
    "text": "6 Preparing Flow Data\nFirst, we import the od_data from Hands-on Exercise 9A.\n\nod_data_fii &lt;- read_rds(\"data/rds/od_data_fii.rds\")\n\n\n6.1 Computing Total Passenger Trips\nNext, compute the total passenger trips between and within planning subzones.\n\nflow_data &lt;- od_data_fii %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarize(TRIPS = sum(MORNING_PEAK))\n\nDisplay the first 10 rows of flow_data:\n\nhead(flow_data, 10)\n\n\n6.2 Separating Intra-Zonal Flows\nThe code below adds two fields to flow_data, separating intra-zonal trips.\n\nflow_data$FlowNoIntra &lt;- ifelse(flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 0, flow_data$TRIPS)\nflow_data$offset &lt;- ifelse(flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 0.000001, 1)\n\n\n6.3 Combining Passenger Volume and Distance Data\nBefore we can join flow_data and distPair, we need to convert data value type of ORIGIN_SZ and DESTIN_SZ fields of flow_data dataframe into factor data type.\n\nflow_data$ORIGIN_SZ &lt;- as.factor(flow_data$ORIGIN_SZ)\nflow_data$DESTIN_SZ &lt;- as.factor(flow_data$DESTIN_SZ)\n\nThen, we can perform left join on flow_data with distPair to combine passenger volumes with distances.\n\nflow_data1 &lt;- flow_data %&gt;%\n  left_join(distPair, by = c(\"ORIGIN_SZ\" = \"orig\", \"DESTIN_SZ\" = \"dest\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#preparing-origin-and-destination-attributes",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#preparing-origin-and-destination-attributes",
    "title": "10B: Calibrating Spatial Interaction Models with R",
    "section": "\n7 Preparing Origin and Destination Attributes",
    "text": "7 Preparing Origin and Destination Attributes\nIn this section, we will prepare the origin and destination attribute data.\n\n7.1 Importing Population Data\n\npop &lt;- read_csv(\"data/aspatial/pop.csv\")\n\n\n7.2 Geospatial Data Wrangling\nJoin the population data with mpsz.\n\npop &lt;- pop %&gt;%\n  left_join(mpsz, by = c(\"PA\" = \"PLN_AREA_N\", \"SZ\" = \"SUBZONE_N\")) %&gt;%\n  select(1:6) %&gt;%\n  rename(SZ_NAME = SZ, SZ = SUBZONE_C)\n\n\n7.3 Adding Origin Attributes\nJoin population data with flow_data1 for origin attributes.\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop, by = c(ORIGIN_SZ = \"SZ\")) %&gt;%\n  rename(ORIGIN_AGE7_12 = AGE7_12, ORIGIN_AGE13_24 = AGE13_24, ORIGIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))\n\n\n7.4 Adding Destination Attributes\nJoin population data with flow_data1 for destination attributes.\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop, by = c(DESTIN_SZ = \"SZ\")) %&gt;%\n  rename(DESTIN_AGE7_12 = AGE7_12, DESTIN_AGE13_24 = AGE13_24, DESTIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))\n\n\n7.5 Saving Processed Data\nThe final output will be saved as SIM_data in RDS format.\n\nwrite_rds(flow_data1, \"data/rds/flow_data_6-9.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#calibrating-spatial-interaction-models",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10b.html#calibrating-spatial-interaction-models",
    "title": "10B: Calibrating Spatial Interaction Models with R",
    "section": "\n8 Calibrating Spatial Interaction Models",
    "text": "8 Calibrating Spatial Interaction Models\nIn this section, you will learn how to calibrate Spatial Interaction Models by using Poisson Regression method.\n\n8.1 Importing the Modelling Data\nFirstly, we will import the saved modelling data.\n\nSIM_data &lt;- read_rds(\"data/rds/flow_data_6-9.rds\")\n\n\n8.2 Visualizing the Dependent Variable\nTo visualize the dependent variable, we will plot the distribution of TRIPS using a histogram.\n\nggplot(data = SIM_data, aes(x = TRIPS)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nNotice that the distribution is highly skewed and not resemble bell shape or also known as normal distribution.\n\n\nWe can also visualize the relationship between TRIPS and distance using a scatter plot.\n\nggplot(data = SIM_data, aes(x = dist, y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nthe relationship between TRIPS and distance hardly resemble a linear relationship.\n\n\nWe can perform log-transformation on both variables to make he relationship appears more linear.\n\nggplot(data = SIM_data, aes(x = log(dist), y = log(TRIPS))) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n\n\n8.3 Handling Zero Values in Variables\nSince Poisson Regression is based of log and log 0 is undefined, it is important for us to ensure that no 0 values in the explanatory variables.\nWe will compute the summary statistics of all variables in SIM_data data frame.\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS         FlowNoIntra      \n Length:20916       Length:20916       Min.   :     1   Min.   :     0.0  \n Class :character   Class :character   1st Qu.:    17   1st Qu.:    15.0  \n Mode  :character   Mode  :character   Median :    87   Median :    81.0  \n                                       Mean   :  1178   Mean   :   980.1  \n                                       3rd Qu.:   454   3rd Qu.:   417.0  \n                                       Max.   :344039   Max.   :218070.0  \n     offset              dist       ORIGIN_AGE7_12   ORIGIN_AGE13_24\n Min.   :0.000001   Min.   :   50   Min.   :   0.0   Min.   :    0  \n 1st Qu.:1.000000   1st Qu.: 3373   1st Qu.:  50.0   1st Qu.:  100  \n Median :1.000000   Median : 6172   Median : 510.0   Median : 1130  \n Mean   :0.986087   Mean   : 6992   Mean   : 888.6   Mean   : 1954  \n 3rd Qu.:1.000000   3rd Qu.: 9918   3rd Qu.:1360.0   3rd Qu.: 3010  \n Max.   :1.000000   Max.   :26136   Max.   :6340.0   Max.   :16380  \n ORIGIN_AGE25_64 DESTIN_AGE7_12   DESTIN_AGE13_24 DESTIN_AGE25_64\n Min.   :    0   Min.   :   0.0   Min.   :    0   Min.   :    0  \n 1st Qu.:  730   1st Qu.:  10.0   1st Qu.:   60   1st Qu.:  630  \n Median : 5730   Median : 510.0   Median : 1100   Median : 5710  \n Mean   : 9092   Mean   : 854.6   Mean   : 1896   Mean   : 8829  \n 3rd Qu.:14180   3rd Qu.:1350.0   3rd Qu.: 2920   3rd Qu.:13830  \n Max.   :74610   Max.   :6340.0   Max.   :16380   Max.   :74610  \n\n\nThe print report above reveals that variables ORIGIN_AGE7_12, ORIGIN_AGE13_24, ORIGIN_AGE25_64,DESTIN_AGE7_12, DESTIN_AGE13_24, DESTIN_AGE25_64 consist of 0 values.\n\nSIM_data$DESTIN_AGE7_12 &lt;- ifelse(SIM_data$DESTIN_AGE7_12 == 0, 0.99, SIM_data$DESTIN_AGE7_12)\nSIM_data$DESTIN_AGE13_24 &lt;- ifelse(SIM_data$DESTIN_AGE13_24 == 0, 0.99, SIM_data$DESTIN_AGE13_24)\nSIM_data$DESTIN_AGE25_64 &lt;- ifelse(SIM_data$DESTIN_AGE25_64 == 0, 0.99, SIM_data$DESTIN_AGE25_64)\nSIM_data$ORIGIN_AGE7_12 &lt;- ifelse(SIM_data$ORIGIN_AGE7_12 == 0, 0.99, SIM_data$ORIGIN_AGE7_12)\nSIM_data$ORIGIN_AGE13_24 &lt;- ifelse(SIM_data$ORIGIN_AGE13_24 == 0, 0.99, SIM_data$ORIGIN_AGE13_24)\nSIM_data$ORIGIN_AGE25_64 &lt;- ifelse(SIM_data$ORIGIN_AGE25_64 == 0, 0.99, SIM_data$ORIGIN_AGE25_64)\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS         FlowNoIntra      \n Length:20916       Length:20916       Min.   :     1   Min.   :     0.0  \n Class :character   Class :character   1st Qu.:    17   1st Qu.:    15.0  \n Mode  :character   Mode  :character   Median :    87   Median :    81.0  \n                                       Mean   :  1178   Mean   :   980.1  \n                                       3rd Qu.:   454   3rd Qu.:   417.0  \n                                       Max.   :344039   Max.   :218070.0  \n     offset              dist       ORIGIN_AGE7_12    ORIGIN_AGE13_24   \n Min.   :0.000001   Min.   :   50   Min.   :   0.99   Min.   :    0.99  \n 1st Qu.:1.000000   1st Qu.: 3373   1st Qu.:  50.00   1st Qu.:  100.00  \n Median :1.000000   Median : 6172   Median : 510.00   Median : 1130.00  \n Mean   :0.986087   Mean   : 6992   Mean   : 888.77   Mean   : 1954.26  \n 3rd Qu.:1.000000   3rd Qu.: 9918   3rd Qu.:1360.00   3rd Qu.: 3010.00  \n Max.   :1.000000   Max.   :26136   Max.   :6340.00   Max.   :16380.00  \n ORIGIN_AGE25_64    DESTIN_AGE7_12    DESTIN_AGE13_24    DESTIN_AGE25_64   \n Min.   :    0.99   Min.   :   0.99   Min.   :    0.99   Min.   :    0.99  \n 1st Qu.:  730.00   1st Qu.:  10.00   1st Qu.:   60.00   1st Qu.:  630.00  \n Median : 5730.00   Median : 510.00   Median : 1100.00   Median : 5710.00  \n Mean   : 9092.13   Mean   : 854.82   Mean   : 1896.17   Mean   : 8829.27  \n 3rd Qu.:14180.00   3rd Qu.:1350.00   3rd Qu.: 2920.00   3rd Qu.:13830.00  \n Max.   :74610.00   Max.   :6340.00   Max.   :16380.00   Max.   :74610.00  \n\n\nAll the 0 values have been replaced by 0.99.\n\n8.4 Unconstrained Spatial Interaction Model\nIn this section, we will calibrate an unconstrained spatial interaction model by using glm() of Base Stats.\n\n\n\n\n\n\nNote\n\n\n\nThe general formula of Unconstrained Spatial Interaction Model\n\\(\\lambda_{ij} = \\exp \\left( k + \\mu \\ln V_i + \\alpha \\ln W_j - \\beta \\ln d_{ij} \\right)\\)\n\n\nThe explanatory variables are origin population by different age cohort, destination population by different age cohort (i.e. ORIGIN_AGE25_64) and distance between origin and destination in km (i.e. dist). To fit an unconstrained Spatial Interaction Model using Poisson regression:\n\nuncSIM &lt;- glm(formula = TRIPS ~ log(ORIGIN_AGE25_64) + log(DESTIN_AGE25_64) + log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nuncSIM\n\n\nCall:  glm(formula = TRIPS ~ log(ORIGIN_AGE25_64) + log(DESTIN_AGE25_64) + \n    log(dist), family = poisson(link = \"log\"), data = SIM_data, \n    na.action = na.exclude)\n\nCoefficients:\n         (Intercept)  log(ORIGIN_AGE25_64)  log(DESTIN_AGE25_64)  \n            10.58389               0.26347               0.02567  \n           log(dist)  \n            -0.73018  \n\nDegrees of Freedom: 20915 Total (i.e. Null);  20912 Residual\nNull Deviance:      105500000 \nResidual Deviance: 62360000     AIC: 62490000\n\n\n\n8.5 Calculating R-squared for Unconstrained SIM\nIn order to measure how much variation of the trips can be accounted by the model, we will define a function to calculate R-squared and apply it to the model.\n\nCalcRSquared &lt;- function(observed, estimated){\n  r &lt;- cor(observed, estimated)\n  r^2\n}\n\nThen, we will calculate the R-squared of the unconstrained model.\n\nCalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)\n\n[1] 0.1938202\n\n\nAlternatively, we can calculate McFadden’s R-squared.\n\nr2_mcfadden(uncSIM)\n\n# R2 for Generalized Linear Regression\n       R2: 0.408\n  adj. R2: 0.408\n\n\n\n\n\n\n\n\nNote\n\n\n\nMcFadden’s R-squared\n\n\nInterpretation: McFadden’s R-squared is used for logistic regression models and measures the improvement of the fitted model over the null model. It is not directly comparable to the traditional R-squared.\n\nRange: McFadden’s R-squared values typically range from 0 to just under 1.\n\n\n0: The model is no better than the null model.\n\n1: The model perfectly predicts the outcome.\n\n\n\nGood Range:\n\n\n0.2 to 0.4: Considered good for logistic regression models.\n\nAbove 0.4: Indicates a very strong model.\n\n\n\n\n\n\n8.6 Origin (Production) Constrained SIM\nIn this section, we will fit an origin constrained SIM, where the trips are constrained by the origin.\n\n\n\n\n\n\nNote\n\n\n\nThe general formula of Origin Constrained Spatial Interaction Model\n\\(\\lambda_{ij} = \\exp\\left( k + \\mu_i + \\alpha \\ln W_j - \\beta \\ln d_{ij} \\right)\\)\nNotice that the difference between Unconstrained Spatial Interaction Model and this formula lies in the second term. In the Unconstrained Spatial Interaction Model formula, it is \\(\\mu \\ln V_i\\) as compared to \\(\\mu_i\\) in Origin Constrained Spatial Interaction Model.\n\n\n\norcSIM &lt;- glm(formula = TRIPS ~ ORIGIN_SZ + log(DESTIN_AGE25_64) + log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(orcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + log(DESTIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)           1.251e+01  3.144e-03  3977.962  &lt; 2e-16 ***\nORIGIN_SZAMSZ02       1.062e+00  3.687e-03   288.178  &lt; 2e-16 ***\nORIGIN_SZAMSZ03       6.217e-01  3.774e-03   164.747  &lt; 2e-16 ***\nORIGIN_SZAMSZ04      -2.100e-02  4.265e-03    -4.924 8.46e-07 ***\nORIGIN_SZAMSZ05      -1.778e-01  4.850e-03   -36.661  &lt; 2e-16 ***\nORIGIN_SZAMSZ06       3.340e-01  4.387e-03    76.126  &lt; 2e-16 ***\nORIGIN_SZAMSZ07      -1.141e+00  7.375e-03  -154.672  &lt; 2e-16 ***\nORIGIN_SZAMSZ08      -8.224e-01  6.804e-03  -120.871  &lt; 2e-16 ***\nORIGIN_SZAMSZ09       2.187e-01  4.538e-03    48.186  &lt; 2e-16 ***\nORIGIN_SZAMSZ10       5.139e-01  3.975e-03   129.304  &lt; 2e-16 ***\nORIGIN_SZAMSZ11      -1.476e+00  8.890e-03  -166.019  &lt; 2e-16 ***\nORIGIN_SZAMSZ12      -1.512e+00  8.974e-03  -168.491  &lt; 2e-16 ***\nORIGIN_SZBDSZ01       1.035e+00  3.647e-03   283.888  &lt; 2e-16 ***\nORIGIN_SZBDSZ02       5.114e-01  4.195e-03   121.896  &lt; 2e-16 ***\nORIGIN_SZBDSZ03       1.013e+00  3.733e-03   271.518  &lt; 2e-16 ***\nORIGIN_SZBDSZ04       1.738e+00  3.265e-03   532.437  &lt; 2e-16 ***\nORIGIN_SZBDSZ05       7.463e-01  3.713e-03   200.998  &lt; 2e-16 ***\nORIGIN_SZBDSZ06       9.612e-01  3.743e-03   256.801  &lt; 2e-16 ***\nORIGIN_SZBDSZ07      -9.204e-01  6.791e-03  -135.530  &lt; 2e-16 ***\nORIGIN_SZBDSZ08      -8.772e-01  6.694e-03  -131.044  &lt; 2e-16 ***\nORIGIN_SZBKSZ01      -2.932e-01  5.277e-03   -55.567  &lt; 2e-16 ***\nORIGIN_SZBKSZ02       4.668e-01  4.229e-03   110.382  &lt; 2e-16 ***\nORIGIN_SZBKSZ03       8.058e-01  3.924e-03   205.345  &lt; 2e-16 ***\nORIGIN_SZBKSZ04      -1.653e-03  4.828e-03    -0.342    0.732    \nORIGIN_SZBKSZ05       2.118e-02  4.537e-03     4.669 3.03e-06 ***\nORIGIN_SZBKSZ06       1.408e-01  4.826e-03    29.172  &lt; 2e-16 ***\nORIGIN_SZBKSZ07       8.012e-01  3.674e-03   218.081  &lt; 2e-16 ***\nORIGIN_SZBKSZ08       1.203e-01  4.328e-03    27.805  &lt; 2e-16 ***\nORIGIN_SZBKSZ09       8.939e-02  4.527e-03    19.745  &lt; 2e-16 ***\nORIGIN_SZBLSZ01      -1.359e+00  1.077e-02  -126.206  &lt; 2e-16 ***\nORIGIN_SZBLSZ02      -2.083e+00  1.559e-02  -133.643  &lt; 2e-16 ***\nORIGIN_SZBLSZ03      -3.206e+00  3.300e-02   -97.132  &lt; 2e-16 ***\nORIGIN_SZBLSZ04      -1.772e+00  1.577e-02  -112.360  &lt; 2e-16 ***\nORIGIN_SZBMSZ01       1.833e-01  3.973e-03    46.130  &lt; 2e-16 ***\nORIGIN_SZBMSZ02      -1.192e+00  5.701e-03  -209.042  &lt; 2e-16 ***\nORIGIN_SZBMSZ03      -3.159e-01  4.531e-03   -69.718  &lt; 2e-16 ***\nORIGIN_SZBMSZ04       2.399e-02  4.011e-03     5.980 2.23e-09 ***\nORIGIN_SZBMSZ05      -1.274e+00  6.120e-03  -208.104  &lt; 2e-16 ***\nORIGIN_SZBMSZ06      -1.756e+00  9.559e-03  -183.732  &lt; 2e-16 ***\nORIGIN_SZBMSZ07      -3.696e-01  4.489e-03   -82.352  &lt; 2e-16 ***\nORIGIN_SZBMSZ08      -4.495e-01  4.511e-03   -99.631  &lt; 2e-16 ***\nORIGIN_SZBMSZ09      -1.141e+00  5.807e-03  -196.571  &lt; 2e-16 ***\nORIGIN_SZBMSZ10      -1.193e+00  6.140e-03  -194.266  &lt; 2e-16 ***\nORIGIN_SZBMSZ11      -8.546e-01  5.373e-03  -159.060  &lt; 2e-16 ***\nORIGIN_SZBMSZ12      -1.026e+00  6.975e-03  -147.165  &lt; 2e-16 ***\nORIGIN_SZBMSZ13      -2.195e-02  4.435e-03    -4.948 7.50e-07 ***\nORIGIN_SZBMSZ14      -5.738e-01  5.292e-03  -108.430  &lt; 2e-16 ***\nORIGIN_SZBMSZ15      -3.203e-01  4.798e-03   -66.749  &lt; 2e-16 ***\nORIGIN_SZBMSZ16      -1.296e+00  6.081e-03  -213.135  &lt; 2e-16 ***\nORIGIN_SZBMSZ17      -1.756e+00  9.297e-03  -188.888  &lt; 2e-16 ***\nORIGIN_SZBPSZ01       2.254e-01  4.507e-03    50.006  &lt; 2e-16 ***\nORIGIN_SZBPSZ02       2.384e-01  4.944e-03    48.214  &lt; 2e-16 ***\nORIGIN_SZBPSZ03       5.272e-01  4.549e-03   115.887  &lt; 2e-16 ***\nORIGIN_SZBPSZ04       5.440e-01  4.077e-03   133.420  &lt; 2e-16 ***\nORIGIN_SZBPSZ05       6.051e-01  3.781e-03   160.027  &lt; 2e-16 ***\nORIGIN_SZBPSZ06      -9.856e-01  6.582e-03  -149.746  &lt; 2e-16 ***\nORIGIN_SZBPSZ07      -8.273e-01  6.535e-03  -126.592  &lt; 2e-16 ***\nORIGIN_SZBSSZ01       2.322e-03  4.357e-03     0.533    0.594    \nORIGIN_SZBSSZ02       4.265e-01  3.924e-03   108.702  &lt; 2e-16 ***\nORIGIN_SZBSSZ03       3.176e-01  3.876e-03    81.942  &lt; 2e-16 ***\nORIGIN_SZBTSZ01       9.283e-02  4.241e-03    21.890  &lt; 2e-16 ***\nORIGIN_SZBTSZ02      -9.336e-01  6.055e-03  -154.184  &lt; 2e-16 ***\nORIGIN_SZBTSZ03      -8.606e-02  4.554e-03   -18.899  &lt; 2e-16 ***\nORIGIN_SZBTSZ04      -6.871e-01  7.481e-03   -91.845  &lt; 2e-16 ***\nORIGIN_SZBTSZ05      -1.472e+00  8.267e-03  -178.077  &lt; 2e-16 ***\nORIGIN_SZBTSZ06      -6.835e-01  5.683e-03  -120.257  &lt; 2e-16 ***\nORIGIN_SZBTSZ07      -1.856e+00  8.657e-03  -214.406  &lt; 2e-16 ***\nORIGIN_SZBTSZ08      -1.019e+00  6.701e-03  -152.085  &lt; 2e-16 ***\nORIGIN_SZCCSZ01      -1.594e+00  1.065e-02  -149.672  &lt; 2e-16 ***\nORIGIN_SZCHSZ01      -1.120e+00  9.221e-03  -121.456  &lt; 2e-16 ***\nORIGIN_SZCHSZ02      -6.325e-01  6.780e-03   -93.284  &lt; 2e-16 ***\nORIGIN_SZCHSZ03       6.495e-01  4.608e-03   140.937  &lt; 2e-16 ***\nORIGIN_SZCKSZ01       4.387e-01  4.047e-03   108.404  &lt; 2e-16 ***\nORIGIN_SZCKSZ02       9.345e-01  4.067e-03   229.779  &lt; 2e-16 ***\nORIGIN_SZCKSZ03       9.446e-01  3.708e-03   254.769  &lt; 2e-16 ***\nORIGIN_SZCKSZ04       1.385e+00  3.782e-03   366.289  &lt; 2e-16 ***\nORIGIN_SZCKSZ05       1.101e+00  4.378e-03   251.560  &lt; 2e-16 ***\nORIGIN_SZCKSZ06       1.306e+00  4.171e-03   312.991  &lt; 2e-16 ***\nORIGIN_SZCLSZ01      -3.752e-01  5.690e-03   -65.937  &lt; 2e-16 ***\nORIGIN_SZCLSZ02      -1.661e+00  1.055e-02  -157.475  &lt; 2e-16 ***\nORIGIN_SZCLSZ03      -3.461e-01  5.238e-03   -66.071  &lt; 2e-16 ***\nORIGIN_SZCLSZ04       8.445e-01  3.627e-03   232.834  &lt; 2e-16 ***\nORIGIN_SZCLSZ05      -1.645e+00  1.013e-02  -162.395  &lt; 2e-16 ***\nORIGIN_SZCLSZ06       9.372e-01  3.478e-03   269.509  &lt; 2e-16 ***\nORIGIN_SZCLSZ07      -1.060e-01  4.398e-03   -24.110  &lt; 2e-16 ***\nORIGIN_SZCLSZ08       3.363e-01  4.833e-03    69.592  &lt; 2e-16 ***\nORIGIN_SZCLSZ09      -1.714e+00  1.353e-02  -126.689  &lt; 2e-16 ***\nORIGIN_SZDTSZ01      -1.720e+00  7.004e-03  -245.518  &lt; 2e-16 ***\nORIGIN_SZDTSZ02      -1.539e+00  6.422e-03  -239.640  &lt; 2e-16 ***\nORIGIN_SZDTSZ03      -2.810e+00  1.301e-02  -215.941  &lt; 2e-16 ***\nORIGIN_SZDTSZ04      -3.750e+00  9.290e-02   -40.363  &lt; 2e-16 ***\nORIGIN_SZDTSZ05      -3.057e+00  2.143e-02  -142.634  &lt; 2e-16 ***\nORIGIN_SZDTSZ06      -2.975e+00  1.737e-02  -171.216  &lt; 2e-16 ***\nORIGIN_SZDTSZ07      -1.877e+00  1.905e-02   -98.511  &lt; 2e-16 ***\nORIGIN_SZDTSZ08      -2.324e+00  9.698e-03  -239.632  &lt; 2e-16 ***\nORIGIN_SZDTSZ09      -3.034e+00  2.054e-02  -147.746  &lt; 2e-16 ***\nORIGIN_SZDTSZ10      -2.158e+00  1.036e-02  -208.287  &lt; 2e-16 ***\nORIGIN_SZDTSZ11      -2.329e+00  1.070e-02  -217.712  &lt; 2e-16 ***\nORIGIN_SZDTSZ12      -3.593e+00  2.551e-02  -140.861  &lt; 2e-16 ***\nORIGIN_SZDTSZ13      -2.397e+00  1.212e-02  -197.773  &lt; 2e-16 ***\nORIGIN_SZGLSZ01      -1.317e+00  7.123e-03  -184.848  &lt; 2e-16 ***\nORIGIN_SZGLSZ02       2.116e-01  4.067e-03    52.013  &lt; 2e-16 ***\nORIGIN_SZGLSZ03       2.050e-01  4.059e-03    50.498  &lt; 2e-16 ***\nORIGIN_SZGLSZ04       9.827e-01  3.416e-03   287.645  &lt; 2e-16 ***\nORIGIN_SZGLSZ05       6.442e-01  3.624e-03   177.781  &lt; 2e-16 ***\nORIGIN_SZHGSZ01       2.595e-01  3.998e-03    64.896  &lt; 2e-16 ***\nORIGIN_SZHGSZ02       6.162e-01  3.842e-03   160.374  &lt; 2e-16 ***\nORIGIN_SZHGSZ03       2.897e-01  4.204e-03    68.905  &lt; 2e-16 ***\nORIGIN_SZHGSZ04       9.444e-01  3.590e-03   263.071  &lt; 2e-16 ***\nORIGIN_SZHGSZ05       1.265e+00  3.527e-03   358.688  &lt; 2e-16 ***\nORIGIN_SZHGSZ06       1.062e-01  4.281e-03    24.815  &lt; 2e-16 ***\nORIGIN_SZHGSZ07       7.740e-01  3.700e-03   209.178  &lt; 2e-16 ***\nORIGIN_SZHGSZ08       2.462e-01  4.275e-03    57.586  &lt; 2e-16 ***\nORIGIN_SZHGSZ09      -5.094e-01  5.808e-03   -87.708  &lt; 2e-16 ***\nORIGIN_SZHGSZ10      -2.665e+00  3.983e-02   -66.910  &lt; 2e-16 ***\nORIGIN_SZJESZ01       3.998e-01  4.103e-03    97.427  &lt; 2e-16 ***\nORIGIN_SZJESZ02       2.755e-01  4.118e-03    66.890  &lt; 2e-16 ***\nORIGIN_SZJESZ03       2.744e-01  4.341e-03    63.207  &lt; 2e-16 ***\nORIGIN_SZJESZ04      -9.169e-01  7.072e-03  -129.657  &lt; 2e-16 ***\nORIGIN_SZJESZ05      -1.967e+00  1.188e-02  -165.550  &lt; 2e-16 ***\nORIGIN_SZJESZ06       3.359e-01  4.037e-03    83.202  &lt; 2e-16 ***\nORIGIN_SZJESZ07      -1.738e+00  9.337e-03  -186.144  &lt; 2e-16 ***\nORIGIN_SZJESZ08      -5.989e-01  8.299e-03   -72.169  &lt; 2e-16 ***\nORIGIN_SZJESZ09       4.456e-01  4.208e-03   105.910  &lt; 2e-16 ***\nORIGIN_SZJESZ10      -1.968e+00  1.632e-02  -120.552  &lt; 2e-16 ***\nORIGIN_SZJESZ11      -2.124e+00  1.681e-02  -126.318  &lt; 2e-16 ***\nORIGIN_SZJWSZ01       2.286e-01  5.369e-03    42.578  &lt; 2e-16 ***\nORIGIN_SZJWSZ02       8.915e-01  3.789e-03   235.292  &lt; 2e-16 ***\nORIGIN_SZJWSZ03       1.293e+00  3.515e-03   367.960  &lt; 2e-16 ***\nORIGIN_SZJWSZ04       1.351e+00  3.578e-03   377.520  &lt; 2e-16 ***\nORIGIN_SZJWSZ05      -1.267e+00  1.009e-02  -125.555  &lt; 2e-16 ***\nORIGIN_SZJWSZ06      -1.005e+00  8.836e-03  -113.734  &lt; 2e-16 ***\nORIGIN_SZJWSZ07      -2.587e+00  2.233e-02  -115.857  &lt; 2e-16 ***\nORIGIN_SZJWSZ08       1.978e+00  3.429e-03   576.877  &lt; 2e-16 ***\nORIGIN_SZJWSZ09       1.944e+00  3.247e-03   598.514  &lt; 2e-16 ***\nORIGIN_SZKLSZ01       1.947e-01  3.918e-03    49.689  &lt; 2e-16 ***\nORIGIN_SZKLSZ02      -4.677e-01  4.893e-03   -95.577  &lt; 2e-16 ***\nORIGIN_SZKLSZ03      -4.055e-01  4.886e-03   -82.983  &lt; 2e-16 ***\nORIGIN_SZKLSZ04      -1.639e+00  6.977e-03  -234.885  &lt; 2e-16 ***\nORIGIN_SZKLSZ05      -8.975e-01  6.538e-03  -137.284  &lt; 2e-16 ***\nORIGIN_SZKLSZ06      -5.593e-01  4.587e-03  -121.911  &lt; 2e-16 ***\nORIGIN_SZKLSZ07      -9.375e-01  6.042e-03  -155.160  &lt; 2e-16 ***\nORIGIN_SZKLSZ08      -8.039e-01  5.230e-03  -153.703  &lt; 2e-16 ***\nORIGIN_SZKLSZ09      -1.545e+00  6.681e-03  -231.271  &lt; 2e-16 ***\nORIGIN_SZLKSZ01      -2.964e+00  2.862e-02  -103.566  &lt; 2e-16 ***\nORIGIN_SZMDSZ01      -2.428e+00  2.166e-02  -112.061  &lt; 2e-16 ***\nORIGIN_SZMDSZ02      -1.119e+00  9.861e-03  -113.450  &lt; 2e-16 ***\nORIGIN_SZMDSZ03      -1.830e+00  1.316e-02  -138.979  &lt; 2e-16 ***\nORIGIN_SZMPSZ01      -9.639e-01  6.419e-03  -150.164  &lt; 2e-16 ***\nORIGIN_SZMPSZ02      -4.675e-01  5.349e-03   -87.390  &lt; 2e-16 ***\nORIGIN_SZMPSZ03       1.260e-01  4.248e-03    29.670  &lt; 2e-16 ***\nORIGIN_SZMSSZ01      -7.329e+00  2.673e-01   -27.422  &lt; 2e-16 ***\nORIGIN_SZMUSZ01      -1.240e+00  5.753e-03  -215.628  &lt; 2e-16 ***\nORIGIN_SZMUSZ02      -3.100e+00  1.434e-02  -216.222  &lt; 2e-16 ***\nORIGIN_SZMUSZ03      -1.786e+00  6.783e-03  -263.255  &lt; 2e-16 ***\nORIGIN_SZNTSZ01      -2.286e+00  2.415e-02   -94.639  &lt; 2e-16 ***\nORIGIN_SZNTSZ02      -2.401e+00  1.230e-02  -195.268  &lt; 2e-16 ***\nORIGIN_SZNTSZ03      -7.543e-01  5.755e-03  -131.074  &lt; 2e-16 ***\nORIGIN_SZNTSZ05      -3.114e+00  3.721e-02   -83.706  &lt; 2e-16 ***\nORIGIN_SZNTSZ06      -3.415e+00  4.002e-02   -85.338  &lt; 2e-16 ***\nORIGIN_SZNVSZ01       6.885e-01  3.551e-03   193.889  &lt; 2e-16 ***\nORIGIN_SZNVSZ02      -4.131e-01  4.796e-03   -86.147  &lt; 2e-16 ***\nORIGIN_SZNVSZ03      -1.054e+00  5.897e-03  -178.743  &lt; 2e-16 ***\nORIGIN_SZNVSZ04      -1.291e+00  7.055e-03  -182.959  &lt; 2e-16 ***\nORIGIN_SZNVSZ05      -2.522e+00  1.287e-02  -195.929  &lt; 2e-16 ***\nORIGIN_SZORSZ01      -2.858e+00  2.619e-02  -109.108  &lt; 2e-16 ***\nORIGIN_SZORSZ02      -1.160e+00  5.665e-03  -204.808  &lt; 2e-16 ***\nORIGIN_SZORSZ03      -1.632e+00  6.782e-03  -240.706  &lt; 2e-16 ***\nORIGIN_SZOTSZ01      -1.691e+00  7.205e-03  -234.655  &lt; 2e-16 ***\nORIGIN_SZOTSZ02      -1.755e+00  8.076e-03  -217.286  &lt; 2e-16 ***\nORIGIN_SZOTSZ03      -7.979e-01  5.279e-03  -151.147  &lt; 2e-16 ***\nORIGIN_SZOTSZ04      -7.263e-01  8.350e-03   -86.984  &lt; 2e-16 ***\nORIGIN_SZPGSZ01      -6.693e-01  9.124e-03   -73.359  &lt; 2e-16 ***\nORIGIN_SZPGSZ02      -3.145e-01  5.659e-03   -55.571  &lt; 2e-16 ***\nORIGIN_SZPGSZ03       1.146e+00  3.625e-03   315.999  &lt; 2e-16 ***\nORIGIN_SZPGSZ04       1.228e+00  3.627e-03   338.445  &lt; 2e-16 ***\nORIGIN_SZPGSZ05       4.787e-01  4.510e-03   106.145  &lt; 2e-16 ***\nORIGIN_SZPLSZ01      -4.797e-01  7.758e-03   -61.839  &lt; 2e-16 ***\nORIGIN_SZPLSZ02      -1.394e+00  1.121e-02  -124.392  &lt; 2e-16 ***\nORIGIN_SZPLSZ03      -2.963e+00  3.138e-02   -94.406  &lt; 2e-16 ***\nORIGIN_SZPLSZ04      -3.465e+00  3.524e-02   -98.323  &lt; 2e-16 ***\nORIGIN_SZPLSZ05      -2.266e+00  1.760e-02  -128.773  &lt; 2e-16 ***\nORIGIN_SZPNSZ01       1.532e+00  3.821e-03   400.912  &lt; 2e-16 ***\nORIGIN_SZPNSZ02      -5.587e-01  9.699e-03   -57.611  &lt; 2e-16 ***\nORIGIN_SZPNSZ03      -1.975e+00  1.746e-02  -113.152  &lt; 2e-16 ***\nORIGIN_SZPNSZ04      -2.601e+00  2.552e-02  -101.923  &lt; 2e-16 ***\nORIGIN_SZPNSZ05      -1.741e+00  1.729e-02  -100.694  &lt; 2e-16 ***\nORIGIN_SZPRSZ01      -6.841e-01  9.325e-03   -73.364  &lt; 2e-16 ***\nORIGIN_SZPRSZ02       1.110e+00  3.790e-03   292.835  &lt; 2e-16 ***\nORIGIN_SZPRSZ03       8.811e-01  3.786e-03   232.709  &lt; 2e-16 ***\nORIGIN_SZPRSZ04      -2.439e-01  6.099e-03   -39.986  &lt; 2e-16 ***\nORIGIN_SZPRSZ05       1.308e+00  3.625e-03   360.972  &lt; 2e-16 ***\nORIGIN_SZPRSZ06      -4.679e-01  6.803e-03   -68.781  &lt; 2e-16 ***\nORIGIN_SZPRSZ07      -2.530e+00  1.680e-02  -150.629  &lt; 2e-16 ***\nORIGIN_SZPRSZ08       1.336e-01  5.012e-03    26.655  &lt; 2e-16 ***\nORIGIN_SZQTSZ01      -3.690e-01  5.363e-03   -68.812  &lt; 2e-16 ***\nORIGIN_SZQTSZ02      -6.760e-01  5.029e-03  -134.429  &lt; 2e-16 ***\nORIGIN_SZQTSZ03      -2.233e-01  4.569e-03   -48.869  &lt; 2e-16 ***\nORIGIN_SZQTSZ04      -1.136e+00  6.204e-03  -183.037  &lt; 2e-16 ***\nORIGIN_SZQTSZ05      -1.992e-01  4.562e-03   -43.664  &lt; 2e-16 ***\nORIGIN_SZQTSZ06      -5.709e-01  5.252e-03  -108.705  &lt; 2e-16 ***\nORIGIN_SZQTSZ07      -1.532e+00  7.795e-03  -196.606  &lt; 2e-16 ***\nORIGIN_SZQTSZ08      -2.386e-01  4.733e-03   -50.403  &lt; 2e-16 ***\nORIGIN_SZQTSZ09      -5.253e-01  5.308e-03   -98.976  &lt; 2e-16 ***\nORIGIN_SZQTSZ10      -3.837e-01  5.196e-03   -73.846  &lt; 2e-16 ***\nORIGIN_SZQTSZ11      -1.313e+00  7.588e-03  -173.079  &lt; 2e-16 ***\nORIGIN_SZQTSZ12      -6.748e-01  6.337e-03  -106.488  &lt; 2e-16 ***\nORIGIN_SZQTSZ13      -8.076e-02  4.804e-03   -16.811  &lt; 2e-16 ***\nORIGIN_SZQTSZ14      -1.335e+00  7.113e-03  -187.705  &lt; 2e-16 ***\nORIGIN_SZQTSZ15      -7.194e-01  8.216e-03   -87.558  &lt; 2e-16 ***\nORIGIN_SZRCSZ01      -6.379e-01  5.283e-03  -120.740  &lt; 2e-16 ***\nORIGIN_SZRCSZ02      -2.358e+00  1.482e-02  -159.094  &lt; 2e-16 ***\nORIGIN_SZRCSZ03      -1.470e+00  7.322e-03  -200.791  &lt; 2e-16 ***\nORIGIN_SZRCSZ04      -2.219e+00  1.109e-02  -200.111  &lt; 2e-16 ***\nORIGIN_SZRCSZ05      -2.770e+00  1.341e-02  -206.629  &lt; 2e-16 ***\nORIGIN_SZRCSZ06      -4.466e-01  6.935e-03   -64.404  &lt; 2e-16 ***\nORIGIN_SZRCSZ08      -2.558e+00  1.610e-02  -158.880  &lt; 2e-16 ***\nORIGIN_SZRCSZ09      -1.978e+00  1.217e-02  -162.512  &lt; 2e-16 ***\nORIGIN_SZRCSZ10      -1.811e+00  6.993e-03  -259.015  &lt; 2e-16 ***\nORIGIN_SZRVSZ01      -2.814e+00  1.312e-02  -214.462  &lt; 2e-16 ***\nORIGIN_SZRVSZ02      -1.124e+00  6.715e-03  -167.428  &lt; 2e-16 ***\nORIGIN_SZRVSZ03      -1.888e+00  9.780e-03  -193.068  &lt; 2e-16 ***\nORIGIN_SZRVSZ04      -1.973e+00  1.378e-02  -143.142  &lt; 2e-16 ***\nORIGIN_SZRVSZ05      -2.176e+00  1.213e-02  -179.378  &lt; 2e-16 ***\nORIGIN_SZSBSZ01       7.906e-01  4.386e-03   180.258  &lt; 2e-16 ***\nORIGIN_SZSBSZ02      -5.268e-01  6.431e-03   -81.909  &lt; 2e-16 ***\nORIGIN_SZSBSZ03       1.010e+00  3.843e-03   262.897  &lt; 2e-16 ***\nORIGIN_SZSBSZ04       7.772e-01  4.361e-03   178.202  &lt; 2e-16 ***\nORIGIN_SZSBSZ05      -7.765e-02  5.496e-03   -14.128  &lt; 2e-16 ***\nORIGIN_SZSBSZ06      -1.650e+00  1.359e-02  -121.412  &lt; 2e-16 ***\nORIGIN_SZSBSZ07      -7.893e-01  9.127e-03   -86.478  &lt; 2e-16 ***\nORIGIN_SZSBSZ08      -9.503e-01  9.362e-03  -101.512  &lt; 2e-16 ***\nORIGIN_SZSBSZ09      -4.758e-01  7.016e-03   -67.806  &lt; 2e-16 ***\nORIGIN_SZSESZ02       1.165e+00  3.595e-03   323.972  &lt; 2e-16 ***\nORIGIN_SZSESZ03       1.289e+00  3.463e-03   372.373  &lt; 2e-16 ***\nORIGIN_SZSESZ04       1.019e+00  3.931e-03   259.250  &lt; 2e-16 ***\nORIGIN_SZSESZ05      -1.106e-01  4.827e-03   -22.907  &lt; 2e-16 ***\nORIGIN_SZSESZ06       9.972e-01  3.761e-03   265.133  &lt; 2e-16 ***\nORIGIN_SZSESZ07      -2.195e+00  1.404e-02  -156.357  &lt; 2e-16 ***\nORIGIN_SZSGSZ01      -8.301e-01  6.827e-03  -121.592  &lt; 2e-16 ***\nORIGIN_SZSGSZ02      -1.135e+00  8.180e-03  -138.755  &lt; 2e-16 ***\nORIGIN_SZSGSZ03       3.108e-01  4.304e-03    72.220  &lt; 2e-16 ***\nORIGIN_SZSGSZ04       3.315e-01  3.954e-03    83.844  &lt; 2e-16 ***\nORIGIN_SZSGSZ05      -1.574e+00  8.178e-03  -192.514  &lt; 2e-16 ***\nORIGIN_SZSGSZ06       4.707e-01  3.752e-03   125.452  &lt; 2e-16 ***\nORIGIN_SZSGSZ07      -5.168e-01  4.973e-03  -103.909  &lt; 2e-16 ***\nORIGIN_SZSKSZ01      -1.388e-01  6.497e-03   -21.359  &lt; 2e-16 ***\nORIGIN_SZSKSZ02       3.980e-01  4.751e-03    83.770  &lt; 2e-16 ***\nORIGIN_SZSKSZ03      -4.619e-01  6.153e-03   -75.064  &lt; 2e-16 ***\nORIGIN_SZSKSZ04      -2.355e+00  2.132e-02  -110.454  &lt; 2e-16 ***\nORIGIN_SZSKSZ05      -1.229e+00  1.245e-02   -98.702  &lt; 2e-16 ***\nORIGIN_SZSLSZ01      -3.172e+00  2.571e-02  -123.358  &lt; 2e-16 ***\nORIGIN_SZSLSZ04      -3.140e-01  5.780e-03   -54.333  &lt; 2e-16 ***\nORIGIN_SZSRSZ01      -1.508e+00  7.084e-03  -212.819  &lt; 2e-16 ***\nORIGIN_SZSRSZ02      -1.783e+00  7.222e-03  -246.939  &lt; 2e-16 ***\nORIGIN_SZSRSZ03      -2.801e+00  1.514e-02  -184.996  &lt; 2e-16 ***\nORIGIN_SZSVSZ01      -2.798e+00  2.815e-02   -99.409  &lt; 2e-16 ***\nORIGIN_SZTHSZ01      -2.986e+00  4.617e-02   -64.671  &lt; 2e-16 ***\nORIGIN_SZTHSZ03      -1.556e+00  1.269e-02  -122.621  &lt; 2e-16 ***\nORIGIN_SZTHSZ04      -3.011e+00  2.435e-02  -123.655  &lt; 2e-16 ***\nORIGIN_SZTHSZ06      -1.631e+00  1.084e-02  -150.482  &lt; 2e-16 ***\nORIGIN_SZTMSZ01       1.080e+00  4.087e-03   264.249  &lt; 2e-16 ***\nORIGIN_SZTMSZ02       2.226e+00  3.176e-03   700.906  &lt; 2e-16 ***\nORIGIN_SZTMSZ03       1.522e+00  3.389e-03   449.101  &lt; 2e-16 ***\nORIGIN_SZTMSZ04       9.516e-01  3.881e-03   245.213  &lt; 2e-16 ***\nORIGIN_SZTMSZ05      -2.458e-01  6.138e-03   -40.038  &lt; 2e-16 ***\nORIGIN_SZTNSZ01      -1.047e+00  5.897e-03  -177.587  &lt; 2e-16 ***\nORIGIN_SZTNSZ02      -1.015e+00  5.720e-03  -177.473  &lt; 2e-16 ***\nORIGIN_SZTNSZ03      -1.518e+00  7.506e-03  -202.275  &lt; 2e-16 ***\nORIGIN_SZTNSZ04      -6.469e-01  5.491e-03  -117.823  &lt; 2e-16 ***\nORIGIN_SZTPSZ01      -6.208e-01  5.132e-03  -120.979  &lt; 2e-16 ***\nORIGIN_SZTPSZ02       4.640e-01  3.614e-03   128.411  &lt; 2e-16 ***\nORIGIN_SZTPSZ03      -4.501e-01  5.102e-03   -88.218  &lt; 2e-16 ***\nORIGIN_SZTPSZ04      -2.797e-01  4.821e-03   -58.026  &lt; 2e-16 ***\nORIGIN_SZTPSZ05      -2.178e-01  4.987e-03   -43.675  &lt; 2e-16 ***\nORIGIN_SZTPSZ06       2.260e-01  5.019e-03    45.026  &lt; 2e-16 ***\nORIGIN_SZTPSZ07      -1.387e-01  5.015e-03   -27.651  &lt; 2e-16 ***\nORIGIN_SZTPSZ08      -6.925e-01  6.545e-03  -105.811  &lt; 2e-16 ***\nORIGIN_SZTPSZ09      -4.794e-01  5.358e-03   -89.465  &lt; 2e-16 ***\nORIGIN_SZTPSZ10      -3.714e-01  5.362e-03   -69.266  &lt; 2e-16 ***\nORIGIN_SZTPSZ11       2.625e-01  4.218e-03    62.229  &lt; 2e-16 ***\nORIGIN_SZTPSZ12      -4.955e-01  5.288e-03   -93.700  &lt; 2e-16 ***\nORIGIN_SZTSSZ01      -3.428e+00  3.961e-02   -86.524  &lt; 2e-16 ***\nORIGIN_SZTSSZ02       5.153e-01  5.790e-03    89.000  &lt; 2e-16 ***\nORIGIN_SZTSSZ03       5.407e-01  5.827e-03    92.803  &lt; 2e-16 ***\nORIGIN_SZTSSZ04       5.158e-01  6.000e-03    85.964  &lt; 2e-16 ***\nORIGIN_SZTSSZ05      -9.510e-01  1.122e-02   -84.796  &lt; 2e-16 ***\nORIGIN_SZTSSZ06      -1.155e+00  1.360e-02   -84.933  &lt; 2e-16 ***\nORIGIN_SZWCSZ01       3.529e-01  5.612e-03    62.877  &lt; 2e-16 ***\nORIGIN_SZWCSZ02      -2.680e+00  2.497e-02  -107.302  &lt; 2e-16 ***\nORIGIN_SZWCSZ03      -4.218e+00  1.325e-01   -31.839  &lt; 2e-16 ***\nORIGIN_SZWDSZ01       1.430e+00  3.467e-03   412.347  &lt; 2e-16 ***\nORIGIN_SZWDSZ02       1.111e+00  3.926e-03   283.079  &lt; 2e-16 ***\nORIGIN_SZWDSZ03       2.250e+00  3.358e-03   669.831  &lt; 2e-16 ***\nORIGIN_SZWDSZ04       1.192e+00  4.101e-03   290.750  &lt; 2e-16 ***\nORIGIN_SZWDSZ05       6.377e-01  4.136e-03   154.160  &lt; 2e-16 ***\nORIGIN_SZWDSZ06       1.295e+00  3.808e-03   340.102  &lt; 2e-16 ***\nORIGIN_SZWDSZ07       2.689e-01  5.407e-03    49.740  &lt; 2e-16 ***\nORIGIN_SZWDSZ08      -1.872e-01  6.132e-03   -30.533  &lt; 2e-16 ***\nORIGIN_SZWDSZ09       1.826e+00  3.498e-03   521.848  &lt; 2e-16 ***\nORIGIN_SZYSSZ01      -5.305e-02  4.658e-03   -11.389  &lt; 2e-16 ***\nORIGIN_SZYSSZ02       1.003e+00  4.134e-03   242.541  &lt; 2e-16 ***\nORIGIN_SZYSSZ03       1.997e+00  3.458e-03   577.479  &lt; 2e-16 ***\nORIGIN_SZYSSZ04       9.186e-01  3.725e-03   246.606  &lt; 2e-16 ***\nORIGIN_SZYSSZ05       1.984e-01  4.595e-03    43.178  &lt; 2e-16 ***\nORIGIN_SZYSSZ06      -8.206e-01  7.460e-03  -109.992  &lt; 2e-16 ***\nORIGIN_SZYSSZ07      -5.298e-01  7.220e-03   -73.381  &lt; 2e-16 ***\nORIGIN_SZYSSZ08      -1.277e-02  5.142e-03    -2.483    0.013 *  \nORIGIN_SZYSSZ09       1.405e+00  3.560e-03   394.739  &lt; 2e-16 ***\nlog(DESTIN_AGE25_64)  2.458e-02  6.646e-05   369.857  &lt; 2e-16 ***\nlog(dist)            -7.137e-01  1.016e-04 -7023.324  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 105499054  on 20915  degrees of freedom\nResidual deviance:  45982898  on 20605  degrees of freedom\nAIC: 46115907\n\nNumber of Fisher Scoring iterations: 7\n\n\nSimilarly, we can calculate R-squared for the origin-constrained model:\n\nCalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)\n\n[1] 0.3847416\n\n\n\n8.7 Destination Constrained\nIn this section, We will fit a destination-constrained Spatial Interaction Model (SIM).\n\n\n\n\n\n\nNote\n\n\n\nThe general formula of Destination Constrained Spatial Interaction Model\n\\(\\lambda_{ij} = \\exp \\left( k + \\mu \\ln V_i + \\alpha_i - \\beta \\ln d_{ij} \\right)\\)\nNotice that the difference between Unconstrained Spatial Interaction Model and this formula lies in the third term. In the Unconstrained Spatial Interaction Model formula, it is \\(\\alpha \\ln W_j\\) as compared to \\(\\alpha_i\\) in Destination Constrained Spatial Interaction Model.\n\n\n\ndecSIM &lt;- glm(formula = TRIPS ~\n                DESTIN_SZ +\n                log(ORIGIN_AGE25_64) +\n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(decSIM)\n\n\nCall:\nglm(formula = TRIPS ~ DESTIN_SZ + log(ORIGIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)          11.1886479  0.0027928  4006.284  &lt; 2e-16 ***\nDESTIN_SZAMSZ02       0.2047468  0.0035739    57.290  &lt; 2e-16 ***\nDESTIN_SZAMSZ03       0.2696890  0.0034700    77.720  &lt; 2e-16 ***\nDESTIN_SZAMSZ04      -0.9029147  0.0051608  -174.956  &lt; 2e-16 ***\nDESTIN_SZAMSZ05      -0.9208381  0.0048845  -188.522  &lt; 2e-16 ***\nDESTIN_SZAMSZ06      -0.7523009  0.0047388  -158.753  &lt; 2e-16 ***\nDESTIN_SZAMSZ07      -1.8644282  0.0085251  -218.699  &lt; 2e-16 ***\nDESTIN_SZAMSZ08      -0.9320542  0.0053993  -172.625  &lt; 2e-16 ***\nDESTIN_SZAMSZ09      -0.9606544  0.0051384  -186.955  &lt; 2e-16 ***\nDESTIN_SZAMSZ10       0.4367176  0.0035636   122.549  &lt; 2e-16 ***\nDESTIN_SZAMSZ11       0.1387581  0.0060108    23.085  &lt; 2e-16 ***\nDESTIN_SZAMSZ12      -0.0968912  0.0044113   -21.965  &lt; 2e-16 ***\nDESTIN_SZBDSZ01       0.5325773  0.0032062   166.106  &lt; 2e-16 ***\nDESTIN_SZBDSZ02      -0.1583330  0.0040652   -38.949  &lt; 2e-16 ***\nDESTIN_SZBDSZ03       0.0326536  0.0036002     9.070  &lt; 2e-16 ***\nDESTIN_SZBDSZ04       1.0265974  0.0029357   349.691  &lt; 2e-16 ***\nDESTIN_SZBDSZ05       0.4370921  0.0032622   133.986  &lt; 2e-16 ***\nDESTIN_SZBDSZ06       0.1411228  0.0036420    38.749  &lt; 2e-16 ***\nDESTIN_SZBDSZ07      -0.8768697  0.0072058  -121.689  &lt; 2e-16 ***\nDESTIN_SZBDSZ08      -1.4154555  0.0073628  -192.244  &lt; 2e-16 ***\nDESTIN_SZBKSZ01      -1.0792597  0.0053008  -203.605  &lt; 2e-16 ***\nDESTIN_SZBKSZ02      -0.1605882  0.0043097   -37.262  &lt; 2e-16 ***\nDESTIN_SZBKSZ03      -0.4113294  0.0044445   -92.548  &lt; 2e-16 ***\nDESTIN_SZBKSZ04       0.1040345  0.0039514    26.328  &lt; 2e-16 ***\nDESTIN_SZBKSZ05      -0.6361868  0.0045293  -140.461  &lt; 2e-16 ***\nDESTIN_SZBKSZ06      -0.8459238  0.0050627  -167.089  &lt; 2e-16 ***\nDESTIN_SZBKSZ07       0.2936470  0.0033772    86.949  &lt; 2e-16 ***\nDESTIN_SZBKSZ08      -1.0336173  0.0057054  -181.166  &lt; 2e-16 ***\nDESTIN_SZBKSZ09      -0.1990406  0.0040672   -48.938  &lt; 2e-16 ***\nDESTIN_SZBLSZ01      -0.3332097  0.0058008   -57.442  &lt; 2e-16 ***\nDESTIN_SZBLSZ02       0.6867036  0.0055489   123.755  &lt; 2e-16 ***\nDESTIN_SZBLSZ03       1.5117931  0.0059625   253.551  &lt; 2e-16 ***\nDESTIN_SZBLSZ04       0.0399457  0.0108522     3.681 0.000232 ***\nDESTIN_SZBMSZ01      -0.1382645  0.0037137   -37.231  &lt; 2e-16 ***\nDESTIN_SZBMSZ02      -0.4926028  0.0039199  -125.667  &lt; 2e-16 ***\nDESTIN_SZBMSZ03      -0.9056345  0.0047824  -189.366  &lt; 2e-16 ***\nDESTIN_SZBMSZ04      -0.5703442  0.0040984  -139.162  &lt; 2e-16 ***\nDESTIN_SZBMSZ05      -0.5916186  0.0049394  -119.775  &lt; 2e-16 ***\nDESTIN_SZBMSZ06      -1.6992029  0.0083045  -204.612  &lt; 2e-16 ***\nDESTIN_SZBMSZ07      -0.1189131  0.0036137   -32.906  &lt; 2e-16 ***\nDESTIN_SZBMSZ08      -1.0778761  0.0047721  -225.870  &lt; 2e-16 ***\nDESTIN_SZBMSZ09      -2.0275228  0.0075864  -267.257  &lt; 2e-16 ***\nDESTIN_SZBMSZ10      -1.5564968  0.0059936  -259.692  &lt; 2e-16 ***\nDESTIN_SZBMSZ11      -1.5778427  0.0059658  -264.483  &lt; 2e-16 ***\nDESTIN_SZBMSZ12      -1.0550880  0.0061596  -171.292  &lt; 2e-16 ***\nDESTIN_SZBMSZ13      -0.2495049  0.0038737   -64.410  &lt; 2e-16 ***\nDESTIN_SZBMSZ14      -1.0137466  0.0060702  -167.005  &lt; 2e-16 ***\nDESTIN_SZBMSZ15      -1.2476855  0.0056991  -218.927  &lt; 2e-16 ***\nDESTIN_SZBMSZ16      -1.6211588  0.0061126  -265.216  &lt; 2e-16 ***\nDESTIN_SZBMSZ17      -1.5085672  0.0071513  -210.951  &lt; 2e-16 ***\nDESTIN_SZBPSZ01      -0.4821870  0.0044490  -108.381  &lt; 2e-16 ***\nDESTIN_SZBPSZ02      -1.4688886  0.0071354  -205.860  &lt; 2e-16 ***\nDESTIN_SZBPSZ03      -1.1618519  0.0067027  -173.342  &lt; 2e-16 ***\nDESTIN_SZBPSZ04      -0.6445302  0.0049336  -130.641  &lt; 2e-16 ***\nDESTIN_SZBPSZ05       0.5220193  0.0032426   160.988  &lt; 2e-16 ***\nDESTIN_SZBPSZ06      -0.7705496  0.0060773  -126.790  &lt; 2e-16 ***\nDESTIN_SZBPSZ07      -0.5975374  0.0062143   -96.156  &lt; 2e-16 ***\nDESTIN_SZBSSZ01      -0.1159850  0.0036849   -31.476  &lt; 2e-16 ***\nDESTIN_SZBSSZ02      -0.7414329  0.0043019  -172.349  &lt; 2e-16 ***\nDESTIN_SZBSSZ03       0.3124431  0.0031917    97.893  &lt; 2e-16 ***\nDESTIN_SZBTSZ01       0.1570827  0.0034455    45.591  &lt; 2e-16 ***\nDESTIN_SZBTSZ02      -0.7950768  0.0055915  -142.194  &lt; 2e-16 ***\nDESTIN_SZBTSZ03      -0.1947127  0.0040495   -48.083  &lt; 2e-16 ***\nDESTIN_SZBTSZ04      -1.6039884  0.0079447  -201.895  &lt; 2e-16 ***\nDESTIN_SZBTSZ05      -0.7366517  0.0056153  -131.188  &lt; 2e-16 ***\nDESTIN_SZBTSZ06      -0.8638970  0.0050164  -172.216  &lt; 2e-16 ***\nDESTIN_SZBTSZ07      -1.9314011  0.0079429  -243.162  &lt; 2e-16 ***\nDESTIN_SZBTSZ08      -1.2455761  0.0066997  -185.914  &lt; 2e-16 ***\nDESTIN_SZCCSZ01      -0.4157153  0.0052731   -78.838  &lt; 2e-16 ***\nDESTIN_SZCHSZ01      -1.0527185  0.0073777  -142.689  &lt; 2e-16 ***\nDESTIN_SZCHSZ02      -0.0306697  0.0045975    -6.671 2.54e-11 ***\nDESTIN_SZCHSZ03       1.6952057  0.0032057   528.814  &lt; 2e-16 ***\nDESTIN_SZCKSZ01      -0.1484317  0.0040290   -36.840  &lt; 2e-16 ***\nDESTIN_SZCKSZ02      -0.4018663  0.0044007   -91.319  &lt; 2e-16 ***\nDESTIN_SZCKSZ03       0.7189825  0.0032425   221.737  &lt; 2e-16 ***\nDESTIN_SZCKSZ04      -0.6740941  0.0051090  -131.943  &lt; 2e-16 ***\nDESTIN_SZCKSZ05      -0.3100378  0.0053366   -58.096  &lt; 2e-16 ***\nDESTIN_SZCKSZ06       0.7865808  0.0037571   209.361  &lt; 2e-16 ***\nDESTIN_SZCLSZ01       0.4766029  0.0038956   122.345  &lt; 2e-16 ***\nDESTIN_SZCLSZ02      -2.2614707  0.0109131  -207.225  &lt; 2e-16 ***\nDESTIN_SZCLSZ03      -0.9662790  0.0060017  -161.000  &lt; 2e-16 ***\nDESTIN_SZCLSZ04       0.1515855  0.0035858    42.274  &lt; 2e-16 ***\nDESTIN_SZCLSZ05      -1.2509920  0.0070287  -177.983  &lt; 2e-16 ***\nDESTIN_SZCLSZ06       0.2066348  0.0033754    61.218  &lt; 2e-16 ***\nDESTIN_SZCLSZ07      -0.5707110  0.0043519  -131.139  &lt; 2e-16 ***\nDESTIN_SZCLSZ08      -0.4633052  0.0048981   -94.589  &lt; 2e-16 ***\nDESTIN_SZCLSZ09       0.3993821  0.0054058    73.880  &lt; 2e-16 ***\nDESTIN_SZDTSZ01      -0.8694081  0.0044649  -194.722  &lt; 2e-16 ***\nDESTIN_SZDTSZ02      -0.8521954  0.0043451  -196.127  &lt; 2e-16 ***\nDESTIN_SZDTSZ03      -1.0743465  0.0051507  -208.582  &lt; 2e-16 ***\nDESTIN_SZDTSZ04      -1.1505259  0.0110647  -103.981  &lt; 2e-16 ***\nDESTIN_SZDTSZ05      -1.0093612  0.0085677  -117.810  &lt; 2e-16 ***\nDESTIN_SZDTSZ06      -1.1371739  0.0058133  -195.615  &lt; 2e-16 ***\nDESTIN_SZDTSZ07      -1.9214590  0.0180651  -106.363  &lt; 2e-16 ***\nDESTIN_SZDTSZ08      -0.6971968  0.0042214  -165.156  &lt; 2e-16 ***\nDESTIN_SZDTSZ09      -1.5178484  0.0094552  -160.530  &lt; 2e-16 ***\nDESTIN_SZDTSZ10      -1.3018755  0.0075368  -172.737  &lt; 2e-16 ***\nDESTIN_SZDTSZ11      -0.8241052  0.0044947  -183.351  &lt; 2e-16 ***\nDESTIN_SZDTSZ12      -2.4402256  0.0146441  -166.636  &lt; 2e-16 ***\nDESTIN_SZDTSZ13      -1.9939705  0.0092374  -215.859  &lt; 2e-16 ***\nDESTIN_SZGLSZ01       0.0262850  0.0041498     6.334 2.39e-10 ***\nDESTIN_SZGLSZ02      -0.3074574  0.0038496   -79.867  &lt; 2e-16 ***\nDESTIN_SZGLSZ03       0.3982838  0.0032437   122.787  &lt; 2e-16 ***\nDESTIN_SZGLSZ04       0.3933413  0.0031685   124.141  &lt; 2e-16 ***\nDESTIN_SZGLSZ05       0.1442632  0.0033403    43.189  &lt; 2e-16 ***\nDESTIN_SZHGSZ01       0.4273977  0.0032226   132.624  &lt; 2e-16 ***\nDESTIN_SZHGSZ02      -0.5494812  0.0044023  -124.816  &lt; 2e-16 ***\nDESTIN_SZHGSZ03      -1.0856653  0.0052758  -205.781  &lt; 2e-16 ***\nDESTIN_SZHGSZ04      -0.2538606  0.0037451   -67.784  &lt; 2e-16 ***\nDESTIN_SZHGSZ05      -0.1395323  0.0037621   -37.089  &lt; 2e-16 ***\nDESTIN_SZHGSZ06      -0.6632432  0.0044051  -150.564  &lt; 2e-16 ***\nDESTIN_SZHGSZ07       0.2923291  0.0033875    86.296  &lt; 2e-16 ***\nDESTIN_SZHGSZ08      -0.2730755  0.0039832   -68.557  &lt; 2e-16 ***\nDESTIN_SZHGSZ09       0.2735423  0.0041633    65.704  &lt; 2e-16 ***\nDESTIN_SZHGSZ10      -3.1736449  0.0284659  -111.489  &lt; 2e-16 ***\nDESTIN_SZJESZ01      -0.1053234  0.0041515   -25.370  &lt; 2e-16 ***\nDESTIN_SZJESZ02      -0.4383285  0.0042949  -102.057  &lt; 2e-16 ***\nDESTIN_SZJESZ03      -0.5711346  0.0046960  -121.621  &lt; 2e-16 ***\nDESTIN_SZJESZ04      -0.0238346  0.0048249    -4.940 7.81e-07 ***\nDESTIN_SZJESZ05      -0.7798774  0.0074938  -104.070  &lt; 2e-16 ***\nDESTIN_SZJESZ06       0.3824640  0.0034475   110.939  &lt; 2e-16 ***\nDESTIN_SZJESZ07      -0.8847081  0.0061908  -142.907  &lt; 2e-16 ***\nDESTIN_SZJESZ08      -0.5789622  0.0064625   -89.589  &lt; 2e-16 ***\nDESTIN_SZJESZ09      -0.4456534  0.0046887   -95.049  &lt; 2e-16 ***\nDESTIN_SZJESZ10       0.7168959  0.0061692   116.205  &lt; 2e-16 ***\nDESTIN_SZJESZ11       1.0389409  0.0054888   189.285  &lt; 2e-16 ***\nDESTIN_SZJWSZ01      -0.3405028  0.0052968   -64.284  &lt; 2e-16 ***\nDESTIN_SZJWSZ02      -0.3557479  0.0045025   -79.011  &lt; 2e-16 ***\nDESTIN_SZJWSZ03       0.6822220  0.0033463   203.873  &lt; 2e-16 ***\nDESTIN_SZJWSZ04       1.0313249  0.0031431   328.118  &lt; 2e-16 ***\nDESTIN_SZJWSZ05      -0.1390898  0.0050165   -27.726  &lt; 2e-16 ***\nDESTIN_SZJWSZ06       0.4283248  0.0045931    93.255  &lt; 2e-16 ***\nDESTIN_SZJWSZ07      -0.8125529  0.0196066   -41.443  &lt; 2e-16 ***\nDESTIN_SZJWSZ08       0.4721844  0.0038233   123.502  &lt; 2e-16 ***\nDESTIN_SZJWSZ09       1.4834158  0.0028734   516.263  &lt; 2e-16 ***\nDESTIN_SZKLSZ01      -0.5939223  0.0040738  -145.792  &lt; 2e-16 ***\nDESTIN_SZKLSZ02      -0.7600734  0.0046596  -163.119  &lt; 2e-16 ***\nDESTIN_SZKLSZ03      -1.2543810  0.0051402  -244.031  &lt; 2e-16 ***\nDESTIN_SZKLSZ04      -1.7311984  0.0066049  -262.109  &lt; 2e-16 ***\nDESTIN_SZKLSZ05      -1.1216909  0.0066398  -168.935  &lt; 2e-16 ***\nDESTIN_SZKLSZ06      -0.9437123  0.0044840  -210.462  &lt; 2e-16 ***\nDESTIN_SZKLSZ07      -1.0592925  0.0050379  -210.265  &lt; 2e-16 ***\nDESTIN_SZKLSZ08      -0.1414796  0.0036529   -38.731  &lt; 2e-16 ***\nDESTIN_SZKLSZ09      -1.8622768  0.0066005  -282.142  &lt; 2e-16 ***\nDESTIN_SZLKSZ01      -1.6806379  0.0192395   -87.353  &lt; 2e-16 ***\nDESTIN_SZMDSZ01      -1.2927817  0.0158848   -81.385  &lt; 2e-16 ***\nDESTIN_SZMDSZ02      -1.1068976  0.0093181  -118.790  &lt; 2e-16 ***\nDESTIN_SZMDSZ03      -2.8169619  0.0208242  -135.274  &lt; 2e-16 ***\nDESTIN_SZMPSZ01      -1.2490736  0.0064894  -192.478  &lt; 2e-16 ***\nDESTIN_SZMPSZ02      -0.8411939  0.0048205  -174.505  &lt; 2e-16 ***\nDESTIN_SZMPSZ03      -0.1963932  0.0039391   -49.858  &lt; 2e-16 ***\nDESTIN_SZMSSZ01      -3.7028759  0.0680912   -54.381  &lt; 2e-16 ***\nDESTIN_SZMUSZ01      -1.1416953  0.0048741  -234.235  &lt; 2e-16 ***\nDESTIN_SZMUSZ02      -1.4043160  0.0069637  -201.663  &lt; 2e-16 ***\nDESTIN_SZMUSZ03      -1.1249185  0.0047737  -235.647  &lt; 2e-16 ***\nDESTIN_SZNTSZ01      -2.7232365  0.0219075  -124.306  &lt; 2e-16 ***\nDESTIN_SZNTSZ02      -2.0281258  0.0087672  -231.332  &lt; 2e-16 ***\nDESTIN_SZNTSZ03      -1.1948616  0.0060363  -197.945  &lt; 2e-16 ***\nDESTIN_SZNTSZ05      -1.7337767  0.0161951  -107.056  &lt; 2e-16 ***\nDESTIN_SZNTSZ06      -3.0002577  0.0278723  -107.643  &lt; 2e-16 ***\nDESTIN_SZNVSZ01      -0.2596984  0.0035898   -72.343  &lt; 2e-16 ***\nDESTIN_SZNVSZ02      -0.4670565  0.0040847  -114.343  &lt; 2e-16 ***\nDESTIN_SZNVSZ03      -0.5798852  0.0043601  -132.998  &lt; 2e-16 ***\nDESTIN_SZNVSZ04      -2.0652499  0.0084658  -243.951  &lt; 2e-16 ***\nDESTIN_SZNVSZ05      -1.8113949  0.0072668  -249.271  &lt; 2e-16 ***\nDESTIN_SZORSZ01      -2.0102988  0.0174760  -115.032  &lt; 2e-16 ***\nDESTIN_SZORSZ02       0.0988466  0.0034722    28.468  &lt; 2e-16 ***\nDESTIN_SZORSZ03      -0.8997969  0.0047365  -189.970  &lt; 2e-16 ***\nDESTIN_SZOTSZ01      -1.5647551  0.0060744  -257.599  &lt; 2e-16 ***\nDESTIN_SZOTSZ02      -0.8001690  0.0053202  -150.401  &lt; 2e-16 ***\nDESTIN_SZOTSZ03      -1.4925670  0.0057452  -259.793  &lt; 2e-16 ***\nDESTIN_SZOTSZ04      -1.5602417  0.0082363  -189.434  &lt; 2e-16 ***\nDESTIN_SZPGSZ01      -2.1137374  0.0140083  -150.892  &lt; 2e-16 ***\nDESTIN_SZPGSZ02      -0.7896523  0.0053545  -147.475  &lt; 2e-16 ***\nDESTIN_SZPGSZ03       0.5822347  0.0032692   178.098  &lt; 2e-16 ***\nDESTIN_SZPGSZ04       0.1448694  0.0036782    39.386  &lt; 2e-16 ***\nDESTIN_SZPGSZ05      -0.8881741  0.0060384  -147.087  &lt; 2e-16 ***\nDESTIN_SZPLSZ01      -0.0795041  0.0058033   -13.700  &lt; 2e-16 ***\nDESTIN_SZPLSZ02      -1.1900069  0.0102914  -115.631  &lt; 2e-16 ***\nDESTIN_SZPLSZ03      -0.1247849  0.0084378   -14.789  &lt; 2e-16 ***\nDESTIN_SZPLSZ04      -0.2719495  0.0081384   -33.416  &lt; 2e-16 ***\nDESTIN_SZPLSZ05      -0.6771576  0.0097439   -69.496  &lt; 2e-16 ***\nDESTIN_SZPNSZ01       1.1397906  0.0042414   268.733  &lt; 2e-16 ***\nDESTIN_SZPNSZ02       1.6933075  0.0055624   304.420  &lt; 2e-16 ***\nDESTIN_SZPNSZ03       0.9586915  0.0062893   152.432  &lt; 2e-16 ***\nDESTIN_SZPNSZ04       1.7374816  0.0063491   273.659  &lt; 2e-16 ***\nDESTIN_SZPNSZ05       0.8918270  0.0092596    96.314  &lt; 2e-16 ***\nDESTIN_SZPRSZ01      -0.6266318  0.0060975  -102.768  &lt; 2e-16 ***\nDESTIN_SZPRSZ02      -0.0691388  0.0040915   -16.898  &lt; 2e-16 ***\nDESTIN_SZPRSZ03       0.7957648  0.0031463   252.920  &lt; 2e-16 ***\nDESTIN_SZPRSZ04      -0.7720323  0.0069948  -110.373  &lt; 2e-16 ***\nDESTIN_SZPRSZ05      -0.0147428  0.0038961    -3.784 0.000154 ***\nDESTIN_SZPRSZ06       0.4832118  0.0041522   116.374  &lt; 2e-16 ***\nDESTIN_SZPRSZ07      -1.5779831  0.0103602  -152.313  &lt; 2e-16 ***\nDESTIN_SZPRSZ08      -0.8342815  0.0056390  -147.948  &lt; 2e-16 ***\nDESTIN_SZQTSZ01      -1.5074560  0.0081347  -185.311  &lt; 2e-16 ***\nDESTIN_SZQTSZ02      -1.4974563  0.0059956  -249.759  &lt; 2e-16 ***\nDESTIN_SZQTSZ03      -0.8830042  0.0053218  -165.922  &lt; 2e-16 ***\nDESTIN_SZQTSZ04      -1.1472088  0.0055287  -207.500  &lt; 2e-16 ***\nDESTIN_SZQTSZ05      -0.9139073  0.0048233  -189.476  &lt; 2e-16 ***\nDESTIN_SZQTSZ06      -1.1834757  0.0052284  -226.353  &lt; 2e-16 ***\nDESTIN_SZQTSZ07      -1.6922635  0.0088214  -191.837  &lt; 2e-16 ***\nDESTIN_SZQTSZ08       0.0925004  0.0037722    24.521  &lt; 2e-16 ***\nDESTIN_SZQTSZ09      -0.3797599  0.0045808   -82.903  &lt; 2e-16 ***\nDESTIN_SZQTSZ10      -0.4079167  0.0042387   -96.235  &lt; 2e-16 ***\nDESTIN_SZQTSZ11       0.2574301  0.0040515    63.539  &lt; 2e-16 ***\nDESTIN_SZQTSZ12      -0.3365383  0.0051991   -64.730  &lt; 2e-16 ***\nDESTIN_SZQTSZ13       0.1248056  0.0039363    31.706  &lt; 2e-16 ***\nDESTIN_SZQTSZ14      -0.1509191  0.0044507   -33.909  &lt; 2e-16 ***\nDESTIN_SZQTSZ15       0.0690162  0.0054153    12.745  &lt; 2e-16 ***\nDESTIN_SZRCSZ01      -1.0906712  0.0051802  -210.548  &lt; 2e-16 ***\nDESTIN_SZRCSZ02      -2.2359026  0.0135798  -164.649  &lt; 2e-16 ***\nDESTIN_SZRCSZ03      -1.1174100  0.0070391  -158.744  &lt; 2e-16 ***\nDESTIN_SZRCSZ04      -2.4568960  0.0102337  -240.080  &lt; 2e-16 ***\nDESTIN_SZRCSZ05      -2.3552607  0.0095366  -246.970  &lt; 2e-16 ***\nDESTIN_SZRCSZ06      -2.1550501  0.0124313  -173.356  &lt; 2e-16 ***\nDESTIN_SZRCSZ08      -2.0841001  0.0102626  -203.077  &lt; 2e-16 ***\nDESTIN_SZRCSZ09      -1.5747291  0.0094616  -166.434  &lt; 2e-16 ***\nDESTIN_SZRCSZ10      -1.1849003  0.0051385  -230.594  &lt; 2e-16 ***\nDESTIN_SZRVSZ01      -2.1529608  0.0085900  -250.637  &lt; 2e-16 ***\nDESTIN_SZRVSZ02      -2.4492143  0.0117753  -207.996  &lt; 2e-16 ***\nDESTIN_SZRVSZ03      -2.4222717  0.0100597  -240.790  &lt; 2e-16 ***\nDESTIN_SZRVSZ04      -1.7371692  0.0114377  -151.881  &lt; 2e-16 ***\nDESTIN_SZRVSZ05      -2.0839854  0.0111068  -187.632  &lt; 2e-16 ***\nDESTIN_SZSBSZ01      -0.0294186  0.0046753    -6.292 3.13e-10 ***\nDESTIN_SZSBSZ02      -0.9958381  0.0062222  -160.046  &lt; 2e-16 ***\nDESTIN_SZSBSZ03       0.7158194  0.0034449   207.793  &lt; 2e-16 ***\nDESTIN_SZSBSZ04       0.1191755  0.0043864    27.169  &lt; 2e-16 ***\nDESTIN_SZSBSZ05      -0.7522878  0.0057118  -131.708  &lt; 2e-16 ***\nDESTIN_SZSBSZ06      -2.7324967  0.0215545  -126.771  &lt; 2e-16 ***\nDESTIN_SZSBSZ07      -0.7273121  0.0152820   -47.593  &lt; 2e-16 ***\nDESTIN_SZSBSZ08       1.5312821  0.0041649   367.666  &lt; 2e-16 ***\nDESTIN_SZSBSZ09       0.8296969  0.0041401   200.405  &lt; 2e-16 ***\nDESTIN_SZSESZ02      -0.1094068  0.0038531   -28.395  &lt; 2e-16 ***\nDESTIN_SZSESZ03       0.7051751  0.0030797   228.975  &lt; 2e-16 ***\nDESTIN_SZSESZ04      -0.4959627  0.0043902  -112.970  &lt; 2e-16 ***\nDESTIN_SZSESZ05      -0.1095390  0.0037931   -28.879  &lt; 2e-16 ***\nDESTIN_SZSESZ06      -0.5019247  0.0047087  -106.594  &lt; 2e-16 ***\nDESTIN_SZSESZ07      -2.8784581  0.0198656  -144.897  &lt; 2e-16 ***\nDESTIN_SZSGSZ01      -0.4217244  0.0048327   -87.264  &lt; 2e-16 ***\nDESTIN_SZSGSZ02       0.0522081  0.0043245    12.073  &lt; 2e-16 ***\nDESTIN_SZSGSZ03      -0.3606981  0.0040326   -89.445  &lt; 2e-16 ***\nDESTIN_SZSGSZ04      -0.3212470  0.0039814   -80.687  &lt; 2e-16 ***\nDESTIN_SZSGSZ05      -1.9946206  0.0072648  -274.558  &lt; 2e-16 ***\nDESTIN_SZSGSZ06       0.4334467  0.0031411   137.991  &lt; 2e-16 ***\nDESTIN_SZSGSZ07      -0.3911286  0.0040499   -96.577  &lt; 2e-16 ***\nDESTIN_SZSISZ01      -0.9199242  0.0131178   -70.128  &lt; 2e-16 ***\nDESTIN_SZSKSZ01      -0.0948233  0.0058707   -16.152  &lt; 2e-16 ***\nDESTIN_SZSKSZ02       0.7988244  0.0041751   191.329  &lt; 2e-16 ***\nDESTIN_SZSKSZ03       0.0431353  0.0049234     8.761  &lt; 2e-16 ***\nDESTIN_SZSKSZ04      -0.6283844  0.0124899   -50.311  &lt; 2e-16 ***\nDESTIN_SZSKSZ05       0.0853350  0.0093562     9.121  &lt; 2e-16 ***\nDESTIN_SZSLSZ01      -0.3676636  0.0065766   -55.905  &lt; 2e-16 ***\nDESTIN_SZSLSZ04      -0.4556080  0.0052586   -86.641  &lt; 2e-16 ***\nDESTIN_SZSRSZ01      -1.6857168  0.0063800  -264.220  &lt; 2e-16 ***\nDESTIN_SZSRSZ02      -1.6369037  0.0074875  -218.618  &lt; 2e-16 ***\nDESTIN_SZSRSZ03      -1.5531939  0.0067905  -228.730  &lt; 2e-16 ***\nDESTIN_SZSVSZ01      -2.1265870  0.0278669   -76.312  &lt; 2e-16 ***\nDESTIN_SZTHSZ01      -2.5637337  0.0281096   -91.205  &lt; 2e-16 ***\nDESTIN_SZTHSZ03      -1.5761506  0.0171972   -91.652  &lt; 2e-16 ***\nDESTIN_SZTHSZ04      -2.2051773  0.0180679  -122.050  &lt; 2e-16 ***\nDESTIN_SZTHSZ06      -1.2196441  0.0115873  -105.257  &lt; 2e-16 ***\nDESTIN_SZTMSZ01       0.0307882  0.0042806     7.192 6.36e-13 ***\nDESTIN_SZTMSZ02       1.7151835  0.0027605   621.327  &lt; 2e-16 ***\nDESTIN_SZTMSZ03       0.7346828  0.0031466   233.481  &lt; 2e-16 ***\nDESTIN_SZTMSZ04       0.8505032  0.0032061   265.273  &lt; 2e-16 ***\nDESTIN_SZTMSZ05       0.6510306  0.0040091   162.390  &lt; 2e-16 ***\nDESTIN_SZTNSZ01      -0.7109821  0.0044663  -159.188  &lt; 2e-16 ***\nDESTIN_SZTNSZ02      -1.4620229  0.0058144  -251.447  &lt; 2e-16 ***\nDESTIN_SZTNSZ03      -1.4562412  0.0070409  -206.827  &lt; 2e-16 ***\nDESTIN_SZTNSZ04      -1.0851666  0.0054825  -197.934  &lt; 2e-16 ***\nDESTIN_SZTPSZ01      -0.5817555  0.0045298  -128.429  &lt; 2e-16 ***\nDESTIN_SZTPSZ02       0.1808566  0.0031446    57.513  &lt; 2e-16 ***\nDESTIN_SZTPSZ03      -0.4988927  0.0045255  -110.240  &lt; 2e-16 ***\nDESTIN_SZTPSZ04      -1.5628293  0.0061959  -252.235  &lt; 2e-16 ***\nDESTIN_SZTPSZ05      -0.8873261  0.0047840  -185.479  &lt; 2e-16 ***\nDESTIN_SZTPSZ06      -0.2876381  0.0053863   -53.402  &lt; 2e-16 ***\nDESTIN_SZTPSZ07      -1.7906770  0.0089538  -199.991  &lt; 2e-16 ***\nDESTIN_SZTPSZ08      -1.3194188  0.0064723  -203.855  &lt; 2e-16 ***\nDESTIN_SZTPSZ09      -0.6211985  0.0049347  -125.883  &lt; 2e-16 ***\nDESTIN_SZTPSZ10      -0.6393478  0.0059480  -107.489  &lt; 2e-16 ***\nDESTIN_SZTPSZ11      -0.3804245  0.0040839   -93.152  &lt; 2e-16 ***\nDESTIN_SZTPSZ12      -0.8566449  0.0050890  -168.331  &lt; 2e-16 ***\nDESTIN_SZTSSZ01      -0.6057724  0.0191686   -31.602  &lt; 2e-16 ***\nDESTIN_SZTSSZ02       1.0228252  0.0073989   138.240  &lt; 2e-16 ***\nDESTIN_SZTSSZ03       1.7210049  0.0054964   313.117  &lt; 2e-16 ***\nDESTIN_SZTSSZ04       1.6552387  0.0055719   297.069  &lt; 2e-16 ***\nDESTIN_SZTSSZ05       1.8953793  0.0058191   325.717  &lt; 2e-16 ***\nDESTIN_SZTSSZ06       0.9420685  0.0094085   100.130  &lt; 2e-16 ***\nDESTIN_SZWCSZ01       1.6641119  0.0036267   458.847  &lt; 2e-16 ***\nDESTIN_SZWCSZ02       0.1145004  0.0081389    14.068  &lt; 2e-16 ***\nDESTIN_SZWCSZ03      -1.2456001  0.0229509   -54.272  &lt; 2e-16 ***\nDESTIN_SZWDSZ01       1.6721786  0.0029145   573.752  &lt; 2e-16 ***\nDESTIN_SZWDSZ02      -0.2568974  0.0047005   -54.653  &lt; 2e-16 ***\nDESTIN_SZWDSZ03       1.2710250  0.0030587   415.540  &lt; 2e-16 ***\nDESTIN_SZWDSZ04       0.2153072  0.0044239    48.669  &lt; 2e-16 ***\nDESTIN_SZWDSZ05       0.2343907  0.0042605    55.015  &lt; 2e-16 ***\nDESTIN_SZWDSZ06       0.5955289  0.0033837   176.001  &lt; 2e-16 ***\nDESTIN_SZWDSZ07       1.2712699  0.0042065   302.217  &lt; 2e-16 ***\nDESTIN_SZWDSZ08       0.7528739  0.0050831   148.112  &lt; 2e-16 ***\nDESTIN_SZWDSZ09       0.7921131  0.0036639   216.196  &lt; 2e-16 ***\nDESTIN_SZYSSZ01       1.2635195  0.0031437   401.923  &lt; 2e-16 ***\nDESTIN_SZYSSZ02       0.2534000  0.0041190    61.519  &lt; 2e-16 ***\nDESTIN_SZYSSZ03      -0.0477465  0.0043261   -11.037  &lt; 2e-16 ***\nDESTIN_SZYSSZ04       0.0517178  0.0040947    12.631  &lt; 2e-16 ***\nDESTIN_SZYSSZ05      -1.5878543  0.0085780  -185.108  &lt; 2e-16 ***\nDESTIN_SZYSSZ06      -1.2417883  0.0064833  -191.535  &lt; 2e-16 ***\nDESTIN_SZYSSZ07      -0.8080207  0.0079004  -102.276  &lt; 2e-16 ***\nDESTIN_SZYSSZ08       0.7024251  0.0032453   216.443  &lt; 2e-16 ***\nDESTIN_SZYSSZ09       0.3893030  0.0033390   116.593  &lt; 2e-16 ***\nlog(ORIGIN_AGE25_64)  0.2272793  0.0001037  2191.851  &lt; 2e-16 ***\nlog(dist)            -0.7146129  0.0001018 -7020.061  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 105499054  on 20915  degrees of freedom\nResidual deviance:  44679882  on 20604  degrees of freedom\nAIC: 44812892\n\nNumber of Fisher Scoring iterations: 7\n\n\nNext, we can examine how the constraints hold for destinations this time.\n\nCalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)\n\n[1] 0.485937\n\n\n\n8.8 Doubly Constrained\nIn this section, We will fit a doubly constrained SIM.\n\n\n\n\n\n\nNote\n\n\n\nThe general formula of Doubly Constrained Spatial Interaction Model\n\\(\\lambda_{ij} = \\exp \\left( k + \\mu_i + \\alpha_i - \\beta \\ln d_{ij} \\right)\\)\nNotice that the difference between Unconstrained Spatial Interaction Model and this formula lies in the second and third term. Comparing Unconstrained Spatial Interaction Model formula and Doubly Constrained Spatial Interaction Model, it is \\(\\mu \\ln V_i\\) compared to \\(\\mu_i\\) and \\(\\alpha \\ln W_j\\) compared to \\(\\alpha_i\\) respectively.\n\n\n\ndbcSIM &lt;- glm(formula = TRIPS ~\n                ORIGIN_SZ +\n                DESTIN_SZ +\n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(dbcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + DESTIN_SZ + log(dist), family = poisson(link = \"log\"), \n    data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                  Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)     12.8209944  0.0037017  3463.498  &lt; 2e-16 ***\nORIGIN_SZAMSZ02  1.0211738  0.0037920   269.300  &lt; 2e-16 ***\nORIGIN_SZAMSZ03  0.5918913  0.0038618   153.267  &lt; 2e-16 ***\nORIGIN_SZAMSZ04  0.1495750  0.0043158    34.658  &lt; 2e-16 ***\nORIGIN_SZAMSZ05  0.0342910  0.0049206     6.969 3.20e-12 ***\nORIGIN_SZAMSZ06  0.4990749  0.0044867   111.235  &lt; 2e-16 ***\nORIGIN_SZAMSZ07 -0.7632253  0.0074431  -102.541  &lt; 2e-16 ***\nORIGIN_SZAMSZ08 -0.6370000  0.0069109   -92.174  &lt; 2e-16 ***\nORIGIN_SZAMSZ09  0.4389776  0.0046271    94.871  &lt; 2e-16 ***\nORIGIN_SZAMSZ10  0.4528313  0.0040674   111.331  &lt; 2e-16 ***\nORIGIN_SZAMSZ11 -1.5882086  0.0091196  -174.153  &lt; 2e-16 ***\nORIGIN_SZAMSZ12 -1.6680341  0.0090745  -183.815  &lt; 2e-16 ***\nORIGIN_SZBDSZ01  0.7900065  0.0037852   208.710  &lt; 2e-16 ***\nORIGIN_SZBDSZ02  0.4100908  0.0043348    94.604  &lt; 2e-16 ***\nORIGIN_SZBDSZ03  0.8165741  0.0038527   211.949  &lt; 2e-16 ***\nORIGIN_SZBDSZ04  1.4216001  0.0033859   419.856  &lt; 2e-16 ***\nORIGIN_SZBDSZ05  0.5426736  0.0038342   141.535  &lt; 2e-16 ***\nORIGIN_SZBDSZ06  0.8337532  0.0038916   214.246  &lt; 2e-16 ***\nORIGIN_SZBDSZ07 -0.8141464  0.0070275  -115.852  &lt; 2e-16 ***\nORIGIN_SZBDSZ08 -0.6895439  0.0067720  -101.822  &lt; 2e-16 ***\nORIGIN_SZBKSZ01 -0.1417253  0.0054077   -26.208  &lt; 2e-16 ***\nORIGIN_SZBKSZ02  0.5709571  0.0044624   127.949  &lt; 2e-16 ***\nORIGIN_SZBKSZ03  1.0136255  0.0041269   245.613  &lt; 2e-16 ***\nORIGIN_SZBKSZ04 -0.0550877  0.0050301   -10.952  &lt; 2e-16 ***\nORIGIN_SZBKSZ05  0.1809565  0.0046783    38.680  &lt; 2e-16 ***\nORIGIN_SZBKSZ06  0.3522991  0.0050200    70.179  &lt; 2e-16 ***\nORIGIN_SZBKSZ07  0.8090159  0.0038448   210.417  &lt; 2e-16 ***\nORIGIN_SZBKSZ08  0.3293552  0.0044605    73.839  &lt; 2e-16 ***\nORIGIN_SZBKSZ09  0.1029554  0.0047049    21.883  &lt; 2e-16 ***\nORIGIN_SZBLSZ01 -1.7475447  0.0109717  -159.277  &lt; 2e-16 ***\nORIGIN_SZBLSZ02 -2.8734452  0.0158781  -180.969  &lt; 2e-16 ***\nORIGIN_SZBLSZ03 -5.0152771  0.0334310  -150.019  &lt; 2e-16 ***\nORIGIN_SZBLSZ04 -2.2662350  0.0166319  -136.258  &lt; 2e-16 ***\nORIGIN_SZBMSZ01  0.2535848  0.0040863    62.058  &lt; 2e-16 ***\nORIGIN_SZBMSZ02 -1.0064943  0.0057776  -174.207  &lt; 2e-16 ***\nORIGIN_SZBMSZ03 -0.0690787  0.0046447   -14.872  &lt; 2e-16 ***\nORIGIN_SZBMSZ04  0.3074282  0.0041340    74.365  &lt; 2e-16 ***\nORIGIN_SZBMSZ05 -1.0255742  0.0062091  -165.172  &lt; 2e-16 ***\nORIGIN_SZBMSZ06 -1.2327549  0.0097168  -126.869  &lt; 2e-16 ***\nORIGIN_SZBMSZ07 -0.2831713  0.0046087   -61.443  &lt; 2e-16 ***\nORIGIN_SZBMSZ08 -0.1874351  0.0046013   -40.736  &lt; 2e-16 ***\nORIGIN_SZBMSZ09 -0.7228122  0.0058864  -122.793  &lt; 2e-16 ***\nORIGIN_SZBMSZ10 -0.8077952  0.0062270  -129.725  &lt; 2e-16 ***\nORIGIN_SZBMSZ11 -0.4924012  0.0054629   -90.136  &lt; 2e-16 ***\nORIGIN_SZBMSZ12 -0.6909135  0.0072100   -95.827  &lt; 2e-16 ***\nORIGIN_SZBMSZ13  0.0512890  0.0045905    11.173  &lt; 2e-16 ***\nORIGIN_SZBMSZ14 -0.2568311  0.0054867   -46.810  &lt; 2e-16 ***\nORIGIN_SZBMSZ15  0.0870108  0.0049432    17.602  &lt; 2e-16 ***\nORIGIN_SZBMSZ16 -0.9610030  0.0061491  -156.284  &lt; 2e-16 ***\nORIGIN_SZBMSZ17 -1.4357633  0.0093761  -153.131  &lt; 2e-16 ***\nORIGIN_SZBPSZ01  0.5477033  0.0046878   116.836  &lt; 2e-16 ***\nORIGIN_SZBPSZ02  0.8280377  0.0051841   159.727  &lt; 2e-16 ***\nORIGIN_SZBPSZ03  1.1025706  0.0048263   228.452  &lt; 2e-16 ***\nORIGIN_SZBPSZ04  0.7644581  0.0042529   179.748  &lt; 2e-16 ***\nORIGIN_SZBPSZ05  0.5761734  0.0039555   145.663  &lt; 2e-16 ***\nORIGIN_SZBPSZ06 -0.8038843  0.0067269  -119.503  &lt; 2e-16 ***\nORIGIN_SZBPSZ07 -0.7081274  0.0067298  -105.223  &lt; 2e-16 ***\nORIGIN_SZBSSZ01  0.0623814  0.0044582    13.993  &lt; 2e-16 ***\nORIGIN_SZBSSZ02  0.5536861  0.0039874   138.858  &lt; 2e-16 ***\nORIGIN_SZBSSZ03  0.2359262  0.0039552    59.649  &lt; 2e-16 ***\nORIGIN_SZBTSZ01  0.0704870  0.0043712    16.125  &lt; 2e-16 ***\nORIGIN_SZBTSZ02 -0.7549336  0.0061482  -122.789  &lt; 2e-16 ***\nORIGIN_SZBTSZ03 -0.0350744  0.0047023    -7.459 8.72e-14 ***\nORIGIN_SZBTSZ04 -0.2858571  0.0078090   -36.606  &lt; 2e-16 ***\nORIGIN_SZBTSZ05 -1.3311102  0.0083964  -158.534  &lt; 2e-16 ***\nORIGIN_SZBTSZ06 -0.5039784  0.0057973   -86.934  &lt; 2e-16 ***\nORIGIN_SZBTSZ07 -1.5400199  0.0087117  -176.777  &lt; 2e-16 ***\nORIGIN_SZBTSZ08 -0.7887679  0.0068453  -115.227  &lt; 2e-16 ***\nORIGIN_SZCCSZ01 -1.5745039  0.0108105  -145.646  &lt; 2e-16 ***\nORIGIN_SZCHSZ01 -1.1361530  0.0093612  -121.369  &lt; 2e-16 ***\nORIGIN_SZCHSZ02 -0.9128000  0.0069668  -131.022  &lt; 2e-16 ***\nORIGIN_SZCHSZ03 -0.4472993  0.0049038   -91.215  &lt; 2e-16 ***\nORIGIN_SZCKSZ01  0.5127473  0.0042287   121.254  &lt; 2e-16 ***\nORIGIN_SZCKSZ02  1.2022570  0.0043552   276.053  &lt; 2e-16 ***\nORIGIN_SZCKSZ03  0.8860008  0.0039444   224.624  &lt; 2e-16 ***\nORIGIN_SZCKSZ04  1.8272911  0.0041197   443.546  &lt; 2e-16 ***\nORIGIN_SZCKSZ05  1.5316688  0.0051392   298.034  &lt; 2e-16 ***\nORIGIN_SZCKSZ06  1.1564174  0.0054508   212.157  &lt; 2e-16 ***\nORIGIN_SZCLSZ01 -0.6010696  0.0058966  -101.936  &lt; 2e-16 ***\nORIGIN_SZCLSZ02 -1.3058599  0.0106228  -122.929  &lt; 2e-16 ***\nORIGIN_SZCLSZ03 -0.1976445  0.0053882   -36.681  &lt; 2e-16 ***\nORIGIN_SZCLSZ04  0.8670957  0.0037702   229.989  &lt; 2e-16 ***\nORIGIN_SZCLSZ05 -1.4675258  0.0102663  -142.946  &lt; 2e-16 ***\nORIGIN_SZCLSZ06  0.9061705  0.0036171   250.525  &lt; 2e-16 ***\nORIGIN_SZCLSZ07 -0.0547981  0.0045274   -12.104  &lt; 2e-16 ***\nORIGIN_SZCLSZ08  0.2882434  0.0051775    55.672  &lt; 2e-16 ***\nORIGIN_SZCLSZ09 -2.2592927  0.0139890  -161.505  &lt; 2e-16 ***\nORIGIN_SZDTSZ01 -1.3547208  0.0070619  -191.836  &lt; 2e-16 ***\nORIGIN_SZDTSZ02 -1.2364916  0.0064723  -191.043  &lt; 2e-16 ***\nORIGIN_SZDTSZ03 -2.5347494  0.0130438  -194.326  &lt; 2e-16 ***\nORIGIN_SZDTSZ04 -3.4173562  0.0929323   -36.773  &lt; 2e-16 ***\nORIGIN_SZDTSZ05 -2.8339289  0.0214468  -132.138  &lt; 2e-16 ***\nORIGIN_SZDTSZ06 -2.8287483  0.0173910  -162.656  &lt; 2e-16 ***\nORIGIN_SZDTSZ07 -1.4138308  0.0191288   -73.911  &lt; 2e-16 ***\nORIGIN_SZDTSZ08 -2.0630511  0.0097602  -211.373  &lt; 2e-16 ***\nORIGIN_SZDTSZ09 -2.6480874  0.0206165  -128.445  &lt; 2e-16 ***\nORIGIN_SZDTSZ10 -1.8351696  0.0104263  -176.013  &lt; 2e-16 ***\nORIGIN_SZDTSZ11 -1.9555077  0.0108002  -181.061  &lt; 2e-16 ***\nORIGIN_SZDTSZ12 -3.1193610  0.0255389  -122.141  &lt; 2e-16 ***\nORIGIN_SZDTSZ13 -2.0406987  0.0121657  -167.742  &lt; 2e-16 ***\nORIGIN_SZGLSZ01 -1.3805437  0.0072209  -191.187  &lt; 2e-16 ***\nORIGIN_SZGLSZ02  0.2358565  0.0041565    56.744  &lt; 2e-16 ***\nORIGIN_SZGLSZ03  0.0341089  0.0041526     8.214  &lt; 2e-16 ***\nORIGIN_SZGLSZ04  0.9786034  0.0035154   278.375  &lt; 2e-16 ***\nORIGIN_SZGLSZ05  0.5811863  0.0037114   156.594  &lt; 2e-16 ***\nORIGIN_SZHGSZ01  0.1686665  0.0040881    41.258  &lt; 2e-16 ***\nORIGIN_SZHGSZ02  0.6787539  0.0039351   172.488  &lt; 2e-16 ***\nORIGIN_SZHGSZ03  0.4547294  0.0042831   106.169  &lt; 2e-16 ***\nORIGIN_SZHGSZ04  0.9678527  0.0036761   263.282  &lt; 2e-16 ***\nORIGIN_SZHGSZ05  1.2917000  0.0036294   355.904  &lt; 2e-16 ***\nORIGIN_SZHGSZ06  0.2142855  0.0043515    49.244  &lt; 2e-16 ***\nORIGIN_SZHGSZ07  0.6701110  0.0037993   176.380  &lt; 2e-16 ***\nORIGIN_SZHGSZ08  0.1562024  0.0043722    35.726  &lt; 2e-16 ***\nORIGIN_SZHGSZ09 -0.7232166  0.0059862  -120.814  &lt; 2e-16 ***\nORIGIN_SZHGSZ10 -3.1262897  0.0398756   -78.401  &lt; 2e-16 ***\nORIGIN_SZJESZ01  0.4508052  0.0043040   104.741  &lt; 2e-16 ***\nORIGIN_SZJESZ02  0.3712710  0.0042775    86.796  &lt; 2e-16 ***\nORIGIN_SZJESZ03  0.3805622  0.0045067    84.443  &lt; 2e-16 ***\nORIGIN_SZJESZ04 -1.0165889  0.0072792  -139.656  &lt; 2e-16 ***\nORIGIN_SZJESZ05 -1.8580763  0.0120151  -154.645  &lt; 2e-16 ***\nORIGIN_SZJESZ06  0.2384917  0.0042026    56.749  &lt; 2e-16 ***\nORIGIN_SZJESZ07 -1.6783671  0.0094270  -178.039  &lt; 2e-16 ***\nORIGIN_SZJESZ08 -0.6513621  0.0086221   -75.545  &lt; 2e-16 ***\nORIGIN_SZJESZ09  0.4198064  0.0044417    94.515  &lt; 2e-16 ***\nORIGIN_SZJESZ10 -2.7745302  0.0169190  -163.989  &lt; 2e-16 ***\nORIGIN_SZJESZ11 -3.2086375  0.0173519  -184.916  &lt; 2e-16 ***\nORIGIN_SZJWSZ01  0.4595116  0.0057545    79.852  &lt; 2e-16 ***\nORIGIN_SZJWSZ02  0.9856003  0.0039792   247.690  &lt; 2e-16 ***\nORIGIN_SZJWSZ03  1.1845095  0.0037710   314.110  &lt; 2e-16 ***\nORIGIN_SZJWSZ04  0.9343282  0.0038871   240.367  &lt; 2e-16 ***\nORIGIN_SZJWSZ05 -1.5766208  0.0102768  -153.416  &lt; 2e-16 ***\nORIGIN_SZJWSZ06 -1.2683438  0.0090746  -139.769  &lt; 2e-16 ***\nORIGIN_SZJWSZ07 -2.2397234  0.0229427   -97.623  &lt; 2e-16 ***\nORIGIN_SZJWSZ08  1.9992609  0.0037950   526.820  &lt; 2e-16 ***\nORIGIN_SZJWSZ09  1.4974956  0.0035176   425.719  &lt; 2e-16 ***\nORIGIN_SZKLSZ01  0.3247754  0.0040006    81.181  &lt; 2e-16 ***\nORIGIN_SZKLSZ02 -0.3400447  0.0049775   -68.317  &lt; 2e-16 ***\nORIGIN_SZKLSZ03 -0.2580403  0.0049578   -52.048  &lt; 2e-16 ***\nORIGIN_SZKLSZ04 -1.2415420  0.0070255  -176.720  &lt; 2e-16 ***\nORIGIN_SZKLSZ05 -0.5469651  0.0066950   -81.698  &lt; 2e-16 ***\nORIGIN_SZKLSZ06 -0.2888779  0.0046575   -62.024  &lt; 2e-16 ***\nORIGIN_SZKLSZ07 -0.6642053  0.0061209  -108.514  &lt; 2e-16 ***\nORIGIN_SZKLSZ08 -0.7044480  0.0053085  -132.701  &lt; 2e-16 ***\nORIGIN_SZKLSZ09 -1.2073066  0.0067273  -179.465  &lt; 2e-16 ***\nORIGIN_SZLKSZ01 -2.3832693  0.0290465   -82.050  &lt; 2e-16 ***\nORIGIN_SZMDSZ01 -1.6623583  0.0228095   -72.880  &lt; 2e-16 ***\nORIGIN_SZMDSZ02 -1.0894780  0.0101251  -107.601  &lt; 2e-16 ***\nORIGIN_SZMDSZ03 -1.5576626  0.0133799  -116.418  &lt; 2e-16 ***\nORIGIN_SZMPSZ01 -0.8193562  0.0065154  -125.757  &lt; 2e-16 ***\nORIGIN_SZMPSZ02 -0.4499772  0.0054364   -82.771  &lt; 2e-16 ***\nORIGIN_SZMPSZ03  0.1072985  0.0043578    24.622  &lt; 2e-16 ***\nORIGIN_SZMSSZ01 -6.6161570  0.2716550   -24.355  &lt; 2e-16 ***\nORIGIN_SZMUSZ01 -0.9145758  0.0058126  -157.344  &lt; 2e-16 ***\nORIGIN_SZMUSZ02 -2.6469649  0.0143884  -183.965  &lt; 2e-16 ***\nORIGIN_SZMUSZ03 -1.4817336  0.0068290  -216.977  &lt; 2e-16 ***\nORIGIN_SZNTSZ01 -2.2277160  0.0241686   -92.174  &lt; 2e-16 ***\nORIGIN_SZNTSZ02 -2.0111227  0.0123512  -162.828  &lt; 2e-16 ***\nORIGIN_SZNTSZ03 -0.4524949  0.0058585   -77.238  &lt; 2e-16 ***\nORIGIN_SZNTSZ05 -2.7479537  0.0372348   -73.801  &lt; 2e-16 ***\nORIGIN_SZNTSZ06 -2.9645842  0.0400589   -74.006  &lt; 2e-16 ***\nORIGIN_SZNVSZ01  0.8704060  0.0036475   238.629  &lt; 2e-16 ***\nORIGIN_SZNVSZ02 -0.2594842  0.0048904   -53.060  &lt; 2e-16 ***\nORIGIN_SZNVSZ03 -0.9402480  0.0059727  -157.425  &lt; 2e-16 ***\nORIGIN_SZNVSZ04 -1.0520174  0.0071039  -148.090  &lt; 2e-16 ***\nORIGIN_SZNVSZ05 -2.2991493  0.0129008  -178.217  &lt; 2e-16 ***\nORIGIN_SZORSZ01 -2.5474177  0.0262225   -97.146  &lt; 2e-16 ***\nORIGIN_SZORSZ02 -1.0318529  0.0057495  -179.468  &lt; 2e-16 ***\nORIGIN_SZORSZ03 -1.3389968  0.0068438  -195.652  &lt; 2e-16 ***\nORIGIN_SZOTSZ01 -1.3085717  0.0072750  -179.873  &lt; 2e-16 ***\nORIGIN_SZOTSZ02 -1.5045539  0.0081728  -184.092  &lt; 2e-16 ***\nORIGIN_SZOTSZ03 -0.4288554  0.0053691   -79.875  &lt; 2e-16 ***\nORIGIN_SZOTSZ04 -0.5091409  0.0084280   -60.411  &lt; 2e-16 ***\nORIGIN_SZPGSZ01  0.6909111  0.0106331    64.978  &lt; 2e-16 ***\nORIGIN_SZPGSZ02 -0.2397081  0.0057837   -41.446  &lt; 2e-16 ***\nORIGIN_SZPGSZ03  0.9957099  0.0037730   263.907  &lt; 2e-16 ***\nORIGIN_SZPGSZ04  1.1597337  0.0037624   308.241  &lt; 2e-16 ***\nORIGIN_SZPGSZ05  0.6492546  0.0046923   138.366  &lt; 2e-16 ***\nORIGIN_SZPLSZ01 -0.5839333  0.0081061   -72.036  &lt; 2e-16 ***\nORIGIN_SZPLSZ02 -1.1064599  0.0114132   -96.946  &lt; 2e-16 ***\nORIGIN_SZPLSZ03 -3.2526684  0.0320369  -101.529  &lt; 2e-16 ***\nORIGIN_SZPLSZ04 -3.7343048  0.0355944  -104.913  &lt; 2e-16 ***\nORIGIN_SZPLSZ05 -2.2665620  0.0179181  -126.496  &lt; 2e-16 ***\nORIGIN_SZPNSZ01  1.0212905  0.0047143   216.637  &lt; 2e-16 ***\nORIGIN_SZPNSZ02 -1.7538504  0.0111979  -156.623  &lt; 2e-16 ***\nORIGIN_SZPNSZ03 -2.7059069  0.0179400  -150.831  &lt; 2e-16 ***\nORIGIN_SZPNSZ04 -4.6167880  0.0263377  -175.292  &lt; 2e-16 ***\nORIGIN_SZPNSZ05 -3.0427726  0.0196666  -154.718  &lt; 2e-16 ***\nORIGIN_SZPRSZ01 -0.6289953  0.0096046   -65.489  &lt; 2e-16 ***\nORIGIN_SZPRSZ02  1.0206156  0.0039549   258.062  &lt; 2e-16 ***\nORIGIN_SZPRSZ03  0.4912065  0.0039421   124.606  &lt; 2e-16 ***\nORIGIN_SZPRSZ04 -0.4025880  0.0064054   -62.852  &lt; 2e-16 ***\nORIGIN_SZPRSZ05  1.1225721  0.0037798   296.996  &lt; 2e-16 ***\nORIGIN_SZPRSZ06 -0.9516629  0.0070083  -135.791  &lt; 2e-16 ***\nORIGIN_SZPRSZ07 -2.5610511  0.0169070  -151.478  &lt; 2e-16 ***\nORIGIN_SZPRSZ08  0.0236310  0.0051603     4.579 4.66e-06 ***\nORIGIN_SZQTSZ01  0.1179359  0.0055302    21.326  &lt; 2e-16 ***\nORIGIN_SZQTSZ02 -0.4078722  0.0051104   -79.812  &lt; 2e-16 ***\nORIGIN_SZQTSZ03  0.1193841  0.0047115    25.339  &lt; 2e-16 ***\nORIGIN_SZQTSZ04 -0.9691910  0.0062944  -153.978  &lt; 2e-16 ***\nORIGIN_SZQTSZ05  0.0998289  0.0046955    21.260  &lt; 2e-16 ***\nORIGIN_SZQTSZ06 -0.2814267  0.0053649   -52.457  &lt; 2e-16 ***\nORIGIN_SZQTSZ07 -1.2548647  0.0078707  -159.436  &lt; 2e-16 ***\nORIGIN_SZQTSZ08 -0.2531659  0.0048952   -51.717  &lt; 2e-16 ***\nORIGIN_SZQTSZ09 -0.4447711  0.0054252   -81.983  &lt; 2e-16 ***\nORIGIN_SZQTSZ10 -0.3430013  0.0053350   -64.293  &lt; 2e-16 ***\nORIGIN_SZQTSZ11 -1.4903190  0.0077334  -192.711  &lt; 2e-16 ***\nORIGIN_SZQTSZ12 -0.6577501  0.0065839   -99.903  &lt; 2e-16 ***\nORIGIN_SZQTSZ13 -0.2096789  0.0050085   -41.864  &lt; 2e-16 ***\nORIGIN_SZQTSZ14 -1.3328463  0.0072466  -183.926  &lt; 2e-16 ***\nORIGIN_SZQTSZ15 -1.0923358  0.0087615  -124.675  &lt; 2e-16 ***\nORIGIN_SZRCSZ01 -0.3755902  0.0053737   -69.894  &lt; 2e-16 ***\nORIGIN_SZRCSZ02 -2.0022955  0.0148554  -134.786  &lt; 2e-16 ***\nORIGIN_SZRCSZ03 -0.9294765  0.0074480  -124.795  &lt; 2e-16 ***\nORIGIN_SZRCSZ04 -2.0113020  0.0111150  -180.953  &lt; 2e-16 ***\nORIGIN_SZRCSZ05 -2.2815677  0.0134388  -169.775  &lt; 2e-16 ***\nORIGIN_SZRCSZ06 -0.1380185  0.0069989   -19.720  &lt; 2e-16 ***\nORIGIN_SZRCSZ08 -2.2838985  0.0161757  -141.193  &lt; 2e-16 ***\nORIGIN_SZRCSZ09 -1.6700447  0.0122155  -136.715  &lt; 2e-16 ***\nORIGIN_SZRCSZ10 -1.4653375  0.0070450  -207.996  &lt; 2e-16 ***\nORIGIN_SZRVSZ01 -2.4788050  0.0131632  -188.313  &lt; 2e-16 ***\nORIGIN_SZRVSZ02 -0.5963401  0.0068203   -87.436  &lt; 2e-16 ***\nORIGIN_SZRVSZ03 -1.3147500  0.0098596  -133.347  &lt; 2e-16 ***\nORIGIN_SZRVSZ04 -1.5215037  0.0138329  -109.992  &lt; 2e-16 ***\nORIGIN_SZRVSZ05 -1.6049655  0.0123359  -130.105  &lt; 2e-16 ***\nORIGIN_SZSBSZ01  0.8915036  0.0049554   179.906  &lt; 2e-16 ***\nORIGIN_SZSBSZ02 -0.5941713  0.0065942   -90.106  &lt; 2e-16 ***\nORIGIN_SZSBSZ03  0.5697082  0.0041613   136.905  &lt; 2e-16 ***\nORIGIN_SZSBSZ04  0.3844219  0.0047855    80.331  &lt; 2e-16 ***\nORIGIN_SZSBSZ05 -0.0485925  0.0057352    -8.473  &lt; 2e-16 ***\nORIGIN_SZSBSZ06 -0.9922846  0.0139889   -70.934  &lt; 2e-16 ***\nORIGIN_SZSBSZ07 -0.1042518  0.0098005   -10.637  &lt; 2e-16 ***\nORIGIN_SZSBSZ08 -1.9893851  0.0098004  -202.991  &lt; 2e-16 ***\nORIGIN_SZSBSZ09 -1.1240957  0.0073195  -153.576  &lt; 2e-16 ***\nORIGIN_SZSESZ02  1.2134372  0.0036997   327.981  &lt; 2e-16 ***\nORIGIN_SZSESZ03  1.1004236  0.0035731   307.971  &lt; 2e-16 ***\nORIGIN_SZSESZ04  1.1489236  0.0040956   280.526  &lt; 2e-16 ***\nORIGIN_SZSESZ05 -0.1461118  0.0049210   -29.691  &lt; 2e-16 ***\nORIGIN_SZSESZ06  1.1678137  0.0038786   301.090  &lt; 2e-16 ***\nORIGIN_SZSESZ07 -1.9241440  0.0140591  -136.861  &lt; 2e-16 ***\nORIGIN_SZSGSZ01 -0.7959607  0.0069928  -113.826  &lt; 2e-16 ***\nORIGIN_SZSGSZ02 -1.2359549  0.0082778  -149.310  &lt; 2e-16 ***\nORIGIN_SZSGSZ03  0.3282470  0.0043939    74.705  &lt; 2e-16 ***\nORIGIN_SZSGSZ04  0.4006316  0.0040311    99.384  &lt; 2e-16 ***\nORIGIN_SZSGSZ05 -1.4296109  0.0082085  -174.163  &lt; 2e-16 ***\nORIGIN_SZSGSZ06  0.3863254  0.0038318   100.822  &lt; 2e-16 ***\nORIGIN_SZSGSZ07 -0.4469943  0.0050392   -88.703  &lt; 2e-16 ***\nORIGIN_SZSKSZ01 -0.1580149  0.0069175   -22.843  &lt; 2e-16 ***\nORIGIN_SZSKSZ02  0.1537997  0.0052382    29.361  &lt; 2e-16 ***\nORIGIN_SZSKSZ03 -0.4326739  0.0063779   -67.840  &lt; 2e-16 ***\nORIGIN_SZSKSZ04 -2.0322053  0.0227241   -89.430  &lt; 2e-16 ***\nORIGIN_SZSKSZ05 -1.1835613  0.0147778   -80.091  &lt; 2e-16 ***\nORIGIN_SZSLSZ01 -2.9837421  0.0258339  -115.497  &lt; 2e-16 ***\nORIGIN_SZSLSZ04 -0.2992181  0.0058854   -50.841  &lt; 2e-16 ***\nORIGIN_SZSRSZ01 -1.0561834  0.0071740  -147.223  &lt; 2e-16 ***\nORIGIN_SZSRSZ02 -1.4438175  0.0072835  -198.231  &lt; 2e-16 ***\nORIGIN_SZSRSZ03 -2.3619347  0.0152284  -155.101  &lt; 2e-16 ***\nORIGIN_SZSVSZ01 -2.2403092  0.0416577   -53.779  &lt; 2e-16 ***\nORIGIN_SZTHSZ01 -3.3500671  0.0462044   -72.505  &lt; 2e-16 ***\nORIGIN_SZTHSZ03 -0.8400127  0.0131456   -63.901  &lt; 2e-16 ***\nORIGIN_SZTHSZ04 -2.3078055  0.0244784   -94.279  &lt; 2e-16 ***\nORIGIN_SZTHSZ06 -1.2485071  0.0110208  -113.287  &lt; 2e-16 ***\nORIGIN_SZTMSZ01  0.8034289  0.0043154   186.178  &lt; 2e-16 ***\nORIGIN_SZTMSZ02  1.5977627  0.0033303   479.760  &lt; 2e-16 ***\nORIGIN_SZTMSZ03  1.2010374  0.0035316   340.081  &lt; 2e-16 ***\nORIGIN_SZTMSZ04  0.3986725  0.0041038    97.147  &lt; 2e-16 ***\nORIGIN_SZTMSZ05 -0.8775543  0.0064806  -135.412  &lt; 2e-16 ***\nORIGIN_SZTNSZ01 -0.7901703  0.0059867  -131.989  &lt; 2e-16 ***\nORIGIN_SZTNSZ02 -0.6947947  0.0058037  -119.716  &lt; 2e-16 ***\nORIGIN_SZTNSZ03 -1.1794385  0.0075996  -155.198  &lt; 2e-16 ***\nORIGIN_SZTNSZ04 -0.2906944  0.0056078   -51.837  &lt; 2e-16 ***\nORIGIN_SZTPSZ01 -0.4220000  0.0052288   -80.706  &lt; 2e-16 ***\nORIGIN_SZTPSZ02  0.5186540  0.0036928   140.449  &lt; 2e-16 ***\nORIGIN_SZTPSZ03 -0.4340206  0.0052061   -83.368  &lt; 2e-16 ***\nORIGIN_SZTPSZ04 -0.0658329  0.0049011   -13.432  &lt; 2e-16 ***\nORIGIN_SZTPSZ05  0.0876853  0.0051031    17.183  &lt; 2e-16 ***\nORIGIN_SZTPSZ06  0.5914622  0.0057688   102.528  &lt; 2e-16 ***\nORIGIN_SZTPSZ07  0.0863881  0.0051162    16.885  &lt; 2e-16 ***\nORIGIN_SZTPSZ08 -0.3835720  0.0066615   -57.580  &lt; 2e-16 ***\nORIGIN_SZTPSZ09 -0.4862839  0.0054787   -88.759  &lt; 2e-16 ***\nORIGIN_SZTPSZ10 -0.1484374  0.0054913   -27.031  &lt; 2e-16 ***\nORIGIN_SZTPSZ11  0.3115335  0.0043348    71.868  &lt; 2e-16 ***\nORIGIN_SZTPSZ12 -0.4386990  0.0053693   -81.705  &lt; 2e-16 ***\nORIGIN_SZTSSZ01 -3.4734418  0.0409852   -84.749  &lt; 2e-16 ***\nORIGIN_SZTSSZ02  0.1327694  0.0076669    17.317  &lt; 2e-16 ***\nORIGIN_SZTSSZ03 -0.1394126  0.0079630   -17.508  &lt; 2e-16 ***\nORIGIN_SZTSSZ04 -0.4834844  0.0081910   -59.026  &lt; 2e-16 ***\nORIGIN_SZTSSZ05 -2.6972890  0.0129593  -208.135  &lt; 2e-16 ***\nORIGIN_SZTSSZ06 -3.1376055  0.0185958  -168.727  &lt; 2e-16 ***\nORIGIN_SZWCSZ01 -0.8838079  0.0063970  -138.159  &lt; 2e-16 ***\nORIGIN_SZWCSZ02 -2.7133955  0.0253131  -107.194  &lt; 2e-16 ***\nORIGIN_SZWCSZ03 -4.6049194  0.1325023   -34.753  &lt; 2e-16 ***\nORIGIN_SZWDSZ01  0.8560664  0.0036494   234.575  &lt; 2e-16 ***\nORIGIN_SZWDSZ02  0.9855869  0.0041492   237.535  &lt; 2e-16 ***\nORIGIN_SZWDSZ03  1.7133802  0.0037306   459.281  &lt; 2e-16 ***\nORIGIN_SZWDSZ04  1.1377918  0.0045405   250.585  &lt; 2e-16 ***\nORIGIN_SZWDSZ05  0.4888027  0.0043787   111.633  &lt; 2e-16 ***\nORIGIN_SZWDSZ06  0.9765953  0.0040953   238.467  &lt; 2e-16 ***\nORIGIN_SZWDSZ07 -0.2293223  0.0058436   -39.243  &lt; 2e-16 ***\nORIGIN_SZWDSZ08 -0.6573590  0.0064698  -101.604  &lt; 2e-16 ***\nORIGIN_SZWDSZ09  1.6829017  0.0038504   437.071  &lt; 2e-16 ***\nORIGIN_SZYSSZ01 -0.4848312  0.0048344  -100.288  &lt; 2e-16 ***\nORIGIN_SZYSSZ02  0.9943936  0.0045034   220.811  &lt; 2e-16 ***\nORIGIN_SZYSSZ03  2.2977837  0.0037334   615.459  &lt; 2e-16 ***\nORIGIN_SZYSSZ04  0.8979911  0.0038661   232.276  &lt; 2e-16 ***\nORIGIN_SZYSSZ05  0.4287521  0.0046808    91.598  &lt; 2e-16 ***\nORIGIN_SZYSSZ06 -0.5936855  0.0075695   -78.432  &lt; 2e-16 ***\nORIGIN_SZYSSZ07 -0.4146970  0.0078162   -53.056  &lt; 2e-16 ***\nORIGIN_SZYSSZ08 -0.3883423  0.0053350   -72.792  &lt; 2e-16 ***\nORIGIN_SZYSSZ09  1.1966606  0.0037486   319.226  &lt; 2e-16 ***\nDESTIN_SZAMSZ02 -0.0636405  0.0036934   -17.231  &lt; 2e-16 ***\nDESTIN_SZAMSZ03  0.1352549  0.0035587    38.006  &lt; 2e-16 ***\nDESTIN_SZAMSZ04 -0.9163012  0.0052190  -175.571  &lt; 2e-16 ***\nDESTIN_SZAMSZ05 -0.8273596  0.0049522  -167.070  &lt; 2e-16 ***\nDESTIN_SZAMSZ06 -0.7114591  0.0048518  -146.637  &lt; 2e-16 ***\nDESTIN_SZAMSZ07 -1.6525934  0.0085950  -192.274  &lt; 2e-16 ***\nDESTIN_SZAMSZ08 -0.8286756  0.0054861  -151.051  &lt; 2e-16 ***\nDESTIN_SZAMSZ09 -1.0100389  0.0052362  -192.896  &lt; 2e-16 ***\nDESTIN_SZAMSZ10  0.0577538  0.0036539    15.806  &lt; 2e-16 ***\nDESTIN_SZAMSZ11  0.0264569  0.0062075     4.262 2.03e-05 ***\nDESTIN_SZAMSZ12  0.0699142  0.0044763    15.619  &lt; 2e-16 ***\nDESTIN_SZBDSZ01  0.4079216  0.0033431   122.020  &lt; 2e-16 ***\nDESTIN_SZBDSZ02 -0.2983737  0.0042145   -70.798  &lt; 2e-16 ***\nDESTIN_SZBDSZ03 -0.1081401  0.0037322   -28.975  &lt; 2e-16 ***\nDESTIN_SZBDSZ04  0.7139597  0.0030744   232.229  &lt; 2e-16 ***\nDESTIN_SZBDSZ05  0.4298721  0.0033834   127.052  &lt; 2e-16 ***\nDESTIN_SZBDSZ06 -0.0090534  0.0038123    -2.375 0.017558 *  \nDESTIN_SZBDSZ07 -0.5446859  0.0074833   -72.787  &lt; 2e-16 ***\nDESTIN_SZBDSZ08 -1.4299619  0.0074446  -192.080  &lt; 2e-16 ***\nDESTIN_SZBKSZ01 -1.2418700  0.0054274  -228.816  &lt; 2e-16 ***\nDESTIN_SZBKSZ02 -0.3747029  0.0045775   -81.858  &lt; 2e-16 ***\nDESTIN_SZBKSZ03 -0.8106383  0.0046912  -172.798  &lt; 2e-16 ***\nDESTIN_SZBKSZ04 -0.0447919  0.0041811   -10.713  &lt; 2e-16 ***\nDESTIN_SZBKSZ05 -0.6469806  0.0046863  -138.059  &lt; 2e-16 ***\nDESTIN_SZBKSZ06 -1.0379007  0.0052498  -197.703  &lt; 2e-16 ***\nDESTIN_SZBKSZ07  0.1008434  0.0035689    28.256  &lt; 2e-16 ***\nDESTIN_SZBKSZ08 -1.1235248  0.0058606  -191.708  &lt; 2e-16 ***\nDESTIN_SZBKSZ09 -0.1769490  0.0042448   -41.686  &lt; 2e-16 ***\nDESTIN_SZBLSZ01 -0.7202679  0.0059344  -121.371  &lt; 2e-16 ***\nDESTIN_SZBLSZ02  0.4289945  0.0057776    74.251  &lt; 2e-16 ***\nDESTIN_SZBLSZ03  1.6577344  0.0062905   263.530  &lt; 2e-16 ***\nDESTIN_SZBLSZ04 -0.4365000  0.0114393   -38.158  &lt; 2e-16 ***\nDESTIN_SZBMSZ01 -0.0437992  0.0038281   -11.442  &lt; 2e-16 ***\nDESTIN_SZBMSZ02 -0.2109099  0.0040034   -52.683  &lt; 2e-16 ***\nDESTIN_SZBMSZ03 -0.5831276  0.0048985  -119.042  &lt; 2e-16 ***\nDESTIN_SZBMSZ04 -0.3088132  0.0042301   -73.004  &lt; 2e-16 ***\nDESTIN_SZBMSZ05 -0.4009981  0.0050362   -79.623  &lt; 2e-16 ***\nDESTIN_SZBMSZ06 -1.1963226  0.0084448  -141.664  &lt; 2e-16 ***\nDESTIN_SZBMSZ07  0.1723604  0.0037269    46.248  &lt; 2e-16 ***\nDESTIN_SZBMSZ08 -0.7228516  0.0048637  -148.622  &lt; 2e-16 ***\nDESTIN_SZBMSZ09 -1.5648751  0.0076588  -204.324  &lt; 2e-16 ***\nDESTIN_SZBMSZ10 -1.0792725  0.0060780  -177.571  &lt; 2e-16 ***\nDESTIN_SZBMSZ11 -1.2337029  0.0060444  -204.105  &lt; 2e-16 ***\nDESTIN_SZBMSZ12 -0.6038761  0.0063848   -94.580  &lt; 2e-16 ***\nDESTIN_SZBMSZ13 -0.0069636  0.0040263    -1.730 0.083716 .  \nDESTIN_SZBMSZ14 -0.6078154  0.0063169   -96.220  &lt; 2e-16 ***\nDESTIN_SZBMSZ15 -0.9452800  0.0058509  -161.562  &lt; 2e-16 ***\nDESTIN_SZBMSZ16 -1.2893936  0.0061729  -208.880  &lt; 2e-16 ***\nDESTIN_SZBMSZ17 -1.3174691  0.0072184  -182.516  &lt; 2e-16 ***\nDESTIN_SZBPSZ01 -0.8121560  0.0046763  -173.675  &lt; 2e-16 ***\nDESTIN_SZBPSZ02 -1.7589943  0.0074436  -236.311  &lt; 2e-16 ***\nDESTIN_SZBPSZ03 -1.6224673  0.0071034  -228.408  &lt; 2e-16 ***\nDESTIN_SZBPSZ04 -0.9099544  0.0051560  -176.486  &lt; 2e-16 ***\nDESTIN_SZBPSZ05  0.2822083  0.0034510    81.776  &lt; 2e-16 ***\nDESTIN_SZBPSZ06 -0.7067413  0.0062576  -112.941  &lt; 2e-16 ***\nDESTIN_SZBPSZ07 -0.5700144  0.0064417   -88.488  &lt; 2e-16 ***\nDESTIN_SZBSSZ01  0.0907030  0.0037765    24.018  &lt; 2e-16 ***\nDESTIN_SZBSSZ02 -0.7477704  0.0043714  -171.058  &lt; 2e-16 ***\nDESTIN_SZBSSZ03  0.3866005  0.0032621   118.514  &lt; 2e-16 ***\nDESTIN_SZBTSZ01  0.1909204  0.0035812    53.312  &lt; 2e-16 ***\nDESTIN_SZBTSZ02 -0.7341012  0.0057096  -128.574  &lt; 2e-16 ***\nDESTIN_SZBTSZ03 -0.0353772  0.0041931    -8.437  &lt; 2e-16 ***\nDESTIN_SZBTSZ04 -1.2491209  0.0082702  -151.039  &lt; 2e-16 ***\nDESTIN_SZBTSZ05 -0.4058884  0.0057519   -70.565  &lt; 2e-16 ***\nDESTIN_SZBTSZ06 -0.6183505  0.0051158  -120.870  &lt; 2e-16 ***\nDESTIN_SZBTSZ07 -1.5213515  0.0080000  -190.170  &lt; 2e-16 ***\nDESTIN_SZBTSZ08 -0.7574454  0.0068701  -110.253  &lt; 2e-16 ***\nDESTIN_SZCCSZ01 -0.3364647  0.0053846   -62.487  &lt; 2e-16 ***\nDESTIN_SZCHSZ01 -1.1192854  0.0075000  -149.238  &lt; 2e-16 ***\nDESTIN_SZCHSZ02 -0.0606036  0.0047464   -12.768  &lt; 2e-16 ***\nDESTIN_SZCHSZ03  1.3032044  0.0033903   384.394  &lt; 2e-16 ***\nDESTIN_SZCKSZ01 -0.4095319  0.0042607   -96.118  &lt; 2e-16 ***\nDESTIN_SZCKSZ02 -0.9058865  0.0047164  -192.071  &lt; 2e-16 ***\nDESTIN_SZCKSZ03  0.2494727  0.0035349    70.575  &lt; 2e-16 ***\nDESTIN_SZCKSZ04 -1.5357890  0.0055042  -279.022  &lt; 2e-16 ***\nDESTIN_SZCKSZ05 -1.2168689  0.0062896  -193.474  &lt; 2e-16 ***\nDESTIN_SZCKSZ06  0.1354467  0.0050849    26.637  &lt; 2e-16 ***\nDESTIN_SZCLSZ01  0.2362502  0.0040934    57.714  &lt; 2e-16 ***\nDESTIN_SZCLSZ02 -2.1201551  0.0109974  -192.787  &lt; 2e-16 ***\nDESTIN_SZCLSZ03 -0.8930509  0.0061663  -144.829  &lt; 2e-16 ***\nDESTIN_SZCLSZ04 -0.0392053  0.0037661   -10.410  &lt; 2e-16 ***\nDESTIN_SZCLSZ05 -0.9701578  0.0071560  -135.572  &lt; 2e-16 ***\nDESTIN_SZCLSZ06  0.0809388  0.0035222    22.980  &lt; 2e-16 ***\nDESTIN_SZCLSZ07 -0.4671167  0.0044749  -104.386  &lt; 2e-16 ***\nDESTIN_SZCLSZ08 -0.4217114  0.0052202   -80.784  &lt; 2e-16 ***\nDESTIN_SZCLSZ09  0.4361858  0.0056700    76.929  &lt; 2e-16 ***\nDESTIN_SZDTSZ01 -0.5713120  0.0045261  -126.226  &lt; 2e-16 ***\nDESTIN_SZDTSZ02 -0.8007120  0.0043987  -182.033  &lt; 2e-16 ***\nDESTIN_SZDTSZ03 -1.0356648  0.0051957  -199.330  &lt; 2e-16 ***\nDESTIN_SZDTSZ04 -0.5609786  0.0111703   -50.221  &lt; 2e-16 ***\nDESTIN_SZDTSZ05 -0.6273075  0.0086387   -72.616  &lt; 2e-16 ***\nDESTIN_SZDTSZ06 -1.0970276  0.0058498  -187.531  &lt; 2e-16 ***\nDESTIN_SZDTSZ07 -1.9471138  0.0181117  -107.506  &lt; 2e-16 ***\nDESTIN_SZDTSZ08 -0.5726861  0.0042779  -133.871  &lt; 2e-16 ***\nDESTIN_SZDTSZ09 -1.6507230  0.0094872  -173.996  &lt; 2e-16 ***\nDESTIN_SZDTSZ10 -1.1437957  0.0076182  -150.140  &lt; 2e-16 ***\nDESTIN_SZDTSZ11 -0.7051074  0.0045503  -154.957  &lt; 2e-16 ***\nDESTIN_SZDTSZ12 -2.3853201  0.0146739  -162.555  &lt; 2e-16 ***\nDESTIN_SZDTSZ13 -1.7104226  0.0092829  -184.255  &lt; 2e-16 ***\nDESTIN_SZGLSZ01  0.1107368  0.0042492    26.061  &lt; 2e-16 ***\nDESTIN_SZGLSZ02 -0.2332991  0.0039456   -59.129  &lt; 2e-16 ***\nDESTIN_SZGLSZ03  0.3998628  0.0033286   120.131  &lt; 2e-16 ***\nDESTIN_SZGLSZ04  0.3437751  0.0032807   104.788  &lt; 2e-16 ***\nDESTIN_SZGLSZ05  0.1319578  0.0034312    38.458  &lt; 2e-16 ***\nDESTIN_SZHGSZ01  0.2919272  0.0033057    88.310  &lt; 2e-16 ***\nDESTIN_SZHGSZ02 -0.7143625  0.0045068  -158.507  &lt; 2e-16 ***\nDESTIN_SZHGSZ03 -1.2327433  0.0053627  -229.872  &lt; 2e-16 ***\nDESTIN_SZHGSZ04 -0.4872286  0.0038424  -126.804  &lt; 2e-16 ***\nDESTIN_SZHGSZ05 -0.5305026  0.0038947  -136.213  &lt; 2e-16 ***\nDESTIN_SZHGSZ06 -0.7221263  0.0044794  -161.212  &lt; 2e-16 ***\nDESTIN_SZHGSZ07  0.1396872  0.0034914    40.009  &lt; 2e-16 ***\nDESTIN_SZHGSZ08 -0.2910404  0.0040741   -71.437  &lt; 2e-16 ***\nDESTIN_SZHGSZ09 -0.0399258  0.0042623    -9.367  &lt; 2e-16 ***\nDESTIN_SZHGSZ10 -3.3525271  0.0284834  -117.701  &lt; 2e-16 ***\nDESTIN_SZJESZ01 -0.3179824  0.0043748   -72.685  &lt; 2e-16 ***\nDESTIN_SZJESZ02 -0.6166505  0.0044556  -138.398  &lt; 2e-16 ***\nDESTIN_SZJESZ03 -0.7409777  0.0048742  -152.021  &lt; 2e-16 ***\nDESTIN_SZJESZ04 -0.1314954  0.0050415   -26.083  &lt; 2e-16 ***\nDESTIN_SZJESZ05 -0.9093176  0.0076274  -119.217  &lt; 2e-16 ***\nDESTIN_SZJESZ06  0.1586402  0.0036120    43.921  &lt; 2e-16 ***\nDESTIN_SZJESZ07 -0.9858786  0.0062868  -156.818  &lt; 2e-16 ***\nDESTIN_SZJESZ08 -0.9337586  0.0066965  -139.440  &lt; 2e-16 ***\nDESTIN_SZJESZ09 -0.4910199  0.0049077  -100.052  &lt; 2e-16 ***\nDESTIN_SZJESZ10  0.6120048  0.0065254    93.788  &lt; 2e-16 ***\nDESTIN_SZJESZ11  1.0847026  0.0058522   185.349  &lt; 2e-16 ***\nDESTIN_SZJWSZ01 -0.8217727  0.0057128  -143.848  &lt; 2e-16 ***\nDESTIN_SZJWSZ02 -0.8115426  0.0047358  -171.364  &lt; 2e-16 ***\nDESTIN_SZJWSZ03  0.2537313  0.0036535    69.450  &lt; 2e-16 ***\nDESTIN_SZJWSZ04  0.7302341  0.0034528   211.489  &lt; 2e-16 ***\nDESTIN_SZJWSZ05 -0.4724558  0.0051651   -91.472  &lt; 2e-16 ***\nDESTIN_SZJWSZ06 -0.2407042  0.0048187   -49.953  &lt; 2e-16 ***\nDESTIN_SZJWSZ07 -1.6158410  0.0202993   -79.601  &lt; 2e-16 ***\nDESTIN_SZJWSZ08 -0.6230617  0.0043179  -144.298  &lt; 2e-16 ***\nDESTIN_SZJWSZ09  0.8898147  0.0031592   281.656  &lt; 2e-16 ***\nDESTIN_SZKLSZ01 -0.4396921  0.0041637  -105.602  &lt; 2e-16 ***\nDESTIN_SZKLSZ02 -0.6062908  0.0047420  -127.855  &lt; 2e-16 ***\nDESTIN_SZKLSZ03 -1.0819377  0.0052061  -207.823  &lt; 2e-16 ***\nDESTIN_SZKLSZ04 -1.5376025  0.0066483  -231.278  &lt; 2e-16 ***\nDESTIN_SZKLSZ05 -0.9160108  0.0067999  -134.710  &lt; 2e-16 ***\nDESTIN_SZKLSZ06 -0.6783138  0.0045567  -148.862  &lt; 2e-16 ***\nDESTIN_SZKLSZ07 -0.8053090  0.0051185  -157.332  &lt; 2e-16 ***\nDESTIN_SZKLSZ08 -0.0089414  0.0037295    -2.397 0.016509 *  \nDESTIN_SZKLSZ09 -1.5380396  0.0066445  -231.475  &lt; 2e-16 ***\nDESTIN_SZLKSZ01 -2.0292471  0.0195548  -103.772  &lt; 2e-16 ***\nDESTIN_SZMDSZ01 -1.6102095  0.0167391   -96.194  &lt; 2e-16 ***\nDESTIN_SZMDSZ02 -1.2155299  0.0095467  -127.325  &lt; 2e-16 ***\nDESTIN_SZMDSZ03 -2.1559429  0.0211092  -102.133  &lt; 2e-16 ***\nDESTIN_SZMPSZ01 -0.9113252  0.0065923  -138.242  &lt; 2e-16 ***\nDESTIN_SZMPSZ02 -0.6876636  0.0049043  -140.215  &lt; 2e-16 ***\nDESTIN_SZMPSZ03 -0.0982520  0.0040534   -24.240  &lt; 2e-16 ***\nDESTIN_SZMSSZ01 -1.2155215  0.0695228   -17.484  &lt; 2e-16 ***\nDESTIN_SZMUSZ01 -1.0087032  0.0049335  -204.461  &lt; 2e-16 ***\nDESTIN_SZMUSZ02 -0.9727755  0.0070311  -138.353  &lt; 2e-16 ***\nDESTIN_SZMUSZ03 -1.0017612  0.0048249  -207.621  &lt; 2e-16 ***\nDESTIN_SZNTSZ01 -2.3340377  0.0219411  -106.378  &lt; 2e-16 ***\nDESTIN_SZNTSZ02 -1.6675277  0.0088191  -189.082  &lt; 2e-16 ***\nDESTIN_SZNTSZ03 -1.0351545  0.0061401  -168.590  &lt; 2e-16 ***\nDESTIN_SZNTSZ05 -1.6317700  0.0162635  -100.334  &lt; 2e-16 ***\nDESTIN_SZNTSZ06 -3.0291034  0.0279066  -108.544  &lt; 2e-16 ***\nDESTIN_SZNVSZ01 -0.2360755  0.0036893   -63.990  &lt; 2e-16 ***\nDESTIN_SZNVSZ02 -0.2677703  0.0041811   -64.043  &lt; 2e-16 ***\nDESTIN_SZNVSZ03 -0.3232023  0.0044374   -72.837  &lt; 2e-16 ***\nDESTIN_SZNVSZ04 -1.7845955  0.0085152  -209.579  &lt; 2e-16 ***\nDESTIN_SZNVSZ05 -1.5100826  0.0073054  -206.707  &lt; 2e-16 ***\nDESTIN_SZORSZ01 -1.4567532  0.0175488   -83.011  &lt; 2e-16 ***\nDESTIN_SZORSZ02  0.2967492  0.0035666    83.202  &lt; 2e-16 ***\nDESTIN_SZORSZ03 -0.7064791  0.0048068  -146.974  &lt; 2e-16 ***\nDESTIN_SZOTSZ01 -1.0978002  0.0061453  -178.639  &lt; 2e-16 ***\nDESTIN_SZOTSZ02 -0.4045287  0.0054335   -74.451  &lt; 2e-16 ***\nDESTIN_SZOTSZ03 -1.2239180  0.0058241  -210.147  &lt; 2e-16 ***\nDESTIN_SZOTSZ04 -1.4445089  0.0082677  -174.717  &lt; 2e-16 ***\nDESTIN_SZPGSZ01 -2.4438950  0.0162749  -150.163  &lt; 2e-16 ***\nDESTIN_SZPGSZ02 -0.8451914  0.0055174  -153.186  &lt; 2e-16 ***\nDESTIN_SZPGSZ03  0.2529362  0.0034356    73.622  &lt; 2e-16 ***\nDESTIN_SZPGSZ04 -0.2478654  0.0038491   -64.395  &lt; 2e-16 ***\nDESTIN_SZPGSZ05 -1.0734785  0.0063344  -169.468  &lt; 2e-16 ***\nDESTIN_SZPLSZ01 -0.5495097  0.0060781   -90.408  &lt; 2e-16 ***\nDESTIN_SZPLSZ02 -1.5722351  0.0104885  -149.902  &lt; 2e-16 ***\nDESTIN_SZPLSZ03 -0.1782908  0.0086850   -20.529  &lt; 2e-16 ***\nDESTIN_SZPLSZ04 -0.1551944  0.0083786   -18.523  &lt; 2e-16 ***\nDESTIN_SZPLSZ05 -0.7996544  0.0099573   -80.308  &lt; 2e-16 ***\nDESTIN_SZPNSZ01 -0.2835835  0.0048952   -57.931  &lt; 2e-16 ***\nDESTIN_SZPNSZ02  0.9154659  0.0066065   138.570  &lt; 2e-16 ***\nDESTIN_SZPNSZ03  0.1077954  0.0066518    16.205  &lt; 2e-16 ***\nDESTIN_SZPNSZ04  1.7847445  0.0073641   242.356  &lt; 2e-16 ***\nDESTIN_SZPNSZ05  0.9532174  0.0108878    87.549  &lt; 2e-16 ***\nDESTIN_SZPRSZ01 -1.0013251  0.0062900  -159.194  &lt; 2e-16 ***\nDESTIN_SZPRSZ02 -0.4210558  0.0043114   -97.662  &lt; 2e-16 ***\nDESTIN_SZPRSZ03  0.6407861  0.0032924   194.624  &lt; 2e-16 ***\nDESTIN_SZPRSZ04 -0.6038200  0.0073749   -81.875  &lt; 2e-16 ***\nDESTIN_SZPRSZ05 -0.3237481  0.0041005   -78.954  &lt; 2e-16 ***\nDESTIN_SZPRSZ06  0.2039871  0.0043057    47.376  &lt; 2e-16 ***\nDESTIN_SZPRSZ07 -1.1457123  0.0104668  -109.461  &lt; 2e-16 ***\nDESTIN_SZPRSZ08 -0.8729830  0.0057992  -150.534  &lt; 2e-16 ***\nDESTIN_SZQTSZ01 -1.4677400  0.0083689  -175.380  &lt; 2e-16 ***\nDESTIN_SZQTSZ02 -1.2697556  0.0060732  -209.077  &lt; 2e-16 ***\nDESTIN_SZQTSZ03 -0.6967149  0.0054986  -126.708  &lt; 2e-16 ***\nDESTIN_SZQTSZ04 -0.7466019  0.0056216  -132.809  &lt; 2e-16 ***\nDESTIN_SZQTSZ05 -0.5993615  0.0049649  -120.719  &lt; 2e-16 ***\nDESTIN_SZQTSZ06 -0.8812866  0.0053353  -165.181  &lt; 2e-16 ***\nDESTIN_SZQTSZ07 -1.4915992  0.0089009  -167.578  &lt; 2e-16 ***\nDESTIN_SZQTSZ08  0.2165260  0.0039176    55.270  &lt; 2e-16 ***\nDESTIN_SZQTSZ09 -0.4146415  0.0046976   -88.266  &lt; 2e-16 ***\nDESTIN_SZQTSZ10 -0.2193841  0.0043617   -50.298  &lt; 2e-16 ***\nDESTIN_SZQTSZ11  0.3378311  0.0041782    80.855  &lt; 2e-16 ***\nDESTIN_SZQTSZ12 -0.2029944  0.0054158   -37.482  &lt; 2e-16 ***\nDESTIN_SZQTSZ13  0.2270464  0.0041252    55.038  &lt; 2e-16 ***\nDESTIN_SZQTSZ14  0.1102927  0.0045744    24.111  &lt; 2e-16 ***\nDESTIN_SZQTSZ15  0.1633004  0.0057721    28.291  &lt; 2e-16 ***\nDESTIN_SZRCSZ01 -0.8071584  0.0052748  -153.022  &lt; 2e-16 ***\nDESTIN_SZRCSZ02 -2.1569024  0.0136086  -158.495  &lt; 2e-16 ***\nDESTIN_SZRCSZ03 -1.0009513  0.0071508  -139.978  &lt; 2e-16 ***\nDESTIN_SZRCSZ04 -2.1570287  0.0102663  -210.107  &lt; 2e-16 ***\nDESTIN_SZRCSZ05 -2.1689708  0.0095674  -226.704  &lt; 2e-16 ***\nDESTIN_SZRCSZ06 -1.8254095  0.0124663  -146.428  &lt; 2e-16 ***\nDESTIN_SZRCSZ08 -1.5012102  0.0103539  -144.990  &lt; 2e-16 ***\nDESTIN_SZRCSZ09 -1.2443962  0.0095075  -130.885  &lt; 2e-16 ***\nDESTIN_SZRCSZ10 -0.8072282  0.0051969  -155.330  &lt; 2e-16 ***\nDESTIN_SZRVSZ01 -1.6546043  0.0086377  -191.555  &lt; 2e-16 ***\nDESTIN_SZRVSZ02 -2.2642314  0.0118550  -190.994  &lt; 2e-16 ***\nDESTIN_SZRVSZ03 -1.9241528  0.0101322  -189.905  &lt; 2e-16 ***\nDESTIN_SZRVSZ04 -1.3647507  0.0114905  -118.772  &lt; 2e-16 ***\nDESTIN_SZRVSZ05 -1.3337470  0.0113096  -117.931  &lt; 2e-16 ***\nDESTIN_SZSBSZ01 -0.3783598  0.0053692   -70.468  &lt; 2e-16 ***\nDESTIN_SZSBSZ02 -0.9714858  0.0063803  -152.263  &lt; 2e-16 ***\nDESTIN_SZSBSZ03  0.5849635  0.0037871   154.461  &lt; 2e-16 ***\nDESTIN_SZSBSZ04  0.0628994  0.0048666    12.925  &lt; 2e-16 ***\nDESTIN_SZSBSZ05 -0.7903141  0.0059734  -132.306  &lt; 2e-16 ***\nDESTIN_SZSBSZ06 -2.4749704  0.0221461  -111.757  &lt; 2e-16 ***\nDESTIN_SZSBSZ07 -2.0802889  0.0163700  -127.079  &lt; 2e-16 ***\nDESTIN_SZSBSZ08  1.0512838  0.0045018   233.528  &lt; 2e-16 ***\nDESTIN_SZSBSZ09  0.4794881  0.0044114   108.692  &lt; 2e-16 ***\nDESTIN_SZSESZ02 -0.5041790  0.0039964  -126.157  &lt; 2e-16 ***\nDESTIN_SZSESZ03  0.3999040  0.0031970   125.086  &lt; 2e-16 ***\nDESTIN_SZSESZ04 -0.8064748  0.0046027  -175.216  &lt; 2e-16 ***\nDESTIN_SZSESZ05 -0.2274573  0.0038846   -58.554  &lt; 2e-16 ***\nDESTIN_SZSESZ06 -0.8726109  0.0049007  -178.058  &lt; 2e-16 ***\nDESTIN_SZSESZ07 -3.2557191  0.0198930  -163.662  &lt; 2e-16 ***\nDESTIN_SZSGSZ01 -0.2147069  0.0049537   -43.343  &lt; 2e-16 ***\nDESTIN_SZSGSZ02 -0.2178068  0.0043929   -49.582  &lt; 2e-16 ***\nDESTIN_SZSGSZ03 -0.4519684  0.0041222  -109.641  &lt; 2e-16 ***\nDESTIN_SZSGSZ04 -0.3205081  0.0040661   -78.824  &lt; 2e-16 ***\nDESTIN_SZSGSZ05 -1.8375273  0.0072964  -251.842  &lt; 2e-16 ***\nDESTIN_SZSGSZ06  0.3861484  0.0032161   120.067  &lt; 2e-16 ***\nDESTIN_SZSGSZ07 -0.3839443  0.0041174   -93.249  &lt; 2e-16 ***\nDESTIN_SZSISZ01 -0.4807184  0.0132026   -36.411  &lt; 2e-16 ***\nDESTIN_SZSKSZ01 -0.6652944  0.0062595  -106.285  &lt; 2e-16 ***\nDESTIN_SZSKSZ02  0.2704252  0.0046528    58.121  &lt; 2e-16 ***\nDESTIN_SZSKSZ03 -0.4653217  0.0051732   -89.948  &lt; 2e-16 ***\nDESTIN_SZSKSZ04 -0.8906681  0.0133805   -66.564  &lt; 2e-16 ***\nDESTIN_SZSKSZ05 -0.4150470  0.0111530   -37.214  &lt; 2e-16 ***\nDESTIN_SZSLSZ01 -0.7565998  0.0066751  -113.347  &lt; 2e-16 ***\nDESTIN_SZSLSZ04 -0.8814465  0.0053640  -164.327  &lt; 2e-16 ***\nDESTIN_SZSRSZ01 -1.1903322  0.0064592  -184.284  &lt; 2e-16 ***\nDESTIN_SZSRSZ02 -1.3027415  0.0075504  -172.539  &lt; 2e-16 ***\nDESTIN_SZSRSZ03 -1.3475702  0.0068354  -197.144  &lt; 2e-16 ***\nDESTIN_SZSVSZ01 -1.0127677  0.0413591   -24.487  &lt; 2e-16 ***\nDESTIN_SZTHSZ01 -3.3280757  0.0281757  -118.119  &lt; 2e-16 ***\nDESTIN_SZTHSZ03 -2.1899228  0.0177909  -123.092  &lt; 2e-16 ***\nDESTIN_SZTHSZ04 -2.5247657  0.0181864  -138.827  &lt; 2e-16 ***\nDESTIN_SZTHSZ06 -1.6350566  0.0118054  -138.501  &lt; 2e-16 ***\nDESTIN_SZTMSZ01 -0.3684293  0.0045579   -80.833  &lt; 2e-16 ***\nDESTIN_SZTMSZ02  1.3042469  0.0029248   445.921  &lt; 2e-16 ***\nDESTIN_SZTMSZ03  0.4611332  0.0033186   138.952  &lt; 2e-16 ***\nDESTIN_SZTMSZ04  0.8108143  0.0034018   238.351  &lt; 2e-16 ***\nDESTIN_SZTMSZ05  0.6733671  0.0042473   158.540  &lt; 2e-16 ***\nDESTIN_SZTNSZ01 -0.4410888  0.0045518   -96.905  &lt; 2e-16 ***\nDESTIN_SZTNSZ02 -1.0328372  0.0058953  -175.197  &lt; 2e-16 ***\nDESTIN_SZTNSZ03 -1.0414947  0.0071340  -145.990  &lt; 2e-16 ***\nDESTIN_SZTNSZ04 -0.9341618  0.0055851  -167.258  &lt; 2e-16 ***\nDESTIN_SZTPSZ01 -0.3698813  0.0046189   -80.079  &lt; 2e-16 ***\nDESTIN_SZTPSZ02  0.2467295  0.0032238    76.534  &lt; 2e-16 ***\nDESTIN_SZTPSZ03 -0.2439122  0.0046552   -52.395  &lt; 2e-16 ***\nDESTIN_SZTPSZ04 -1.5337020  0.0062616  -244.936  &lt; 2e-16 ***\nDESTIN_SZTPSZ05 -0.9305243  0.0048843  -190.515  &lt; 2e-16 ***\nDESTIN_SZTPSZ06 -0.4458706  0.0063048   -70.720  &lt; 2e-16 ***\nDESTIN_SZTPSZ07 -1.8014933  0.0091025  -197.912  &lt; 2e-16 ***\nDESTIN_SZTPSZ08 -1.1930009  0.0065955  -180.881  &lt; 2e-16 ***\nDESTIN_SZTPSZ09 -0.3469701  0.0050671   -68.476  &lt; 2e-16 ***\nDESTIN_SZTPSZ10 -0.9026251  0.0060902  -148.210  &lt; 2e-16 ***\nDESTIN_SZTPSZ11 -0.3080454  0.0042040   -73.275  &lt; 2e-16 ***\nDESTIN_SZTPSZ12 -0.7156204  0.0051754  -138.273  &lt; 2e-16 ***\nDESTIN_SZTSSZ01 -0.8543639  0.0200859   -42.536  &lt; 2e-16 ***\nDESTIN_SZTSSZ02 -0.5825767  0.0092558   -62.942  &lt; 2e-16 ***\nDESTIN_SZTSSZ03  0.2500858  0.0075201    33.256  &lt; 2e-16 ***\nDESTIN_SZTSSZ04  0.4593958  0.0074856    61.370  &lt; 2e-16 ***\nDESTIN_SZTSSZ05  1.5286175  0.0074395   205.473  &lt; 2e-16 ***\nDESTIN_SZTSSZ06  1.6286875  0.0134475   121.114  &lt; 2e-16 ***\nDESTIN_SZWCSZ01  1.3710389  0.0041810   327.920  &lt; 2e-16 ***\nDESTIN_SZWCSZ02 -0.7273251  0.0084384   -86.192  &lt; 2e-16 ***\nDESTIN_SZWCSZ03 -1.9636127  0.0230329   -85.253  &lt; 2e-16 ***\nDESTIN_SZWDSZ01  0.9399623  0.0031066   302.572  &lt; 2e-16 ***\nDESTIN_SZWDSZ02 -0.7981392  0.0049869  -160.048  &lt; 2e-16 ***\nDESTIN_SZWDSZ03  0.5407450  0.0034954   154.700  &lt; 2e-16 ***\nDESTIN_SZWDSZ04 -0.4445645  0.0050274   -88.428  &lt; 2e-16 ***\nDESTIN_SZWDSZ05 -0.1434480  0.0045552   -31.491  &lt; 2e-16 ***\nDESTIN_SZWDSZ06  0.1461975  0.0036640    39.901  &lt; 2e-16 ***\nDESTIN_SZWDSZ07  0.2388041  0.0046521    51.332  &lt; 2e-16 ***\nDESTIN_SZWDSZ08 -0.0098378  0.0054437    -1.807 0.070733 .  \nDESTIN_SZWDSZ09 -0.2806644  0.0041193   -68.135  &lt; 2e-16 ***\nDESTIN_SZYSSZ01  0.9357382  0.0033642   278.144  &lt; 2e-16 ***\nDESTIN_SZYSSZ02 -0.3420741  0.0045422   -75.310  &lt; 2e-16 ***\nDESTIN_SZYSSZ03 -1.2656914  0.0047488  -266.528  &lt; 2e-16 ***\nDESTIN_SZYSSZ04 -0.3567482  0.0043080   -82.811  &lt; 2e-16 ***\nDESTIN_SZYSSZ05 -1.9189376  0.0087174  -220.126  &lt; 2e-16 ***\nDESTIN_SZYSSZ06 -1.3204784  0.0065783  -200.734  &lt; 2e-16 ***\nDESTIN_SZYSSZ07 -0.6894968  0.0085776   -80.383  &lt; 2e-16 ***\nDESTIN_SZYSSZ08  0.6192002  0.0033756   183.436  &lt; 2e-16 ***\nDESTIN_SZYSSZ09 -0.0120655  0.0035260    -3.422 0.000622 ***\nlog(dist)       -0.6933493  0.0001075 -6451.265  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 105499054  on 20915  degrees of freedom\nResidual deviance:  36022972  on 20297  degrees of freedom\nAIC: 36156596\n\nNumber of Fisher Scoring iterations: 7\n\n\nWe can examine how the constraints hold this time.\n\nCalcRSquared(dbcSIM$data$TRIPS, dbcSIM$fitted.values)\n\n[1] 0.5614171\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThere is a relatively greater improvement in the \\(R^2\\) value using the doubly constrained model.\n\n\n\n8.9 Model Comparison\nAnother useful model performance measure for continuous dependent variable is Root Mean Squared Error. We can use compare_performance() of performance package for this purpose.\nFirst, we will create a list of models:\n\nmodel_list &lt;- list(unconstrained=uncSIM,\n                   originConstrained=orcSIM,\n                   destinationConstrained=decSIM,\n                   doublyConstrained=dbcSIM)\n\nThen, compare their RMSE values:\n\ncompare_performance(model_list,\n                    metrics = \"RMSE\")\n\n# Comparison of Model Performance Indices\n\nName                   | Model |     RMSE\n-----------------------------------------\nunconstrained          |   glm | 5485.538\noriginConstrained      |   glm | 4849.984\ndestinationConstrained |   glm | 4409.233\ndoublyConstrained      |   glm | 4231.607\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe doubly constrained SIM has the lowest RMSE, making it the best model.\n\n\n\n8.10 Visualizing Fitted Values\nWe can extract and visualize the fitted values for each model. To do so, start by extracting the fitted values for each model and adding their fitted values to SIM_data:\n\ndf &lt;- as.data.frame(uncSIM$fitted.values) %&gt;%\n  round(digits = 0)\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(uncTRIPS = \"uncSIM$fitted.values\")\n\ndf &lt;- as.data.frame(orcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(orcTRIPS = \"orcSIM$fitted.values\")\n\ndf &lt;- as.data.frame(decSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(decTRIPS = \"decSIM$fitted.values\")\n\ndf &lt;- as.data.frame(dbcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(dbcTRIPS = \"dbcSIM$fitted.values\")\n\nCreate scatter plots for each model and present in single plot:\n\nunc_p &lt;- ggplot(data = SIM_data,\n                aes(x = uncTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\norc_p &lt;- ggplot(data = SIM_data,\n                aes(x = orcTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndec_p &lt;- ggplot(data = SIM_data,\n                aes(x = decTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndbc_p &lt;- ggplot(data = SIM_data,\n                aes(x = dbcTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\nggarrange(unc_p, orc_p, dec_p, dbc_p,\n          ncol = 2,\n          nrow = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nThe doubly constrained model provides the best fit to the data, as seen by the closer clustering around the diagonal line.\nBoth the origin and destination-constrained models improve over the unconstrained model but still show some deviations.\nThe unconstrained model performs the worst, with a weak relationship between predicted and actual values."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#preparing-the-flow-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#preparing-the-flow-data",
    "title": "10A: Processing and Visualising Flow Data",
    "section": "\n6 Preparing the Flow Data",
    "text": "6 Preparing the Flow Data\n\n6.1 Importing the OD data\nFirst, we import the Passenger Volume by Origin Destination Bus Stops dataset using read_csv() from the readr package.\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202408.csv\")\nglimpse(odbus)\n\nRows: 5,760,081\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2024-08\", \"2024-08\", \"2024-08\", \"2024-08\", \"2024-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/…\n$ TIME_PER_HOUR       &lt;dbl&gt; 18, 7, 19, 9, 5, 12, 23, 15, 12, 13, 7, 9, 17, 15,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"76201\", \"10351\", \"76061\", \"14271\", \"54581\", \"1008…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"76079\", \"13201\", \"75371\", \"07021\", \"66471\", \"1007…\n$ TOTAL_TRIPS         &lt;dbl&gt; 6, 7, 1, 2, 1, 145, 2, 78, 2, 1, 3, 1, 2, 3, 5, 3,…\n\n\nodbus tibble data frame shows that the values in ORIGIN_PT_CODE and DESTINATON_PT_CODE are in character data type, we will convert themm into factor data type.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\nglimpse(odbus)\n\nRows: 5,760,081\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2024-08\", \"2024-08\", \"2024-08\", \"2024-08\", \"2024-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/…\n$ TIME_PER_HOUR       &lt;dbl&gt; 18, 7, 19, 9, 5, 12, 23, 15, 12, 13, 7, 9, 17, 15,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 76201, 10351, 76061, 14271, 54581, 10089, 67231, 5…\n$ DESTINATION_PT_CODE &lt;fct&gt; 76079, 13201, 75371, 07021, 66471, 10079, 67179, 5…\n$ TOTAL_TRIPS         &lt;dbl&gt; 6, 7, 1, 2, 1, 145, 2, 78, 2, 1, 3, 1, 2, 3, 5, 3,…\n\n\n\n6.2 Extracting the Study Data\nFor the purpose of this exercise, we extract commuting flows on weekdays between 6 and 9 a.m. and sum the trips.\n\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE, DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\nThe table below shows the head content of odbus6_9:\n\ndatatable(head(odbus6_9, 10))\n\n\n\n\n\n\n6.3 Saving and loading the data\nWe save the filtered data for future use in RDS format.\n\nwrite_rds(odbus6_9, \"data/rds/odbus6_9.rds\")\nodbus6_9 &lt;- read_rds(\"data/rds/odbus6_9.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#working-with-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#working-with-geospatial-data",
    "title": "10A: Processing and Visualising Flow Data",
    "section": "\n7 Working with Geospatial Data",
    "text": "7 Working with Geospatial Data\nFor this exercise, two geospatial datasets will be used:\n\n\nBusStop: Contains the locations of bus stops as of Q4 2022.\n\nMPSZ-2019: Provides the sub-zone boundaries from the URA Master Plan 2019.\n\nBoth datasets are in ESRI shapefile format.\n\n7.1 Importing Geospatial Data\nThe code below imports the geospatial data:\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\", layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex10/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5166 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48285.52 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/walter/code/isss626/isss626-gaa/Hands-on_Ex/Hands-on_Ex10/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz &lt;- write_rds(mpsz, \"data/rds/mpsz.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#visualising-spatial-interaction",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10a.html#visualising-spatial-interaction",
    "title": "10A: Processing and Visualising Flow Data",
    "section": "\n9 Visualising Spatial Interaction",
    "text": "9 Visualising Spatial Interaction\nIn this section, we will prepare a desire line by using stplanr package.\n\n9.1 Removing Intra-Zonal Flows\nWe will exclude flows within the same zone to focus on inter-zonal flows. The code below removes these intra-zonal flows:\n\nod_data_fij &lt;- od_data[od_data$ORIGIN_SZ != od_data$DESTIN_SZ,]\n\n\n\n\n\n\n\nTip\n\n\n\nThe comma in the code od_data1 &lt;- od_data[od_data$ORIGIN_SZ != od_data$DESTIN_SZ,] is crucial because it specifies that you are subsetting the rows of the data frame based on a condition, while keeping all the columns.\n\n\nSave the result for future use:\n\nwrite_rds(od_data_fij, \"data/rds/od_data_fij.rds\")\n\n\nod_data_fij &lt;- read_rds(\"data/rds/od_data_fij.rds\")\n\n\n9.2 Creating Desire Lines\n\n\n\n\n\n\nNote\n\n\n\nDesire lines are used to illustrate on a map the flows of people or goods from point to point based on the values from a matrix.\n\n\nNext, we use od2line() from the stplanr package to generate desire lines:\n\nflowLine &lt;- od2line(flow = od_data_fij, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\nflowLine\n\nSimple feature collection with 20625 features and 3 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 5105.594 ymin: 25813.33 xmax: 46654.41 ymax: 49552.79\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   ORIGIN_SZ DESTIN_SZ MORNING_PEAK                       geometry\n1     AMSZ01    AMSZ02        10895 LINESTRING (29501.77 39419....\n2     AMSZ01    AMSZ03        15626 LINESTRING (29501.77 39419....\n3     AMSZ01    AMSZ04         2865 LINESTRING (29501.77 39419....\n4     AMSZ01    AMSZ05         8166 LINESTRING (29501.77 39419....\n5     AMSZ01    AMSZ06         2309 LINESTRING (29501.77 39419....\n6     AMSZ01    AMSZ07         1446 LINESTRING (29501.77 39419....\n7     AMSZ01    AMSZ08         2572 LINESTRING (29501.77 39419....\n8     AMSZ01    AMSZ09         2380 LINESTRING (29501.77 39419....\n9     AMSZ01    AMSZ10          287 LINESTRING (29501.77 39419....\n10    AMSZ01    AMSZ11          741 LINESTRING (29501.77 39419....\n\n\nSave the generated desire lines:\n\nwrite_rds(flowLine, \"data/rds/flowLine.rds\")\n\nflowLine &lt;- read_rds(\"data/rds/flowLine.rds\")\n\n\n9.3 Filtering High-Volume Flows\nTo simplify the visual output and focus on significant flows, we filter for high-volumes flows.\n\nsummary(flowLine$MORNING_PEAK)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n     1.0     16.0     84.0    993.9    429.0 218070.0 \n\n\nFor example, we can visualize flow greater than or equal to 2000 as shown below.\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \n  # filter for 2000\n  filter(MORNING_PEAK &gt;= 2000) %&gt;%  \ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6)\n\n\n\n\n\n\n#           alpha = 0.3)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "In-Class Exercise 7",
    "section": "",
    "text": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method – ISSS626 Geospatial Analytics and Applications"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#exercise-reference",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#exercise-reference",
    "title": "In-Class Exercise 7",
    "section": "",
    "text": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method – ISSS626 Geospatial Analytics and Applications"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#overview",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#overview",
    "title": "In-Class Exercise 7",
    "section": "\n1.2 Overview",
    "text": "1.2 Overview\nIn this exercise, we will explore Calibrating Hedonic Pricing Models for Private Highrise Property using the Geographically Weighted Regression (GWR) Method, focusing on spatially varying relationships in property pricing data."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#learning-outcome",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#learning-outcome",
    "title": "In-Class Exercise 7",
    "section": "\n1.3 Learning Outcome",
    "text": "1.3 Learning Outcome\n\nImport and load R packages for spatial and statistical analysis.\nPerform correlation analysis using the ggstatsplot package.\nBuild a hedonic pricing model using Multiple Linear Regression (MLR).\nAssess and diagnose the MLR model using the olsrr package.\nTest for spatial autocorrelation in model residuals.\nBuild GWR models using fixed and adaptive bandwidth methods.\nVisualize GWR outputs, including local R² values and coefficient estimates.\nInterpret spatial patterns in GWR model results."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#import-the-r-packages",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#import-the-r-packages",
    "title": "In-Class Exercise 7",
    "section": "\n1.4 Import the R Packages",
    "text": "1.4 Import the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\nolsrr\nProvides tools for OLS regression diagnostics and variable selection.\nAssessing and improving the multiple linear regression model.\n\n\nggstatsplot\nEnhances data visualization and statistical analysis.\nPerforming correlation analysis and visualizing model parameters.\n\n\nggpubr\nCreates publication-ready plots based on ggplot2.\nVisualizing statistical plots.\n\n\nsf\nHandles spatial data operations for vector data.\nImporting and managing geospatial data like planning subzone boundaries.\n\n\nspdep\nAnalyzes spatial dependence and weights.\nComputing spatial weights and performing Moran’s I test.\n\n\nGWmodel\nImplements Geographically Weighted Models.\nBuilding GWR models with fixed and adaptive bandwidths.\n\n\ntmap\nGenerates thematic maps.\nVisualizing spatial data and GWR model outputs.\n\n\ntidyverse\nA suite of packages for data manipulation and visualization.\nData manipulation and joining datasets.\n\n\ngtsummary\nSummarizes data and statistical models.\nSummarizing regression outputs.\n\n\nperformance\nAssesses model quality and performance.\nEvaluating model diagnostics.\n\n\nsee\nProvides visualization tools for model diagnostics.\nVisualizing diagnostic plots.\n\n\nsfdep\nAnalyzes spatial dependence in sf objects.\nPerforming spatial autocorrelation tests on spatial data frames.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(olsrr, ggstatsplot, ggpubr, \n               sf, spdep, GWmodel, tmap,\n               tidyverse, gtsummary, performance,\n               see, sfdep)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#the-data",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#the-data",
    "title": "In-Class Exercise 7",
    "section": "\n1.5 The Data",
    "text": "1.5 The Data\nThe following datasets will be used in this exercise:\n\n\n\n\n\n\n\nDataset Name\nDescription\nFormat\n\n\n\nMaster Plan 2014 Subzone Boundary\nGeospatial data representing the boundaries of different areas in Singapore, specifically at the planning subzone level.\nESRI Shapefile\n\n\ncondo_resale_2015\nAspatial data containing records of condominium resale history in Singapore for the year 2015.\nCSV"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#correlation-analysis---ggstatsplot-methods",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#correlation-analysis---ggstatsplot-methods",
    "title": "In-Class Exercise 7",
    "section": "\n2.1 Correlation Analysis - ggstatsplot methods",
    "text": "2.1 Correlation Analysis - ggstatsplot methods\nInstead of using corrplot package, in the code chunk below, ggcorrmat() of ggstatsplot is used.\n\nggcorrmat(condo_resale[, 5:23])\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\n\nSome strong positive correlations that is statistically significant includes Proximity to Bus Stops (PROX_BUS_STOP) with Proximity to Childcare (PROX_CHILDCARE) (0.77) and Proximity to Childcare (PROX_CHILDCARE) with Proximity to Primary School (PROX_PRIMARY_SCHOOL) (0.63) among many others."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#building-a-hedonic-pricing-model-by-using-multiple-linear-regression-method",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#building-a-hedonic-pricing-model-by-using-multiple-linear-regression-method",
    "title": "In-Class Exercise 7",
    "section": "\n2.2 Building a Hedonic Pricing Model by using Multiple Linear Regression Method",
    "text": "2.2 Building a Hedonic Pricing Model by using Multiple Linear Regression Method\nThe code block below using lm() to calibrate the multiple linear regression model.\n\ncondo_mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + \n                  AGE   + PROX_CBD + PROX_CHILDCARE + \n                  PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n                  PROX_HAWKER_MARKET    + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + \n                  PROX_SUPERMARKET + PROX_BUS_STOP + \n                  NO_Of_UNITS + FAMILY_FRIENDLY + \n                  FREEHOLD + LEASEHOLD_99YR, \n                data=condo_resale_sf)\nsummary(condo_mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD + \n    LEASEHOLD_99YR, data = condo_resale_sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3471036  -286903   -22426   239412 12254549 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           543071.4   136210.9   3.987 7.03e-05 ***\nAREA_SQM               12688.7      370.1  34.283  &lt; 2e-16 ***\nAGE                   -24566.0     2766.0  -8.881  &lt; 2e-16 ***\nPROX_CBD              -78122.0     6791.4 -11.503  &lt; 2e-16 ***\nPROX_CHILDCARE       -333219.0   111020.3  -3.001 0.002734 ** \nPROX_ELDERLYCARE      170950.0    42110.8   4.060 5.19e-05 ***\nPROX_URA_GROWTH_AREA   38507.6    12523.7   3.075 0.002147 ** \nPROX_HAWKER_MARKET     23801.2    29299.9   0.812 0.416739    \nPROX_KINDERGARTEN     144098.0    82738.7   1.742 0.081795 .  \nPROX_MRT             -322775.9    58528.1  -5.515 4.14e-08 ***\nPROX_PARK             564487.9    66563.0   8.481  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      186170.5    65515.2   2.842 0.004553 ** \nPROX_TOP_PRIMARY_SCH    -477.1    20598.0  -0.023 0.981525    \nPROX_SHOPPING_MALL   -207721.5    42855.5  -4.847 1.39e-06 ***\nPROX_SUPERMARKET      -48074.7    77145.3  -0.623 0.533273    \nPROX_BUS_STOP         675755.0   138552.0   4.877 1.20e-06 ***\nNO_Of_UNITS             -216.2       90.3  -2.394 0.016797 *  \nFAMILY_FRIENDLY       142128.3    47055.1   3.020 0.002569 ** \nFREEHOLD              300646.5    77296.5   3.890 0.000105 ***\nLEASEHOLD_99YR        -77137.4    77570.9  -0.994 0.320192    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1416 degrees of freedom\nMultiple R-squared:  0.652, Adjusted R-squared:  0.6474 \nF-statistic: 139.6 on 19 and 1416 DF,  p-value: &lt; 2.2e-16\n\n\n\nclass(condo_mlr)\n\n[1] \"lm\"\n\n\nThe output is an lm object containing various important pieces of information:\n\nResiduals: The differences between the actual and predicted property prices. These will be useful later for spatial analysis to check for any spatial autocorrelation or patterns in the model’s errors.\nFitted Values: The predicted selling prices based on the model’s coefficients. These represent the estimated prices of the properties given their characteristics, such as area, proximity to amenities, and tenure type."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#model-assessment-olsrr-method",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#model-assessment-olsrr-method",
    "title": "In-Class Exercise 7",
    "section": "\n2.3 Model Assessment: olsrr method",
    "text": "2.3 Model Assessment: olsrr method\nIn this section, we will use olsrr to perform OLS regression. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\n\n2.3.1 Generating tidy linear regression report\n\nols_regress(condo_mlr)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     750537.537 \nR-Squared                    0.652       MSE                571262902261.220 \nAdj. R-Squared               0.647       Coef. Var                    43.160 \nPred R-Squared               0.637       AIC                       42971.173 \nMAE                     412117.987       SBC                       43081.835 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.515738e+15          19        7.977571e+13    139.648    0.0000 \nResidual      8.089083e+14        1416    571262902261.220                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     543071.420    136210.918                   3.987    0.000     275874.535     810268.305 \n            AREA_SQM      12688.669       370.119        0.579     34.283    0.000      11962.627      13414.710 \n                 AGE     -24566.001      2766.041       -0.166     -8.881    0.000     -29991.980     -19140.022 \n            PROX_CBD     -78121.985      6791.377       -0.267    -11.503    0.000     -91444.227     -64799.744 \n      PROX_CHILDCARE    -333219.036    111020.303       -0.087     -3.001    0.003    -551000.984    -115437.089 \n    PROX_ELDERLYCARE     170949.961     42110.748        0.083      4.060    0.000      88343.803     253556.120 \nPROX_URA_GROWTH_AREA      38507.622     12523.661        0.059      3.075    0.002      13940.700      63074.545 \n  PROX_HAWKER_MARKET      23801.197     29299.923        0.019      0.812    0.417     -33674.725      81277.120 \n   PROX_KINDERGARTEN     144097.972     82738.669        0.030      1.742    0.082     -18205.570     306401.514 \n            PROX_MRT    -322775.874     58528.079       -0.123     -5.515    0.000    -437586.937    -207964.811 \n           PROX_PARK     564487.876     66563.011        0.148      8.481    0.000     433915.162     695060.590 \n    PROX_PRIMARY_SCH     186170.524     65515.193        0.072      2.842    0.005      57653.253     314687.795 \nPROX_TOP_PRIMARY_SCH       -477.073     20597.972       -0.001     -0.023    0.982     -40882.894      39928.747 \n  PROX_SHOPPING_MALL    -207721.520     42855.500       -0.109     -4.847    0.000    -291788.613    -123654.427 \n    PROX_SUPERMARKET     -48074.679     77145.257       -0.012     -0.623    0.533    -199405.956     103256.599 \n       PROX_BUS_STOP     675755.044    138551.991        0.133      4.877    0.000     403965.817     947544.272 \n         NO_Of_UNITS       -216.180        90.302       -0.046     -2.394    0.017       -393.320        -39.040 \n     FAMILY_FRIENDLY     142128.272     47055.082        0.056      3.020    0.003      49823.107     234433.438 \n            FREEHOLD     300646.543     77296.529        0.117      3.890    0.000     149018.525     452274.561 \n      LEASEHOLD_99YR     -77137.375     77570.869       -0.030     -0.994    0.320    -229303.551      75028.801 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\n\n\n\n\nNote\n\n\n\nA quick glance on the report indicates that not all variables are statistically significant, meaning that while some factors strongly influence property prices, and others have minimal impact based on this model.\n\n\n\n2.3.1.1 Multicollinearity\n\nols_vif_tol(condo_mlr)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8601326 1.162611\n2                   AGE 0.7011585 1.426211\n3              PROX_CBD 0.4575471 2.185567\n4        PROX_CHILDCARE 0.2898233 3.450378\n5      PROX_ELDERLYCARE 0.5922238 1.688551\n6  PROX_URA_GROWTH_AREA 0.6614081 1.511926\n7    PROX_HAWKER_MARKET 0.4373874 2.286303\n8     PROX_KINDERGARTEN 0.8356793 1.196631\n9              PROX_MRT 0.4949877 2.020252\n10            PROX_PARK 0.8015728 1.247547\n11     PROX_PRIMARY_SCH 0.3823248 2.615577\n12 PROX_TOP_PRIMARY_SCH 0.4878620 2.049760\n13   PROX_SHOPPING_MALL 0.4903052 2.039546\n14     PROX_SUPERMARKET 0.6142127 1.628100\n15        PROX_BUS_STOP 0.3311024 3.020213\n16          NO_Of_UNITS 0.6543336 1.528272\n17      FAMILY_FRIENDLY 0.7191719 1.390488\n18             FREEHOLD 0.2728521 3.664990\n19       LEASEHOLD_99YR 0.2645988 3.779307\n\n\n\n\n\n\n\n\nNote\n\n\n\nEven though FREEHOLD and LEASEHOLD_99YR are highly correlated, we don’t need to remove either variable because their Variance Inflation Factor (VIF) values are both less than 5. This indicates that while they are correlated, they do not introduce significant multicollinearity that would negatively impact the stability of the regression model.\nRecap on VIF:\nThe Variance Inflation Factor (VIF) measures the extent of multicollinearity in a regression model. Specifically, it quantifies how much the variance of a regression coefficient is inflated due to collinearity with other predictors. A VIF &lt; 5 generally suggests that multicollinearity is not severe, while values above 10 indicate a high degree of collinearity that could distort the model’s results.\n\n\n\n2.3.2 Variable Selection\nIn this section, we are performing automatic parameter selection based on statistical significance, ensuring that only the most relevant variables are included in the model.\nVariable Selection Methods:\n\n\nForward Stepwise: Variables are added one by one, starting with the most statistically significant.\n\nBackward Stepwise: Variables are removed one by one, starting with the least significant.\n\nMixed Stepwise: A combination of forward and backward stepwise, where variables can be added or removed at each step.\n\nWe typically use forward stepwise selection with a p-value threshold (forward_p) since we want to retain variables that are statistically significant at each step of the model building process.\n\ncondo_fw_mlr &lt;- ols_step_forward_p(\n  condo_mlr,\n  p_val = 0.05,  # Only include variables with p-value &lt; 0.05\n  details = FALSE # Set to TRUE to display the output at each step\n)\n\n\nplot(condo_fw_mlr)\n\n\n\n\n\n\n\n\n2.3.3 Visualising Model Parameters\nIn this section, we use the ggcoefstats function from the ggstatsplot package to visualize the coefficients of the regression model. This plot helps in interpreting the magnitude and direction of the relationships between the predictor variables and the dependent variable (selling price).\n\nggcoefstats(condo_mlr,\n            sort = \"ascending\")\n\n\n\n\n\n\n\n\n2.3.4 Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code block below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo_fw_mlr$model)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n\n2.3.5 Test for Normality Assumption\nLastly, the code block below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo_fw_mlr$model)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) resembles normal distribution.\n\n\nWhen formal statistical test methods is preferred, we can use ols_test_normality() of olsrr package as shown in the code block below.\n\nols_test_normality(condo_fw_mlr$model)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#testing-for-spatial-autocorrelation",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#testing-for-spatial-autocorrelation",
    "title": "In-Class Exercise 7",
    "section": "\n2.4 Testing for Spatial Autocorrelation",
    "text": "2.4 Testing for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visualize the residual of the hedonic pricing model.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame. We will also simplify the variable names for easy reference and usage.\n\nmlr_output &lt;- as.data.frame(condo_fw_mlr$model$residuals) %&gt;%\n  rename(`FW_MLR_RES` = `condo_fw_mlr$model$residuals`)\n\nNext, we will join the newly created data frame with condo_resale_sf object.\n\ncondo_resale_sf &lt;- cbind(condo_resale_sf, \n                        mlr_output$FW_MLR_RES) %&gt;%\n  rename(`MLR_RES` = `mlr_output.FW_MLR_RES`)\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\n\ntmap_mode(\"view\")\ntm_shape(mpsz)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale_sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\")\n\n\n\n\ntmap_mode(\"plot\")\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe figure above reveal that there is sign of spatial autocorrelation.\n\n\n\n2.4.1 Spatial Stationary Test\nTo proof that our observation is indeed true, we will perform the Moran’s I test.\n\\(H_o\\): The residuals are randomly distributed (also known as spatial stationary) .\n\\(H_1\\): The residuals are spatially non-stationary.\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\ncondo_resale_sf &lt;- condo_resale_sf %&gt;%\n  mutate(nb = st_knn(geometry, k=6,\n                     longlat = FALSE),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\nNext, global_moran_perm() of sfdep is used to perform global Moran permutation test.\n\n# for reproducibility\nset.seed(1234) \n\nglobal_moran_perm(condo_resale_sf$MLR_RES, \n                  condo_resale_sf$nb, \n                  condo_resale_sf$wt, \n                  alternative = \"two.sided\", \n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.32254, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 2.2e-16 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.32254 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#building-hedonic-pricing-models-using-gwmodel",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#building-hedonic-pricing-models-using-gwmodel",
    "title": "In-Class Exercise 7",
    "section": "\n2.5 Building Hedonic Pricing Models using GWmodel",
    "text": "2.5 Building Hedonic Pricing Models using GWmodel\nIn this section, we will model hedonic pricing by using geographically weighted regression model. Two spatial weights will be used, they are: fixed and adaptive bandwidth schemes.\n\n2.5.1 Building Fixed Bandwidth GWR Model\n\n2.5.1.1 Computing fixed bandwith\nIn the code block below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach agreement.\n\nbw_fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                     PROX_CBD + PROX_CHILDCARE + \n                     PROX_ELDERLYCARE   + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                     NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale_sf, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.379526e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3396 CV score: 4.721292e+14 \nFixed bandwidth: 971.3402 CV score: 4.721292e+14 \nFixed bandwidth: 971.3398 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3399 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe result shows that the recommended bandwidth is 971.3405 metres. Since we are using CRS 3414 which use meter as unit, the unit is in meter.\n\n\n\n2.5.1.2 GWModel method - fixed bandwith\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\ngwr_fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + \n                         AGE    + PROX_CBD + PROX_CHILDCARE + \n                         PROX_ELDERLYCARE   +PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH +\n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                         NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale_sf, \n                       bw=bw_fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\ngwr_fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-16 02:01:39.452004 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale_sf, bw = bw_fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.34 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3599e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7426e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5001e+06 -1.5970e+05  3.1970e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8074e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112794435\n   AREA_SQM                 21575\n   AGE                     434203\n   PROX_CBD               2704604\n   PROX_CHILDCARE         1654086\n   PROX_ELDERLYCARE      38867861\n   PROX_URA_GROWTH_AREA  78515805\n   PROX_MRT               3124325\n   PROX_PARK             18122439\n   PROX_PRIMARY_SCH       4637517\n   PROX_SHOPPING_MALL     1529953\n   PROX_BUS_STOP         11342209\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720745\n   FREEHOLD               6073642\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3807 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6193 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.534069e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430418 \n\n   ***********************************************************************\n   Program stops at: 2024-10-16 02:01:40.871896 \n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations: The output is saved in a list of class gwrm. The report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the global multiple linear regression model of 42967.1.\n\n\n\n2.5.2 Building Adaptive Bandwidth GWR Model\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\n2.5.2.1 Computing the adaptive bandwidth\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code block used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\nbw_adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale_sf, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe result shows that the 30 is the recommended data points to be used.\n\n\n\n2.5.2.2 Constructing the adaptive bandwidth gwr model\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\ngwr_adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale_sf, \n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-16 02:01:50.529361 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale_sf, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-10-16 02:01:52.321114 \n\n\n\n\n\n\n\n\nNote\n\n\n\nObservations:\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61.\n\n\n\n2.5.3 Visualising GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list.\n\n2.5.4 Converting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\ngwr_adaptive_output &lt;- as.data.frame(\n  gwr_adaptive$SDF) %&gt;%\n  select(-c(2:15))\n\n\ngwr_sf_adaptive &lt;- cbind(condo_resale_sf,\n                         gwr_adaptive_output)\n\nNext, glimpse() is used to display the content of condo_resale_sf.adaptive sf data frame.\n\nglimpse(gwr_sf_adaptive)\n\nRows: 1,436\nColumns: 63\n$ nb                      &lt;nb&gt; &lt;66, 77, 123, 238, 239, 343&gt;, &lt;21, 162, 163, 19…\n$ wt                      &lt;list&gt; &lt;0.1666667, 0.1666667, 0.1666667, 0.1666667, …\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n$ geometry.1              &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\nsummary(gwr_adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901 \n\n\n\n2.5.5 Visualising local R2\nThe code block below is used to create an interactive point symbol map.\n\n\n\n\n\n\nWarning\n\n\n\nNote that there is an unsolved issue with the mpsz data from the official sources.\nTo prevent potential errors during mapping, we can use the tmap_options(check.and.fix = TRUE) to automatically corrects any issues with the spatial data during visualization.\n\n\n\ntmap_mode(\"view\")\ntmap_options(check.and.fix = TRUE)\ntm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(gwr_sf_adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\ntmap_mode(\"plot\")\n\n\n2.5.6 Visualising coefficient estimates\nThe code chunks below is used to create an interactive point symbol map.\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\nAREA_SQM_SE &lt;- tm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(gwr_sf_adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(gwr_sf_adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\n2.5.6.1 By URA Planning Region\n\ntm_shape(mpsz[mpsz$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(gwr_sf_adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "title": "In-Class Exercise 8",
    "section": "",
    "text": "ISSS626 Geospatial Analytics and Applications – In-class Exercise 8: Supplement to Hands-on Exercise 8"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#exercise-reference",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#exercise-reference",
    "title": "In-Class Exercise 8",
    "section": "",
    "text": "ISSS626 Geospatial Analytics and Applications – In-class Exercise 8: Supplement to Hands-on Exercise 8"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#overview",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#overview",
    "title": "In-Class Exercise 8",
    "section": "\n2 Overview",
    "text": "2 Overview\nIn this exercise, we will go through a sample exercise for Take-Home Exercise 3B and In-Class Exercise 08, which supplement what we have learnt in Hands-On Exercise 8."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#import-the-r-packages",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#import-the-r-packages",
    "title": "In-Class Exercise 8",
    "section": "\n3 Import the R Packages",
    "text": "3 Import the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\ntidyverse\nA collection of R packages for data manipulation and visualization.\nData wrangling, cleaning, and visualization tasks.\n\n\nsf\nProvides tools for handling spatial data.\nImporting and managing geospatial data.\n\n\nhttr\nSimplifies working with URLs and HTTP requests.\nAccessing APIs and retrieving data from web services.\n\n\njsonlite\nHandles JSON data in R.\nParsing and working with JSON responses from APIs.\n\n\nrvest\nFacilitates web scraping.\nExtracting data from websites.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(tidyverse, sf, httr, jsonlite, rvest)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#data-wrangling",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#data-wrangling",
    "title": "In-Class Exercise 8",
    "section": "\n4 Data Wrangling",
    "text": "4 Data Wrangling\nThe HDB resale data can be downloaded from here. The dataset contains resale flat prices based on registration date from Jan 2017 to Sep 2024.\nThe code below reads the raw CSV file containing the resale flat data and filters it to include only records from January 2023 to September 2024.\n\nresale &lt;- read_csv(\"data/raw_data/resale.csv\") %&gt;%\n  filter(month &gt;= \"2023-01\" & month &lt;= \"2024-09\")\n\nThe following code tidies the data by creating new columns: - address: Combines block and street_name to form a complete address. - remaining_lease_yr: Extracts the remaining lease years as an integer. - remaining_lease_mth: Extracts the remaining lease months as an integer.\n\nresale_tidy &lt;- resale %&gt;%\n  mutate(address = paste(block,street_name)) %&gt;%\n  mutate(remaining_lease_yr = as.integer(\n    str_sub(remaining_lease, 0, 2)))%&gt;%\n  mutate(remaining_lease_mth = as.integer(\n    str_sub(remaining_lease, 9, 11)))\n\nNext, we filter the tidy dataset to include only records from September 2024.\n\nresale_selected &lt;- resale_tidy %&gt;%\n  filter(month == \"2024-09\")\n\nThen, we generate a sorted list of unique addresses from the filtered dataset. This will be used to retrieve geographical coordinates.\n\nadd_list &lt;- sort(unique(resale_selected$address))\n\nIn the code below, the get_coords function retrieves latitude and longitude coordinates for each address in the list. It uses the OneMap API to query addresses and returns a dataframe with postal codes and geographical coordinates: - If a single result is found, the coordinates are retrieved and stored. - If multiple results are found, addresses with “NIL” as postal are dropped, and the top result is selected. - If no valid results are found, NA is stored.\n\nget_coords &lt;- function(add_list){\n\n  # Create a data frame to store all retrieved coordinates\n  postal_coords &lt;- data.frame()\n\n  for (i in add_list){\n    #print(i)\n\n    r &lt;- GET('https://www.onemap.gov.sg/api/common/elastic/search?',\n           query=list(searchVal=i,\n                     returnGeom='Y',\n                     getAddrDetails='Y'))\n    data &lt;- fromJSON(rawToChar(r$content))\n    found &lt;- data$found\n    res &lt;- data$results\n\n    # Create a new data frame for each address\n    new_row &lt;- data.frame()\n\n    # If single result, append\n    if (found == 1){\n      postal &lt;- res$POSTAL\n      lat &lt;- res$LATITUDE\n      lng &lt;- res$LONGITUDE\n      new_row &lt;- data.frame(address= i,\n                            postal = postal,\n                            latitude = lat,\n                            longitude = lng)\n    }\n\n    # If multiple results, drop NIL and append top 1\n    else if (found &gt; 1){\n      # Remove those with NIL as postal\n      res_sub &lt;- res[res$POSTAL != \"NIL\", ]\n\n      # Set as NA first if no Postal\n      if (nrow(res_sub) == 0) {\n          new_row &lt;- data.frame(address= i,\n                                postal = NA,\n                                latitude = NA,\n                                longitude = NA)\n      }\n\n      else{\n        top1 &lt;- head(res_sub, n = 1)\n        postal &lt;- top1$POSTAL\n        lat &lt;- top1$LATITUDE\n        lng &lt;- top1$LONGITUDE\n        new_row &lt;- data.frame(address= i,\n                              postal = postal,\n                              latitude = lat,\n                              longitude = lng)\n      }\n    }\n\n    else {\n      new_row &lt;- data.frame(address= i,\n                            postal = NA,\n                            latitude = NA,\n                            longitude = NA)\n    }\n\n    # Add the row\n    postal_coords &lt;- rbind(postal_coords, new_row)\n  }\n  return(postal_coords)\n}\n\nWe apply the function to the list of addresses and the retrieved coordinates are saved as an RDS file for future use.\n\ncoords &lt;- get_coords(add_list)\n\nwrite_rds(coords, \"data/rds/coords.rds\")\n\nThis concludes the sample exercise on how to handle the dataset for Take-Home Exercise 3B.\n\nWe will proceed with In-Class Exercise 08 next."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#import-the-r-packages-1",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#import-the-r-packages-1",
    "title": "In-Class Exercise 8",
    "section": "\n5 Import the R Packages",
    "text": "5 Import the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\nsf\nHandles spatial data for vector operations.\nImporting and manipulating geospatial data.\n\n\nspdep\nProvides spatial dependence analysis tools.\nConducting spatial autocorrelation and spatial weights analysis.\n\n\nGWmodel\nImplements Geographically Weighted Models.\nBuilding and analyzing geographically weighted regression models.\n\n\nSpatialML\nSupports machine learning models with spatial data.\nApplying machine learning techniques to spatial datasets.\n\n\nkableExtra\nEnhances table creation for displaying results.\nCreating well-formatted tables for presenting data summaries.\n\n\ntmap\nCreates thematic maps for spatial data visualization.\nVisualizing geospatial data and model results.\n\n\nrsample\nFacilitates data resampling techniques for statistical modeling.\nSplitting data into training and testing sets.\n\n\nMetrics\nProvides performance metrics for model evaluation.\nAssessing accuracy, RMSE, and other evaluation metrics.\n\n\ntidyverse\nA suite of packages for data manipulation and visualization.\nData wrangling, cleaning, and visualization tasks.\n\n\nolsrr\nTools for OLS regression diagnostics and variable selection.\nDiagnosing and improving multiple linear regression models.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(sf, spdep, GWmodel, SpatialML, kableExtra,\n               tmap, rsample, Metrics, tidyverse, olsrr)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#the-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#the-data",
    "title": "In-Class Exercise 8",
    "section": "\n6 The Data",
    "text": "6 The Data\nThe data file mdata.rds consists of the following information:\n\n\nDataset Type\nDescription\nSource & Format\n\n\n\nAspatial Dataset\nHDB Resale data: A list of HDB resale transacted prices in Singapore from Jan 2017 onwards.\nData.gov.sg, CSV format\n\n\nGeospatial Dataset\n\nMP14_SUBZONE_WEB_PL: URA 2014 Master Plan Planning Subzone boundary data.\nData.gov.sg, ESRI Shapefile format\n\n\nLocational Factors with Geographic Coordinates\nEldercare data: A list of eldercare locations in Singapore.\nData.gov.sg, Shapefile format\n\n\n\nHawker Centre data: A list of hawker centres in Singapore.\nData.gov.sg, GeoJSON format\n\n\n\nParks data: A list of parks in Singapore.\nData.gov.sg, GeoJSON format\n\n\n\nSupermarket data: A list of supermarkets in Singapore.\nData.gov.sg, GeoJSON format\n\n\n\nCHAS Clinics data: A list of CHAS clinics in Singapore.\nData.gov.sg, GeoJSON format\n\n\n\nChildcare Service data: A list of childcare services in Singapore.\nData.gov.sg, GeoJSON format\n\n\n\nKindergartens data: A list of kindergartens in Singapore.\nData.gov.sg, GeoJSON format\n\n\n\nMRT data: A list of MRT/LRT stations with names and codes.\nDatamall.lta.gov.sg, Shapefile format\n\n\n\nBus Stops data: A list of bus stops in Singapore.\nDatamall.lta.gov.sg, Shapefile format\n\n\nLocational Factors without Geographic Coordinates\nPrimary School data: General information on schools in Singapore.\nData.gov.sg, CSV format\n\n\n\nCBD Coordinates: Central Business District coordinates obtained from Google.\nGoogle\n\n\n\nShopping Malls data: A list of shopping malls in Singapore.\nWikipedia, List of shopping malls in Singapore\n\n\n\n\nGood Primary Schools: A ranking of primary schools based on popularity.\nLocal Salary Forum\n\n\n\nTo load the dataset into R:\n\nmdata &lt;- read_rds(\"data/rds/mdata.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#data-sampling",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#data-sampling",
    "title": "In-Class Exercise 8",
    "section": "\n7 Data Sampling",
    "text": "7 Data Sampling\nCalibrating predictive models are computational intensive, especially random forest method is used. For quick prototyping, a 10% sample will be selected at random from the data by using the code block below.\n\nset.seed(1234)\nHDB_sample &lt;- mdata %&gt;%\n  sample_n(1500)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#building-non-spatial-multiple-linear-regression",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#building-non-spatial-multiple-linear-regression",
    "title": "In-Class Exercise 8",
    "section": "\n10 Building Non-Spatial Multiple Linear Regression",
    "text": "10 Building Non-Spatial Multiple Linear Regression\nWhen constructing predictive models, it is advisable to avoid including all variables to avoid overfitting. Instead, only the most relevant predictors that contribute to the model’s performance should be selected.\nOn the other hand, explanatory models aim to understand relationships between variables and identify which factors have significant effects on the outcome. In such cases, including all variables can help provide a clearer picture of these relationships.\nIn this example, we build a non-spatial multiple linear regression model using the training data,\n\n# Build model\nprice_mlr &lt;- lm(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL +\n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                data=train_data)\n\n# Check model with olsrr\nolsrr::ols_regress(price_mlr)\n\n                              Model Summary                                \n--------------------------------------------------------------------------\nR                           0.859       RMSE                    61604.120 \nR-Squared                   0.737       MSE                3800583670.022 \nAdj. R-Squared              0.737       Coef. Var                  14.193 \nPred R-Squared              0.737       AIC                    257320.224 \nMAE                     47485.556       SBC                    257436.117 \n--------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares           DF       Mean Square       F          Sig. \n--------------------------------------------------------------------------------\nRegression    1.100899e+14           14      7.863561e+12     2069.04    0.0000 \nResidual      3.922202e+13        10320    3800583670.022                       \nTotal         1.493119e+14        10334                                         \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                 \n------------------------------------------------------------------------------------------------------------------\n                   model          Beta    Std. Error    Std. Beta       t        Sig          lower         upper \n------------------------------------------------------------------------------------------------------------------\n             (Intercept)    107601.073     10601.261                  10.150    0.000     86820.546    128381.599 \n          floor_area_sqm      2780.698        90.579        0.164     30.699    0.000      2603.146      2958.251 \n            storey_order     14299.298       339.115        0.234     42.167    0.000     13634.567     14964.029 \n    remaining_lease_mths       344.490         4.592        0.442     75.027    0.000       335.489       353.490 \n                PROX_CBD    -16930.196       201.254       -0.586    -84.124    0.000    -17324.693    -16535.700 \n        PROX_ELDERLYCARE    -14441.025       994.867       -0.079    -14.516    0.000    -16391.157    -12490.893 \n             PROX_HAWKER    -19265.648      1273.597       -0.083    -15.127    0.000    -21762.144    -16769.151 \n                PROX_MRT    -32564.272      1744.232       -0.105    -18.670    0.000    -35983.305    -29145.240 \n               PROX_PARK     -5712.625      1483.885       -0.021     -3.850    0.000     -8621.328     -2803.922 \n               PROX_MALL    -14717.388      2007.818       -0.044     -7.330    0.000    -18653.100    -10781.675 \n        PROX_SUPERMARKET    -26881.938      4189.624       -0.035     -6.416    0.000    -35094.414    -18669.462 \nWITHIN_350M_KINDERGARTEN      8520.472       632.812        0.072     13.464    0.000      7280.038      9760.905 \n   WITHIN_350M_CHILDCARE     -4510.650       354.015       -0.074    -12.741    0.000     -5204.589     -3816.711 \n         WITHIN_350M_BUS       813.493       222.574        0.020      3.655    0.000       377.205      1249.781 \n       WITHIN_1KM_PRISCH     -8010.834       491.512       -0.102    -16.298    0.000     -8974.293     -7047.376 \n------------------------------------------------------------------------------------------------------------------\n\n\n\n10.1 Multicolinearity Check with VIF\nVariance Inflation Factor (VIF) analysis is conducted to detect the presence of multicollinearity among the predictors. High VIF values suggest redundancy, indicating that some predictors might need to be removed.\n\nvif &lt;- performance::check_collinearity(price_mlr)\n\nkable(vif,\n      caption = \"Variance Inflation Factor (VIF) Results\") %&gt;%\n  kable_styling(font_size = 18)\n\n\nVariance Inflation Factor (VIF) Results\n\nTerm\nVIF\nVIF_CI_low\nVIF_CI_high\nSE_factor\nTolerance\nTolerance_CI_low\nTolerance_CI_high\n\n\n\nfloor_area_sqm\n1.126308\n1.104360\n1.152871\n1.061276\n0.8878567\n0.8673997\n0.9055016\n\n\nstorey_order\n1.206586\n1.181102\n1.235657\n1.098447\n0.8287846\n0.8092862\n0.8466672\n\n\nremaining_lease_mths\n1.363528\n1.331762\n1.398335\n1.167702\n0.7333919\n0.7151363\n0.7508850\n\n\nPROX_CBD\n1.905054\n1.852553\n1.960788\n1.380237\n0.5249196\n0.5099991\n0.5397957\n\n\nPROX_ELDERLYCARE\n1.178400\n1.154108\n1.206522\n1.085541\n0.8486080\n0.8288284\n0.8664703\n\n\nPROX_HAWKER\n1.187828\n1.163132\n1.216262\n1.089875\n0.8418729\n0.8221915\n0.8597474\n\n\nPROX_MRT\n1.240457\n1.213579\n1.270718\n1.113758\n0.8061545\n0.7869568\n0.8240092\n\n\nPROX_PARK\n1.195883\n1.170847\n1.224588\n1.093564\n0.8362021\n0.8166011\n0.8540825\n\n\nPROX_MALL\n1.409846\n1.376277\n1.446409\n1.187369\n0.7092975\n0.6913675\n0.7265978\n\n\nPROX_SUPERMARKET\n1.154751\n1.131493\n1.182124\n1.074594\n0.8659873\n0.8459353\n0.8837880\n\n\nWITHIN_350M_KINDERGARTEN\n1.125809\n1.103886\n1.152360\n1.061042\n0.8882499\n0.8677846\n0.9058910\n\n\nWITHIN_350M_CHILDCARE\n1.335594\n1.304923\n1.369351\n1.155679\n0.7487304\n0.7302729\n0.7663289\n\n\nWITHIN_350M_BUS\n1.148544\n1.125564\n1.175729\n1.071701\n0.8706679\n0.8505364\n0.8884435\n\n\nWITHIN_1KM_PRISCH\n1.550879\n1.511876\n1.592853\n1.245343\n0.6447958\n0.6278044\n0.6614298\n\n\n\n\n\nTo visualize the results:\n\nplot(vif) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-with-mlr",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-with-mlr",
    "title": "In-Class Exercise 8",
    "section": "\n9 Predictive Modelling with MLR",
    "text": "9 Predictive Modelling with MLR\n\n9.1 Computing Adaptive Bandwidth\nAn adaptive bandwidth is calculated using geographically weighted regression (GWR), which allows for local variations in relationships between variables.\n\n# Compute adaptive bandwidth\nbw_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL +\n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=train_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\nThen, we save this model for future use:\n\n# Save adaptive bandwidth\nwrite_rds(bw_adaptive, \"data/rds/bw_adaptive.rds\")\n\n\nbw_adaptive &lt;- read_rds(\"data/rds/bw_adaptive.rds\")\n\n\n9.2 Model Calibration\nThe GWR model is then calibrated to examine spatially varying relationships:\n\n# Calibrate gwr-based hedonic pricing model\ngwr_adaptive &lt;- gwr.basic(formula = resale_price ~\n                            floor_area_sqm + storey_order +\n                            remaining_lease_mths + PROX_CBD +\n                            PROX_ELDERLYCARE + PROX_HAWKER +\n                            PROX_MRT + PROX_PARK + PROX_MALL +\n                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                            WITHIN_1KM_PRISCH,\n                          data=train_data,\n                          bw = bw_adaptive,\n                          kernel = 'gaussian',\n                          adaptive=TRUE,\n                          longlat = FALSE)\n\nThen, we save this calibrated model for future use:\n\n# Save calibrated model\nwrite_rds(gwr_adaptive, \"data/rds/gwr_adaptive.rds\")\n\n\ngwr_adaptive &lt;- read_rds(\"data/rds/gwr_adaptive.rds\")\n\n\n# Compute test data adaptive bandwidth\ngwr_bw_test_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL +\n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=test_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\nTo compute the predicted values:\n\n# Compute predicted values\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaixwning_lease_mths + PROX_CBD +\n                          PROX_ELDERLYCARE + PROX_HAWKER +\n                          PROX_MRT + PROX_PARK + PROX_MALL +\n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                          WITHIN_1KM_PRISCH,\n                        data=train_data_sp,\n                        predictdata = test_data,\n                        bw = bw_adaptive,\n                        kernel = 'gaussian',\n                        adaptive=TRUE,\n                        longlat = FALSE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-with-spatialml",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-with-spatialml",
    "title": "In-Class Exercise 8",
    "section": "\n10 Predictive Modelling with SpatialML",
    "text": "10 Predictive Modelling with SpatialML\nSince the SpatialML package is based on the ranger package, coordinate data must be prepared before calibration.\n\n10.1 Preparing Coordinate Data\n\n# Get coordinates from full, training and test data\ncoords &lt;- st_coordinates(mdata)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\nwrite_rds(coords_train, \"data/rds/coords_train.rds\" )\nwrite_rds(coords_test, \"data/rds/coords_test.rds\" )\n\n\ncoords_train &lt;- read_rds(\"data/rds/coords_train.rds\")\ncoords_test &lt;- read_rds(\"data/rds/coords_test.rds\")\n\nAdditionally, the geometry field is removed:\n\n# Drop geometry\ntrain_data_nogeom &lt;- train_data %&gt;%\n  st_drop_geometry()\n\n\n10.2 Calibrating Random Forest and GRF Models\nTo calibrate a RF model:\n\n# Set seed\nset.seed(1234)\n\n# Calibrate random forest model\nrf &lt;- ranger(resale_price ~ floor_area_sqm + storey_order +\n               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +\n               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +\n               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n               WITHIN_1KM_PRISCH,\n             data=train_data_nogeom)\n\n# Check result\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       731404460 \nR squared (OOB):                  0.9493789 \n\n\n\nwrite_rds(rf, \"data/rds/rf.rds\")\n\n\nrf &lt;- read_rds(\"data/rds/rf.rds\")\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       731404460 \nR squared (OOB):                  0.9493789 \n\n\n\n10.3 Calibrating GRF Model\nTo calibrate a GRF model:\n\n# Set seed\nset.seed(42)\n\n# Calibrate geographic random forest model\ngwRF_adaptive &lt;- grf(formula = resale_price ~ floor_area_sqm + storey_order +\n                       remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +\n                       PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +\n                       PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                       WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                       WITHIN_1KM_PRISCH,\n                     dframe=train_data_nogeom,\n                     bw=55,\n                     ntree = 100, # default - 500\n                     mtry = 2, # default - p/3 ~ 4\n                     kernel=\"adaptive\",\n                     coords=coords_train)\n\nThe model can be saved and loaded for future use:\n\n# Save model output\nwrite_rds(gwRF_adaptive, \"data/rds/gwRF_adaptive.rds\")\n\n\n# Load model output\ngwRF_adaptive &lt;- read_rds(\"data/rds/gwRF_adaptive.rds\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe global model is a ranger object which can provide additional insights:\n\n\nLocal Variable Importance: This metric calculates the importance of each variable for every data point, allowing us to see which predictors are more influential in different locations.\n\nLocal Goodness of Fit (LGofFit): For each data point, the model assesses how well the local predictions match the observed values, offering insights into model performance across different areas.\n\nForests: Each local forest contains various metrics, such as sample size, to understand the local behavior and conditions affecting predictions.\n\n\n\n\n10.4 Predict with Test Data\nSince the GRF model requires coordinate data as part of its input, the coordinates from the test data need to be merged with the original dataset after removing the geometry field.\n\ntest_data_nogeom &lt;- cbind(\n  test_data, coords_test) %&gt;%\n  st_drop_geometry()\n\nNext, predict.grf() of spatialML package will be used to predict the resale value by using the test data and gwRF_adaptive model calibrated earlier.\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive,\n                         test_data_nogeom,\n                         x.var.name=\"X\",\n                         y.var.name=\"Y\",\n                         local.w=1,\n                         global.w=0,\n                         nthreads = 4)\n\n\nGRF_pred &lt;- write_rds(gwRF_pred, \"data/rds/GRF_pred.rds\")\n\n\nGRF_pred &lt;- read_rds(\"data/rds/GRF_pred.rds\")\nGRF_pred_df &lt;- as.data.frame(GRF_pred)\n\nTo analyze the differences between the predicted and actual values, the predictions are merged back with the test dataset to compare predicted against actual resale prices.\n\n# Combine predicted values with test data\ntest_data_pred &lt;- cbind(test_data, GRF_pred_df)\n\nSave the combined data for future reference:\n\nwrite_rds(test_data_pred, \"data/rds/test_data_pred.rds\")\n\n\ntest_data_pred &lt;- read_rds(\"data/rds/test_data_pred.rds\")\n\nTo calculate Root Mean Square Error (RMSE):\n\nrmse(test_data_pred$resale_price,\n     test_data_pred$GRF_pred)\n\n[1] 28891.61\n\n\nTo visualize the predicted vs actual value with a scatterplot.\n\nggplot(data = test_data_pred,\n       aes(x = GRF_pred,\n           y = resale_price)) +\n  geom_point()\n\n\n\n\n\n\n\nIdeally, points should align along the diagonal line, indicating accurate predictions. Points below it show underestimation, while points above indicate overestimation of price prediction."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#checking-of-overlapping-point",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#checking-of-overlapping-point",
    "title": "In-Class Exercise 8",
    "section": "\n8 Checking of overlapping point",
    "text": "8 Checking of overlapping point\n\n\n\n\n\n\nWarning\n\n\n\nWhen using GWmodel to calibrate explanatory or predictive models, it is very important to ensure that there are no overlapping point features.\n\n\nThe code block below is used to check if there are overlapping point features.\n\noverlapping_points &lt;- HDB_sample %&gt;%\n  mutate(overlap = lengths(st_equals(., .)) &gt; 1)\n\n\n8.1 Spatial jitter\nIn the code code block below, st_jitter() of sf package is used to move the point features by 5m to avoid overlapping point features.\n\nHDB_sample &lt;- HDB_sample %&gt;%\n  st_jitter(amount = 5)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#train-test-split",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#train-test-split",
    "title": "In-Class Exercise 8",
    "section": "\n9 Train-Test Split",
    "text": "9 Train-Test Split\nNote that in this case, we use random sampling method to split the data into training and testing sets. No stratification was applied. (We should adopt a stratification method for Take-Home Exercise 3B to ensure better representation across subgroups.)\nWe will use initial_split() of rsample package. rsample is a package from tidymodels framework.\n\nset.seed(1234)\nresale_split &lt;- initial_split(mdata,\n                              prop = 6.5/10,)\ntrain_data &lt;- training(resale_split)\ntest_data &lt;- testing(resale_split)\n\n\nwrite_rds(train_data, \"data/rds/train_data.rds\")\nwrite_rds(test_data, \"data/rds/test_data.rds\")\n\n\ntrain_data &lt;- read_rds(\"data/rds/train_data.rds\")\ntest_data &lt;- read_rds(\"data/rds/test_data.rds\")\n\n\n9.1 Multicolinearity Check\nMulticollinearity can affect the stability and interpretability of a regression model. To identify potential multicollinearity, we will use ggcorrmat() of ggstatsplot to plot a correlation matrix to check if there are pairs of highly correlated independent variables.\n\nmdata_nogeo &lt;- mdata %&gt;%\n  st_drop_geometry()\n\nggstatsplot::ggcorrmat(mdata_nogeo[, 2:17]) #columns 2 to 17 to plot Correlation Matrix"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-with-gwr",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-with-gwr",
    "title": "In-Class Exercise 8",
    "section": "\n11 Predictive Modelling with gwr",
    "text": "11 Predictive Modelling with gwr\n\n11.1 Computing Adaptive Bandwidth\nAn adaptive bandwidth is calculated using geographically weighted regression (GWR), which allows for local variations in relationships between variables.\n\n# Compute adaptive bandwidth\nbw_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL +\n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=train_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\nThen, we save this model for future use:\n\n# Save adaptive bandwidth\nwrite_rds(bw_adaptive, \"data/rds/bw_adaptive.rds\")\n\n\nbw_adaptive &lt;- read_rds(\"data/rds/bw_adaptive.rds\")\n\n\n11.2 Model Calibration\nThe GWR model is then calibrated to examine spatially varying relationships:\n\n# Calibrate gwr-based hedonic pricing model\ngwr_adaptive &lt;- gwr.basic(formula = resale_price ~\n                            floor_area_sqm + storey_order +\n                            remaining_lease_mths + PROX_CBD +\n                            PROX_ELDERLYCARE + PROX_HAWKER +\n                            PROX_MRT + PROX_PARK + PROX_MALL +\n                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                            WITHIN_1KM_PRISCH,\n                          data=train_data,\n                          bw = bw_adaptive,\n                          kernel = 'gaussian',\n                          adaptive=TRUE,\n                          longlat = FALSE)\n\nThen, we save this calibrated model for future use:\n\n# Save calibrated model\nwrite_rds(gwr_adaptive, \"data/rds/gwr_adaptive.rds\")\n\n\ngwr_adaptive &lt;- read_rds(\"data/rds/gwr_adaptive.rds\")\n\n\n11.3 Predicting with test data\n\n# Compute test data adaptive bandwidth\ngwr_bw_test_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL +\n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=test_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\nThen, we save the output for future use:\n\nwrite_rds(gwr_bw_test_adaptive,\n          \"data/rds/gwr_bw_test.rds\")\n\n\n# #| eval: False\ngwr_bw_test_adaptive &lt;- read_rds(\n  \"data/rds/gwr_bw_test.rds\")\n\nTo compute the predicted values:\n\n# Compute predicted values\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                        data=train_data, \n                        predictdata = test_data, \n                        bw=bw_adaptive, \n                        kernel = 'gaussian', \n                        adaptive=TRUE, \n                        longlat = FALSE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-rf-method",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-rf-method",
    "title": "In-Class Exercise 8",
    "section": "\n12 Predictive Modelling: RF method",
    "text": "12 Predictive Modelling: RF method\nSince the SpatialML package is based on the ranger package, coordinate data must be prepared before calibration.\n\n12.1 Preparing Coordinate Data\n\n# Get coordinates from full, training and test data\ncoords &lt;- st_coordinates(mdata)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\nwrite_rds(coords_train, \"data/rds/coords_train.rds\" )\nwrite_rds(coords_test, \"data/rds/coords_test.rds\" )\n\n\ncoords_train &lt;- read_rds(\"data/rds/coords_train.rds\")\ncoords_test &lt;- read_rds(\"data/rds/coords_test.rds\")\n\nAdditionally, the geometry field is removed:\n\n# Drop geometry\ntrain_data_nogeom &lt;- train_data %&gt;%\n  st_drop_geometry()\n\n\n12.2 Calibrating Random Forest Model\nTo calibrate a RF model:\n\n# Set seed\nset.seed(1234)\n\n# Calibrate random forest model\nrf &lt;- ranger(resale_price ~ floor_area_sqm + storey_order +\n               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +\n               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +\n               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n               WITHIN_1KM_PRISCH,\n             data=train_data_nogeom)\n\n# Check result\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       731404460 \nR squared (OOB):                  0.9493789 \n\n\n\nwrite_rds(rf, \"data/rds/rf.rds\")\n\n\nrf &lt;- read_rds(\"data/rds/rf.rds\")\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       731404460 \nR squared (OOB):                  0.9493789 \n\n\n\n12.3 Calibrating GRF Model\nTo calibrate a GRF model:\n\n# #| eval: False\n# Set seed\nset.seed(1234)\n\n# Calibrate geographic random forest model\ngwRF_adaptive &lt;- grf(formula = resale_price ~ floor_area_sqm + storey_order +\n                       remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +\n                       PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +\n                       PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                       WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                       WITHIN_1KM_PRISCH,\n                     dframe=train_data_nogeom,\n                     bw=55,\n                     ntree = 100, # default - 500\n                     mtry = 2, # default - p/3 ~ 4\n                     kernel=\"adaptive\",\n                     coords=coords_train)\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom, num.trees = 100, mtry = 2, importance = \"impurity\",      num.threads = NULL) \n\nType:                             Regression \nNumber of trees:                  100 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             2 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       852910439 \nR squared (OOB):                  0.9409694 \n          floor_area_sqm             storey_order     remaining_lease_mths \n            6.824704e+12             1.435742e+13             2.552037e+13 \n                PROX_CBD         PROX_ELDERLYCARE              PROX_HAWKER \n            3.953814e+13             9.342137e+12             7.823712e+12 \n                PROX_MRT                PROX_PARK                PROX_MALL \n            8.977883e+12             6.837247e+12             5.648711e+12 \n        PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN    WITHIN_350M_CHILDCARE \n            4.978032e+12             1.995655e+12             2.710805e+12 \n         WITHIN_350M_BUS        WITHIN_1KM_PRISCH \n            2.674085e+12             9.334929e+12 \n      Min.    1st Qu.     Median       Mean    3rd Qu.       Max. \n-280245.37  -13938.89       9.62     193.26   15164.22  298800.00 \n      Min.    1st Qu.     Median       Mean    3rd Qu.       Max. \n-101882.33   -5505.77     144.69      32.36    6077.11  124333.78 \n                               Min          Max        Mean         StD\nfloor_area_sqm                   0 342935222211 15130214965 30947225673\nstorey_order             215636836 183127037962 13238718931 20201703205\nremaining_lease_mths     499341160 450850229473 23468200057 45872487449\nPROX_CBD                  18349045 387976898577 12714159519 26521447462\nPROX_ELDERLYCARE          15318889 300156818677 11449655559 23214713430\nPROX_HAWKER               23102080 357846940402 11462149546 22914119254\nPROX_MRT                  15735167 280468410292 11127206558 21802562779\nPROX_PARK                  8185645 313013903378 10585959103 19977013805\nPROX_MALL                 23261562 342701497449 11923313029 24424229742\nPROX_SUPERMARKET           5486603 324945655359 11342139747 24323697099\nWITHIN_350M_KINDERGARTEN         0 191962017128  3648095052 12301497250\nWITHIN_350M_CHILDCARE            0 208967876431  6613838351 18044173338\nWITHIN_350M_BUS                  0 168569774257  6196822101 12774759201\nWITHIN_1KM_PRISCH                0 166710098545  2738509148  8263517948\n\n\nThe model can be saved and loaded for future use:\n\n# #| eval: False\n# Save model output\nwrite_rds(gwRF_adaptive, \"data/rds/gwRF_adaptive.rds\")\n\n\n# Load model output\ngwRF_adaptive &lt;- read_rds(\"data/rds/gwRF_adaptive.rds\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe global model is a ranger object which can provide additional insights:\n\n\nLocal Variable Importance: This metric calculates the importance of each variable for every data point, allowing us to see which predictors are more influential in different locations.\n\nLocal Goodness of Fit (LGofFit): For each data point, the model assesses how well the local predictions match the observed values, offering insights into model performance across different areas.\n\nForests: Each local forest contains various metrics, such as sample size, to understand the local behavior and conditions affecting predictions.\n\n\n\n\n12.4 Predict with Test Data\nSince the GRF model requires coordinate data as part of its input, the coordinates from the test data need to be merged with the original dataset after removing the geometry field.\n\ntest_data_nogeom &lt;- cbind(\n  test_data, coords_test) %&gt;%\n  st_drop_geometry()\n\nNext, predict.grf() of spatialML package will be used to predict the resale value by using the test data and gwRF_adaptive model calibrated earlier.\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive,\n                         test_data_nogeom,\n                         x.var.name=\"X\",\n                         y.var.name=\"Y\",\n                         local.w=1,\n                         global.w=0,\n                         nthreads = 4)\n\n\nGRF_pred &lt;- write_rds(gwRF_pred, \"data/rds/GRF_pred.rds\")\n\n\nGRF_pred &lt;- read_rds(\"data/rds/GRF_pred.rds\")\n# create df\nGRF_pred_df &lt;- as.data.frame(GRF_pred)\n\nTo analyze the differences between the predicted and actual values, the predictions are merged back with the test dataset to compare predicted against actual resale prices.\n\n# Combine predicted values with test data\ntest_data_pred &lt;- cbind(test_data, GRF_pred_df)\n\nSave the combined data for future reference:\n\nwrite_rds(test_data_pred, \"data/rds/test_data_pred.rds\")\n\n\ntest_data_pred &lt;- read_rds(\"data/rds/test_data_pred.rds\")\n\nTo calculate Root Mean Square Error (RMSE):\n\nrmse(test_data_pred$resale_price,\n     test_data_pred$GRF_pred)\n\n[1] 28961.7\n\n\nTo visualize the predicted vs actual value with a scatterplot.\n\nggplot(data = test_data_pred,\n       aes(x = GRF_pred,\n           y = resale_price)) +\n  geom_point()\n\n\n\n\n\n\n\nIdeally, points should align along the diagonal line, indicating accurate predictions. Points below it show underestimation, while points above indicate overestimation of price prediction."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "title": "In-Class Exercise 9",
    "section": "",
    "text": "ISSS626 Geospatial Analytics and Applications – In-class Exercise 9: Geography of Accessibility"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#exercise-reference",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#exercise-reference",
    "title": "In-Class Exercise 9",
    "section": "",
    "text": "ISSS626 Geospatial Analytics and Applications – In-class Exercise 9: Geography of Accessibility"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#overview",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#overview",
    "title": "In-Class Exercise 9",
    "section": "\n2 Overview",
    "text": "2 Overview\nIn this exercise, we will import geospatial data, create buffers for accessibility analysis, use spatial joins to assess facility proximity, visualize spatial data on maps, and calculate Hansen’s Accessibility metrics."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#import-the-r-packages",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#import-the-r-packages",
    "title": "In-Class Exercise 9",
    "section": "\n3 Import the R Packages",
    "text": "3 Import the R Packages\nThe following R packages will be used in this exercise:\n\n\n\n\n\n\n\nPackage\nPurpose\nUse Case in Exercise\n\n\n\ntidyverse\nData manipulation and visualization in R.\nData wrangling, cleaning, and visualization.\n\n\nsf\nHandling and visualizing geospatial data.\nImporting and managing geospatial data, creating buffers.\n\n\nSpatialAcc\nMeasuring spatial accessibility metrics.\nComputing Hansen’s Accessibility.\n\n\ntmap\nThematic map visualization.\nCreating maps for spatial data visualization.\n\n\nggstatsplot\nEnhanced statistical data visualization.\nVisualizing accessibility differences across regions.\n\n\n\nTo install and load these packages, use the following code:\n\npacman::p_load(SpatialAcc, sf, tidyverse, tmap, ggstatsplot)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#data-wrangling",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#data-wrangling",
    "title": "In-Class Exercise 9",
    "section": "\n4 Data Wrangling",
    "text": "4 Data Wrangling\nWe will download and use the CHAS Clinics and Eldercare Services data sets from data.gov.sg portal.\nTo read the ELDERCARE shapefile data:\n\neldercare &lt;- st_read(dsn = \"data/raw_data\",\n                     layer = \"ELDERCARE\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `ELDERCARE' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex09/data/raw_data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 133 features and 18 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21\n\n\nTo read the CHAS clinics kml file:\n\nCHAS &lt;- st_read(\"data/raw_data/CHASClinics.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MOH_CHAS_CLINICS' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex09/data/raw_data/CHASClinics.kml' \n  using driver `KML'\nSimple feature collection with 1193 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.5818 ymin: 1.016264 xmax: 103.9903 ymax: 1.456037\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe will also use the datasets from Hands-on Exercise 9\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MP14_SUBZONE_NO_SEA_PL\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MP14_SUBZONE_NO_SEA_PL' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex09/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nhexagons &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"hexagons\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `hexagons' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex09/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3125 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21506.33 xmax: 50010.26 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\n\neldercare &lt;- st_read(dsn = \"data/geospatial\",\n                     layer = \"ELDERCARE\") %&gt;%\n  st_transform(csr = 3414)\n\nReading layer `ELDERCARE' from data source \n  `/Users/walter/code/isss626/isss626-gaa/In-class_Ex/In-class_Ex09/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 120 features and 19 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21 / Singapore TM\n\n\n\nODMatrix &lt;- read_csv(\"data/aspatial/OD_Matrix.csv\", \n                     skip = 0)\n\n\n4.1 Data Cleaning and Updating Attributes\n\n4.1.1 Supply:\nSet to 100 first to calibrate the model.\n\neldercare &lt;- eldercare %&gt;%\n  select(fid, ADDRESSPOS) %&gt;%\n  mutate(capacity = 100)\n\n\n4.1.2 Demand:\n\nhexagons &lt;- hexagons %&gt;%\n  select(fid) %&gt;%\n  mutate(demand = 100)\n\n\n4.1.3 OD Matrix\n\ndistmat &lt;- ODMatrix %&gt;%\n  select(origin_id, destination_id, total_cost) %&gt;%\n  spread(destination_id, total_cost)%&gt;%\n  select(c(-c('origin_id')))\n\nConvert the distance matrix to km units:\n\ndistmat_km &lt;- as.matrix(distmat/1000)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#count-number-of-chas-clinics-within-a-distance-around-each-eldercare-centre",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#count-number-of-chas-clinics-within-a-distance-around-each-eldercare-centre",
    "title": "In-Class Exercise 9",
    "section": "\n5 Count Number of CHAS Clinics within a Distance Around Each Eldercare Centre",
    "text": "5 Count Number of CHAS Clinics within a Distance Around Each Eldercare Centre\nTo count the number of points within a distance, we will do the following steps:\n\ncreate a buffer of 1 km around each eldercare centre\nvisualize the data\ncount points\n\n\n5.1 Create Buffer\nNote the singapore crs is in metres. To create a 1km buffer, dist should be 1000.\n\nbuffer_1km &lt;- st_buffer(eldercare, \n                        dist = 1000)\n\n\n5.2 Visualize Plots\n\ntmap_mode(\"view\")\ntm_shape(buffer_1km) +\n  tm_polygons() +\ntm_shape(CHAS) +\n  tm_dots()\n\n\n\n\n\n\n5.3 Count Points\nTo count number of CHAS Clinics within 1 KM around each Eldercare Centre\n\nbuffer_1km$pts_count &lt;- lengths(\n  st_intersects(buffer_1km, CHAS))\nbuffer_1km$pts_count\n\n  [1] 17 31 26 13 26 28 13 24 11 14 17 32  6 20 21 32 15 19 23 19 11 17 20 22 41\n [26] 17 18 39 24 25 15 16 28 28 14 30 23  6 21 15  9 24 24 25 30  8 32 22 17 28\n [51] 33 16 16 16  8 23 16 12 17 19  8 21 14 20 12 22 11 24 18 17 13 16 13 18 19\n [76] 12 19 23 23 21 15 10 15 23  9 22 26 28 22 16 14 31 25 30  9 14 14 14 10 22\n[101] 34 19 16 11  9 17 24 12 31 28 17 16 26 31 24 32 22 29 18 30"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#computing-hansens-accessibility",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#computing-hansens-accessibility",
    "title": "In-Class Exercise 9",
    "section": "\n6 Computing Hansen’s Accessibility",
    "text": "6 Computing Hansen’s Accessibility\nTo compute Hansen’s Accessibility:\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50,\n                            power = 2, \n                            family = \"Hansen\"))\n\nThen we tidy the output:\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\n\nacc_Hansen &lt;- as_tibble(acc_Hansen)\n\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)\n\n\n6.1 Visualising Hansen’s Accessibility\n\nmapex &lt;- st_bbox(hexagons)\n\ntmap_mode(\"plot\")\ntm_shape(hexagon_Hansen,\n         bbox = mapex) + \n  tm_fill(col = \"accHansen\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: Hansen method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)\n\n\n6.2 Visualize Statistical Graphic\n\nhexagon_Hansen &lt;- st_join(hexagon_Hansen, mpsz, \n                          join = st_intersects)\n\n\nggbetweenstats(\n  data = hexagon_Hansen,\n  x = REGION_N,\n  y = accHansen,\n  type = \"p\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html",
    "title": "In-Class Exercise 10",
    "section": "",
    "text": "https://isss626-ay2024-25aug.netlify.app/in-class_ex/in-class_ex10/in-class_ex10#/title-slide"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#exercise-reference",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#exercise-reference",
    "title": "In-Class Exercise 10",
    "section": "",
    "text": "https://isss626-ay2024-25aug.netlify.app/in-class_ex/in-class_ex10/in-class_ex10#/title-slide"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#learning-outcome",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#learning-outcome",
    "title": "In-Class Exercise 10",
    "section": "\n2 Learning Outcome",
    "text": "2 Learning Outcome\nIn this exercise, we will recap on the use of geocoding and learn how to work with Open Government Data."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#import-the-r-packages",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#import-the-r-packages",
    "title": "In-Class Exercise 10",
    "section": "\n3 Import the R Packages",
    "text": "3 Import the R Packages\n\npacman::p_load(tidyverse, sf, tmap, httr, performance)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#geocoding",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#geocoding",
    "title": "In-Class Exercise 10",
    "section": "\n4 Geocoding",
    "text": "4 Geocoding\nThe HDB resale data can be downloaded from here. The dataset contains resale flat prices based on registration date from Jan 2017 to Sep 2024.\nThe code below reads the raw CSV file containing the resale flat data and filters it to include only records from January 2023 to September 2024.\n\nresale &lt;- read_csv(\"data/raw_data/resale.csv\") %&gt;%\n  filter(month &gt;= \"2023-01\" & month &lt;= \"2024-09\")\n\nThe following code tidies the data by creating new columns: - address: Combines block and street_name to form a complete address. - remaining_lease_yr: Extracts the remaining lease years as an integer. - remaining_lease_mth: Extracts the remaining lease months as an integer.\n\nresale_tidy &lt;- resale %&gt;%\n  mutate(address = paste(block,street_name)) %&gt;%\n  mutate(remaining_lease_yr = as.integer(\n    str_sub(remaining_lease, 0, 2)))%&gt;%\n  mutate(remaining_lease_mth = as.integer(\n    str_sub(remaining_lease, 9, 11)))\n\nNext, we filter the tidy dataset to include only records from September 2024 and take the first 10 addresses as an example.\n\nresale_selected &lt;- resale_tidy %&gt;%\n  filter(month == \"2024-09\")\n\nfirst_10_resale &lt;- head(resale_selected, 10)\n\nThen, we generate a sorted list of unique addresses from the filtered dataset. This will be used to retrieve geographical coordinates.\n\nadd_list &lt;- sort(unique(first_10_resale$address))\nadd_list\n\n[1] \"174 ANG MO KIO AVE 4\"  \"223 ANG MO KIO AVE 1\"  \"225 ANG MO KIO AVE 1\" \n[4] \"308A ANG MO KIO AVE 1\" \"308B ANG MO KIO AVE 1\" \"314 ANG MO KIO AVE 3\" \n[7] \"320 ANG MO KIO AVE 1\"  \"321 ANG MO KIO AVE 1\"  \"331 ANG MO KIO AVE 1\" \n\n\nIn the code below, we will perform geocoding and save the output into 2 data frames, found and not_found.\nfound data frames contains data from successful API calls and not_found contains data with api errors etc. These data require additional care and manual geocoding may be required.\n\nurl &lt;- \"https://onemap.gov.sg/api/common/elastic/search\"\nfound &lt;- data.frame()\nnot_found &lt;- data.frame()\n\nfor (address in add_list){\n  query &lt;- list('searchVal'=address, 'returnGeom'='Y', \n                'getAddrDetails'='Y', 'pageNum'='1')\n  res &lt;- GET(url, query=query)\n  \n  if ((content(res)$found)!=0){\n    tmp_df &lt;- data.frame(content(res))[4:13]\n    tmp_df$address&lt;- address\n    found &lt;- rbind(found, tmp_df)\n\n  } else {\n    not_found &lt;- rbind(not_found, data.frame(address = address))\n  }\n  \n}\n\n\nfound\n\n                         results.SEARCHVAL results.BLK_NO   results.ROAD_NAME\n1                        KEBUN BARU LINK 1            174 ANG MO KIO AVENUE 4\n2 223 ANG MO KIO AVENUE 1 SINGAPORE 560223            223 ANG MO KIO AVENUE 1\n3 225 ANG MO KIO AVENUE 1 SINGAPORE 560225            225 ANG MO KIO AVENUE 1\n4                          TECK GHEE VISTA           308A ANG MO KIO AVENUE 1\n5                          TECK GHEE VISTA           308B ANG MO KIO AVENUE 1\n6                      TECK GHEE EVERGREEN            314 ANG MO KIO AVENUE 3\n7     STAR LEARNERS @ ANG MO KIO PTE. LTD.            320 ANG MO KIO AVENUE 1\n8      NEIGHBOURHOOD POLICE POST TECK GHEE            321 ANG MO KIO AVENUE 1\n9                           MY FIRST SKOOL            331 ANG MO KIO AVENUE 1\n                      results.BUILDING\n1                    KEBUN BARU LINK 1\n2                                  NIL\n3                                  NIL\n4                      TECK GHEE VISTA\n5                      TECK GHEE VISTA\n6                  TECK GHEE EVERGREEN\n7 STAR LEARNERS @ ANG MO KIO PTE. LTD.\n8  NEIGHBOURHOOD POLICE POST TECK GHEE\n9                       MY FIRST SKOOL\n                                                                results.ADDRESS\n1                    174 ANG MO KIO AVENUE 4 KEBUN BARU LINK 1 SINGAPORE 560174\n2                                      223 ANG MO KIO AVENUE 1 SINGAPORE 560223\n3                                      225 ANG MO KIO AVENUE 1 SINGAPORE 560225\n4                     308A ANG MO KIO AVENUE 1 TECK GHEE VISTA SINGAPORE 561308\n5                     308B ANG MO KIO AVENUE 1 TECK GHEE VISTA SINGAPORE 562308\n6                  314 ANG MO KIO AVENUE 3 TECK GHEE EVERGREEN SINGAPORE 560314\n7 320 ANG MO KIO AVENUE 1 STAR LEARNERS @ ANG MO KIO PTE. LTD. SINGAPORE 560320\n8  321 ANG MO KIO AVENUE 1 NEIGHBOURHOOD POLICE POST TECK GHEE SINGAPORE 560321\n9                       331 ANG MO KIO AVENUE 1 MY FIRST SKOOL SINGAPORE 560331\n  results.POSTAL        results.X        results.Y results.LATITUDE\n1         560174 28478.5794445509 39676.8076131288 1.37509746867904\n2         560223 28534.6432265872 38676.1728609148 1.36604808445916\n3         560225  28537.680043661 38825.2326317504 1.36739612776859\n4         561308 29198.1455183588 38613.7381223254 1.36548342757106\n5         562308 29248.5946499519 38589.7120627463  1.3652661423815\n6         560314 29865.9980458226 38695.9702712912 1.36622707120636\n7         560320  29676.907292584 38625.7954039071 1.36559244608528\n8         560321 29712.2350843353 38575.9067748357 1.36514126911853\n9         560331 29941.7457938343 38240.8809963278 1.36211140145298\n  results.LONGITUDE               address\n1   103.83761896123  174 ANG MO KIO AVE 4\n2  103.838122716883  223 ANG MO KIO AVE 1\n3  103.838150007464  225 ANG MO KIO AVE 1\n4  103.844084739929 308A ANG MO KIO AVE 1\n5  103.844538059044 308B ANG MO KIO AVE 1\n6  103.850085858983  314 ANG MO KIO AVE 3\n7  103.848386744168  320 ANG MO KIO AVE 1\n8    103.8487041858  321 ANG MO KIO AVE 1\n9   103.85076647513  331 ANG MO KIO AVE 1\n\n\n\nnot_found\n\ndata frame with 0 columns and 0 rows\n\n\nIn this example, we get all successful calls and 0 failures when performing geocoding.\nNext, we tidy the field names.\n\ncolnames(found)\n\n [1] \"results.SEARCHVAL\" \"results.BLK_NO\"    \"results.ROAD_NAME\"\n [4] \"results.BUILDING\"  \"results.ADDRESS\"   \"results.POSTAL\"   \n [7] \"results.X\"         \"results.Y\"         \"results.LATITUDE\" \n[10] \"results.LONGITUDE\" \"address\"          \n\n\n\nfound_filtered &lt;- found %&gt;%\n  select(results.BLK_NO, results.ROAD_NAME, results.POSTAL, results.X, results.Y, address) %&gt;%\n  rename(\n    POSTAL = results.POSTAL,\n    XCOORD = results.X,\n    YCOORD = results.Y,\n    BLK_NO = results.BLK_NO,\n    ROAD_NAME = results.ROAD_NAME\n  )\nfound_filtered \n\n  BLK_NO           ROAD_NAME POSTAL           XCOORD           YCOORD\n1    174 ANG MO KIO AVENUE 4 560174 28478.5794445509 39676.8076131288\n2    223 ANG MO KIO AVENUE 1 560223 28534.6432265872 38676.1728609148\n3    225 ANG MO KIO AVENUE 1 560225  28537.680043661 38825.2326317504\n4   308A ANG MO KIO AVENUE 1 561308 29198.1455183588 38613.7381223254\n5   308B ANG MO KIO AVENUE 1 562308 29248.5946499519 38589.7120627463\n6    314 ANG MO KIO AVENUE 3 560314 29865.9980458226 38695.9702712912\n7    320 ANG MO KIO AVENUE 1 560320  29676.907292584 38625.7954039071\n8    321 ANG MO KIO AVENUE 1 560321 29712.2350843353 38575.9067748357\n9    331 ANG MO KIO AVENUE 1 560331 29941.7457938343 38240.8809963278\n                address\n1  174 ANG MO KIO AVE 4\n2  223 ANG MO KIO AVE 1\n3  225 ANG MO KIO AVE 1\n4 308A ANG MO KIO AVE 1\n5 308B ANG MO KIO AVE 1\n6  314 ANG MO KIO AVE 3\n7  320 ANG MO KIO AVE 1\n8  321 ANG MO KIO AVE 1\n9  331 ANG MO KIO AVE 1\n\n\nNext, we join resale with found to form resale_geocoded. Then we convert this tibble dataframe to sf point feature data frame.\n\n# we need to add an address column for joining\nfirst_10_resale &lt;- first_10_resale %&gt;%\n  mutate(address = paste(block, street_name))\n\n\nresale_geocoded = left_join(\n  first_10_resale, found_filtered, \n  by = c('address' = 'address'))\n\nresale_geocoded\n\n# A tibble: 10 × 19\n   month   town       flat_type block street_name    storey_range floor_area_sqm\n   &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;                 &lt;dbl&gt;\n 1 2024-09 ANG MO KIO 2 ROOM    314   ANG MO KIO AV… 01 TO 03                 44\n 2 2024-09 ANG MO KIO 2 ROOM    174   ANG MO KIO AV… 10 TO 12                 45\n 3 2024-09 ANG MO KIO 2 ROOM    174   ANG MO KIO AV… 04 TO 06                 45\n 4 2024-09 ANG MO KIO 3 ROOM    223   ANG MO KIO AV… 10 TO 12                 82\n 5 2024-09 ANG MO KIO 3 ROOM    320   ANG MO KIO AV… 04 TO 06                 73\n 6 2024-09 ANG MO KIO 3 ROOM    331   ANG MO KIO AV… 01 TO 03                 68\n 7 2024-09 ANG MO KIO 3 ROOM    308A  ANG MO KIO AV… 16 TO 18                 70\n 8 2024-09 ANG MO KIO 3 ROOM    321   ANG MO KIO AV… 07 TO 09                 88\n 9 2024-09 ANG MO KIO 3 ROOM    308B  ANG MO KIO AV… 22 TO 24                 70\n10 2024-09 ANG MO KIO 3 ROOM    225   ANG MO KIO AV… 01 TO 03                 67\n# ℹ 12 more variables: flat_model &lt;chr&gt;, lease_commence_date &lt;dbl&gt;,\n#   remaining_lease &lt;chr&gt;, resale_price &lt;dbl&gt;, address &lt;chr&gt;,\n#   remaining_lease_yr &lt;int&gt;, remaining_lease_mth &lt;int&gt;, BLK_NO &lt;chr&gt;,\n#   ROAD_NAME &lt;chr&gt;, POSTAL &lt;chr&gt;, XCOORD &lt;chr&gt;, YCOORD &lt;chr&gt;\n\n\nTo convert to sf:\n\nresale_geocoded_sf &lt;- st_as_sf(resale_geocoded, \n                            coords = c(\"XCOORD\",\n                                       \"YCOORD\"),\n                            crs=3414)\n\nNext we check for overlapping point features.\n\noverlapping_points &lt;- resale_geocoded_sf %&gt;%\n  mutate(overlap = lengths(st_equals(., .)) &gt; 1)\n\nIn the code below, st_jitter() of sf package is used to move the point features by 5m to avoid overlapping point features.\n\nresale_geocoded_sf &lt;- resale_geocoded_sf %&gt;%\n  st_jitter(amount = 5)\n\nresale_geocoded_sf\n\nSimple feature collection with 10 features and 17 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 28475.2 ymin: 38239.86 xmax: 29945.86 ymax: 39681.17\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 10 × 18\n   month   town       flat_type block street_name    storey_range floor_area_sqm\n * &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;                 &lt;dbl&gt;\n 1 2024-09 ANG MO KIO 2 ROOM    314   ANG MO KIO AV… 01 TO 03                 44\n 2 2024-09 ANG MO KIO 2 ROOM    174   ANG MO KIO AV… 10 TO 12                 45\n 3 2024-09 ANG MO KIO 2 ROOM    174   ANG MO KIO AV… 04 TO 06                 45\n 4 2024-09 ANG MO KIO 3 ROOM    223   ANG MO KIO AV… 10 TO 12                 82\n 5 2024-09 ANG MO KIO 3 ROOM    320   ANG MO KIO AV… 04 TO 06                 73\n 6 2024-09 ANG MO KIO 3 ROOM    331   ANG MO KIO AV… 01 TO 03                 68\n 7 2024-09 ANG MO KIO 3 ROOM    308A  ANG MO KIO AV… 16 TO 18                 70\n 8 2024-09 ANG MO KIO 3 ROOM    321   ANG MO KIO AV… 07 TO 09                 88\n 9 2024-09 ANG MO KIO 3 ROOM    308B  ANG MO KIO AV… 22 TO 24                 70\n10 2024-09 ANG MO KIO 3 ROOM    225   ANG MO KIO AV… 01 TO 03                 67\n# ℹ 11 more variables: flat_model &lt;chr&gt;, lease_commence_date &lt;dbl&gt;,\n#   remaining_lease &lt;chr&gt;, resale_price &lt;dbl&gt;, address &lt;chr&gt;,\n#   remaining_lease_yr &lt;int&gt;, remaining_lease_mth &lt;int&gt;, BLK_NO &lt;chr&gt;,\n#   ROAD_NAME &lt;chr&gt;, POSTAL &lt;chr&gt;, geometry &lt;POINT [m]&gt;"
  }
]